{"embeddings": [[11.338332176208496, 10.982555389404297], [9.161252975463867, 9.609678268432617], [8.988525390625, 10.680891036987305], [10.969489097595215, 8.18349838256836], [10.931853294372559, 11.55734920501709], [8.017501831054688, 7.387673377990723], [11.406792640686035, 9.57496166229248], [12.472043991088867, 9.975025177001953], [10.811735153198242, 9.981705665588379], [10.70896053314209, 10.584769248962402], [9.10544204711914, 8.954940795898438], [8.059554100036621, 10.899638175964355], [10.168313026428223, 10.169196128845215], [9.118852615356445, 8.80565357208252], [8.286665916442871, 10.123854637145996], [12.138282775878906, 8.601763725280762], [12.028122901916504, 11.274117469787598], [12.709716796875, 9.574345588684082], [11.411815643310547, 9.187952041625977], [11.28772258758545, 9.257529258728027], [8.365163803100586, 7.639739036560059], [8.605772018432617, 8.16334342956543], [12.283719062805176, 8.880191802978516], [8.27393627166748, 11.41672420501709], [8.634696960449219, 10.297004699707031], [10.735450744628906, 10.953168869018555], [9.519739151000977, 9.592101097106934], [8.354543685913086, 10.059462547302246], [8.173667907714844, 9.820448875427246], [9.842689514160156, 11.71480655670166], [11.699307441711426, 8.996749877929688], [8.208460807800293, 11.598210334777832], [12.858932495117188, 8.915870666503906], [12.214493751525879, 9.307588577270508], [8.597291946411133, 11.680329322814941], [11.60139274597168, 10.256805419921875], [8.649923324584961, 10.35284423828125], [8.687225341796875, 10.388181686401367], [12.347288131713867, 9.639983177185059], [9.874029159545898, 10.424644470214844], [11.521742820739746, 11.506426811218262], [7.952844619750977, 7.420429706573486], [10.424477577209473, 8.334609985351562], [10.824373245239258, 11.356645584106445], [9.125832557678223, 9.44546127319336], [11.345885276794434, 10.830280303955078], [7.021023273468018, 9.622810363769531], [8.608283042907715, 10.018536567687988], [9.041117668151855, 9.494762420654297], [9.010601997375488, 10.550240516662598], [10.04898452758789, 10.657930374145508], [13.075270652770996, 8.794761657714844], [9.447362899780273, 8.449724197387695], [12.416054725646973, 8.676040649414062], [8.564210891723633, 11.770328521728516], [11.592211723327637, 9.47569751739502], [10.004319190979004, 9.006694793701172], [11.655113220214844, 8.149800300598145], [8.450628280639648, 12.04057788848877], [9.899223327636719, 9.590498924255371], [9.496112823486328, 11.785134315490723], [9.837910652160645, 9.706923484802246], [8.509478569030762, 11.14624309539795], [12.603703498840332, 9.8715238571167], [7.948060512542725, 7.956515789031982], [11.849881172180176, 8.36540412902832], [12.7913179397583, 9.80830192565918], [10.476381301879883, 12.501818656921387], [8.088887214660645, 8.00810432434082], [9.039266586303711, 8.628495216369629], [10.985000610351562, 10.576910018920898], [12.044245719909668, 11.091136932373047], [11.420378684997559, 11.174381256103516], [10.680553436279297, 12.478578567504883], [10.79520034790039, 9.647809028625488], [9.359220504760742, 10.434589385986328], [12.213630676269531, 10.75142765045166], [7.897649765014648, 7.584345817565918], [9.479393005371094, 8.4092435836792], [11.056870460510254, 12.426326751708984], [8.469724655151367, 7.811777591705322], [9.841153144836426, 9.7733154296875], [7.9761762619018555, 11.319635391235352], [11.131460189819336, 11.949311256408691], [11.21831226348877, 8.345266342163086], [11.284868240356445, 9.569533348083496], [10.62488842010498, 11.913824081420898], [11.292186737060547, 12.662482261657715], [10.277181625366211, 12.129424095153809], [11.925899505615234, 8.91611385345459], [8.08691692352295, 11.043224334716797], [11.250265121459961, 12.635294914245605], [8.213579177856445, 11.785990715026855], [11.806130409240723, 9.838607788085938], [9.614082336425781, 12.105290412902832], [11.940317153930664, 9.961825370788574], [8.606648445129395, 9.054509162902832], [8.674948692321777, 11.291229248046875], [11.913972854614258, 11.20811939239502], [12.325087547302246, 9.564801216125488], [12.869757652282715, 9.201684951782227], [9.546473503112793, 10.048641204833984], [11.205145835876465, 11.602619171142578], [11.152908325195312, 12.013357162475586], [7.395949840545654, 10.17969799041748], [12.85903549194336, 8.878024101257324], [9.026634216308594, 8.726539611816406], [9.887603759765625, 8.904170989990234], [8.396588325500488, 7.929800033569336], [12.819446563720703, 8.871585845947266], [11.916064262390137, 9.12794017791748], [8.61815357208252, 12.090561866760254], [8.225162506103516, 11.585418701171875], [7.246789455413818, 9.799788475036621], [8.194729804992676, 7.774040699005127], [11.857234954833984, 10.881780624389648], [11.592802047729492, 11.732358932495117], [7.872014999389648, 11.061089515686035], [11.745083808898926, 9.287498474121094], [11.194135665893555, 10.783895492553711], [11.966889381408691, 10.036328315734863], [11.884062767028809, 11.529269218444824], [12.023316383361816, 9.548599243164062], [11.004620552062988, 12.594565391540527], [12.783462524414062, 9.819226264953613], [8.354302406311035, 7.892594814300537], [10.123781204223633, 10.201742172241211], [9.999831199645996, 9.5379638671875], [11.196660041809082, 11.793928146362305], [7.26434850692749, 9.847115516662598], [11.57345962524414, 10.15830135345459], [9.502851486206055, 9.29992961883545], [7.848850727081299, 11.097001075744629], [9.135612487792969, 8.615592002868652], [10.73206901550293, 9.547212600708008], [12.223359107971191, 8.541098594665527], [8.679716110229492, 11.068541526794434], [10.849355697631836, 12.80042839050293], [7.800878047943115, 11.01479721069336], [10.624848365783691, 10.291566848754883], [12.092007637023926, 8.880338668823242], [11.734403610229492, 11.866585731506348], [7.946647644042969, 11.345417976379395], [12.652525901794434, 8.725531578063965], [10.417680740356445, 9.516508102416992], [8.585404396057129, 9.661603927612305], [12.06670093536377, 9.265616416931152], [12.905755996704102, 8.546317100524902], [10.89007568359375, 10.672935485839844], [8.01008129119873, 7.654785633087158], [10.420395851135254, 9.724215507507324], [10.84078598022461, 12.465841293334961], [10.54465103149414, 9.44339370727539], [9.329475402832031, 9.677530288696289], [11.919137954711914, 11.539353370666504], [9.437650680541992, 9.991068840026855], [12.923026084899902, 8.942846298217773], [11.659252166748047, 11.8757963180542], [8.114466667175293, 7.426952838897705], [10.302572250366211, 11.303396224975586], [9.709799766540527, 9.190661430358887], [10.047307014465332, 10.691588401794434], [9.999713897705078, 9.959699630737305], [12.712896347045898, 9.169300079345703], [10.418603897094727, 10.488693237304688], [10.071332931518555, 8.810169219970703], [8.02963924407959, 11.707119941711426], [7.139065742492676, 9.717935562133789], [9.23863410949707, 8.403919219970703], [10.661999702453613, 10.60534954071045], [8.622391700744629, 11.2847900390625], [8.880424499511719, 9.419920921325684], [8.810776710510254, 9.982817649841309], [8.933385848999023, 9.790090560913086], [11.421849250793457, 8.115379333496094], [11.296215057373047, 8.207706451416016], [9.356999397277832, 8.82120132446289], [9.791834831237793, 10.511260032653809], [7.1248345375061035, 9.735686302185059], [8.335835456848145, 11.387558937072754], [10.702778816223145, 11.18606185913086], [7.983373641967773, 7.622164249420166], [12.050642013549805, 9.690696716308594], [9.94955062866211, 9.41372299194336], [13.004463195800781, 9.069071769714355], [8.368400573730469, 11.645599365234375], [8.197409629821777, 7.843410491943359], [11.182836532592773, 11.925317764282227], [11.019865989685059, 11.758081436157227], [12.639486312866211, 8.83207893371582], [12.60432243347168, 8.48936653137207], [10.480056762695312, 10.433235168457031], [9.417145729064941, 10.313285827636719], [8.130587577819824, 11.438514709472656], [9.358150482177734, 11.613997459411621], [10.23180866241455, 10.599918365478516], [8.443136215209961, 9.855608940124512], [10.169380187988281, 12.10507869720459], [8.42003059387207, 9.921646118164062], [8.502711296081543, 9.832470893859863], [10.269472122192383, 9.455390930175781], [9.122398376464844, 10.764571189880371], [7.708677291870117, 10.752347946166992], [10.238449096679688, 10.647283554077148], [11.890057563781738, 8.205103874206543], [12.407177925109863, 9.05008316040039], [12.2158784866333, 8.66028118133545], [12.065898895263672, 9.13500690460205], [10.038627624511719, 10.273001670837402], [11.074305534362793, 12.855388641357422], [10.709466934204102, 11.809181213378906], [9.490474700927734, 10.168282508850098], [10.70969295501709, 9.514973640441895], [10.092086791992188, 11.14535903930664], [8.128352165222168, 7.903029918670654], [11.228046417236328, 10.894829750061035], [10.970791816711426, 9.81717586517334], [11.052787780761719, 11.897330284118652], [11.576603889465332, 8.06122875213623], [9.207600593566895, 10.497220039367676], [8.665933609008789, 10.659143447875977], [10.805440902709961, 12.880263328552246], [8.902905464172363, 10.435925483703613], [12.369953155517578, 9.739264488220215], [10.161116600036621, 12.091464042663574], [7.228675365447998, 9.719544410705566], [10.996723175048828, 8.621179580688477], [10.57687759399414, 10.093429565429688], [10.133319854736328, 11.446816444396973], [12.849154472351074, 9.987056732177734], [11.016096115112305, 10.527945518493652], [12.5081148147583, 9.09998607635498], [11.247795104980469, 10.000091552734375], [8.06919002532959, 7.341828346252441], [7.229028701782227, 9.736552238464355], [7.2938008308410645, 9.970629692077637], [7.043335437774658, 9.663996696472168], [8.326272964477539, 7.898728847503662], [8.614896774291992, 11.972432136535645], [9.521915435791016, 8.553413391113281], [7.2974748611450195, 9.602903366088867], [11.52450180053711, 10.652523040771484], [11.059263229370117, 12.030379295349121], [8.055084228515625, 10.821837425231934], [10.049019813537598, 9.990535736083984], [7.8489990234375, 9.804665565490723], [9.272072792053223, 11.075193405151367], [8.04012393951416, 7.38232946395874], [11.239336967468262, 11.600732803344727], [10.466315269470215, 11.173137664794922], [10.90591812133789, 10.088383674621582], [12.671685218811035, 8.594243049621582], [7.541134834289551, 10.574325561523438], [7.961001396179199, 11.256296157836914], [10.599875450134277, 11.751113891601562], [7.7891645431518555, 10.76194953918457], [11.21251392364502, 12.700586318969727], [9.539937019348145, 11.937662124633789], [9.880440711975098, 11.990800857543945], [12.929337501525879, 8.889145851135254], [8.640381813049316, 11.172149658203125], [12.381871223449707, 8.38585376739502], [9.847892761230469, 11.001774787902832], [10.988462448120117, 12.45272159576416], [13.03213119506836, 9.367947578430176], [12.590874671936035, 8.949012756347656], [8.039032936096191, 7.541177272796631], [9.975190162658691, 9.363225936889648], [7.707160949707031, 10.9409818649292], [9.208219528198242, 11.518937110900879], [10.50454330444336, 9.860816955566406], [11.077088356018066, 12.959152221679688], [7.114724159240723, 9.779346466064453], [11.090311050415039, 11.336043357849121], [7.821141719818115, 10.276647567749023], [12.248291969299316, 10.697041511535645], [8.035335540771484, 11.552031517028809], [9.471985816955566, 12.041141510009766], [9.02192211151123, 10.931693077087402], [7.973865032196045, 7.364350318908691], [11.643131256103516, 11.682571411132812], [12.259134292602539, 10.078028678894043], [10.316909790039062, 11.356269836425781], [12.143037796020508, 9.64162826538086], [8.927240371704102, 8.29784870147705], [8.32340145111084, 9.143149375915527], [12.013505935668945, 11.69417667388916], [11.030949592590332, 12.945229530334473], [11.990718841552734, 8.13471794128418], [10.215764999389648, 10.9093656539917], [8.065226554870605, 7.953787326812744], [12.784642219543457, 8.511077880859375], [8.35440444946289, 7.738571643829346], [11.596558570861816, 9.104681015014648], [12.015791893005371, 8.988999366760254], [12.938386917114258, 9.600924491882324], [7.8114752769470215, 9.704117774963379], [8.291306495666504, 11.98171615600586], [8.657968521118164, 11.975397109985352], [12.572218894958496, 9.33427906036377], [11.88310718536377, 11.268930435180664], [12.478997230529785, 9.420186996459961], [8.200557708740234, 11.851966857910156], [11.17247486114502, 12.819915771484375], [10.839945793151855, 12.745003700256348], [11.005956649780273, 12.902606964111328]], "keys": ["2401.1222", "2401.12221", "2401.12223", "2401.12224", "2401.12225", "2401.12226", "2401.12228", "2401.1223", "2401.12231", "2401.12233", "2401.12234", "2401.12235", "2401.12236", "2401.1224", "2401.12241", "2401.12242", "2401.12244", "2401.12246", "2401.12247", "2401.12249", "2401.12251", "2401.12254", "2401.12255", "2401.12258", "2401.12259", "2401.12261", "2401.12262", "2401.12263", "2401.12265", "2401.12266", "2401.12273", "2401.12275", "2401.12292", "2401.12295", "2401.12317", "2401.12321", "2401.12322", "2401.12324", "2401.12326", "2401.12332", "2401.1234", "2401.12342", "2401.12343", "2401.12344", "2401.12346", "2401.1235", "2401.12351", "2401.12356", "2401.12358", "2401.12364", "2401.12369", "2401.12375", "2401.12377", "2401.12379", "2401.1238", "2401.12382", "2401.12383", "2401.12385", "2401.12389", "2401.12391", "2401.12392", "2401.12393", "2401.12405", "2401.12406", "2401.12407", "2401.12412", "2401.12413", "2401.12414", "2401.12415", "2401.12416", "2401.12418", "2401.12419", "2401.12421", "2401.12422", "2401.12423", "2401.12424", "2401.12425", "2401.12427", "2401.12428", "2401.12433", "2401.12435", "2401.12436", "2401.12437", "2401.12439", "2401.12443", "2401.12445", "2401.12447", "2401.12451", "2401.12452", "2401.12453", "2401.12455", "2401.12456", "2401.12459", "2401.12461", "2401.12464", "2401.12467", "2401.12468", "2401.1247", "2401.12471", "2401.12472", "2401.12474", "2401.12478", "2401.12479", "2401.1248", "2401.12481", "2401.12483", "2401.12485", "2401.12486", "2401.12489", "2401.12491", "2401.12492", "2401.12496", "2401.12497", "2401.12499", "2401.12501", "2401.12503", "2401.12507", "2401.12508", "2401.12509", "2401.12511", "2401.12513", "2401.12517", "2401.1252", "2401.12521", "2401.12522", "2401.12526", "2401.12532", "2401.12533", "2401.12535", "2401.12538", "2401.1254", "2401.12542", "2401.12546", "2401.1255", "2401.12553", "2401.12554", "2401.12557", "2401.12561", "2401.12562", "2401.12564", "2401.12566", "2401.12568", "2401.12574", "2401.12576", "2401.12578", "2401.12582", "2401.12585", "2401.12586", "2401.12588", "2401.12589", "2401.1259", "2401.12592", "2401.12593", "2401.12594", "2401.12596", "2401.12597", "2401.12599", "2401.126", "2401.12602", "2401.12603", "2401.12604", "2401.12609", "2401.1261", "2401.12611", "2401.12617", "2401.12618", "2401.12624", "2401.12627", "2401.1263", "2401.12631", "2401.12632", "2401.12633", "2401.12634", "2401.12636", "2401.12638", "2401.12639", "2401.12643", "2401.12644", "2401.12645", "2401.12646", "2401.12648", "2401.12649", "2401.12652", "2401.12653", "2401.12656", "2401.12662", "2401.12664", "2401.12665", "2401.12666", "2401.12671", "2401.12672", "2401.12681", "2401.12683", "2401.12686", "2401.12687", "2401.12689", "2401.1269", "2401.12694", "2401.12698", "2401.12699", "2401.127", "2401.12703", "2401.12707", "2401.12708", "2401.12711", "2401.12713", "2401.12714", "2401.1272", "2401.12722", "2401.12724", "2401.12729", "2401.12731", "2401.12732", "2401.12733", "2401.12734", "2401.12736", "2401.12739", "2401.12743", "2401.12744", "2401.12745", "2401.12747", "2401.12751", "2401.12755", "2401.12756", "2401.12761", "2401.12763", "2401.12768", "2401.1278", "2401.12783", "2401.12789", "2401.1279", "2401.12794", "2401.12798", "2401.12799", "2401.128", "2401.12801", "2401.12803", "2401.12806", "2401.12808", "2401.12815", "2401.12818", "2401.12819", "2401.1282", "2401.12822", "2401.12824", "2401.12826", "2401.1283", "2401.12832", "2401.12835", "2401.12842", "2401.12843", "2401.12846", "2401.12848", "2401.12849", "2401.12851", "2401.12852", "2401.12853", "2401.12857", "2401.12862", "2401.12863", "2401.12866", "2401.12869", "2401.1287", "2401.12872", "2401.12873", "2401.12874", "2401.1288", "2401.12881", "2401.12882", "2401.12888", "2401.12895", "2401.129", "2401.12901", "2401.12902", "2401.12914", "2401.12915", "2401.12917", "2401.12919", "2401.1292", "2401.12921", "2401.12925", "2401.12926", "2401.1293", "2401.12941", "2401.12942", "2401.12943", "2401.12945", "2401.12946", "2401.12947", "2401.1295", "2401.12952", "2401.12954", "2401.12955", "2401.12956", "2401.12959", "2401.12961", "2401.12962", "2401.12963", "2401.12965", "2401.1297", "2401.12972", "2401.12973", "2401.12975", "2401.12977", "2401.12978", "2401.12979"], "additional_info": [{"arxiv_id": "2401.1222", "title": "Automatic Recognition of Learning Resource Category in a Digital Library", "abstract": "Digital libraries often face the challenge of processing a large volume of\ndiverse document types. The manual collection and tagging of metadata can be a\ntime-consuming and error-prone task. To address this, we aim to develop an\nautomatic metadata extractor for digital libraries. In this work, we introduce\nthe Heterogeneous Learning Resources (HLR) dataset designed for document image\nclassification. The approach involves decomposing individual learning resources\ninto constituent document images (sheets). These images are then processed\nthrough an OCR tool to extract textual representation. State-of-the-art\nclassifiers are employed to classify both the document image and its textual\ncontent. Subsequently, the labels of the constituent document images are\nutilized to predict the label of the overall document.", "field": "Computer Science", "categories": "cs.DL,cs.CV"}, {"arxiv_id": "2401.12221", "title": "Impact of Information Technology in Cyberwars", "abstract": "Different types of warfare have evolved between nations and states in the\nmodern era, each with its technological breakthroughs and use of cutting-edge\ntechnologies. With the help of the latest innovations, technologies and ideas\nemerging and contributing more to the It sector, making it more advanced and\nresulting in different technologies used for cyber warfare, information\ntechnology has a stronghold, power, and control over many other integrated\nautomated technologies. To identify the various technologies that are primarily\nused in cyber warfare. This exploratory study used a systematic review\ntechnique and a theme analysis approach to examine prior works in information\ntechnology relevant to cyber warfare.", "field": "Computer Science", "categories": "cs.CR,cs.NI"}, {"arxiv_id": "2401.12223", "title": "The Global Impact of AI-Artificial Intelligence: Recent Advances and\n  Future Directions, A Review", "abstract": "Artificial intelligence (AI) is an emerging technology that has the potential\nto transform many aspects of society, including the economy, healthcare, and\ntransportation. This article synthesizes recent research literature on the\nglobal impact of AI, exploring its potential benefits and risks. The article\nhighlights the implications of AI, including its impact on economic, ethical,\nsocial, security & privacy, and job displacement aspects. It discusses the\nethical concerns surrounding AI development, including issues of bias,\nsecurity, and privacy violations. To ensure the responsible development and\ndeployment of AI, collaboration between government, industry, and academia is\nessential. The article concludes by emphasizing the importance of public\nengagement and education to promote awareness and understanding of AI's impact\non society at large.", "field": "Computer Science", "categories": "cs.CR,cs.AI"}, {"arxiv_id": "2401.12224", "title": "LLM4EDA: Emerging Progress in Large Language Models for Electronic\n  Design Automation", "abstract": "Driven by Moore's Law, the complexity and scale of modern chip design are\nincreasing rapidly. Electronic Design Automation (EDA) has been widely applied\nto address the challenges encountered in the full chip design process. However,\nthe evolution of very large-scale integrated circuits has made chip design\ntime-consuming and resource-intensive, requiring substantial prior expert\nknowledge. Additionally, intermediate human control activities are crucial for\nseeking optimal solutions. In system design stage, circuits are usually\nrepresented with Hardware Description Language (HDL) as a textual format.\nRecently, Large Language Models (LLMs) have demonstrated their capability in\ncontext understanding, logic reasoning and answer generation. Since circuit can\nbe represented with HDL in a textual format, it is reasonable to question\nwhether LLMs can be leveraged in the EDA field to achieve fully automated chip\ndesign and generate circuits with improved power, performance, and area (PPA).\nIn this paper, we present a systematic study on the application of LLMs in the\nEDA field, categorizing it into the following cases: 1) assistant chatbot, 2)\nHDL and script generation, and 3) HDL verification and analysis. Additionally,\nwe highlight the future research direction, focusing on applying LLMs in logic\nsynthesis, physical design, multi-modal feature extraction and alignment of\ncircuits. We collect relevant papers up-to-date in this field via the following\nlink: https://github.com/Thinklab-SJTU/Awesome-LLM4EDA.", "field": "Computer Science", "categories": "cs.AR,cs.AI"}, {"arxiv_id": "2401.12225", "title": "Multimodal Data Curation via Object Detection and Filter Ensembles", "abstract": "We propose an approach for curating multimodal data that we used for our\nentry in the 2023 DataComp competition filtering track. Our technique combines\nobject detection and weak supervision-based ensembling. In the first of two\nsteps in our approach, we employ an out-of-the-box zero-shot object detection\nmodel to extract granular information and produce a variety of filter designs.\nIn the second step, we employ weak supervision to ensemble filtering rules.\nThis approach results in a 4% performance improvement when compared to the\nbest-performing baseline, producing the top-ranking position in the small scale\ntrack at the time of writing. Furthermore, in the medium scale track, we\nachieve a noteworthy 4.2% improvement over the baseline by simply ensembling\nexisting baselines with weak supervision.", "field": "Computer Science", "categories": "cs.CV,cs.LG"}, {"arxiv_id": "2401.12226", "title": "High order multiscale methods for advection-diffusion equation with\n  highly oscillatory boundary condition", "abstract": "In this paper we propose high order numerical methods to solve a 2D\nadvection-diffusion equation, in the highly oscillatory regime. We use an\nintegrator strategy that allows the construction of arbitrary high-order\nschemes which leads to an accurate approximation of the solution without any\ntime step-size restriction. This paper focuses on the time multiscale challenge\nof the problem, that comes from the velocity, an epsilon-periodic function,\nwhose expression is explicitly known. epsilon-uniform third order in time\nnumerical approximations are obtained. For the space discretization, this\nstrategy is combined with high order finite difference schemes. Numerical\nexperiments show that the proposed methods achieve the expected order of\naccuracy.", "field": "Computer Science", "categories": "math.NA,cs.NA,35K15, 35K20, 35M10, 65N06,G.1.8"}, {"arxiv_id": "2401.12228", "title": "Topics evolution through multilayer networks; Analysing 2M tweets from\n  2022 Qatar FIFA World Cup", "abstract": "In this study, we conducted a comprehensive data collection on the 2022 Qatar\nFIFA World Cup event and used a multilayer network approach to visualize the\nmain topics, while considering their context and meaning relationships. We\nstructured the data into layers that corresponded with the stages of the\ntournament and utilized Gephi software to generate the multilayer networks. Our\nvisualizations displayed both the relationships between topics and words,\nshowing the word-context relationship, as well as the dynamics and changes over\ntime by layer of the most frequently discussed topics.", "field": "Computer Science", "categories": "cs.SI,cs.CY,cs.IR"}, {"arxiv_id": "2401.1223", "title": "Computing in the Era of Large Generative Models: From Cloud-Native to\n  AI-Native", "abstract": "In this paper, we investigate the intersection of large generative AI models\nand cloud-native computing architectures. Recent large models such as ChatGPT,\nwhile revolutionary in their capabilities, face challenges like escalating\ncosts and demand for high-end GPUs. Drawing analogies between\nlarge-model-as-a-service (LMaaS) and cloud database-as-a-service (DBaaS), we\ndescribe an AI-native computing paradigm that harnesses the power of both\ncloud-native technologies (e.g., multi-tenancy and serverless computing) and\nadvanced machine learning runtime (e.g., batched LoRA inference). These joint\nefforts aim to optimize costs-of-goods-sold (COGS) and improve resource\naccessibility. The journey of merging these two domains is just at the\nbeginning and we hope to stimulate future research and development in this\narea.", "field": "Computer Science", "categories": "cs.DC,cs.LG"}, {"arxiv_id": "2401.12231", "title": "Disentangled Condensation for Large-scale Graphs", "abstract": "Graph condensation has emerged as an intriguing technique to provide Graph\nNeural Networks for large-scale graphs with a more compact yet informative\nsmall graph to save the expensive costs of large-scale graph learning. Despite\nthe promising results achieved, previous graph condensation methods often\nemploy an entangled condensation strategy that involves condensing nodes and\nedges simultaneously, leading to substantial GPU memory demands. This entangled\nstrategy has considerably impeded the scalability of graph condensation,\nimpairing its capability to condense extremely large-scale graphs and produce\ncondensed graphs with high fidelity. Therefore, this paper presents\nDisentangled Condensation for large-scale graphs, abbreviated as DisCo, to\nprovide scalable graph condensation for graphs of varying sizes. At the heart\nof DisCo are two complementary components, namely node and edge condensation\nmodules, that realize the condensation of nodes and edges in a disentangled\nmanner. In the node condensation module, we focus on synthesizing condensed\nnodes that exhibit a similar node feature distribution to original nodes using\na pre-trained node classification model while incorporating class centroid\nalignment and anchor attachment regularizers. After node condensation, in the\nedge condensation module, we preserve the topology structure by transferring\nthe link prediction model of the original graph to the condensed nodes,\ngenerating the corresponding condensed edges. Based on the disentangled\nstrategy, the proposed DisCo can successfully scale up to the ogbn-papers100M\ngraph with over 100 million nodes and 1 billion edges with flexible reduction\nrates. Extensive experiments on five common datasets further demonstrate that\nthe proposed DisCo yields results superior to state-of-the-art counterparts by\na significant margin. The source code is available at\nhttps://github.com/BangHonor/DisCo.", "field": "Computer Science", "categories": "cs.SI,cs.LG"}, {"arxiv_id": "2401.12233", "title": "Memorization in Self-Supervised Learning Improves Downstream\n  Generalization", "abstract": "Self-supervised learning (SSL) has recently received significant attention\ndue to its ability to train high-performance encoders purely on unlabeled\ndata-often scraped from the internet. This data can still be sensitive and\nempirical evidence suggests that SSL encoders memorize private information of\ntheir training data and can disclose them at inference time. Since existing\ntheoretical definitions of memorization from supervised learning rely on\nlabels, they do not transfer to SSL. To address this gap, we propose SSLMem, a\nframework for defining memorization within SSL. Our definition compares the\ndifference in alignment of representations for data points and their augmented\nviews returned by both encoders that were trained on these data points and\nencoders that were not. Through comprehensive empirical analysis on diverse\nencoder architectures and datasets we highlight that even though SSL relies on\nlarge datasets and strong augmentations-both known in supervised learning as\nregularization techniques that reduce overfitting-still significant fractions\nof training data points experience high memorization. Through our empirical\nresults, we show that this memorization is essential for encoders to achieve\nhigher generalization performance on different downstream tasks.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.12234", "title": "A Lightweight FPGA-based IDS-ECU Architecture for Automotive CAN", "abstract": "Recent years have seen an exponential rise in complex software-driven\nfunctionality in vehicles, leading to a rising number of electronic control\nunits (ECUs), network capabilities, and interfaces. These expanded capabilities\nalso bring-in new planes of vulnerabilities making intrusion detection and\nmanagement a critical capability; however, this can often result in more ECUs\nand network elements due to the high computational overheads. In this paper, we\npresent a consolidated ECU architecture incorporating an Intrusion Detection\nSystem (IDS) for Automotive Controller Area Network (CAN) along with\ntraditional ECU functionality on an off-the-shelf hybrid FPGA device, with\nnear-zero overhead for the ECU functionality. We propose two quantised\nmulti-layer perceptrons (QMLP's) as isolated IDSs for detecting a range of\nattack vectors including Denial-of-Service, Fuzzing and Spoofing, which are\naccelerated using off-the-shelf deep-learning processing unit (DPU) IP block\nfrom Xilinx, operating fully transparently to the software on the ECU. The\nproposed models achieve the state-of-the-art classification accuracy for all\nthe attacks, while we observed a 15x reduction in power consumption when\ncompared against the GPU-based implementation of the same models quantised\nusing Nvidia libraries. We also achieved a 2.3x speed up in per-message\nprocessing latency (at 0.24 ms from the arrival of a CAN message) to meet the\nstrict end-to-end latency on critical CAN nodes and a 2.6x reduction in power\nconsumption for inference when compared to the state-of-the-art IDS models on\nembedded IDS and loosely coupled IDS accelerators (GPUs) discussed in the\nliterature.", "field": "Computer Science", "categories": "cs.AR,cs.CR,cs.LG,cs.SY,eess.SY"}, {"arxiv_id": "2401.12235", "title": "Stochastic Dynamic Power Dispatch with High Generalization and Few-Shot\n  Adaption via Contextual Meta Graph Reinforcement Learning", "abstract": "Reinforcement learning is an emerging approaches to facilitate multi-stage\nsequential decision-making problems. This paper studies a real-time multi-stage\nstochastic power dispatch considering multivariate uncertainties. Current\nresearches suffer from low generalization and practicality, that is, the\nlearned dispatch policy can only handle a specific dispatch scenario, its\nperformance degrades significantly if actual samples and training samples are\ninconsistent. To fill these gaps, a novel contextual meta graph reinforcement\nlearning (Meta-GRL) for a highly generalized multi-stage optimal dispatch\npolicy is proposed. Specifically, a more general contextual Markov decision\nprocess (MDP) and scalable graph representation are introduced to achieve a\nmore generalized multi-stage stochastic power dispatch modeling. An upper\nmeta-learner is proposed to encode context for different dispatch scenarios and\nlearn how to achieve dispatch task identification while the lower policy\nlearner learns context-specified dispatch policy. After sufficient offline\nlearning, this approach can rapidly adapt to unseen and undefined scenarios\nwith only a few updations of the hypothesis judgments generated by the\nmeta-learner. Numerical comparisons with state-of-the-art policies and\ntraditional reinforcement learning verify the optimality, efficiency,\nadaptability, and scalability of the proposed Meta-GRL.", "field": "Computer Science", "categories": "cs.LG,cs.SY,eess.SY"}, {"arxiv_id": "2401.12236", "title": "The Surprising Harmfulness of Benign Overfitting for Adversarial\n  Robustness", "abstract": "Recent empirical and theoretical studies have established the generalization\ncapabilities of large machine learning models that are trained to\n(approximately or exactly) fit noisy data. In this work, we prove a surprising\nresult that even if the ground truth itself is robust to adversarial examples,\nand the benignly overfitted model is benign in terms of the ``standard''\nout-of-sample risk objective, this benign overfitting process can be harmful\nwhen out-of-sample data are subject to adversarial manipulation. More\nspecifically, our main results contain two parts: (i) the min-norm estimator in\noverparameterized linear model always leads to adversarial vulnerability in the\n``benign overfitting'' setting; (ii) we verify an asymptotic trade-off result\nbetween the standard risk and the ``adversarial'' risk of every ridge\nregression estimator, implying that under suitable conditions these two items\ncannot both be small at the same time by any single choice of the ridge\nregularization parameter. Furthermore, under the lazy training regime, we\ndemonstrate parallel results on two-layer neural tangent kernel (NTK) model,\nwhich align with empirical observations in deep neural networks. Our finding\nprovides theoretical insights into the puzzling phenomenon observed in\npractice, where the true target function (e.g., human) is robust against\nadverasrial attack, while beginly overfitted neural networks lead to models\nthat are not robust.", "field": "Computer Science", "categories": "cs.LG,cs.CR,stat.ML"}, {"arxiv_id": "2401.1224", "title": "Quantised Neural Network Accelerators for Low-Power IDS in Automotive\n  Networks", "abstract": "In this paper, we explore low-power custom quantised Multi-Layer Perceptrons\n(MLPs) as an Intrusion Detection System (IDS) for automotive controller area\nnetwork (CAN). We utilise the FINN framework from AMD/Xilinx to quantise, train\nand generate hardware IP of our MLP to detect denial of service (DoS) and\nfuzzying attacks on CAN network, using ZCU104 (XCZU7EV) FPGA as our target ECU\narchitecture with integrated IDS capabilities. Our approach achieves\nsignificant improvements in latency (0.12 ms per-message processing latency)\nand inference energy consumption (0.25 mJ per inference) while achieving\nsimilar classification performance as state-of-the-art approaches in the\nliterature.", "field": "Computer Science", "categories": "cs.CR,cs.AR,cs.LG,cs.SY,eess.SY"}, {"arxiv_id": "2401.12241", "title": "Power System Resource Expansion Planning", "abstract": "Power System Resource Planning is the recurrent process of studying and\ndetermining what facilities and procedures should be provided to satisfy and\npromote appropriate future demands for electricity. The electric power system\nas planned should meet or balance societal goals. These include availability of\nelectricity to all potential users at lowest possible cost, minimum\nenvironmental damage, high levels of safety and reliability, etc. Plans should\nbe technically and financially feasible. Plans also should achieve the\nobjectives the entity doing the planning, including minimizing risk. The\nemergence of meta-heuristics has given robustness to the non-analytical\nmethods, because of the rationale behind them. Besides, evolutionary algorithms\nhave provided a higher degree of confidence in a stochastic convergence to\noptimum and have supported this confidence with a mathematical background\nexplaining not only how they achieve convergence but also how to improve the\nconvergence rate. The present work of analyses and implementation can be\ndivided into: i) Transmission Constrained Generation Expansion Planning (TC\nGEP), ii) Composite Generation Expansion and Transmission Network Expansion\nPlanning (GEP TNEP), iii) Transmission Network Expansion (TNEP) Planning using\nAC model, iv) Composite Transmission Network Expansion Planning (TNEP) and\nReactive Power Expansion Planning (RPP) and v) Transmission Network Planning\nusing Interior-Point Method (IP TNEP).", "field": "Computer Science", "categories": "eess.SY,cs.SY"}, {"arxiv_id": "2401.12242", "title": "BadChain: Backdoor Chain-of-Thought Prompting for Large Language Models", "abstract": "Large language models (LLMs) are shown to benefit from chain-of-thought (COT)\nprompting, particularly when tackling tasks that require systematic reasoning\nprocesses. On the other hand, COT prompting also poses new vulnerabilities in\nthe form of backdoor attacks, wherein the model will output unintended\nmalicious content under specific backdoor-triggered conditions during\ninference. Traditional methods for launching backdoor attacks involve either\ncontaminating the training dataset with backdoored instances or directly\nmanipulating the model parameters during deployment. However, these approaches\nare not practical for commercial LLMs that typically operate via API access. In\nthis paper, we propose BadChain, the first backdoor attack against LLMs\nemploying COT prompting, which does not require access to the training dataset\nor model parameters and imposes low computational overhead. BadChain leverages\nthe inherent reasoning capabilities of LLMs by inserting a backdoor reasoning\nstep into the sequence of reasoning steps of the model output, thereby altering\nthe final response when a backdoor trigger exists in the query prompt.\nEmpirically, we show the effectiveness of BadChain for two COT strategies\nacross four LLMs (Llama2, GPT-3.5, PaLM2, and GPT-4) and six complex benchmark\ntasks encompassing arithmetic, commonsense, and symbolic reasoning. Moreover,\nwe show that LLMs endowed with stronger reasoning capabilities exhibit higher\nsusceptibility to BadChain, exemplified by a high average attack success rate\nof 97.0% across the six benchmark tasks on GPT-4. Finally, we propose two\ndefenses based on shuffling and demonstrate their overall ineffectiveness\nagainst BadChain. Therefore, BadChain remains a severe threat to LLMs,\nunderscoring the urgency for the development of robust and effective future\ndefenses.", "field": "Computer Science", "categories": "cs.CR,cs.LG"}, {"arxiv_id": "2401.12244", "title": "Large-scale Reinforcement Learning for Diffusion Models", "abstract": "Text-to-image diffusion models are a class of deep generative models that\nhave demonstrated an impressive capacity for high-quality image generation.\nHowever, these models are susceptible to implicit biases that arise from\nweb-scale text-image training pairs and may inaccurately model aspects of\nimages we care about. This can result in suboptimal samples, model bias, and\nimages that do not align with human ethics and preferences. In this paper, we\npresent an effective scalable algorithm to improve diffusion models using\nReinforcement Learning (RL) across a diverse set of reward functions, such as\nhuman preference, compositionality, and fairness over millions of images. We\nillustrate how our approach substantially outperforms existing methods for\naligning diffusion models with human preferences. We further illustrate how\nthis substantially improves pretrained Stable Diffusion (SD) models, generating\nsamples that are preferred by humans 80.3% of the time over those from the base\nSD model while simultaneously improving both the composition and diversity of\ngenerated samples.", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.LG"}, {"arxiv_id": "2401.12246", "title": "Orion-14B: Open-source Multilingual Large Language Models", "abstract": "In this study, we introduce Orion-14B, a collection of multilingual large\nlanguage models with 14 billion parameters. We utilize a data scheduling\napproach to train a foundational model on a diverse corpus of 2.5 trillion\ntokens, sourced from texts in English, Chinese, Japanese, Korean, and other\nlanguages. Additionally, we fine-tuned a series of models tailored for\nconversational applications and other specific use cases. Our evaluation\nresults demonstrate that Orion-14B achieves state-of-the-art performance across\na broad spectrum of tasks. We make the Orion-14B model family and its\nassociated code publicly accessible https://github.com/OrionStarAI/Orion,\naiming to inspire future research and practical applications in the field.", "field": "Computer Science", "categories": "cs.CL,cs.LG"}, {"arxiv_id": "2401.12247", "title": "Exploring consumers response to text-based chatbots in e-commerce: The\n  moderating role of task complexity and chatbot disclosure", "abstract": "Artificial intelligence based chatbots have brought unprecedented business\npotential. This study aims to explore consumers trust and response to a\ntext-based chatbot in ecommerce, involving the moderating effects of task\ncomplexity and chatbot identity disclosure. A survey method with 299 useable\nresponses was conducted in this research. This study adopted the ordinary least\nsquares regression to test the hypotheses. First, the consumers perception of\nboth the empathy and friendliness of the chatbot positively impacts their trust\nin it. Second, task complexity negatively moderates the relationship between\nfriendliness and consumers trust. Third, disclosure of the text based chatbot\nnegatively moderates the relationship between empathy and consumers trust,\nwhile it positively moderates the relationship between friendliness and\nconsumers trust. Fourth, consumers trust in the chatbot increases their\nreliance on the chatbot and decreases their resistance to the chatbot in future\ninteractions. Adopting the stimulus organism response framework, this study\nprovides important insights on consumers perception and response to the\ntext-based chatbot. The findings of this research also make suggestions that\ncan increase consumers positive responses to text based chatbots. Extant\nstudies have investigated the effects of automated bots attributes on consumers\nperceptions. However, the boundary conditions of these effects are largely\nignored. This research is one of the first attempts to provide a deep\nunderstanding of consumers responses to a chatbot.", "field": "Computer Science", "categories": "cs.AI"}, {"arxiv_id": "2401.12249", "title": "Understanding users negative emotions and continuous usage intention in\n  short video platforms", "abstract": "While short videos bring a lot of information and happiness to users, they\nalso occupy users time and short videos gradually change peoples living habits.\nThis paper studies the negative effects and negative emotions of users caused\nby using short video platforms, as well as the users intention to continue\nusing the short video platform when they have negative emotions. Therefore,\nthis study uses flow theory and illusion of control theory to construct a\nresearch hypothesis model and preliminarily confirms six influencing factors,\nand uses sequential mixed research method to conduct quantitative and\nqualitative research. The results show that users use of short video platforms\nwill have negative emotions and negative emotions will affect users intention\nto continue to use short video platforms. This study expands the breadth and\ndepth of research on short videos and enriches the research of negative\nemotions on the intention to continue using human computer interaction\nsoftware. Additionally, illusion of control theory is introduced into the field\nof human computer interaction for the first time, which enriches the\napplication scenarios of control illusion theory.", "field": "Computer Science", "categories": "cs.HC,H.0; A.0; K.6; K.4"}, {"arxiv_id": "2401.12251", "title": "Diffusion Representation for Asymmetric Kernels", "abstract": "We extend the diffusion-map formalism to data sets that are induced by\nasymmetric kernels. Analytical convergence results of the resulting expansion\nare proved, and an algorithm is proposed to perform the dimensional reduction.\nIn this work we study data sets in which its geometry structure is induced by\nan asymmetric kernel. We use a priori coordinate system to represent this\ngeometry and, thus, be able to improve the computational complexity of reducing\nthe dimensionality of data sets. A coordinate system connected to the tensor\nproduct of Fourier basis is used to represent the underlying geometric\nstructure obtained by the diffusion-map, thus reducing the dimensionality of\nthe data set and making use of the speedup provided by the two-dimensional Fast\nFourier Transform algorithm (2-D FFT). We compare our results with those\nobtained by other eigenvalue expansions, and verify the efficiency of the\nalgorithms with synthetic data, as well as with real data from applications\nincluding climate change studies.", "field": "Computer Science", "categories": "cs.LG,eess.IV"}, {"arxiv_id": "2401.12254", "title": "Transfer learning-assisted inverse modeling in nanophotonics based on\n  mixture density networks", "abstract": "The simulation of nanophotonic structures relies on electromagnetic solvers,\nwhich play a crucial role in understanding their behavior. However, these\nsolvers often come with a significant computational cost, making their\napplication in design tasks, such as optimization, impractical. To address this\nchallenge, machine learning techniques have been explored for accurate and\nefficient modeling and design of photonic devices. Deep neural networks, in\nparticular, have gained considerable attention in this field. They can be used\nto create both forward and inverse models. An inverse modeling approach avoids\nthe need for coupling a forward model with an optimizer and directly performs\nthe prediction of the optimal design parameters values.\n  In this paper, we propose an inverse modeling method for nanophotonic\nstructures, based on a mixture density network model enhanced by transfer\nlearning. Mixture density networks can predict multiple possible solutions at a\ntime including their respective importance as Gaussian distributions. However,\nmultiple challenges exist for mixture density network models. An important\nchallenge is that an upper bound on the number of possible simultaneous\nsolutions needs to be specified in advance. Also, another challenge is that the\nmodel parameters must be jointly optimized, which can result computationally\nexpensive. Moreover, optimizing all parameters simultaneously can be\nnumerically unstable and can lead to degenerate predictions. The proposed\napproach allows overcoming these limitations using transfer learning-based\ntechniques, while preserving a high accuracy in the prediction capability of\nthe design solutions given an optical response as an input. A dimensionality\nreduction step is also explored. Numerical results validate the proposed\nmethod.", "field": "Computer Science", "categories": "cs.LG,physics.optics"}, {"arxiv_id": "2401.12255", "title": "Instructional Fingerprinting of Large Language Models", "abstract": "The exorbitant cost of training Large language models (LLMs) from scratch\nmakes it essential to fingerprint the models to protect intellectual property\nvia ownership authentication and to ensure downstream users and developers\ncomply with their license terms (e.g. restricting commercial use). In this\nstudy, we present a pilot study on LLM fingerprinting as a form of very\nlightweight instruction tuning. Model publisher specifies a confidential\nprivate key and implants it as an instruction backdoor that causes the LLM to\ngenerate specific text when the key is present. Results on 11 popularly-used\nLLMs showed that this approach is lightweight and does not affect the normal\nbehavior of the model. It also prevents publisher overclaim, maintains\nrobustness against fingerprint guessing and parameter-efficient training, and\nsupports multi-stage fingerprinting akin to MIT License. Code is available in\nhttps://cnut1648.github.io/Model-Fingerprint/.", "field": "Computer Science", "categories": "cs.CR,cs.AI"}, {"arxiv_id": "2401.12258", "title": "Emergent Dominance Hierarchies in Reinforcement Learning Agents", "abstract": "Modern Reinforcement Learning (RL) algorithms are able to outperform humans\nin a wide variety of tasks. Multi-agent reinforcement learning (MARL) settings\npresent additional challenges, and successful cooperation in mixed-motive\ngroups of agents depends on a delicate balancing act between individual and\ngroup objectives. Social conventions and norms, often inspired by human\ninstitutions, are used as tools for striking this balance.\n  In this paper, we examine a fundamental, well-studied social convention that\nunderlies cooperation in both animal and human societies: Dominance\nhierarchies.\n  We adapt the ethological theory of dominance hierarchies to artificial\nagents, borrowing the established terminology and definitions with as few\namendments as possible. We demonstrate that populations of RL agents, operating\nwithout explicit programming or intrinsic rewards, can invent, learn, enforce,\nand transmit a dominance hierarchy to new populations. The dominance\nhierarchies that emerge have a similar structure to those studied in chickens,\nmice, fish, and other species.", "field": "Computer Science", "categories": "cs.MA,cs.AI,cs.GT,cs.LG"}, {"arxiv_id": "2401.12259", "title": "Agreement Technologies for Coordination in Smart Cities", "abstract": "Many challenges in today's society can be tackled by distributed open\nsystems. This is particularly true for domains that are commonly perceived\nunder the umbrella of smart cities, such as intelligent transportation, smart\nenergy grids, or participative governance. When designing computer applications\nfor these domains, it is necessary to account for the fact that the elements of\nsuch systems, often called software agents, are usually made by different\ndesigners and act on behalf of particular stakeholders. Furthermore, it is\nunknown at design time when such agents will enter or leave the system, and\nwhat interests new agents will represent. To instil coordination in such\nsystems is particularly demanding, as usually only part of them can be directly\ncontrolled at runtime. Agreement technologies refer to a sandbox of tools and\nmechanisms for the development of such open multiagent systems, which are based\non the notion of agreement. In this paper, we argue that agreement technologies\nare a suitable means for achieving coordination in smart city domains, and back\nour claim through examples of several real-world applications.", "field": "Computer Science", "categories": "cs.MA,cs.AI,I.2.1"}, {"arxiv_id": "2401.12261", "title": "Analyzing the Quality Attributes of AI Vision Models in Open\n  Repositories Under Adversarial Attacks", "abstract": "As AI models rapidly evolve, they are frequently released to open\nrepositories, such as HuggingFace. It is essential to perform quality assurance\nvalidation on these models before integrating them into the production\ndevelopment lifecycle. In addition to evaluating efficiency in terms of\nbalanced accuracy and computing costs, adversarial attacks are potential\nthreats to the robustness and explainability of AI models. Meanwhile, XAI\napplies algorithms that approximate inputs to outputs post-hoc to identify the\ncontributing features. Adversarial perturbations may also degrade the utility\nof XAI explanations that require further investigation. In this paper, we\npresent an integrated process designed for downstream evaluation tasks,\nincluding validating AI model accuracy, evaluating robustness with benchmark\nperturbations, comparing explanation utility, and assessing overhead. We\ndemonstrate an evaluation scenario involving six computer vision models, which\ninclude CNN-based, Transformer-based, and hybrid architectures, three types of\nperturbations, and five XAI methods, resulting in ninety unique combinations.\nThe process reveals the explanation utility among the XAI methods in terms of\nthe identified key areas responding to the adversarial perturbation. The\nprocess produces aggregated results that illustrate multiple attributes of each\nAI model.", "field": "Computer Science", "categories": "cs.CR,cs.AI"}, {"arxiv_id": "2401.12262", "title": "Machine learning-based network intrusion detection for big and\n  imbalanced data using oversampling, stacking feature embedding and feature\n  extraction", "abstract": "Cybersecurity has emerged as a critical global concern. Intrusion Detection\nSystems (IDS) play a critical role in protecting interconnected networks by\ndetecting malicious actors and activities. Machine Learning (ML)-based behavior\nanalysis within the IDS has considerable potential for detecting dynamic cyber\nthreats, identifying abnormalities, and identifying malicious conduct within\nthe network. However, as the number of data grows, dimension reduction becomes\nan increasingly difficult task when training ML models. Addressing this, our\npaper introduces a novel ML-based network intrusion detection model that uses\nRandom Oversampling (RO) to address data imbalance and Stacking Feature\nEmbedding based on clustering results, as well as Principal Component Analysis\n(PCA) for dimension reduction and is specifically designed for large and\nimbalanced datasets. This model's performance is carefully evaluated using\nthree cutting-edge benchmark datasets: UNSW-NB15, CIC-IDS-2017, and\nCIC-IDS-2018. On the UNSW-NB15 dataset, our trials show that the RF and ET\nmodels achieve accuracy rates of 99.59% and 99.95%, respectively. Furthermore,\nusing the CIC-IDS2017 dataset, DT, RF, and ET models reach 99.99% accuracy,\nwhile DT and RF models obtain 99.94% accuracy on CIC-IDS2018. These performance\nresults continuously outperform the state-of-art, indicating significant\nprogress in the field of network intrusion detection. This achievement\ndemonstrates the efficacy of the suggested methodology, which can be used\npractically to accurately monitor and identify network traffic intrusions,\nthereby blocking possible threats.", "field": "Computer Science", "categories": "cs.CR,cs.LG"}, {"arxiv_id": "2401.12263", "title": "Maintenance policy for a system with a weighted linear combination of\n  degradation processes", "abstract": "This paper develops maintenance policies for a system under condition\nmonitoring. We assume that a number of defects may develop and the degradation\nprocess of each defect follows a gamma process, respectively. The system is\ninspected periodically and maintenance actions are performed on the defects\npresent in the system. The effectiveness of the maintenance is assumed\nimperfect and it is modelled using a geometric process. By performing these\nmaintenance actions, different costs are incurred depending on the type and the\ndegradation levels of the defects. Furthermore, once a linear combination of\nthe degradation processes exceeds a pre-specified threshold, the system needs a\nspecial maintenance and an extra cost is imposed. The system is renewed after\nseveral preventive maintenance activities have been performed. The main concern\nof this paper is to optimise the time between renewals and the number of\nrenewals. Numerical examples are given to illustrate the results derived in the\npaper.", "field": "Computer Science", "categories": "cs.SY,math.PR"}, {"arxiv_id": "2401.12265", "title": "Assessment of the maintenance cost and analysis of availability measures\n  in a finite life cycle for a system subject to competing failures", "abstract": "This paper deals with the assessment of the performance of a system under a\nfinite planning horizon. The system is subject to two dependent causes of\nfailure: internal degradation and sudden shocks. We assume that internal\ndegradation follows a gamma process. When the deterioration level of the\ndegradation process exceeds a predetermined value, a degradation failure\noccurs. Sudden shocks arrive at the system following a doubly stochastic\nPoisson process (DSPP). A sudden shock provokes the total breakdown of the\nsystem. A condition-based maintenance (CBM) with periodic inspection times is\ndeveloped. To evaluate the maintenance cost, recursive methods combining\nnumerical integration and Monte Carlo simulation are developed to evalute the\nexpected cost rate and its standard deviation. Also, recursive methods to\ncalculate some transient measures of the system are given. Numerical examples\nare provided to illustrate the analytical results.", "field": "Computer Science", "categories": "cs.SY,math.PR"}, {"arxiv_id": "2401.12266", "title": "An Exploratory Study of Multimodal Physiological Data in Jazz\n  Improvisation Using Basic Machine Learning Techniques", "abstract": "Our study delves into the \"Embodied Musicking Dataset,\" exploring the\nintertwined relationships and correlations between physiological and\npsychological dimensions during improvisational music performances. The primary\nobjective is to ascertain the presence of a definitive causal or correlational\nrelationship between these states and comprehend their manifestation in musical\ncompositions. This rich dataset provides a perspective on how musicians\ncoordinate their physicality with sonic events in real-time improvisational\nscenarios, emphasizing the concept of \"Embodied Musicking.\"", "field": "Computer Science", "categories": "cs.SD,eess.AS"}, {"arxiv_id": "2401.12273", "title": "The Ethics of Interaction: Mitigating Security Threats in LLMs", "abstract": "This paper comprehensively explores the ethical challenges arising from\nsecurity threats to Language Learning Models (LLMs). These intricate digital\nrepositories are increasingly integrated into our daily lives, making them\nprime targets for attacks that can compromise their training data and the\nconfidentiality of their data sources. The paper delves into the nuanced\nethical repercussions of such security threats on society and individual\nprivacy. We scrutinize five major threats: prompt injection, jailbreaking,\nPersonal Identifiable Information (PII) exposure, sexually explicit content,\nand hate based content, going beyond mere identification to assess their\ncritical ethical consequences and the urgency they create for robust defensive\nstrategies. The escalating reliance on LLMs underscores the crucial need for\nensuring these systems operate within the bounds of ethical norms, particularly\nas their misuse can lead to significant societal and individual harm. We\npropose conceptualizing and developing an evaluative tool tailored for LLMs,\nwhich would serve a dual purpose, guiding developers and designers in\npreemptive fortification of backend systems and scrutinizing the ethical\ndimensions of LLM chatbot responses during the testing phase. By comparing LLM\nresponses with those expected from humans in a moral context, we aim to discern\nthe degree to which AI behaviors align with the ethical values held by a\nbroader society. Ultimately, this paper not only underscores the ethical\ntroubles presented by LLMs, it also highlights a path toward cultivating trust\nin these systems.", "field": "Computer Science", "categories": "cs.CR,cs.AI,cs.CL"}, {"arxiv_id": "2401.12275", "title": "Multi-Agent Dynamic Relational Reasoning for Social Robot Navigation", "abstract": "Social robot navigation can be helpful in various contexts of daily life but\nrequires safe human-robot interactions and efficient trajectory planning. While\nmodeling pairwise relations has been widely studied in multi-agent interacting\nsystems, the ability to capture larger-scale group-wise activities is limited.\nIn this paper, we propose a systematic relational reasoning approach with\nexplicit inference of the underlying dynamically evolving relational\nstructures, and we demonstrate its effectiveness for multi-agent trajectory\nprediction and social robot navigation. In addition to the edges between pairs\nof nodes (i.e., agents), we propose to infer hyperedges that adaptively connect\nmultiple nodes to enable group-wise reasoning in an unsupervised manner. Our\napproach infers dynamically evolving relation graphs and hypergraphs to capture\nthe evolution of relations, which the trajectory predictor employs to generate\nfuture states. Meanwhile, we propose to regularize the sharpness and sparsity\nof the learned relations and the smoothness of the relation evolution, which\nproves to enhance training stability and model performance. The proposed\napproach is validated on synthetic crowd simulations and real-world benchmark\ndatasets. Experiments demonstrate that the approach infers reasonable relations\nand achieves state-of-the-art prediction performance. In addition, we present a\ndeep reinforcement learning (DRL) framework for social robot navigation, which\nincorporates relational reasoning and trajectory prediction systematically. In\na group-based crowd simulation, our method outperforms the strongest baseline\nby a significant margin in terms of safety, efficiency, and social compliance\nin dense, interactive scenarios.", "field": "Computer Science", "categories": "cs.RO,cs.AI,cs.CV,cs.LG,cs.MA"}, {"arxiv_id": "2401.12292", "title": "GRATH: Gradual Self-Truthifying for Large Language Models", "abstract": "Truthfulness is paramount for large language models (LLMs) as they are\nincreasingly deployed in real-world applications. However, existing LLMs still\nstruggle with generating truthful answers and content, as evidenced by their\nmodest performance on benchmarks like TruthfulQA. To address this issue, we\npropose GRAdual self-truTHifying (GRATH), a novel post-processing method to\nenhance truthfulness of LLMs. GRATH utilizes out-of-domain question prompts to\ngenerate corresponding answers and adaptively optimizes the model via direct\npreference optimization (DPO). Note that during this process, GRATH learns\ntruthfulness in a self-supervised manner without requiring annotated answers.\nIn particular, GRATH first generates pairwise truthfulness training data by\nprompting the LLM itself, with each pair containing a question and its correct\nand incorrect answers. The model is then fine-tuned using DPO to learn from the\ndifference between answer pairs. Subsequently, GRATH iteratively refines the\ntruthfulness data and optimizes the model, leading to a gradual improvement in\nmodel truthfulness. Empirically, we evaluate GRATH using different 7B-LLMs and\ncompare with LLMs with similar or even larger sizes on benchmark datasets. Our\nresults show that GRATH effectively improves LLMs' truthfulness without\ncompromising other core capabilities. Notably, GRATH achieves state-of-the-art\nperformance on TruthfulQA, with MC1 accuracy as 54.71% and MC2 accuracy as\n69.10%, which even surpass those on larger-scale models, such as\nLlama2-Chat-70B, by 23.62% and 24.18%, respectively.", "field": "Computer Science", "categories": "cs.CL,cs.AI"}, {"arxiv_id": "2401.12295", "title": "Cheap Learning: Maximising Performance of Language Models for Social\n  Data Science Using Minimal Data", "abstract": "The field of machine learning has recently made significant progress in\nreducing the requirements for labelled training data when building new models.\nThese `cheaper' learning techniques hold significant potential for the social\nsciences, where development of large labelled training datasets is often a\nsignificant practical impediment to the use of machine learning for analytical\ntasks. In this article we review three `cheap' techniques that have developed\nin recent years: weak supervision, transfer learning and prompt engineering.\nFor the latter, we also review the particular case of zero-shot prompting of\nlarge language models. For each technique we provide a guide of how it works\nand demonstrate its application across six different realistic social science\napplications (two different tasks paired with three different dataset makeups).\nWe show good performance for all techniques, and in particular we demonstrate\nhow prompting of large language models can achieve high accuracy at very low\ncost. Our results are accompanied by a code repository to make it easy for\nothers to duplicate our work and use it in their own research. Overall, our\narticle is intended to stimulate further uptake of these techniques in the\nsocial sciences.", "field": "Computer Science", "categories": "cs.CL,I.2.7; J.4"}, {"arxiv_id": "2401.12317", "title": "Software Engineering for Robotics: Future Research Directions; Report\n  from the 2023 Workshop on Software Engineering for Robotics", "abstract": "Robots are experiencing a revolution as they permeate many aspects of our\ndaily lives, from performing house maintenance to infrastructure inspection,\nfrom efficiently warehousing goods to autonomous vehicles, and more. This\ntechnical progress and its impact are astounding. This revolution, however, is\noutstripping the capabilities of existing software development processes,\ntechniques, and tools, which largely have remained unchanged for decades. These\ncapabilities are ill-suited to handling the challenges unique to robotics\nsoftware such as dealing with a wide diversity of domains, heterogeneous\nhardware, programmed and learned components, complex physical environments\ncaptured and modeled with uncertainty, emergent behaviors that include human\ninteractions, and scalability demands that span across multiple dimensions.\n  Looking ahead to the need to develop software for robots that are ever more\nubiquitous, autonomous, and reliant on complex adaptive components, hardware,\nand data, motivated an NSF-sponsored community workshop on the subject of\nSoftware Engineering for Robotics, held in Detroit, Michigan in October 2023.\nThe goal of the workshop was to bring together thought leaders across robotics\nand software engineering to coalesce a community, and identify key problems in\nthe area of SE for robotics that that community should aim to solve over the\nnext 5 years. This report serves to summarize the motivation, activities, and\nfindings of that workshop, in particular by articulating the challenges unique\nto robot software, and identifying a vision for fruitful near-term research\ndirections to tackle them.", "field": "Computer Science", "categories": "cs.RO,cs.SE"}, {"arxiv_id": "2401.12321", "title": "The outcomes of generative AI are exactly the Nash equilibria of a\n  non-potential game", "abstract": "In this article we show that the asymptotic outcomes of both shallow and deep\nneural networks such as those used in BloombergGPT to generate economic time\nseries are exactly the Nash equilibria of a non-potential game. We then design\nand analyze deep neural network algorithms that converge to these equilibria.\nThe methodology is extended to federated deep neural networks between clusters\nof regional servers and on-device clients. Finally, the variational\ninequalities behind large language models including encoder-decoder related\ntransformers are established.", "field": "Computer Science", "categories": "cs.GT"}, {"arxiv_id": "2401.12322", "title": "Smart Recommendations for Renting Bikes in Bike Sharing Systems", "abstract": "Vehicle-sharing systems -- such as bike-, car-, or motorcycle-sharing systems\n-- have become increasingly popular in big cities in recent years. On the one\nhand, they provide a cheaper and environmentally friendlier means of\ntransportation than private cars, and on the other hand, they satisfy the\nindividual mobility demands of citizens better than traditional public\ntransport systems. One of their advantages in this regard is their\navailability, e.g., the possibility of taking (or leaving) a vehicle almost\nanywhere in a city. This availability obviously depends on different strategic\nand operational management decisions and policies, such as the dimension of the\nfleet or the (re)distribution of vehicles. Agglutination problems -- where, due\nto usage patterns, available vehicles are concentrated in certain areas,\nwhereas no vehicles are available in others -- are quite common in such\nsystems, and need to be dealt with. Research has been dedicated to this\nproblem, specifying different techniques to reduce imbalanced situations. In\nthis paper, we present and compare strategies for recommending stations to\nusers who wish to rent or return bikes in station-based bike-sharing systems.\nOur first contribution is a novel recommendation strategy based on queuing\ntheory that recommends stations based on their utility to the user in terms of\nlower distance and higher probability of finding a bike or slot. Then, we go\none step further, defining a strategy that recommends stations by combining the\nutility of a particular user with the utility of the global system, measured in\nterms of the improvement in the distribution of bikes and slots with respect to\nthe expected future demand, with the aim of implicitly avoiding or alleviating\nbalancing problems. We present several experiments to evaluate our proposal\nwith real data from the bike sharing system BiciMAD in Madrid.", "field": "Computer Science", "categories": "cs.AI,I.2.1"}, {"arxiv_id": "2401.12324", "title": "Streamlining Advanced Taxi Assignment Strategies based on Legal Analysis", "abstract": "In recent years many novel applications have appeared that promote the\nprovision of services and activities in a collaborative manner. The key idea\nbehind such systems is to take advantage of idle or underused capacities of\nexisting resources, in order to provide improved services that assist people in\ntheir daily tasks, with additional functionality, enhanced efficiency, and/or\nreduced cost. Particularly in the domain of urban transportation, many\nresearchers have put forward novel ideas, which are then implemented and\nevaluated through prototypes that usually draw upon AI methods and tools.\nHowever, such proposals also bring up multiple non-technical issues that need\nto be identified and addressed adequately if such systems are ever meant to be\napplied to the real world. While, in practice, legal and ethical aspects\nrelated to such AI-based systems are seldomly considered in the beginning of\nthe research and development process, we argue that they not only restrict\ndesign decisions, but can also help guiding them. In this manuscript, we set\nout from a prototype of a taxi coordination service that mediates between\nindividual (and autonomous) taxis and potential customers. After representing\nkey aspects of its operation in a semi-structured manner, we analyse its\nviability from the viewpoint of current legal restrictions and constraints, so\nas to identify additional non-functional requirements as well as options to\naddress them. Then, we go one step ahead, and actually modify the existing\nprototype to incorporate the previously identified recommendations. Performing\nexperiments with this improved system helps us identify the most adequate\noption among several legally admissible alternatives.", "field": "Computer Science", "categories": "cs.AI,I.2.1"}, {"arxiv_id": "2401.12326", "title": "Fine-tuning Large Language Models for Multigenerator, Multidomain, and\n  Multilingual Machine-Generated Text Detection", "abstract": "SemEval-2024 Task 8 introduces the challenge of identifying machine-generated\ntexts from diverse Large Language Models (LLMs) in various languages and\ndomains. The task comprises three subtasks: binary classification in\nmonolingual and multilingual (Subtask A), multi-class classification (Subtask\nB), and mixed text detection (Subtask C). This paper focuses on Subtask A & B.\nEach subtask is supported by three datasets for training, development, and\ntesting. To tackle this task, two methods: 1) using traditional machine\nlearning (ML) with natural language preprocessing (NLP) for feature extraction,\nand 2) fine-tuning LLMs for text classification. The results show that\ntransformer models, particularly LoRA-RoBERTa, exceed traditional ML methods in\neffectiveness, with majority voting being particularly effective in\nmultilingual contexts for identifying machine-generated texts.", "field": "Computer Science", "categories": "cs.CL,cs.AI"}, {"arxiv_id": "2401.12332", "title": "A Precise Characterization of SGD Stability Using Loss Surface Geometry", "abstract": "Stochastic Gradient Descent (SGD) stands as a cornerstone optimization\nalgorithm with proven real-world empirical successes but relatively limited\ntheoretical understanding. Recent research has illuminated a key factor\ncontributing to its practical efficacy: the implicit regularization it\ninstigates. Several studies have investigated the linear stability property of\nSGD in the vicinity of a stationary point as a predictive proxy for sharpness\nand generalization error in overparameterized neural networks (Wu et al., 2022;\nJastrzebski et al., 2019; Cohen et al., 2021). In this paper, we delve deeper\ninto the relationship between linear stability and sharpness. More\nspecifically, we meticulously delineate the necessary and sufficient conditions\nfor linear stability, contingent on hyperparameters of SGD and the sharpness at\nthe optimum. Towards this end, we introduce a novel coherence measure of the\nloss Hessian that encapsulates pertinent geometric properties of the loss\nfunction that are relevant to the linear stability of SGD. It enables us to\nprovide a simplified sufficient condition for identifying linear instability at\nan optimum. Notably, compared to previous works, our analysis relies on\nsignificantly milder assumptions and is applicable for a broader class of loss\nfunctions than known before, encompassing not only mean-squared error but also\ncross-entropy loss.", "field": "Computer Science", "categories": "cs.LG,math.OC"}, {"arxiv_id": "2401.1234", "title": "Contrastive Learning and Cycle Consistency-based Transductive Transfer\n  Learning for Target Annotation", "abstract": "Annotating automatic target recognition (ATR) is a highly challenging task,\nprimarily due to the unavailability of labeled data in the target domain.\nHence, it is essential to construct an optimal target domain classifier by\nutilizing the labeled information of the source domain images. The transductive\ntransfer learning (TTL) method that incorporates a CycleGAN-based unpaired\ndomain translation network has been previously proposed in the literature for\neffective ATR annotation. Although this method demonstrates great potential for\nATR, it severely suffers from lower annotation performance, higher Fr\\'echet\nInception Distance (FID) score, and the presence of visual artifacts in the\nsynthetic images. To address these issues, we propose a hybrid contrastive\nlearning base unpaired domain translation (H-CUT) network that achieves a\nsignificantly lower FID score. It incorporates both attention and entropy to\nemphasize the domain-specific region, a noisy feature mixup module to generate\nhigh variational synthetic negative patches, and a modulated noise contrastive\nestimation (MoNCE) loss to reweight all negative patches using optimal\ntransport for better performance. Our proposed contrastive learning and\ncycle-consistency-based TTL (C3TTL) framework consists of two H-CUT networks\nand two classifiers. It simultaneously optimizes cycle-consistency, MoNCE, and\nidentity losses. In C3TTL, two H-CUT networks have been employed through a\nbijection mapping to feed the reconstructed source domain images into a\npretrained classifier to guide the optimal target domain classifier. Extensive\nexperimental analysis conducted on three ATR datasets demonstrates that the\nproposed C3TTL method is effective in annotating civilian and military\nvehicles, as well as ship targets.", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.LG,eess.IV,stat.ML"}, {"arxiv_id": "2401.12342", "title": "Discretisations of mixed-dimensional Thermo-Hydro-Mechanical models\n  preserving energy estimates", "abstract": "In this study, we explore mixed-dimensional Thermo-Hydro-Mechanical (THM)\nmodels in fractured porous media accounting for Coulomb frictional contact at\nmatrix fracture interfaces. The simulation of such models plays an important\nrole in many applications such as hydraulic stimulation in deep geothermal\nsystems and assessing induced seismic risks in CO2 storage. We first extend to\nthe mixed-dimensional framework the thermodynamically consistent THM models\nderived in [16] based on first and second principles of thermodynamics. Two\nformulations of the energy equation will be considered based either on energy\nconservation or on the entropy balance, assuming a vanishing\nthermo-poro-elastic dissipation. Our focus is on space time discretisations\npreserving energy estimates for both types of formulations and for a general\nsingle phase fluid thermodynamical model. This is achieved by a Finite Volume\ndiscretisation of the non-isothermal flow based on coercive fluxes and a\ntailored discretisation of the non-conservative convective terms. It is\ncombined with a mixed Finite Element formulation of the contact-mechanical\nmodel with face-wise constant Lagrange multipliers accounting for the surface\ntractions, which preserves the dissipative properties of the contact terms. The\ndiscretisations of both THM formulations are investigated and compared in terms\nof convergence, accuracy and robustness on 2D test cases. It includes a\nDiscrete Fracture Matrix model with a convection dominated thermal regime, and\neither a weakly compressible liquid or a highly compressible gas\nthermodynamical model.", "field": "Computer Science", "categories": "math.NA,cs.NA"}, {"arxiv_id": "2401.12343", "title": "Subgraph Extraction-based Feedback-guided Iterative Scheduling for HLS", "abstract": "This paper proposes ISDC, a novel feedback-guided iterative system of\ndifference constraints (SDC) scheduling algorithm for high-level synthesis\n(HLS). ISDC leverages subgraph extraction-based low-level feedback from\ndownstream tools like logic synthesizers to iteratively refine HLS scheduling.\nTechnical innovations include: (1) An enhanced SDC formulation that effectively\nintegrates low-level feedback into the linear-programming (LP) problem; (2) A\nfanout and window-based subgraph extraction mechanism driving the feedback\ncycle; (3) A no-human-in-loop ISDC flow compatible with a wide range of\ndownstream tools and process design kits (PDKs). Evaluation shows that ISDC\nreduces register usage by 28.5% against an industrial-strength open-source HLS\ntool.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.12344", "title": "OCT-SelfNet: A Self-Supervised Framework with Multi-Modal Datasets for\n  Generalized and Robust Retinal Disease Detection", "abstract": "Despite the revolutionary impact of AI and the development of locally trained\nalgorithms, achieving widespread generalized learning from multi-modal data in\nmedical AI remains a significant challenge. This gap hinders the practical\ndeployment of scalable medical AI solutions. Addressing this challenge, our\nresearch contributes a self-supervised robust machine learning framework,\nOCT-SelfNet, for detecting eye diseases using optical coherence tomography\n(OCT) images. In this work, various data sets from various institutions are\ncombined enabling a more comprehensive range of representation. Our method\naddresses the issue using a two-phase training approach that combines\nself-supervised pretraining and supervised fine-tuning with a mask autoencoder\nbased on the SwinV2 backbone by providing a solution for real-world clinical\ndeployment. Extensive experiments on three datasets with different encoder\nbackbones, low data settings, unseen data settings, and the effect of\naugmentation show that our method outperforms the baseline model, Resnet-50 by\nconsistently attaining AUC-ROC performance surpassing 77% across all tests,\nwhereas the baseline model exceeds 54%. Moreover, in terms of the AUC-PR\nmetric, our proposed method exceeded 42%, showcasing a substantial increase of\nat least 10% in performance compared to the baseline, which exceeded only 33%.\nThis contributes to our understanding of our approach's potential and\nemphasizes its usefulness in clinical settings.", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.LG"}, {"arxiv_id": "2401.12346", "title": "Fuzzy quantitative attack tree analysis", "abstract": "Attack trees are important for security, as they help to identify weaknesses\nand vulnerabilities in a system. Quantitative attack tree analysis supports a\nnumber security metrics, which formulate important KPIs such as the shortest,\nmost likely and cheapest attacks.\n  A key bottleneck in quantitative analysis is that the values are usually not\nknown exactly, due to insufficient data and/or lack of knowledge. Fuzzy logic\nis a prominent framework to handle such uncertain values, with applications in\nnumerous domains. While several studies proposed fuzzy approaches to attack\ntree analysis, none of them provided a firm definition of fuzzy metric values\nor generic algorithms for computation of fuzzy metrics.\n  In this work, we define a generic formulation for fuzzy metric values that\napplies to most quantitative metrics. The resulting metric value is a fuzzy\nnumber obtained by following Zadeh's extension principle, obtained when we\nequip the basis attack steps, i.e., the leaves of the attack trees, with fuzzy\nnumbers. In addition, we prove a modular decomposition theorem that yields a\nbottom-up algorithm to efficiently calculate the top fuzzy metric value.", "field": "Computer Science", "categories": "cs.CR"}, {"arxiv_id": "2401.1235", "title": "Scaling Up Quantization-Aware Neural Architecture Search for Efficient\n  Deep Learning on the Edge", "abstract": "Neural Architecture Search (NAS) has become the de-facto approach for\ndesigning accurate and efficient networks for edge devices. Since models are\ntypically quantized for edge deployment, recent work has investigated\nquantization-aware NAS (QA-NAS) to search for highly accurate and efficient\nquantized models. However, existing QA-NAS approaches, particularly few-bit\nmixed-precision (FB-MP) methods, do not scale to larger tasks. Consequently,\nQA-NAS has mostly been limited to low-scale tasks and tiny networks. In this\nwork, we present an approach to enable QA-NAS (INT8 and FB-MP) on large-scale\ntasks by leveraging the block-wise formulation introduced by block-wise NAS. We\ndemonstrate strong results for the semantic segmentation task on the Cityscapes\ndataset, finding FB-MP models 33% smaller and INT8 models 17.6% faster than\nDeepLabV3 (INT8) without compromising task performance.", "field": "Computer Science", "categories": "cs.CV,cs.LG"}, {"arxiv_id": "2401.12351", "title": "Performance Analysis of 6G Multiuser Massive MIMO-OFDM THz Wireless\n  Systems with Hybrid Beamforming under Intercarrier Interference", "abstract": "6G networks are expected to provide more diverse capabilities than their\npredecessors and are likely to support applications beyond current mobile\napplications, such as virtual and augmented reality (VR/AR), AI, and the\nInternet of Things (IoT). In contrast to typical multiple-input multiple-output\n(MIMO) systems, THz MIMO precoding cannot be conducted totally at baseband\nusing digital precoders due to the restricted number of signal mixers and\nanalog-to-digital converters that can be supported due to their cost and power\nconsumption. In this thesis, we analyzed the performance of multiuser massive\nMIMO-OFDM THz wireless systems with hybrid beamforming. Carrier frequency\noffset (CFO) is one of the most well-known disturbances for OFDM. For\npracticality, we accounted for CFO, which results in Intercarrier Interference.\nIncorporating the combined impact of molecular absorption, high sparsity, and\nmulti-path fading, we analyzed a three-dimensional wideband THz channel and the\ncarrier frequency offset in multi-carrier systems. With this model, we first\npresented a two-stage wideband hybrid beamforming technique comprising\nRiemannian manifolds optimization for analog beamforming and then a\nzero-forcing (ZF) approach for digital beamforming. We adjusted the objective\nfunction to reduce complexity, and instead of maximizing the bit rate, we\ndetermined parameters by minimizing interference. Numerical results demonstrate\nthe significance of considering ICI for practical implementation for the THz\nsystem. We demonstrated how our change in problem formulation minimizes latency\nwithout compromising results. We also evaluated spectral efficiency by varying\nthe number of RF chains and antennas. The spectral efficiency grows as the\nnumber of RF chains and antennas increases, but the spectral efficiency of\nantennas declines when the number of users increases.", "field": "Computer Science", "categories": "cs.IT,eess.SP,math.IT"}, {"arxiv_id": "2401.12356", "title": "Efficient Collaborations through Weight-Driven Coalition Dynamics in\n  Federated Learning Systems", "abstract": "In the era of the Internet of Things (IoT), decentralized paradigms for\nmachine learning are gaining prominence. In this paper, we introduce a\nfederated learning model that capitalizes on the Euclidean distance between\ndevice model weights to assess their similarity and disparity. This is\nfoundational for our system, directing the formation of coalitions among\ndevices based on the closeness of their model weights. Furthermore, the concept\nof a barycenter, representing the average of model weights, helps in the\naggregation of updates from multiple devices. We evaluate our approach using\nhomogeneous and heterogeneous data distribution, comparing it against\ntraditional federated learning averaging algorithm. Numerical results\ndemonstrate its potential in offering structured, outperformed and\ncommunication-efficient model for IoT-based machine learning.", "field": "Computer Science", "categories": "cs.LG,cs.DC,cs.GT"}, {"arxiv_id": "2401.12358", "title": "A Security Risk Assessment Method for Distributed Ledger Technology\n  (DLT) based Applications: Three Industry Case Studies", "abstract": "Distributed ledger technologies have gained significant attention and\nadoption in recent years. Despite various security features distributed ledger\ntechnology provides, they are vulnerable to different and new malicious\nattacks, such as selfish mining and Sybil attacks. While such vulnerabilities\nhave been investigated, detecting and discovering appropriate countermeasures\nstill need to be reported. Cybersecurity knowledge is limited and fragmented in\nthis domain, while distributed ledger technology usage grows daily. Thus,\nresearch focusing on overcoming potential attacks on distributed ledgers is\nrequired. This study aims to raise awareness of the cybersecurity of\ndistributed ledger technology by designing a security risk assessment method\nfor distributed ledger technology applications. We have developed a database\nwith possible security threats and known attacks on distributed ledger\ntechnologies to accompany the method, including sets of countermeasures. We\nemployed a semi-systematic literature review combined with method engineering\nto develop a method that organizations can use to assess their cybersecurity\nrisk for distributed ledger applications. The method has subsequently been\nevaluated in three case studies, which show that the method helps to\neffectively conduct security risk assessments for distributed ledger\napplications in these organizations.", "field": "Computer Science", "categories": "cs.CR,cs.SE"}, {"arxiv_id": "2401.12364", "title": "Guiding the Search Towards Failure-Inducing Test Inputs Using Support\n  Vector Machines", "abstract": "In this paper, we present NSGA-II-SVM (Non-dominated Sorting Genetic\nAlgorithm with Support Vector Machine Guidance), a novel learnable evolutionary\nand search-based testing algorithm that leverages Support Vector Machine (SVM)\nclassification models to direct the search towards failure-revealing test\ninputs. Supported by genetic search, NSGA-II-SVM creates iteratively SVM-based\nmodels of the test input space, learning which regions in the search space are\npromising to be explored. A subsequent sampling and repetition of evolutionary\nsearch iterations allow to refine and make the model more accurate in the\nprediction. Our preliminary evaluation of NSGA-II-SVM by testing an Automated\nValet Parking system shows that NSGA-II-SVM is more effective in identifying\nmore critical test cases than a state of the art learnable evolutionary testing\ntechnique as well as naive random search.", "field": "Computer Science", "categories": "cs.SE,cs.NE"}, {"arxiv_id": "2401.12369", "title": "SubgroupTE: Advancing Treatment Effect Estimation with Subgroup\n  Identification", "abstract": "Precise estimation of treatment effects is crucial for evaluating\nintervention effectiveness. While deep learning models have exhibited promising\nperformance in learning counterfactual representations for treatment effect\nestimation (TEE), a major limitation in most of these models is that they treat\nthe entire population as a homogeneous group, overlooking the diversity of\ntreatment effects across potential subgroups that have varying treatment\neffects. This limitation restricts the ability to precisely estimate treatment\neffects and provide subgroup-specific treatment recommendations. In this paper,\nwe propose a novel treatment effect estimation model, named SubgroupTE, which\nincorporates subgroup identification in TEE. SubgroupTE identifies\nheterogeneous subgroups with different treatment responses and more precisely\nestimates treatment effects by considering subgroup-specific causal effects. In\naddition, SubgroupTE iteratively optimizes subgrouping and treatment effect\nestimation networks to enhance both estimation and subgroup identification.\nComprehensive experiments on the synthetic and semi-synthetic datasets exhibit\nthe outstanding performance of SubgroupTE compared with the state-of-the-art\nmodels on treatment effect estimation. Additionally, a real-world study\ndemonstrates the capabilities of SubgroupTE in enhancing personalized treatment\nrecommendations for patients with opioid use disorder (OUD) by advancing\ntreatment effect estimation with subgroup identification.", "field": "Computer Science", "categories": "cs.LG,stat.ME"}, {"arxiv_id": "2401.12375", "title": "Development of an NLP-driven computer-based test guide for visually\n  impaired students", "abstract": "In recent years, advancements in Natural Language Processing (NLP) techniques\nhave revolutionized the field of accessibility and exclusivity of testing,\nparticularly for visually impaired students (VIS). CBT has shown in years back\nits relevance in terms of administering exams electronically, making the test\nprocess easier, providing quicker and more accurate results, and offering\ngreater flexibility and accessibility for candidates. Yet, its relevance was\nnot felt by the visually impaired students as they cannot access printed\ndocuments. Hence, in this paper, we present an NLP-driven Computer-Based Test\nguide for visually impaired students. It employs a speech technology\npre-trained methods to provide real-time assistance and support to visually\nimpaired students. The system utilizes NLP technologies to convert the\ntext-based questions and the associated options in a machine-readable format.\nSubsequently, the speech technology pre-trained model processes the converted\ntext enabling the VIS to comprehend and analyze the content. Furthermore, we\nvalidated that this pre-trained model is not perverse by testing for accuracy\nusing sample audio datasets labels (A, B, C, D, E, F, G) to compare with the\nvoice recordings obtained from 20 VIS which is been predicted by the system to\nattain values for precision, recall, and F1-scores. These metrics are used to\nassess the performance of the pre-trained model and have indicated that it is\nproficient enough to give its better performance to the evaluated system. The\nmethodology adopted for this system is Object Oriented Analysis and Design\nMethodology (OOADM) where Objects are discussed and built by modeling\nreal-world instances.", "field": "Computer Science", "categories": "cs.CL,cs.AI"}, {"arxiv_id": "2401.12377", "title": "ACS: Concurrent Kernel Execution on Irregular, Input-Dependent\n  Computational Graphs", "abstract": "GPUs are widely used to accelerate many important classes of workloads today.\nHowever, we observe that several important emerging classes of workloads,\nincluding simulation engines for deep reinforcement learning and dynamic neural\nnetworks, are unable to fully utilize the massive parallelism that GPUs offer.\nThese applications tend to have kernels that are small in size, i.e., have few\nthread blocks that do not saturate compute resources. Executing independent\nkernels concurrently is a promising approach to improve parallelism and\nutilization. However, this inter-kernel concurrency is difficult to leverage in\nsuch workloads with existing approaches: First, the inter-kernel dependencies\nand computational graph are input-dependent and vary each time the application\nis executed. Second, the computational graphs tend to be irregular, requiring\nfine-grain scheduling and synchronization; thus incurring significant\nsynchronization overheads if kernel execution is parallelized. In this work, we\npropose ACS, a framework that enables lightweight detection of inter-kernel\ndependencies and low overhead kernel scheduling at runtime. The key idea behind\nACS is to perform inter-kernel dependency checks for a small window of kernels\nat runtime, similar to out-of order instruction scheduling. This enables\nconcurrent execution of kernels in applications whose computational graphs are\ninput dependent and require fine-grained scheduling. We propose ACS-SW, a\nsoftware-only open-source implementation of ACS and ACS-HW, a hardware-software\ncooperative implementation. ACS-HW further reduces synchronization overheads by\nreducing communication between the CPU and GPU. We evaluate ACS for deep RL\nsimulation and dynamic DNNs on both real hardware and a GPU simulator. We\ndemonstrate speedups of up to 2.19x (1.56x on average) by improving GPU\nutilization with concurrent kernel execution.", "field": "Computer Science", "categories": "cs.AR"}, {"arxiv_id": "2401.12379", "title": "Analyzing the Effectiveness of Large Language Models on Text-to-SQL\n  Synthesis", "abstract": "This study investigates various approaches to using Large Language Models\n(LLMs) for Text-to-SQL program synthesis, focusing on the outcomes and insights\nderived. Employing the popular Text-to-SQL dataset, spider, the goal was to\ninput a natural language question along with the database schema and output the\ncorrect SQL SELECT query. The initial approach was to fine-tune a local and\nopen-source model to generate the SELECT query. After QLoRa fine-tuning\nWizardLM's WizardCoder-15B model on the spider dataset, the execution accuracy\nfor generated queries rose to a high of 61%. With the second approach, using\nthe fine-tuned gpt-3.5-turbo-16k (Few-shot) + gpt-4-turbo (Zero-shot error\ncorrection), the execution accuracy reached a high of 82.1%. Of all the\nincorrect queries, most can be categorized into a seven different categories of\nwhat went wrong: selecting the wrong columns or wrong order of columns,\ngrouping by the wrong column, predicting the wrong values in conditionals,\nusing different aggregates than the ground truth, extra or too few JOIN\nclauses, inconsistencies in the Spider dataset, and lastly completely incorrect\nquery structure. Most if not all of the queries fall into these categories and\nit is insightful to understanding where the faults still lie with LLM program\nsynthesis and where they can be improved.", "field": "Computer Science", "categories": "cs.AI,cs.DB,cs.PL"}, {"arxiv_id": "2401.1238", "title": "A System for Human-Robot Teaming through End-User Programming and Shared\n  Autonomy", "abstract": "Many industrial tasks-such as sanding, installing fasteners, and wire\nharnessing-are difficult to automate due to task complexity and variability. We\ninstead investigate deploying robots in an assistive role for these tasks,\nwhere the robot assumes the physical task burden and the skilled worker\nprovides both the high-level task planning and low-level feedback necessary to\neffectively complete the task. In this article, we describe the development of\na system for flexible human-robot teaming that combines state-of-the-art\nmethods in end-user programming and shared autonomy and its implementation in\nsanding applications. We demonstrate the use of the system in two types of\nsanding tasks, situated in aircraft manufacturing, that highlight two potential\nworkflows within the human-robot teaming setup. We conclude by discussing\nchallenges and opportunities in human-robot teaming identified during the\ndevelopment, application, and demonstration of our system.", "field": "Computer Science", "categories": "cs.RO"}, {"arxiv_id": "2401.12382", "title": "Longitudinal Sentiment Classification of Reddit Posts", "abstract": "We report results of a longitudinal sentiment classification of Reddit posts\nwritten by students of four major Canadian universities. We work with the texts\nof the posts, concentrating on the years 2020-2023. By finely tuning a\nsentiment threshold to a range of [-0.075,0.075], we successfully built\nclassifiers proficient in categorizing post sentiments into positive and\nnegative categories. Noticeably, our sentiment classification results are\nconsistent across the four university data sets.", "field": "Computer Science", "categories": "cs.CL,cs.LG,cs.SI,I.2.6"}, {"arxiv_id": "2401.12383", "title": "A New Class of Algorithms for Finding Short Vectors in Lattices Lifted\n  from Co-dimension $k$ Codes", "abstract": "We introduce a new class of algorithms for finding a short vector in lattices\ndefined by codes of co-dimension $k$ over $\\mathbb{Z}_P^d$, where $P$ is prime.\nThe co-dimension $1$ case is solved by exploiting the packing properties of the\nprojections mod $P$ of an initial set of non-lattice vectors onto a single dual\ncodeword. The technical tools we introduce are sorting of the projections\nfollowed by single-step pairwise Euclidean reduction of the projections,\nresulting in monotonic convergence of the positive-valued projections to zero.\nThe length of vectors grows by a geometric factor each iteration. For fixed $P$\nand $d$, and large enough user-defined input sets, we show that it is possible\nto minimize the number of iterations, and thus the overall length expansion\nfactor, to obtain a short lattice vector. Thus we obtain a novel approach for\ncontrolling the output length, which resolves an open problem posed by Noah\nStephens-Davidowitz (the possibility of an approximation scheme for the\nshortest-vector problem (SVP) which does not reduce to near-exact SVP). In our\napproach, one may obtain short vectors even when the lattice dimension is quite\nlarge, e.g., 8000. For fixed $P$, the algorithm yields shorter vectors for\nlarger $d$. We additionally present a number of extensions and generalizations\nof our fundamental co-dimension $1$ method. These include a method for\nobtaining many different lattice vectors by multiplying the dual codeword by an\ninteger and then modding by $P$; a co-dimension $k$ generalization; a large\ninput set generalization; and finally, a \"block\" generalization, which involves\nthe replacement of pairwise (Euclidean) reduction by a $k$-party\n(non-Euclidean) reduction. The $k$-block generalization of our algorithm\nconstitutes a class of polynomial-time algorithms indexed by $k\\geq 2$, which\nyield successively improved approximations for the short vector problem.", "field": "Computer Science", "categories": "cs.CR,math.NT"}, {"arxiv_id": "2401.12385", "title": "On Basic Feasible Functionals and the Interpretation Method", "abstract": "The class of basic feasible functionals (BFF) is the analog of FP (polynomial\ntime functions) for type-two functionals, that is, functionals that can take\n(first-order) functions as arguments. BFF can be defined by means of oracle\nTuring machines of time bounded by a second-order polynomial. On the other\nhand, higher-order term rewriting provides an elegant formalism for expressing\nhigher-order computation. We address the problem of characterizing the class\nBFF by higher-order term rewriting. Various kinds of interpretations for\nfirst-order term rewriting have been introduced in the literature for proving\ntermination and characterizing (first-order) complexity classes. Here we\nconsider a recently introduced notion of cost-size interpretations for\nhigher-order term rewriting and see definitions as ways of computing\nfunctionals. We then prove that the class of functionals represented by\nhigher-order terms admitting a certain kind of cost-size interpretation is\nexactly BFF.", "field": "Computer Science", "categories": "cs.LO,cs.CC,F.1.3"}, {"arxiv_id": "2401.12389", "title": "Experience-Learning Inspired Two-Step Reward Method for Efficient Legged\n  Locomotion Learning Towards Natural and Robust Gaits", "abstract": "Multi-legged robots offer enhanced stability in complex terrains, yet\nautonomously learning natural and robust motions in such environments remains\nchallenging. Drawing inspiration from animals' progressive learning patterns,\nfrom simple to complex tasks, we introduce a universal two-stage learning\nframework with two-step reward setting based on self-acquired experience, which\nefficiently enables legged robots to incrementally learn natural and robust\nmovements. In the first stage, robots learn through gait-related rewards to\ntrack velocity on flat terrain, acquiring natural, robust movements and\ngenerating effective motion experience data. In the second stage, mirroring\nanimal learning from existing experiences, robots learn to navigate challenging\nterrains with natural and robust movements using adversarial imitation\nlearning. To demonstrate our method's efficacy, we trained both quadruped\nrobots and a hexapod robot, and the policy were successfully transferred to a\nphysical quadruped robot GO1, which exhibited natural gait patterns and\nremarkable robustness in various terrains.", "field": "Computer Science", "categories": "cs.RO"}, {"arxiv_id": "2401.12391", "title": "Approximation of Pufferfish Privacy for Gaussian Priors", "abstract": "This paper studies how to approximate pufferfish privacy when the adversary's\nprior belief of the published data is Gaussian distributed. Using Monge's\noptimal transport plan, we show that $(\\epsilon, \\delta)$-pufferfish privacy is\nattained if the additive Laplace noise is calibrated to the differences in mean\nand variance of the Gaussian distributions conditioned on every discriminative\nsecret pair. A typical application is the private release of the summation (or\naverage) query, for which sufficient conditions are derived for approximating\n$\\epsilon$-statistical indistinguishability in individual's sensitive data. The\nresult is then extended to arbitrary prior beliefs trained by Gaussian mixture\nmodels (GMMs): calibrating Laplace noise to a convex combination of differences\nin mean and variance between Gaussian components attains\n$(\\epsilon,\\delta)$-pufferfish privacy.", "field": "Computer Science", "categories": "cs.IT,cs.CR,math.IT"}, {"arxiv_id": "2401.12392", "title": "Evaluating Roadside Perception for Autonomous Vehicles: Insights from\n  Field Testing", "abstract": "Roadside perception systems are increasingly crucial in enhancing traffic\nsafety and facilitating cooperative driving for autonomous vehicles. Despite\nrapid technological advancements, a major challenge persists for this newly\narising field: the absence of standardized evaluation methods and benchmarks\nfor these systems. This limitation hampers the ability to effectively assess\nand compare the performance of different systems, thus constraining progress in\nthis vital field. This paper introduces a comprehensive evaluation methodology\nspecifically designed to assess the performance of roadside perception systems.\nOur methodology encompasses measurement techniques, metric selection, and\nexperimental trial design, all grounded in real-world field testing to ensure\nthe practical applicability of our approach.\n  We applied our methodology in Mcity\\footnote{\\url{https://mcity.umich.edu/}},\na controlled testing environment, to evaluate various off-the-shelf perception\nsystems. This approach allowed for an in-depth comparative analysis of their\nperformance in realistic scenarios, offering key insights into their respective\nstrengths and limitations. The findings of this study are poised to inform the\ndevelopment of industry-standard benchmarks and evaluation methods, thereby\nenhancing the effectiveness of roadside perception system development and\ndeployment for autonomous vehicles. We anticipate that this paper will\nstimulate essential discourse on standardizing evaluation methods for roadside\nperception systems, thus pushing the frontiers of this technology. Furthermore,\nour results offer both academia and industry a comprehensive understanding of\nthe capabilities of contemporary infrastructure-based perception systems.", "field": "Computer Science", "categories": "cs.RO,cs.AI"}, {"arxiv_id": "2401.12393", "title": "A Learning-based Declarative Privacy-Preserving Framework for Federated\n  Data Management", "abstract": "It is challenging to balance the privacy and accuracy for federated query\nprocessing over multiple private data silos. In this work, we will demonstrate\nan end-to-end workflow for automating an emerging privacy-preserving technique\nthat uses a deep learning model trained using the Differentially-Private\nStochastic Gradient Descent (DP-SGD) algorithm to replace portions of actual\ndata to answer a query. Our proposed novel declarative privacy-preserving\nworkflow allows users to specify \"what private information to protect\" rather\nthan \"how to protect\". Under the hood, the system automatically chooses\nquery-model transformation plans as well as hyper-parameters. At the same time,\nthe proposed workflow also allows human experts to review and tune the selected\nprivacy-preserving mechanism for audit/compliance, and optimization purposes.", "field": "Computer Science", "categories": "cs.DB,cs.AI"}, {"arxiv_id": "2401.12405", "title": "Learning Recovery Strategies for Dynamic Self-healing in Reactive\n  Systems", "abstract": "Self-healing systems depend on following a set of predefined instructions to\nrecover from a known failure state. Failure states are generally detected based\non domain specific specialized metrics. Failure fixes are applied at predefined\napplication hooks that are not sufficiently expressive to manage different\nfailure types. Self-healing is usually applied in the context of distributed\nsystems, where the detection of failures is constrained to communication\nproblems, and resolution strategies often consist of replacing complete\ncomponents. Our proposal targets complex reactive systems, defining monitors as\npredicates specifying satisfiability conditions of system properties. Such\nmonitors are functionally expressive and can be defined at run time to detect\nfailure states at any execution point. Once failure states are detected, we use\na Reinforcement Learning-based technique to learn a recovery strategy based on\nusers' corrective sequences. Finally, to execute the learned strategies, we\nextract them as COP variations that activate dynamically whenever the failure\nstate is detected, overwriting the base system behavior with the recovery\nstrategy for that state. We validate the feasibility and effectiveness of our\nframework through a prototypical reactive application for tracking mouse\nmovements, and the DeltaIoT exemplar for self-healing systems. Our results\ndemonstrate that with just the definition of monitors, the system is effective\nin detecting and recovering from failures between 55%-92% of the cases in the\nfirst application, and at par with the predefined strategies in the second\napplication.", "field": "Computer Science", "categories": "cs.DC,cs.SE"}, {"arxiv_id": "2401.12406", "title": "Enhancing In-context Learning via Linear Probe Calibration", "abstract": "In-context learning (ICL) is a new paradigm for natural language processing\nthat utilizes Generative Pre-trained Transformer (GPT)-like models. This\napproach uses prompts that include in-context demonstrations to generate the\ncorresponding output for a new query input. However, applying ICL in real cases\ndoes not scale with the number of samples, and lacks robustness to different\nprompt templates and demonstration permutations. In this paper, we first show\nthat GPT-like models using ICL result in unreliable predictions based on a new\nmetric based on Shannon entropy. Then, to solve this problem, we propose a new\ntechnique called the Linear Probe Calibration (LinC), a method that calibrates\nthe model's output probabilities, resulting in reliable predictions and\nimproved performance, while requiring only minimal additional samples (as few\nas five labeled data samples). LinC significantly enhances the ICL test\nperformance of GPT models on various benchmark datasets, with an average\nimprovement of up to 21%, and up to a 50% improvement in some cases, and\nsignificantly boosts the performance of PEFT methods, especially in the low\nresource regime. Moreover, LinC achieves lower expected calibration error, and\nis highly robust to varying label proportions, prompt templates, and\ndemonstration permutations. Our code is available at\n\\url{https://github.com/mominabbass/LinC}.", "field": "Computer Science", "categories": "cs.CL,cs.AI,cs.LG"}, {"arxiv_id": "2401.12407", "title": "Comments on finite termination of the generalized Newton method for\n  absolute value equations", "abstract": "We consider the generalized Newton method (GNM) for the absolute value\nequation (AVE) $Ax-|x|=b$. The method has finite termination property whenever\nit is convergent, no matter whether the AVE has a unique solution. We prove\nthat GNM is convergent whenever $\\rho(|A^{-1}|)<1/3$. We also present new\nresults for the case where $A-I$ is a nonsingular $M$-matrix or an irreducible\nsingular $M$-matrix. When $A-I$ is an irreducible singular $M$-matrix, the AVE\nmay have infinitely many solutions. In this case, we show that GNM always\nterminates with a uniquely identifiable solution, as long as the initial guess\nhas at least one nonpositive component.", "field": "Computer Science", "categories": "math.NA,cs.NA"}, {"arxiv_id": "2401.12412", "title": "Program Decomposition and Translation with Static Analysis", "abstract": "The rising popularity of Large Language Models (LLMs) has motivated exploring\ntheir use in code-related tasks. Code LLMs with more than millions of\nparameters are trained on a massive amount of code in different Programming\nLanguages (PLs). Such models are used for automating various Software\nEngineering (SE) tasks using prompt engineering. However, given the very large\nsize of industry-scale project files, a major issue of these LLMs is their\nlimited context window size, motivating the question of \"Can these LLMs process\nvery large files and can we effectively perform prompt engineering?\". Code\ntranslation aims to convert source code from one PL to another. In this work,\nwe assess the effect of method-level program decomposition on context window of\nLLMs and investigate how this approach can enable translation of very large\nfiles which originally could not be done due to out-of-context issue. Our\nobservations from 20 well-known java projects and approximately 60K methods\nsuggest that method-level program decomposition significantly improves the\nlimited context window problem of LLMs by 99.5%. Furthermore, our empirical\nanalysis indicate that with method-level decomposition, each input fragment on\naverage only consumes 5% of the context window, leaving more context space for\nprompt engineering and the output. Finally, we investigate the effectiveness of\na Call Graph (CG) approach for translating very large files when doing\nmethod-level program decomposition.", "field": "Computer Science", "categories": "cs.SE"}, {"arxiv_id": "2401.12413", "title": "How Far Can 100 Samples Go? Unlocking Overall Zero-Shot Multilingual\n  Translation via Tiny Multi-Parallel Data", "abstract": "Zero-shot translation is an open problem, aiming to translate between\nlanguage pairs unseen during training in Multilingual Machine Translation\n(MMT). A common, albeit resource-consuming, solution is to mine as many\ntranslation directions as possible to add to the parallel corpus. In this\npaper, we show that the zero-shot capability of an English-centric model can be\neasily enhanced by fine-tuning with a very small amount of multi-parallel data.\nFor example, on the EC30 dataset, we show that up to +21.7 ChrF non-English\noverall improvements (870 directions) can be achieved by using only 100\nmulti-parallel samples, meanwhile preserving capability in English-centric\ndirections. We further study the size effect of fine-tuning data and its\ntransfer capabilities. Surprisingly, our empirical analysis shows that\ncomparable overall improvements can be achieved even through fine-tuning in a\nsmall, randomly sampled direction set (10\\%). Also, the resulting non-English\nperformance is quite close to the upper bound (complete translation). Due to\nits high efficiency and practicality, we encourage the community 1) to consider\nthe use of the fine-tuning method as a strong baseline for zero-shot\ntranslation and 2) to construct more comprehensive and high-quality\nmulti-parallel data to cover real-world demand.", "field": "Computer Science", "categories": "cs.CL,cs.LG"}, {"arxiv_id": "2401.12414", "title": "Icy Moon Surface Simulation and Stereo Depth Estimation for Sampling\n  Autonomy", "abstract": "Sampling autonomy for icy moon lander missions requires understanding of\ntopographic and photometric properties of the sampling terrain. Unavailability\nof high resolution visual datasets (either bird-eye view or point-of-view from\na lander) is an obstacle for selection, verification or development of\nperception systems. We attempt to alleviate this problem by: 1) proposing\nGraphical Utility for Icy moon Surface Simulations (GUISS) framework, for\nversatile stereo dataset generation that spans the spectrum of bulk photometric\nproperties, and 2) focusing on a stereo-based visual perception system and\nevaluating both traditional and deep learning-based algorithms for depth\nestimation from stereo matching. The surface reflectance properties of icy moon\nterrains (Enceladus and Europa) are inferred from multispectral datasets of\nprevious missions. With procedural terrain generation and physically valid\nillumination sources, our framework can fit a wide range of hypotheses with\nrespect to visual representations of icy moon terrains. This is followed by a\nstudy over the performance of stereo matching algorithms under different visual\nhypotheses. Finally, we emphasize the standing challenges to be addressed for\nsimulating perception data assets for icy moons such as Enceladus and Europa.\nOur code can be found here: https://github.com/nasa-jpl/guiss.", "field": "Computer Science", "categories": "cs.CV,cs.GR,cs.RO"}, {"arxiv_id": "2401.12415", "title": "On enforcing non-negativity in polynomial approximations in high\n  dimensions", "abstract": "Polynomial approximations of functions are widely used in scientific\ncomputing. In certain applications, it is often desired to require the\npolynomial approximation to be non-negative (resp. non-positive), or bounded\nwithin a given range, due to constraints posed by the underlying physical\nproblems. Efficient numerical methods are thus needed to enforce such\nconditions. In this paper, we discuss effective numerical algorithms for\npolynomial approximation under non-negativity constraints. We first formulate\nthe constrained optimization problem, its primal and dual forms, and then\ndiscuss efficient first-order convex optimization methods, with a particular\nfocus on high dimensional problems. Numerical examples are provided, for up to\n$200$ dimensions, to demonstrate the effectiveness and scalability of the\nmethods.", "field": "Computer Science", "categories": "math.NA,cs.NA,42C05, 41A10, 65K10, 90C25"}, {"arxiv_id": "2401.12416", "title": "Enhancing Reliability of Neural Networks at the Edge: Inverted\n  Normalization with Stochastic Affine Transformations", "abstract": "Bayesian Neural Networks (BayNNs) naturally provide uncertainty in their\npredictions, making them a suitable choice in safety-critical applications.\nAdditionally, their realization using memristor-based in-memory computing (IMC)\narchitectures enables them for resource-constrained edge applications. In\naddition to predictive uncertainty, however, the ability to be inherently\nrobust to noise in computation is also essential to ensure functional safety.\nIn particular, memristor-based IMCs are susceptible to various sources of\nnon-idealities such as manufacturing and runtime variations, drift, and\nfailure, which can significantly reduce inference accuracy. In this paper, we\npropose a method to inherently enhance the robustness and inference accuracy of\nBayNNs deployed in IMC architectures. To achieve this, we introduce a novel\nnormalization layer combined with stochastic affine transformations. Empirical\nresults in various benchmark datasets show a graceful degradation in inference\naccuracy, with an improvement of up to $58.11\\%$.", "field": "Computer Science", "categories": "cs.LG,cs.AR,cs.ET"}, {"arxiv_id": "2401.12418", "title": "Towards Improved Variational Inference for Deep Bayesian Models", "abstract": "Deep learning has revolutionized the last decade, being at the forefront of\nextraordinary advances in a wide range of tasks including computer vision,\nnatural language processing, and reinforcement learning, to name but a few.\nHowever, it is well-known that deep models trained via maximum likelihood\nestimation tend to be overconfident and give poorly-calibrated predictions.\nBayesian deep learning attempts to address this by placing priors on the model\nparameters, which are then combined with a likelihood to perform posterior\ninference. Unfortunately, for deep models, the true posterior is intractable,\nforcing the user to resort to approximations. In this thesis, we explore the\nuse of variational inference (VI) as an approximation, as it is unique in\nsimultaneously approximating the posterior and providing a lower bound to the\nmarginal likelihood. If tight enough, this lower bound can be used to optimize\nhyperparameters and to facilitate model selection. However, this capacity has\nrarely been used to its full extent for Bayesian neural networks, likely\nbecause the approximate posteriors typically used in practice can lack the\nflexibility to effectively bound the marginal likelihood. We therefore explore\nthree aspects of Bayesian learning for deep models: 1) we ask whether it is\nnecessary to perform inference over as many parameters as possible, or whether\nit is reasonable to treat many of them as optimizable hyperparameters; 2) we\npropose a variational posterior that provides a unified view of inference in\nBayesian neural networks and deep Gaussian processes; 3) we demonstrate how VI\ncan be improved in certain deep Gaussian process models by analytically\nremoving symmetries from the posterior, and performing inference on Gram\nmatrices instead of features. We hope that our contributions will provide a\nstepping stone to fully realize the promises of VI in the future.", "field": "Computer Science", "categories": "cs.LG,stat.ML"}, {"arxiv_id": "2401.12419", "title": "Multi-modal News Understanding with Professionally Labelled Videos\n  (ReutersViLNews)", "abstract": "While progress has been made in the domain of video-language understanding,\ncurrent state-of-the-art algorithms are still limited in their ability to\nunderstand videos at high levels of abstraction, such as news-oriented videos.\nAlternatively, humans easily amalgamate information from video and language to\ninfer information beyond what is visually observable in the pixels. An example\nof this is watching a news story, where the context of the event can play as\nbig of a role in understanding the story as the event itself. Towards a\nsolution for designing this ability in algorithms, we present a large-scale\nanalysis on an in-house dataset collected by the Reuters News Agency, called\nReuters Video-Language News (ReutersViLNews) dataset which focuses on\nhigh-level video-language understanding with an emphasis on long-form news. The\nReutersViLNews Dataset consists of long-form news videos collected and labeled\nby news industry professionals over several years and contains prominent news\nreporting from around the world. Each video involves a single story and\ncontains action shots of the actual event, interviews with people associated\nwith the event, footage from nearby areas, and more. ReutersViLNews dataset\ncontains videos from seven subject categories: disaster, finance,\nentertainment, health, politics, sports, and miscellaneous with annotations\nfrom high-level to low-level, title caption, visual video description,\nhigh-level story description, keywords, and location. We first present an\nanalysis of the dataset statistics of ReutersViLNews compared to previous\ndatasets. Then we benchmark state-of-the-art approaches for four different\nvideo-language tasks. The results suggest that news-oriented videos are a\nsubstantial challenge for current video-language understanding algorithms and\nwe conclude by providing future directions in designing approaches to solve the\nReutersViLNews dataset.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.12421", "title": "AdaEmbed: Semi-supervised Domain Adaptation in the Embedding Space", "abstract": "Semi-supervised domain adaptation (SSDA) presents a critical hurdle in\ncomputer vision, especially given the frequent scarcity of labeled data in\nreal-world settings. This scarcity often causes foundation models, trained on\nextensive datasets, to underperform when applied to new domains. AdaEmbed, our\nnewly proposed methodology for SSDA, offers a promising solution to these\nchallenges. Leveraging the potential of unlabeled data, AdaEmbed facilitates\nthe transfer of knowledge from a labeled source domain to an unlabeled target\ndomain by learning a shared embedding space. By generating accurate and uniform\npseudo-labels based on the established embedding space, the model overcomes the\nlimitations of conventional SSDA, thus enhancing performance significantly. Our\nmethod's effectiveness is validated through extensive experiments on benchmark\ndatasets such as DomainNet, Office-Home, and VisDA-C, where AdaEmbed\nconsistently outperforms all the baselines, setting a new state of the art for\nSSDA. With its straightforward implementation and high data efficiency,\nAdaEmbed stands out as a robust and pragmatic solution for real-world\nscenarios, where labeled data is scarce. To foster further research and\napplication in this area, we are sharing the codebase of our unified framework\nfor semi-supervised domain adaptation.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.12422", "title": "InverseMatrixVT3D: An Efficient Projection Matrix-Based Approach for 3D\n  Occupancy Prediction", "abstract": "This paper introduces InverseMatrixVT3D, an efficient method for transforming\nmulti-view image features into 3D feature volumes for 3D semantic occupancy\nprediction. Existing methods for constructing 3D volumes often rely on depth\nestimation, device-specific operators, or transformer queries, which hinders\nthe widespread adoption of 3D occupancy models. In contrast, our approach\nleverages two projection matrices to store the static mapping relationships and\nmatrix multiplications to efficiently generate global Bird's Eye View (BEV)\nfeatures and local 3D feature volumes. Specifically, we achieve this by\nperforming matrix multiplications between multi-view image feature maps and two\nsparse projection matrices. We introduce a sparse matrix handling technique for\nthe projection matrices to optimise GPU memory usage. Moreover, a global-local\nattention fusion module is proposed to integrate the global BEV features with\nthe local 3D feature volumes to obtain the final 3D volume. We also employ a\nmulti-scale supervision mechanism to further enhance performance. Comprehensive\nexperiments on the nuScenes dataset demonstrate the simplicity and\neffectiveness of our method. The code will be made available\nat:https://github.com/DanielMing123/InverseMatrixVT3D", "field": "Computer Science", "categories": "cs.CV,cs.RO"}, {"arxiv_id": "2401.12423", "title": "Rank, Pack, or Approve: Voting Methods in Participatory Budgeting", "abstract": "Participatory budgeting is a popular method to engage residents in budgeting\ndecisions by local governments. The Stanford Participatory Budgeting platform\nis an online platform that has been used to engage residents in more than 150\nbudgeting processes. We present a data set with anonymized budget opinions from\nthese processes with K-approval, K-ranking or knapsack primary ballots. For a\nsubset of the voters, it includes paired votes with a different elicitation\nmethod in the same process. This presents a unique data set, as the voters,\nprojects and setting are all related to real-world decisions that the voters\nhave an actual interest in. With data from primary ballots we find that while\nballot complexity (number of projects to choose from, number of projects to\nselect and ballot length) is correlated with a higher median time spent by\nvoters, it is not correlated with a higher abandonment rate.\n  We use vote pairs with different voting methods to analyze the effect of\nvoting methods on the cost of selected projects, more comprehensively than was\npreviously possible. In most elections, voters selected significantly more\nexpensive projects using K-approval than using knapsack, although we also find\na small number of examples with a significant effect in the opposite direction.\nThis effect happens at the aggregate level as well as for individual voters,\nand is influenced both by the implicit constraints of the voting method and the\nexplicit constraints of the voting interface. Finally, we validate the use of\nK-ranking elicitation to offer a paper alternative for knapsack voting.", "field": "Computer Science", "categories": "cs.CY"}, {"arxiv_id": "2401.12424", "title": "DALex: Lexicase-like Selection via Diverse Aggregation", "abstract": "Lexicase selection has been shown to provide advantages over other selection\nalgorithms in several areas of evolutionary computation and machine learning.\nIn its standard form, lexicase selection filters a population or other\ncollection based on randomly ordered training cases that are considered one at\na time. This iterated filtering process can be time-consuming, particularly in\nsettings with large numbers of training cases. In this paper, we propose a new\nmethod that is nearly equivalent to lexicase selection in terms of the\nindividuals that it selects, but which does so significantly more quickly. The\nnew method, called DALex (for Diversely Aggregated Lexicase), selects the best\nindividual with respect to a weighted sum of training case errors, where the\nweights are randomly sampled. This allows us to formulate the core computation\nrequired for selection as matrix multiplication instead of recursive loops of\ncomparisons, which in turn allows us to take advantage of optimized and\nparallel algorithms designed for matrix multiplication for speedup.\nFurthermore, we show that we can interpolate between the behavior of lexicase\nselection and its \"relaxed\" variants, such as epsilon or batch lexicase\nselection, by adjusting a single hyperparameter, named \"particularity\npressure,\" which represents the importance granted to each individual training\ncase. Results on program synthesis, deep learning, symbolic regression, and\nlearning classifier systems demonstrate that DALex achieves significant\nspeedups over lexicase selection and its relaxed variants while maintaining\nalmost identical problem-solving performance. Under a fixed computational\nbudget, these savings free up resources that can be directed towards increasing\npopulation size or the number of generations, enabling the potential for\nsolving more difficult problems.", "field": "Computer Science", "categories": "cs.NE,cs.LG"}, {"arxiv_id": "2401.12425", "title": "The Neglected Tails of Vision-Language Models", "abstract": "Vision-language models (VLMs) excel in zero-shot recognition but exhibit\ndrastically imbalanced performance across visual concepts. For example, CLIP,\ndespite an impressive mean zero-shot accuracy on ImageNet (72.7%), yields\n$<$10% on ten concepts (e.g., gyromitra and night snake), presumably, because\nthese concepts are under-represented in VLMs' imbalanced pretraining data. Yet,\nassessing this imbalance is challenging as it is non-trivial to calculate the\nfrequency of specific concepts within VLMs' large-scale pretraining data. Our\nwork makes the first attempt to measure the concept frequency by analyzing\npretraining texts. We use off-the-shelf language models to help count relevant\ntexts that contain synonyms of the given concepts and resolve linguistic\nambiguity. We confirm that popular VLM datasets like LAION indeed exhibit\nlong-tailed concept distributions, which strongly correlate with per-class\naccuracies. Further, contemporary multimodal systems, e.g., visual chatbots and\ntext-to-image generators, also struggle with the rare concepts identified by\nour method. To mitigate VLMs' imbalanced performance in zero-shot recognition,\nwe propose REtrieval-Augmented Learning REAL. First, instead of prompting VLMs\nusing the original class names, REAL uses their most frequent synonyms found in\nVLMs' pretraining texts. This already outperforms human-engineered and\nLLM-generated prompts over nine benchmark datasets, likely because VLMs have\nseen more images associated with the frequently used synonyms. Second, REAL\nuses all the concept synonyms to retrieve a small, class-balanced set of\npretraining data to train a robust classifier. REAL surpasses the recent\nretrieval-augmented solution REACT, using 400x less storage and 10,000x less\ntraining time!", "field": "Computer Science", "categories": "cs.CV,cs.CL,cs.LG"}, {"arxiv_id": "2401.12427", "title": "Order Conditions for Nonlinearly Partitioned Runge-Kutta Methods", "abstract": "Recently a new class of nonlinearly partitioned Runge-Kutta (NPRK) methods\nwas proposed for nonlinearly partitioned systems of ordinary differential\nequations, $y' = F(y,y)$. The target class of problems are ones in which\ndifferent scales, stiffnesses, or physics are coupled in a nonlinear way,\nwherein the desired partition cannot be written in a classical additive or\ncomponent-wise fashion. Here we use rooted-tree analysis to derive full order\nconditions for NPRK$_M$ methods, where $M$ denotes the number of nonlinear\npartitions. Due to the nonlinear coupling and thereby mixed product\ndifferentials, it turns out the standard node-colored rooted-tree analysis used\nin analyzing ODE integrators does not naturally apply. Instead we develop a new\nedge-colored rooted-tree framework to address the nonlinear coupling. The\nresulting order conditions are enumerated, provided directly for up to 4th\norder with $M=2$ and 3rd-order with $M=3$, and related to existing order\nconditions of additive and partitioned RK methods.", "field": "Computer Science", "categories": "math.NA,cs.NA"}, {"arxiv_id": "2401.12428", "title": "CIM-MLC: A Multi-level Compilation Stack for Computing-In-Memory\n  Accelerators", "abstract": "In recent years, various computing-in-memory (CIM) processors have been\npresented, showing superior performance over traditional architectures. To\nunleash the potential of various CIM architectures, such as device precision,\ncrossbar size, and crossbar number, it is necessary to develop compilation\ntools that are fully aware of the CIM architectural details and implementation\ndiversity. However, due to the lack of architectural support in current popular\nopen-source compiling stacks, existing CIM designs either manually deploy\nnetworks or build their own compilers, which is time-consuming and\nlabor-intensive. Although some works expose the specific CIM device programming\ninterfaces to compilers, they are often bound to a fixed CIM architecture,\nlacking the flexibility to support the CIM architectures with different\ncomputing granularity. On the other hand, existing compilation works usually\nconsider the scheduling of limited operation types (such as crossbar-bound\nmatrix-vector multiplication). Unlike conventional processors, CIM accelerators\nare featured by their diverse architecture, circuit, and device, which cannot\nbe simply abstracted by a single level if we seek to fully explore the\nadvantages brought by CIM. Therefore, we propose CIM-MLC, a universal\nmulti-level compilation framework for general CIM architectures. We first\nestablish a general hardware abstraction for CIM architectures and computing\nmodes to represent various CIM accelerators. Based on the proposed abstraction,\nCIM-MLC can compile tasks onto a wide range of CIM accelerators having\ndifferent devices, architectures, and programming interfaces. More importantly,\ncompared with existing compilation work, CIM-MLC can explore the mapping and\nscheduling strategies across multiple architectural tiers, which form a\ntractable yet effective design space, to achieve better scheduling and\ninstruction generation results.", "field": "Computer Science", "categories": "cs.AR,cs.CL,D.3.4"}, {"arxiv_id": "2401.12433", "title": "A Novel Garment Transfer Method Supervised by Distilled Knowledge of\n  Virtual Try-on Model", "abstract": "When a shopper chooses garments online, garment transfer technology wears the\ngarment from the model image onto the shopper's image, allowing the shopper to\ndecide whether the garment is suitable for them. As garment transfer leverages\nwild and cheap person image as garment condition, it has attracted tremendous\ncommunity attention and holds vast commercial potential. However, since the\nground truth of garment transfer is almost unavailable in reality, previous\nstudies have treated garment transfer as either pose transfer or garment-pose\ndisentanglement, and trained garment transfer in self-supervised learning, yet\ndo not cover garment transfer intentions completely. Therefore, the training\nsupervising the garment transfer is a rock-hard issue. Notably, virtual try-on\ntechnology has exhibited superior performance using self-supervised learning.\nWe supervise the garment transfer training via knowledge distillation from\nvirtual try-on. Specifically, we first train the transfer parsing reasoning\nmodel at multi-phases to provide shape guidance for downstream tasks. The\ntransfer parsing reasoning model learns the response and feature knowledge from\nthe try-on parsing reasoning model and absorbs the hard knowledge from the\nground truth. By leveraging the warping knowledge from virtual try-on, we\nestimate a progressive flow to precisely warp the garment by learning the shape\nand content correspondence. To enhance transfer realism, we propose a\nwell-designed arm regrowth task to infer exposed skin pixel content.\nExperiments demonstrate that our method has state-of-the-art performance in\ntransferring garments between person compared with other virtual try-on and\ngarment transfer methods.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.12435", "title": "Quantitative Analysis of Molecular Transport in the Extracellular Space\n  Using Physics-Informed Neural Network", "abstract": "The brain extracellular space (ECS), an irregular, extremely tortuous\nnanoscale space located between cells or between cells and blood vessels, is\ncrucial for nerve cell survival. It plays a pivotal role in high-level brain\nfunctions such as memory, emotion, and sensation. However, the specific form of\nmolecular transport within the ECS remain elusive. To address this challenge,\nthis paper proposes a novel approach to quantitatively analyze the molecular\ntransport within the ECS by solving an inverse problem derived from the\nadvection-diffusion equation (ADE) using a physics-informed neural network\n(PINN). PINN provides a streamlined solution to the ADE without the need for\nintricate mathematical formulations or grid settings. Additionally, the\noptimization of PINN facilitates the automatic computation of the diffusion\ncoefficient governing long-term molecule transport and the velocity of\nmolecules driven by advection. Consequently, the proposed method allows for the\nquantitative analysis and identification of the specific pattern of molecular\ntransport within the ECS through the calculation of the Peclet number.\nExperimental validation on two datasets of magnetic resonance images (MRIs)\ncaptured at different time points showcases the effectiveness of the proposed\nmethod. Notably, our simulations reveal identical molecular transport patterns\nbetween datasets representing rats with tracer injected into the same brain\nregion. These findings highlight the potential of PINN as a promising tool for\ncomprehensively exploring molecular transport within the ECS.", "field": "Computer Science", "categories": "cs.AI,cs.LG,math.AP"}, {"arxiv_id": "2401.12436", "title": "Wasserstein Differential Privacy", "abstract": "Differential privacy (DP) has achieved remarkable results in the field of\nprivacy-preserving machine learning. However, existing DP frameworks do not\nsatisfy all the conditions for becoming metrics, which prevents them from\nderiving better basic private properties and leads to exaggerated values on\nprivacy budgets. We propose Wasserstein differential privacy (WDP), an\nalternative DP framework to measure the risk of privacy leakage, which\nsatisfies the properties of symmetry and triangle inequality. We show and prove\nthat WDP has 13 excellent properties, which can be theoretical supports for the\nbetter performance of WDP than other DP frameworks. In addition, we derive a\ngeneral privacy accounting method called Wasserstein accountant, which enables\nWDP to be applied in stochastic gradient descent (SGD) scenarios containing\nsub-sampling. Experiments on basic mechanisms, compositions and deep learning\nshow that the privacy budgets obtained by Wasserstein accountant are relatively\nstable and less influenced by order. Moreover, the overestimation on privacy\nbudgets can be effectively alleviated. The code is available at\nhttps://github.com/Hifipsysta/WDP.", "field": "Computer Science", "categories": "cs.LG,cs.CR"}, {"arxiv_id": "2401.12437", "title": "Convex-Concave Zero-sum Markov Stackelberg Games", "abstract": "Zero-sum Markov Stackelberg games can be used to model myriad problems, in\ndomains ranging from economics to human robot interaction. In this paper, we\ndevelop policy gradient methods that solve these games in continuous state and\naction settings using noisy gradient estimates computed from observed\ntrajectories of play. When the games are convex-concave, we prove that our\nalgorithms converge to Stackelberg equilibrium in polynomial time. We also show\nthat reach-avoid problems are naturally modeled as convex-concave zero-sum\nMarkov Stackelberg games, and that Stackelberg equilibrium policies are more\neffective than their Nash counterparts in these problems.", "field": "Computer Science", "categories": "cs.GT"}, {"arxiv_id": "2401.12439", "title": "MAST: Video Polyp Segmentation with a Mixture-Attention Siamese\n  Transformer", "abstract": "Accurate segmentation of polyps from colonoscopy videos is of great\nsignificance to polyp treatment and early prevention of colorectal cancer.\nHowever, it is challenging due to the difficulties associated with modelling\nlong-range spatio-temporal relationships within a colonoscopy video. In this\npaper, we address this challenging task with a novel Mixture-Attention Siamese\nTransformer (MAST), which explicitly models the long-range spatio-temporal\nrelationships with a mixture-attention mechanism for accurate polyp\nsegmentation. Specifically, we first construct a Siamese transformer\narchitecture to jointly encode paired video frames for their feature\nrepresentations. We then design a mixture-attention module to exploit the\nintra-frame and inter-frame correlations, enhancing the features with rich\nspatio-temporal relationships. Finally, the enhanced features are fed to two\nparallel decoders for predicting the segmentation maps. To the best of our\nknowledge, our MAST is the first transformer model dedicated to video polyp\nsegmentation. Extensive experiments on the large-scale SUN-SEG benchmark\ndemonstrate the superior performance of MAST in comparison with the\ncutting-edge competitors. Our code is publicly available at\nhttps://github.com/Junqing-Yang/MAST.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.12443", "title": "Patch2QL: Discover Cognate Defects in Open Source Software Supply Chain\n  With Auto-generated Static Analysis Rules", "abstract": "In the open source software (OSS) ecosystem, there exists a complex software\nsupply chain, where developers upstream and downstream widely borrow and reuse\ncode. This results in the widespread occurrence of recurring defects, missing\nfixes, and propagation issues. These are collectively referred to as cognate\ndefects, and their scale and threats have not received extensive attention and\nsystematic research. Software composition analysis and code clone detection\nmethods are unable to cover the various variant issues in the supply chain\nscenario, while code static analysis, or static application security testing\n(SAST) techniques struggle to target specific defects. In this paper, we\npropose a novel technique for detecting cognate defects in OSS through the\nautomatic generation of SAST rules. Specifically, it extracts key syntax and\nsemantic information from pre- and post-patch versions of code through\nstructural comparison and control flow to data flow analysis, and generates\nrules that matches these key elements. We have implemented a prototype tool\ncalled Patch2QL and applied it to fundamental OSS in C/C++. In experiments, we\ndiscovered 7 new vulnerabilities with medium to critical severity in the most\npopular upstream software, as well as numerous potential security issues. When\nanalyzing downstream projects in the supply chain, we found a significant\nnumber of representative cognate defects, clarifying the threat posed by this\nissue. Additionally, compared to general-purpose SAST and signature-based\nmechanisms, the generated rules perform better at discover all variants of\ncognate defects.", "field": "Computer Science", "categories": "cs.CR,cs.SE"}, {"arxiv_id": "2401.12445", "title": "Session-level Normalization and Click-through Data Enhancement for\n  Session-based Evaluation", "abstract": "Since a user usually has to issue a sequence of queries and examine multiple\ndocuments to resolve a complex information need in a search session,\nresearchers have paid much attention to evaluating search systems at the\nsession level rather than the single-query level. Most existing session-level\nmetrics evaluate each query separately and then aggregate the query-level\nscores using a session-level weighting function. The assumptions behind these\nmetrics are that all queries in the session should be involved, and their\norders are fixed. However, if a search system could make the user satisfied\nwith her first few queries, she may not need any subsequent queries. Besides,\nin most real-world search scenarios, due to a lack of explicit feedback from\nreal users, we can only leverage some implicit feedback, such as users' clicks,\nas relevance labels for offline evaluation. Such implicit feedback might be\ndifferent from the real relevance in a search session as some documents may be\nomitted in the previous query but identified in the later reformulations. To\naddress the above issues, we make two assumptions about session-based\nevaluation, which explicitly describe an ideal session-search system and how to\nenhance click-through data in computing session-level evaluation metrics. Based\non our assumptions, we design a session-level metric called Normalized\nU-Measure (NUM). NUM evaluates a session as a whole and utilizes an ideal\nsession to normalize the result of the actual session. Besides, it infers\nsession-level relevance labels based on implicit feedback. Experiments on two\npublic datasets demonstrate the effectiveness of NUM by comparing it with\nexisting session-based metrics in terms of correlation with user satisfaction\nand intuitiveness. We also conduct ablation studies to explore whether these\nassumptions hold.", "field": "Computer Science", "categories": "cs.IR"}, {"arxiv_id": "2401.12447", "title": "NIV-SSD: Neighbor IoU-Voting Single-Stage Object Detector From Point\n  Cloud", "abstract": "Previous single-stage detectors typically suffer the misalignment between\nlocalization accuracy and classification confidence. To solve the misalignment\nproblem, we introduce a novel rectification method named neighbor IoU-voting\n(NIV) strategy. Typically, classification and regression are treated as\nseparate branches, making it challenging to establish a connection between\nthem. Consequently, the classification confidence cannot accurately reflect the\nregression quality. NIV strategy can serve as a bridge between classification\nand regression branches by calculating two types of statistical data from the\nregression output to correct the classification confidence. Furthermore, to\nalleviate the imbalance of detection accuracy for complete objects with dense\npoints (easy objects) and incomplete objects with sparse points (difficult\nobjects), we propose a new data augmentation scheme named object resampling. It\nundersamples easy objects and oversamples difficult objects by randomly\ntransforming part of easy objects into difficult objects. Finally, combining\nthe NIV strategy and object resampling augmentation, we design an efficient\nsingle-stage detector termed NIV-SSD. Extensive experiments on several datasets\nindicate the effectiveness of the NIV strategy and the competitive performance\nof the NIV-SSD detector. The code will be available at\nhttps://github.com/Say2L/NIV-SSD.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.12451", "title": "Methods and strategies for improving the novel view synthesis quality of\n  neural radiation field", "abstract": "Neural Radiation Field (NeRF) technology can learn a 3D implicit model of a\nscene from 2D images and synthesize realistic novel view images. This\ntechnology has received widespread attention from the industry and has good\napplication prospects. In response to the problem that the rendering quality of\nNeRF images needs to be improved, many researchers have proposed various\nmethods to improve the rendering quality in the past three years. The latest\nrelevant papers are classified and reviewed, the technical principles behind\nquality improvement are analyzed, and the future evolution direction of quality\nimprovement methods is discussed. This study can help researchers quickly\nunderstand the current state and evolutionary context of technology in this\nfield, which is helpful in inspiring the development of more efficient\nalgorithms and promoting the application of NeRF technology in related fields.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.12452", "title": "Self-supervised Learning of LiDAR 3D Point Clouds via 2D-3D Neural\n  Calibration", "abstract": "This paper introduces a novel self-supervised learning framework for\nenhancing 3D perception in autonomous driving scenes. Specifically, our\napproach, named NCLR, focuses on 2D-3D neural calibration, a novel pretext task\nthat estimates the rigid transformation aligning camera and LiDAR coordinate\nsystems. First, we propose the learnable transformation alignment to bridge the\ndomain gap between image and point cloud data, converting features into a\nunified representation space for effective comparison and matching. Second, we\nidentify the overlapping area between the image and point cloud with the fused\nfeatures. Third, we establish dense 2D-3D correspondences to estimate the rigid\ntransformation. The framework not only learns fine-grained matching from points\nto pixels but also achieves alignment of the image and point cloud at a\nholistic level, understanding their relative pose. We demonstrate NCLR's\nefficacy by applying the pre-trained backbone to downstream tasks, such as\nLiDAR-based 3D semantic segmentation, object detection, and panoptic\nsegmentation. Comprehensive experiments on various datasets illustrate the\nsuperiority of NCLR over existing self-supervised methods. The results confirm\nthat joint learning from different modalities significantly enhances the\nnetwork's understanding abilities and effectiveness of learned representation.\nCode will be available at \\url{https://github.com/Eaphan/NCLR}.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.12453", "title": "\"The teachers are confused as well\": A Multiple-Stakeholder Ethics\n  Discussion on Large Language Models in Computing Education", "abstract": "Large Language Models (LLMs) are advancing quickly and impacting people's\nlives for better or worse. In higher education, concerns have emerged such as\nstudents' misuse of LLMs and degraded education outcomes. To unpack the ethical\nconcerns of LLMs for higher education, we conducted a case study consisting of\nstakeholder interviews (n=20) in higher education computer science. We found\nthat students use several distinct mental models to interact with LLMs - LLMs\nserve as a tool for (a) writing, (b) coding, and (c) information retrieval,\nwhich differ somewhat in ethical considerations. Students and teachers brought\nup ethical issues that directly impact them, such as inaccurate LLM responses,\nhallucinations, biases, privacy leakage, and academic integrity issues.\nParticipants emphasized the necessity of guidance and rules for the use of LLMs\nin higher education, including teaching digital literacy, rethinking education,\nand having cautious and contextual policies. We reflect on the ethical\nchallenges and propose solutions.", "field": "Computer Science", "categories": "cs.CY,cs.HC"}, {"arxiv_id": "2401.12455", "title": "Multi-agent deep reinforcement learning with centralized training and\n  decentralized execution for transportation infrastructure management", "abstract": "We present a multi-agent Deep Reinforcement Learning (DRL) framework for\nmanaging large transportation infrastructure systems over their life-cycle.\nLife-cycle management of such engineering systems is a computationally\nintensive task, requiring appropriate sequential inspection and maintenance\ndecisions able to reduce long-term risks and costs, while dealing with\ndifferent uncertainties and constraints that lie in high-dimensional spaces. To\ndate, static age- or condition-based maintenance methods and risk-based or\nperiodic inspection plans have mostly addressed this class of optimization\nproblems. However, optimality, scalability, and uncertainty limitations are\noften manifested under such approaches. The optimization problem in this work\nis cast in the framework of constrained Partially Observable Markov Decision\nProcesses (POMDPs), which provides a comprehensive mathematical basis for\nstochastic sequential decision settings with observation uncertainties, risk\nconsiderations, and limited resources. To address significantly large state and\naction spaces, a Deep Decentralized Multi-agent Actor-Critic (DDMAC) DRL method\nwith Centralized Training and Decentralized Execution (CTDE), termed as\nDDMAC-CTDE is developed. The performance strengths of the DDMAC-CTDE method are\ndemonstrated in a generally representative and realistic example application of\nan existing transportation network in Virginia, USA. The network includes\nseveral bridge and pavement components with nonstationary degradation,\nagency-imposed constraints, and traffic delay and risk considerations. Compared\nto traditional management policies for transportation networks, the proposed\nDDMAC-CTDE method vastly outperforms its counterparts. Overall, the proposed\nalgorithmic framework provides near optimal solutions for transportation\ninfrastructure management under real-world constraints and complexities.", "field": "Computer Science", "categories": "cs.MA,cs.AI,cs.LG,cs.SY,eess.SY"}, {"arxiv_id": "2401.12456", "title": "Exploration and Improvement of Nerf-based 3D Scene Editing Techniques", "abstract": "NeRF's high-quality scene synthesis capability was quickly accepted by\nscholars in the years after it was proposed, and significant progress has been\nmade in 3D scene representation and synthesis. However, the high computational\ncost limits intuitive and efficient editing of scenes, making NeRF's\ndevelopment in the scene editing field facing many challenges. This paper\nreviews the preliminary explorations of scholars on NeRF in the scene or object\nediting field in recent years, mainly changing the shape and texture of scenes\nor objects in new synthesized scenes; through the combination of residual\nmodels such as GaN and Transformer with NeRF, the generalization ability of\nNeRF scene editing has been further expanded, including realizing real-time new\nperspective editing feedback, multimodal editing of text synthesized 3D scenes,\n4D synthesis performance, and in-depth exploration in light and shadow editing,\ninitially achieving optimization of indirect touch editing and detail\nrepresentation in complex scenes. Currently, most NeRF editing methods focus on\nthe touch points and materials of indirect points, but when dealing with more\ncomplex or larger 3D scenes, it is difficult to balance accuracy, breadth,\nefficiency, and quality. Overcoming these challenges may become the direction\nof future NeRF 3D scene editing technology.", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.GR"}, {"arxiv_id": "2401.12459", "title": "Towards Socially and Morally Aware RL agent: Reward Design With LLM", "abstract": "When we design and deploy an Reinforcement Learning (RL) agent, reward\nfunctions motivates agents to achieve an objective. An incorrect or incomplete\nspecification of the objective can result in behavior that does not align with\nhuman values - failing to adhere with social and moral norms that are ambiguous\nand context dependent, and cause undesired outcomes such as negative side\neffects and exploration that is unsafe. Previous work have manually defined\nreward functions to avoid negative side effects, use human oversight for safe\nexploration, or use foundation models as planning tools. This work studies the\nability of leveraging Large Language Models (LLM)' understanding of morality\nand social norms on safe exploration augmented RL methods. This work evaluates\nlanguage model's result against human feedbacks and demonstrates language\nmodel's capability as direct reward signals.", "field": "Computer Science", "categories": "cs.AI"}, {"arxiv_id": "2401.12461", "title": "Fast Adversarial Training against Textual Adversarial Attacks", "abstract": "Many adversarial defense methods have been proposed to enhance the\nadversarial robustness of natural language processing models. However, most of\nthem introduce additional pre-set linguistic knowledge and assume that the\nsynonym candidates used by attackers are accessible, which is an ideal\nassumption. We delve into adversarial training in the embedding space and\npropose a Fast Adversarial Training (FAT) method to improve the model\nrobustness in the synonym-unaware scenario from the perspective of single-step\nperturbation generation and perturbation initialization. Based on the\nobservation that the adversarial perturbations crafted by single-step and\nmulti-step gradient ascent are similar, FAT uses single-step gradient ascent to\ncraft adversarial examples in the embedding space to expedite the training\nprocess. Based on the observation that the perturbations generated on the\nidentical training sample in successive epochs are similar, FAT fully utilizes\nhistorical information when initializing the perturbation. Extensive\nexperiments demonstrate that FAT significantly boosts the robustness of BERT\nmodels in the synonym-unaware scenario, and outperforms the defense baselines\nunder various attacks with character-level and word-level modifications.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.12464", "title": "Estimation of posture and joint angle of human body using foot pressure\n  distribution: Morphological computation with human foot", "abstract": "This paper proposes a novel contact and wearable sensing system for\nestimating the upper body posture and joint angles (ankle, knee, and hip) of\nthe human body using foot pressure distribution information obtained from a\nsensor attached to the plantar region. In the proposed estimation method,\nsensors are installed only on the plantar region, which is the end of the human\nbody and the point of contact with the environment. The posture and joint\nangles of other parts of the body are estimated using only this information. As\na contact and wearable sensor, the proposed system differs from previous\nmeasurement systems in the sense that the sensor does not need to be placed\nnear the target joint or body. The estimation was carried out using a\nmultivariate linear regression model with the foot pressure distribution as the\ninput and the joint angle or posture as the output. The results reveal that it\nis possible to estimate the posture and joint angles of the human body from\nfoot pressure distribution information (R2$\\fallingdotseq$0.9). The proposed\nestimation method was validated by morphological computation to confirm that it\nis enabled by foot morphology. The validation approach compared the estimation\naccuracy achieved when an object was interposed between the foot pressure\ndistribution sensor and the plantar region and the morphological relationship\nof the plantar region to the environment varied. The results reveal that there\nis a significant difference in the estimation accuracy between cases with and\nwithout an intervening object, suggesting that the morphology of the plantar\nregion contributes to the estimation. Furthermore, the proposed estimation\nmethod is considered as physical reservoir computing, wherein the human foot is\nused as a computational resource.", "field": "Computer Science", "categories": "cs.HC,cs.RO"}, {"arxiv_id": "2401.12467", "title": "An open dataset for the evolution of oracle bone characters: EVOBC", "abstract": "The earliest extant Chinese characters originate from oracle bone\ninscriptions, which are closely related to other East Asian languages. These\ninscriptions hold immense value for anthropology and archaeology. However,\ndeciphering oracle bone script remains a formidable challenge, with only\napproximately 1,600 of the over 4,500 extant characters elucidated to date.\nFurther scholarly investigation is required to comprehensively understand this\nancient writing system. Artificial Intelligence technology is a promising\navenue for deciphering oracle bone characters, particularly concerning their\nevolution. However, one of the challenges is the lack of datasets mapping the\nevolution of these characters over time. In this study, we systematically\ncollected ancient characters from authoritative texts and websites spanning six\nhistorical stages: Oracle Bone Characters - OBC (15th century B.C.), Bronze\nInscriptions - BI (13th to 221 B.C.), Seal Script - SS (11th to 8th centuries\nB.C.), Spring and Autumn period Characters - SAC (770 to 476 B.C.), Warring\nStates period Characters - WSC (475 B.C. to 221 B.C.), and Clerical Script - CS\n(221 B.C. to 220 A.D.). Subsequently, we constructed an extensive dataset,\nnamely EVolution Oracle Bone Characters (EVOBC), consisting of 229,170 images\nrepresenting 13,714 distinct character categories. We conducted validation and\nsimulated deciphering on the constructed dataset, and the results demonstrate\nits high efficacy in aiding the study of oracle bone script. This openly\naccessible dataset aims to digitalize ancient Chinese scripts across multiple\neras, facilitating the decipherment of oracle bone script by examining the\nevolution of glyph forms.", "field": "Computer Science", "categories": "cs.AI"}, {"arxiv_id": "2401.12468", "title": "Minimum observability of probabilistic Boolean networks", "abstract": "This paper studies the minimum observability of probabilistic Boolean\nnetworks (PBNs), the main objective of which is to add the fewest measurements\nto make an unobservable PBN become observable. First of all, the algebraic form\nof a PBN is established with the help of semi-tensor product (STP) of matrices.\nBy combining the algebraic forms of two identical PBNs into a parallel system,\na method to search the states that need to be H-distinguishable is proposed\nbased on the robust set reachability technique. Secondly, a necessary and\nsufficient condition is given to find the minimum measurements such that a\ngiven set can be H-distinguishable. Moreover, by comparing the numbers of\nmeasurements for all the feasible H-distinguishable state sets, the least\nmeasurements that make the system observable are gained. Finally, an example is\ngiven to verify the validity of the obtained results.", "field": "Computer Science", "categories": "eess.SY,cs.SY"}, {"arxiv_id": "2401.1247", "title": "Reinforcement Learning for Graph Coloring: Understanding the Power and\n  Limits of Non-Label Invariant Representations", "abstract": "Register allocation is one of the most important problems for modern\ncompilers. With a practically unlimited number of user variables and a small\nnumber of CPU registers, assigning variables to registers without conflicts is\na complex task. This work demonstrates the use of casting the register\nallocation problem as a graph coloring problem. Using technologies such as\nPyTorch and OpenAI Gymnasium Environments we will show that a Proximal Policy\nOptimization model can learn to solve the graph coloring problem. We will also\nshow that the labeling of a graph is critical to the performance of the model\nby taking the matrix representation of a graph and permuting it. We then test\nthe model's effectiveness on each of these permutations and show that it is not\neffective when given a relabeling of the same graph. Our main contribution lies\nin showing the need for label reordering invariant representations of graphs\nfor machine learning models to achieve consistent performance.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.12471", "title": "Zero Shot Open-ended Video Inference", "abstract": "Zero-shot open-ended inference on untrimmed videos poses a significant\nchallenge, especially when no annotated data is utilized to navigate the\ninference direction. In this work, we aim to address this underexplored domain\nby introducing an adaptable framework that efficiently combines both the frozen\nvision-language (VL) model and off-the-shelf large language model (LLM) for\nconducting zero-shot open-ended inference tasks without requiring any\nadditional training or fine-tuning. Our comprehensive experiments span various\nvideo action datasets for goal inference and action recognition tasks. The\nresults demonstrate the framework's superior performance in goal inference\ncompared to conventional vision-language models in open-ended and close-ended\nscenarios. Notably, the proposed framework exhibits the capability to\ngeneralize effectively to action recognition tasks, underscoring its\nversatility and potential contributions to advancing the video-based zero-shot\nunderstanding.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.12472", "title": "Contrastive Learning in Distilled Models", "abstract": "Natural Language Processing models like BERT can provide state-of-the-art\nword embeddings for downstream NLP tasks. However, these models yet to perform\nwell on Semantic Textual Similarity, and may be too large to be deployed as\nlightweight edge applications. We seek to apply a suitable contrastive learning\nmethod based on the SimCSE paper, to a model architecture adapted from a\nknowledge distillation based model, DistilBERT, to address these two issues.\nOur final lightweight model DistilFace achieves an average of 72.1 in\nSpearman's correlation on STS tasks, a 34.2 percent improvement over BERT base.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.12474", "title": "Large Language Models are Superpositions of All Characters: Attaining\n  Arbitrary Role-play via Self-Alignment", "abstract": "Considerable efforts have been invested in augmenting the role-playing\nproficiency of open-source large language models (LLMs) by emulating\nproprietary counterparts. Nevertheless, we posit that LLMs inherently harbor\nrole-play capabilities, owing to the extensive knowledge of characters and\npotential dialogues ingrained in their vast training corpora. Thus, in this\nstudy, we introduce Ditto, a self-alignment method for role-play. Ditto\ncapitalizes on character knowledge, encouraging an instruction-following LLM to\nsimulate role-play dialogues as a variant of reading comprehension. This method\ncreates a role-play training set comprising 4,000 characters, surpassing the\nscale of currently available datasets by tenfold regarding the number of roles.\nSubsequently, we fine-tune the LLM using this self-generated dataset to augment\nits role-playing capabilities. Upon evaluating our meticulously constructed and\nreproducible role-play benchmark and the roleplay subset of MT-Bench, Ditto, in\nvarious parameter scales, consistently maintains a consistent role identity and\nprovides accurate role-specific knowledge in multi-turn role-play\nconversations. Notably, it outperforms all open-source role-play baselines,\nshowcasing performance levels comparable to advanced proprietary chatbots.\nFurthermore, we present the first comprehensive cross-supervision alignment\nexperiment in the role-play domain, revealing that the intrinsic capabilities\nof LLMs confine the knowledge within role-play. Meanwhile, the role-play styles\ncan be easily acquired with the guidance of smaller models. We open-source\nrelated resources at https://github.com/OFA-Sys/Ditto.", "field": "Computer Science", "categories": "cs.CL,cs.LG"}, {"arxiv_id": "2401.12478", "title": "Mini-batch Submodular Maximization", "abstract": "We present the first mini-batch algorithm for maximizing a non-negative\nmonotone decomposable submodular function, $F=\\sum_{i=1}^N f^i$, under a set of\nconstraints. We improve over the sparsifier based approach both in theory and\nin practice. We experimentally observe that our algorithm generates solutions\nthat are far superior to those generated by the sparsifier based approach.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.DS"}, {"arxiv_id": "2401.12479", "title": "TD^2-Net: Toward Denoising and Debiasing for Dynamic Scene Graph\n  Generation", "abstract": "Dynamic scene graph generation (SGG) focuses on detecting objects in a video\nand determining their pairwise relationships. Existing dynamic SGG methods\nusually suffer from several issues, including 1) Contextual noise, as some\nframes might contain occluded and blurred objects. 2) Label bias, primarily due\nto the high imbalance between a few positive relationship samples and numerous\nnegative ones. Additionally, the distribution of relationships exhibits a\nlong-tailed pattern. To address the above problems, in this paper, we introduce\na network named TD$^2$-Net that aims at denoising and debiasing for dynamic\nSGG. Specifically, we first propose a denoising spatio-temporal transformer\nmodule that enhances object representation with robust contextual information.\nThis is achieved by designing a differentiable Top-K object selector that\nutilizes the gumbel-softmax sampling strategy to select the relevant\nneighborhood for each object. Second, we introduce an asymmetrical reweighting\nloss to relieve the issue of label bias. This loss function integrates\nasymmetry focusing factors and the volume of samples to adjust the weights\nassigned to individual samples. Systematic experimental results demonstrate the\nsuperiority of our proposed TD$^2$-Net over existing state-of-the-art\napproaches on Action Genome databases. In more detail, TD$^2$-Net outperforms\nthe second-best competitors by 12.7 \\% on mean-Recall@10 for predicate\nclassification.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.1248", "title": "Explore Synergistic Interaction Across Frames for Interactive Video\n  Object Segmentation", "abstract": "Interactive Video Object Segmentation (iVOS) is a challenging task that\nrequires real-time human-computer interaction. To improve the user experience,\nit is important to consider the user's input habits, segmentation quality,\nrunning time and memory consumption.However, existing methods compromise user\nexperience with single input mode and slow running speed. Specifically, these\nmethods only allow the user to interact with one single frame, which limits the\nexpression of the user's intent.To overcome these limitations and better align\nwith people's usage habits, we propose a framework that can accept multiple\nframes simultaneously and explore synergistic interaction across frames (SIAF).\nConcretely, we designed the Across-Frame Interaction Module that enables users\nto annotate different objects freely on multiple frames. The AFI module will\nmigrate scribble information among multiple interactive frames and generate\nmulti-frame masks. Additionally, we employ the id-queried mechanism to process\nmultiple objects in batches. Furthermore, for a more efficient propagation and\nlightweight model, we design a truncated re-propagation strategy to replace the\nprevious multi-round fusion module, which employs an across-round memory that\nstores important interaction information. Our SwinB-SIAF achieves new\nstate-of-the-art performance on DAVIS 2017 (89.6%, J&F@60). Moreover, our\nR50-SIAF is more than 3 faster than the state-of-the-art competitor under\nchallenging multi-object scenarios.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.12481", "title": "AIRS-assisted Vehicular Networks with Rate-Splitting SWIPT Receivers:\n  Joint Trajectory and Communication Design", "abstract": "In this correspondence, we propose to use an intelligent reflective surface\n(IRS) installed on unmanned aerial vehicle (UAV), referred to as aerial IRS\n(AIRS), for vehicular networks, where simultaneous wireless information and\npower transfer (SWIPT) receivers to concurrently allow information decoding\n(ID) and energy harvesting (EH) are equipped at the battery-limited vehicles.\nFor efficiently supporting the multiple moving vehicles, we adopt\nrate-splitting multiple access (RSMA) technique. With the aim of maximizing the\nsum rate of vehicles, we jointly optimize trajectory and phase shift design of\nAIRS, transmit power and rate allocation for RSMA along with power splitting\nratio for SWIPT implementation. Via simulations, the superior performances of\nthe proposed algorithm are validated compared to the conventional partial\noptimizations.", "field": "Computer Science", "categories": "cs.IT,math.IT"}, {"arxiv_id": "2401.12483", "title": "Persona-centric Metamorphic Relation guided Robustness Evaluation for\n  Multi-turn Dialogue Modelling", "abstract": "Recently there has been significant progress in the field of dialogue system\nthanks to the introduction of training paradigms such as fine-tune and prompt\nlearning. Persona can function as the prior knowledge for maintaining the\npersonality consistency of dialogue systems, which makes it perform well on\naccuracy. Nonetheless, the conventional reference-based evaluation method falls\nshort in capturing the genuine text comprehension prowess of the model,\nsignificantly relying on the quality of data annotation. In contrast, the\napplication of metamorphic testing offers a more profound insight into the\nmodel's distinct capabilities without necessitating supplementary annotation\nlabels. This approach furnishes a more comprehensive portrayal of the model's\nintricacies and exposes intricacies concealed within reference-based validation\ntechniques. Consequently, we introduce a persona-centric metamorphic relation\nconstruction for metamorphic testing, aimed at evaluating both the persona\nconsistency and robustness of personalized dialogue models. For that reason,\nthis work evaluates several widely used training paradigms including learning\nfrom scratch, pretrain + fine-tune and prompt learning in personalized dialogue\nretrieval to know if they are more robust or if they have the same flaws as\ntheir predecessor. Under three kinds of designed metamorphic relations with\nconsistent outputs, our experimental results reveal that prompt learning shows\nstronger robustness compared to training from scratch and fine-tune. Although\ntested retrieval models gain competitively high retrieval accuracy according to\nthe traditional reference-based validation, they are still fragile and\ndemonstrate various unexpected behaviors, thus there is still room for future\nimprovement in personalized dialogue retrieval.", "field": "Computer Science", "categories": "cs.IR"}, {"arxiv_id": "2401.12485", "title": "Adiabatic Quantum Support Vector Machines", "abstract": "Adiabatic quantum computers can solve difficult optimization problems (e.g.,\nthe quadratic unconstrained binary optimization problem), and they seem well\nsuited to train machine learning models. In this paper, we describe an\nadiabatic quantum approach for training support vector machines. We show that\nthe time complexity of our quantum approach is an order of magnitude better\nthan the classical approach. Next, we compare the test accuracy of our quantum\napproach against a classical approach that uses the Scikit-learn library in\nPython across five benchmark datasets (Iris, Wisconsin Breast Cancer (WBC),\nWine, Digits, and Lambeq). We show that our quantum approach obtains accuracies\non par with the classical approach. Finally, we perform a scalability study in\nwhich we compute the total training times of the quantum approach and the\nclassical approach with increasing number of features and number of data points\nin the training dataset. Our scalability results show that the quantum approach\nobtains a 3.5--4.5 times speedup over the classical approach on datasets with\nmany (millions of) features.", "field": "Computer Science", "categories": "cs.LG,cs.AI,quant-ph,stat.ML"}, {"arxiv_id": "2401.12486", "title": "Quaternary codes and their binary images", "abstract": "Recently, simplicial complexes are used in constructions of several infinite\nfamilies of minimal and optimal linear codes by Hyun {\\em et al.} Building upon\ntheir research, in this paper more linear codes over the ring $\\mathbb{Z}_4$\nare constructed by simplicial complexes. Specifically, the Lee weight\ndistributions of the resulting quaternary codes are determined and two infinite\nfamilies of four-Lee-weight quaternary codes are obtained. Compared to the\ndatabases of $\\mathbb Z_4$ codes by Aydin {\\em et al.}, at least nine new\nquaternary codes are found. Thanks to the special structure of the defining\nsets, we have the ability to determine whether the Gray images of certain\nobtained quaternary codes are linear or not. This allows us to obtain two\ninfinite families of binary nonlinear codes and one infinite family of binary\nminimal linear codes. Furthermore, utilizing these minimal binary codes, some\nsecret sharing schemes as a byproduct also are established.", "field": "Computer Science", "categories": "cs.IT,math.IT"}, {"arxiv_id": "2401.12489", "title": "Unsupervised Learning Method for the Wave Equation Based on Finite\n  Difference Residual Constraints Loss", "abstract": "The wave equation is an important physical partial differential equation, and\nin recent years, deep learning has shown promise in accelerating or replacing\ntraditional numerical methods for solving it. However, existing deep learning\nmethods suffer from high data acquisition costs, low training efficiency, and\ninsufficient generalization capability for boundary conditions. To address\nthese issues, this paper proposes an unsupervised learning method for the wave\nequation based on finite difference residual constraints. We construct a novel\nfinite difference residual constraint based on structured grids and finite\ndifference methods, as well as an unsupervised training strategy, enabling\nconvolutional neural networks to train without data and predict the forward\npropagation process of waves. Experimental results show that finite difference\nresidual constraints have advantages over physics-informed neural networks\n(PINNs) type physical information constraints, such as easier fitting, lower\ncomputational costs, and stronger source term generalization capability, making\nour method more efficient in training and potent in application.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.12491", "title": "Assessing and Understanding Creativity in Large Language Models", "abstract": "In the field of natural language processing, the rapid development of large\nlanguage model (LLM) has attracted more and more attention. LLMs have shown a\nhigh level of creativity in various tasks, but the methods for assessing such\ncreativity are inadequate. The assessment of LLM creativity needs to consider\ndifferences from humans, requiring multi-dimensional measurement while\nbalancing accuracy and efficiency. This paper aims to establish an efficient\nframework for assessing the level of creativity in LLMs. By adapting the\nmodified Torrance Tests of Creative Thinking, the research evaluates the\ncreative performance of various LLMs across 7 tasks, emphasizing 4 criteria\nincluding Fluency, Flexibility, Originality, and Elaboration. In this context,\nwe develop a comprehensive dataset of 700 questions for testing and an\nLLM-based evaluation method. In addition, this study presents a novel analysis\nof LLMs' responses to diverse prompts and role-play situations. We found that\nthe creativity of LLMs primarily falls short in originality, while excelling in\nelaboration. Besides, the use of prompts and the role-play settings of the\nmodel significantly influence creativity. Additionally, the experimental\nresults also indicate that collaboration among multiple LLMs can enhance\noriginality. Notably, our findings reveal a consensus between human evaluations\nand LLMs regarding the personality traits that influence creativity. The\nfindings underscore the significant impact of LLM design on creativity and\nbridges artificial intelligence and human creativity, offering insights into\nLLMs' creativity and potential applications.", "field": "Computer Science", "categories": "cs.CL,cs.AI"}, {"arxiv_id": "2401.12492", "title": "Comparing Human-Centered Language Modeling: Is it Better to Model\n  Groups, Individual Traits, or Both?", "abstract": "Natural language processing has made progress in incorporating human context\ninto its models, but whether it is more effective to use group-wise attributes\n(e.g., over-45-year-olds) or model individuals remains open. Group attributes\nare technically easier but coarse: not all 45-year-olds write the same way. In\ncontrast, modeling individuals captures the complexity of each person's\nidentity. It allows for a more personalized representation, but we may have to\nmodel an infinite number of users and require data that may be impossible to\nget. We compare modeling human context via group attributes, individual users,\nand combined approaches. Combining group and individual features significantly\nbenefits user-level regression tasks like age estimation or personality\nassessment from a user's documents. Modeling individual users significantly\nimproves the performance of single document-level classification tasks like\nstance and topic detection. We also find that individual-user modeling does\nwell even without user's historical data.", "field": "Computer Science", "categories": "cs.CL,cs.AI,cs.LG"}, {"arxiv_id": "2401.12496", "title": "DexTouch: Learning to Seek and Manipulate Objects with Tactile Dexterity", "abstract": "The sense of touch is an essential ability for skillfully performing a\nvariety of tasks, providing the capacity to search and manipulate objects\nwithout relying on visual information. Extensive research has been conducted\nover time to apply these human tactile abilities to robots. In this paper, we\nintroduce a multi-finger robot system designed to search for and manipulate\nobjects using the sense of touch without relying on visual information.\nRandomly located target objects are searched using tactile sensors, and the\nobjects are manipulated for tasks that mimic daily-life. The objective of the\nstudy is to endow robots with human-like tactile capabilities. To achieve this,\nbinary tactile sensors are implemented on one side of the robot hand to\nminimize the Sim2Real gap. Training the policy through reinforcement learning\nin simulation and transferring the trained policy to the real environment, we\ndemonstrate that object search and manipulation using tactile sensors is\npossible even in an environment without vision information. In addition, an\nablation study was conducted to analyze the effect of tactile information on\nmanipulative tasks. Our project page is available at\nhttps://lee-kangwon.github.io/dextouch/", "field": "Computer Science", "categories": "cs.RO,cs.LG"}, {"arxiv_id": "2401.12497", "title": "Building Minimal and Reusable Causal State Abstractions for\n  Reinforcement Learning", "abstract": "Two desiderata of reinforcement learning (RL) algorithms are the ability to\nlearn from relatively little experience and the ability to learn policies that\ngeneralize to a range of problem specifications. In factored state spaces, one\napproach towards achieving both goals is to learn state abstractions, which\nonly keep the necessary variables for learning the tasks at hand. This paper\nintroduces Causal Bisimulation Modeling (CBM), a method that learns the causal\nrelationships in the dynamics and reward functions for each task to derive a\nminimal, task-specific abstraction. CBM leverages and improves implicit\nmodeling to train a high-fidelity causal dynamics model that can be reused for\nall tasks in the same environment. Empirical validation on manipulation\nenvironments and Deepmind Control Suite reveals that CBM's learned implicit\ndynamics models identify the underlying causal relationships and state\nabstractions more accurately than explicit ones. Furthermore, the derived state\nabstractions allow a task learner to achieve near-oracle levels of sample\nefficiency and outperform baselines on all tasks.", "field": "Computer Science", "categories": "cs.AI,cs.LG,cs.RO,I.2.9; I.2.8; I.2.6"}, {"arxiv_id": "2401.12499", "title": "On the Fundamental Tradeoff of Joint Communication and Quickest Change\n  Detection", "abstract": "In this work, we take the initiative in studying the fundamental tradeoff\nbetween communication and quickest change detection (QCD) under an integrated\nsensing and communication setting. We formally establish a joint communication\nand sensing problem for quickest change detection. Then, by utilizing constant\nsubblock-composition codes and a modified QuSum detection rule, which we call\nsubblock QuSum (SQS), we provide an inner bound on the fundamental tradeoff\nbetween communication rate and change point detection delay in the asymptotic\nregime of vanishing false alarm rate. We further provide a partial converse\nthat matches our inner bound for a certain class of codes. This implies that\nthe SQS detection strategy is asymptotically optimal for our codes as the false\nalarm rate constraint vanishes. We also present some canonical examples of the\ntradeoff region for a binary channel, a scalar Gaussian channel, and a MIMO\nGaussian channel.", "field": "Computer Science", "categories": "cs.IT,eess.SP,math.IT"}, {"arxiv_id": "2401.12501", "title": "A parametrix method for elliptic surface PDEs", "abstract": "Elliptic problems along smooth surfaces embedded in three dimensions occur in\nthin-membrane mechanics, electromagnetics (harmonic vector fields), and\ncomputational geometry. In this work, we present a parametrix-based integral\nequation method applicable to several forms of variable coefficient surface\nelliptic problems. Via the use of an approximate Green's function, the surface\nPDEs are transformed into well-conditioned integral equations. We demonstrate\nhigh-order numerical examples of this method applied to problems on general\nsurfaces using a variant of the fast multipole method based on smooth\ninterpolation properties of the kernel. Lastly, we discuss extensions of the\nmethod to surfaces with boundaries.", "field": "Computer Science", "categories": "math.NA,cs.NA,35R01, 35C15, 65R20, 35J47, 45B05"}, {"arxiv_id": "2401.12503", "title": "Small Language Model Meets with Reinforced Vision Vocabulary", "abstract": "Playing Large Vision Language Models (LVLMs) in 2023 is trendy among the AI\ncommunity. However, the relatively large number of parameters (more than 7B) of\npopular LVLMs makes it difficult to train and deploy on consumer GPUs,\ndiscouraging many researchers with limited resources. Imagine how cool it would\nbe to experience all the features of current LVLMs on an old GTX1080ti (our\nonly game card). Accordingly, we present Vary-toy in this report, a small-size\nVary along with Qwen-1.8B as the base ``large'' language model. In Vary-toy, we\nintroduce an improved vision vocabulary, allowing the model to not only possess\nall features of Vary but also gather more generality. Specifically, we replace\nnegative samples of natural images with positive sample data driven by object\ndetection in the procedure of generating vision vocabulary, more sufficiently\nutilizing the capacity of the vocabulary network and enabling it to efficiently\nencode visual information corresponding to natural objects. For experiments,\nVary-toy can achieve 65.6% ANLS on DocVQA, 59.1% accuracy on ChartQA, 88.1%\naccuracy on RefCOCO, and 29% on MMVet. The code will be publicly available on\nthe homepage.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.12507", "title": "Open-Set Facial Expression Recognition", "abstract": "Facial expression recognition (FER) models are typically trained on datasets\nwith a fixed number of seven basic classes. However, recent research works\npoint out that there are far more expressions than the basic ones. Thus, when\nthese models are deployed in the real world, they may encounter unknown\nclasses, such as compound expressions that cannot be classified into existing\nbasic classes. To address this issue, we propose the open-set FER task for the\nfirst time. Though there are many existing open-set recognition methods, we\nargue that they do not work well for open-set FER because FER data are all\nhuman faces with very small inter-class distances, which makes the open-set\nsamples very similar to close-set samples. In this paper, we are the first to\ntransform the disadvantage of small inter-class distance into an advantage by\nproposing a new way for open-set FER. Specifically, we find that small\ninter-class distance allows for sparsely distributed pseudo labels of open-set\nsamples, which can be viewed as symmetric noisy labels. Based on this novel\nobservation, we convert the open-set FER to a noisy label detection problem. We\nfurther propose a novel method that incorporates attention map consistency and\ncycle training to detect the open-set samples. Extensive experiments on various\nFER datasets demonstrate that our method clearly outperforms state-of-the-art\nopen-set recognition methods by large margins. Code is available at\nhttps://github.com/zyh-uaiaaaa.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.12508", "title": "On the Stochastic (Variance-Reduced) Proximal Gradient Method for\n  Regularized Expected Reward Optimization", "abstract": "We consider a regularized expected reward optimization problem in the\nnon-oblivious setting that covers many existing problems in reinforcement\nlearning (RL). In order to solve such an optimization problem, we apply and\nanalyze the classical stochastic proximal gradient method. In particular, the\nmethod has shown to admit an $O(\\epsilon^{-4})$ sample complexity to an\n$\\epsilon$-stationary point, under standard conditions. Since the variance of\nthe classical stochastic gradient estimator is typically large which slows down\nthe convergence, we also apply an efficient stochastic variance-reduce proximal\ngradient method with an importance sampling based ProbAbilistic Gradient\nEstimator (PAGE). To the best of our knowledge, the application of this method\nrepresents a novel approach in addressing the general regularized reward\noptimization problem. Our analysis shows that the sample complexity can be\nimproved from $O(\\epsilon^{-4})$ to $O(\\epsilon^{-3})$ under additional\nconditions. Our results on the stochastic (variance-reduced) proximal gradient\nmethod match the sample complexity of their most competitive counterparts under\nsimilar settings in the RL literature.", "field": "Computer Science", "categories": "cs.LG,math.OC"}, {"arxiv_id": "2401.12509", "title": "Digital cloning of online social networks for language-sensitive\n  agent-based modeling of misinformation spread", "abstract": "We develop a simulation framework for studying misinformation spread within\nonline social networks that blends agent-based modeling and natural language\nprocessing techniques. While many other agent-based simulations exist in this\nspace, their ability to provide actionable insights in in part limited by their\nlack of fidelity and generalizability to existing networks. To partially\naddress these concerns, we create a 'digital clone' of a known misinformation\nsharing network by downloading social media histories for over ten thousand of\nits users. We parse these histories to both extract the structure of the\nnetwork and model the nuanced ways in which information is shared and spread\namong its members. Unlike many other agent-based methods in this space,\ninformation sharing between users in our framework is sensitive to topic of\ndiscussion, user preferences, and online community dynamics. To evaluate the\nfidelity of our method, we seed our cloned network with a set of posts recorded\nin the base network and compare propagation dynamics between the two, observing\nreasonable agreement across the twin networks over a variety of metrics.\nLastly, we explore how the cloned network may serve as a flexible, low-cost\ntestbed for misinformation countermeasure evaluation and red teaming analysis.\nWe hope the tools explored here augment existing efforts in the space and\nunlock new opportunities for misinformation countermeasure evaluation, a field\nthat may become increasingly important to consider with the anticipated rise of\nmisinformation campaigns fueled by generative artificial intelligence.", "field": "Computer Science", "categories": "cs.SI,cs.LG"}, {"arxiv_id": "2401.12511", "title": "Convolutional Initialization for Data-Efficient Vision Transformers", "abstract": "Training vision transformer networks on small datasets poses challenges. In\ncontrast, convolutional neural networks (CNNs) can achieve state-of-the-art\nperformance by leveraging their architectural inductive bias. In this paper, we\ninvestigate whether this inductive bias can be reinterpreted as an\ninitialization bias within a vision transformer network. Our approach is\nmotivated by the finding that random impulse filters can achieve almost\ncomparable performance to learned filters in CNNs. We introduce a novel\ninitialization strategy for transformer networks that can achieve comparable\nperformance to CNNs on small datasets while preserving its architectural\nflexibility.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.12513", "title": "Detecting and recognizing characters in Greek papyri with YOLOv8, DeiT\n  and SimCLR", "abstract": "The capacity to isolate and recognize individual characters from facsimile\nimages of papyrus manuscripts yields rich opportunities for digital analysis.\nFor this reason the `ICDAR 2023 Competition on Detection and Recognition of\nGreek Letters on Papyri' was held as part of the 17th International Conference\non Document Analysis and Recognition. This paper discusses our submission to\nthe competition. We used an ensemble of YOLOv8 models to detect and classify\nindividual characters and employed two different approaches for refining the\ncharacter predictions, including a transformer based DeiT approach and a\nResNet-50 model trained on a large corpus of unlabelled data using SimCLR, a\nself-supervised learning method. Our submission won the recognition challenge\nwith a mAP of 42.2%, and was runner-up in the detection challenge with a mean\naverage precision (mAP) of 51.4%. At the more relaxed intersection over union\nthreshold of 0.5, we achieved the highest mean average precision and mean\naverage recall results for both detection and classification. We ran our\nprediction pipeline on more than 4,500 images from the Oxyrhynchus Papyri to\nillustrate the utility of our approach, and we release the results publicly in\nmultiple formats.", "field": "Computer Science", "categories": "cs.CV,cs.AI,68T10"}, {"arxiv_id": "2401.12517", "title": "DDMI: Domain-Agnostic Latent Diffusion Models for Synthesizing\n  High-Quality Implicit Neural Representations", "abstract": "Recent studies have introduced a new class of generative models for\nsynthesizing implicit neural representations (INRs) that capture arbitrary\ncontinuous signals in various domains. These models opened the door for\ndomain-agnostic generative models, but they often fail to achieve high-quality\ngeneration. We observed that the existing methods generate the weights of\nneural networks to parameterize INRs and evaluate the network with fixed\npositional embeddings (PEs). Arguably, this architecture limits the expressive\npower of generative models and results in low-quality INR generation. To\naddress this limitation, we propose Domain-agnostic Latent Diffusion Model for\nINRs (DDMI) that generates adaptive positional embeddings instead of neural\nnetworks' weights. Specifically, we develop a Discrete-to-continuous space\nVariational AutoEncoder (D2C-VAE), which seamlessly connects discrete data and\nthe continuous signal functions in the shared latent space. Additionally, we\nintroduce a novel conditioning mechanism for evaluating INRs with the\nhierarchically decomposed PEs to further enhance expressive power. Extensive\nexperiments across four modalities, e.g., 2D images, 3D shapes, Neural Radiance\nFields, and videos, with seven benchmark datasets, demonstrate the versatility\nof DDMI and its superior performance compared to the existing INR generative\nmodels.", "field": "Computer Science", "categories": "cs.LG,stat.ML"}, {"arxiv_id": "2401.1252", "title": "Key Information Retrieval to Classify the Unstructured Data Content of\n  Preferential Trade Agreements", "abstract": "With the rapid proliferation of textual data, predicting long texts has\nemerged as a significant challenge in the domain of natural language\nprocessing. Traditional text prediction methods encounter substantial\ndifficulties when grappling with long texts, primarily due to the presence of\nredundant and irrelevant information, which impedes the model's capacity to\ncapture pivotal insights from the text. To address this issue, we introduce a\nnovel approach to long-text classification and prediction. Initially, we employ\nembedding techniques to condense the long texts, aiming to diminish the\nredundancy therein. Subsequently,the Bidirectional Encoder Representations from\nTransformers (BERT) embedding method is utilized for text classification\ntraining. Experimental outcomes indicate that our method realizes considerable\nperformance enhancements in classifying long texts of Preferential Trade\nAgreements. Furthermore, the condensation of text through embedding methods not\nonly augments prediction accuracy but also substantially reduces computational\ncomplexity. Overall, this paper presents a strategy for long-text prediction,\noffering a valuable reference for researchers and engineers in the natural\nlanguage processing sphere.", "field": "Computer Science", "categories": "cs.CL,cs.IR,cs.LG"}, {"arxiv_id": "2401.12521", "title": "Exploring Virtual Reality through Ihde's Instrumental Realism", "abstract": "Based on Ihde's theory, this paper explores the relationship between virtual\nreality (VR) as an instrument and phenomenology. It reviews the \"technological\nrevolution\" spurred by the development of VR technology and discusses how VR\nhas been used to study subjective experience, explore perception and\nembodiment, enhance empathy and perspective, and investigate altered states of\nconsciousness. The paper emphasizes the role of VR as an instrumental\ntechnology, particularly its ability to expand human perception and cognition.\nReflecting on this in conjunction with the work of Husserl and Ihde, among\nothers, it revisits the potential of VR to provide new avenues for scientific\ninquiry and experience and to transform our understanding of the world through\nVR.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.12522", "title": "BiTA: Bi-Directional Tuning for Lossless Acceleration in Large Language\n  Models", "abstract": "Large language models (LLMs) commonly employ autoregressive generation during\ninference, leading to high memory bandwidth demand and consequently extended\nlatency. To mitigate this inefficiency, we present Bi-directional Tuning for\nlossless Acceleration (BiTA), an innovative method expediting LLMs via\nstreamlined semi-autoregressive generation and draft verification. Inspired by\nthe concept of prompt tuning, we enhance LLMs with a parameter-efficient design\ncalled bi-directional tuning for the capability in semi-autoregressive\ngeneration. Employing efficient tree-based decoding, the models perform draft\ncandidate generation and verification in parallel, ensuring outputs identical\nto their autoregressive counterparts under greedy sampling. BiTA serves as a\nlightweight plug-in module, seamlessly boosting the inference efficiency of\nexisting LLMs without requiring additional assistance models or incurring\nsignificant extra memory costs. Applying the proposed BiTA, LLaMA-2-70B-Chat\nachieves a 2.7$\\times$ speedup on the MT-Bench benchmark. Extensive experiments\nconfirm our method surpasses state-of-the-art acceleration techniques.", "field": "Computer Science", "categories": "cs.CL,cs.AI,cs.LG"}, {"arxiv_id": "2401.12526", "title": "Refined generalization analysis of the Deep Ritz Method and\n  Physics-Informed Neural Networks", "abstract": "In this paper, we present refined generalization bounds for the Deep Ritz\nMethod (DRM) and Physics-Informed Neural Networks (PINNs). For the DRM, we\nfocus on two prototype elliptic PDEs: Poisson equation and static Schr\\\"odinger\nequation on the $d$-dimensional unit hypercube with the Neumann boundary\ncondition. And sharper generalization bounds are derived based on the\nlocalization techniques under the assumptions that the exact solutions of the\nPDEs lie in the Barron space or the general Sobolev spaces. For the PINNs, we\ninvestigate the general linear second elliptic PDEs with Dirichlet boundary\ncondition.", "field": "Computer Science", "categories": "math.NA,cs.NA"}, {"arxiv_id": "2401.12532", "title": "DAFA: Distance-Aware Fair Adversarial Training", "abstract": "The disparity in accuracy between classes in standard training is amplified\nduring adversarial training, a phenomenon termed the robust fairness problem.\nExisting methodologies aimed to enhance robust fairness by sacrificing the\nmodel's performance on easier classes in order to improve its performance on\nharder ones. However, we observe that under adversarial attacks, the majority\nof the model's predictions for samples from the worst class are biased towards\nclasses similar to the worst class, rather than towards the easy classes.\nThrough theoretical and empirical analysis, we demonstrate that robust fairness\ndeteriorates as the distance between classes decreases. Motivated by these\ninsights, we introduce the Distance-Aware Fair Adversarial training (DAFA)\nmethodology, which addresses robust fairness by taking into account the\nsimilarities between classes. Specifically, our method assigns distinct loss\nweights and adversarial margins to each class and adjusts them to encourage a\ntrade-off in robustness among similar classes. Experimental results across\nvarious datasets demonstrate that our method not only maintains average robust\naccuracy but also significantly improves the worst robust accuracy, indicating\na marked improvement in robust fairness compared to existing methods.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.12533", "title": "Efficient Constrained $k$-Center Clustering with Background Knowledge", "abstract": "Center-based clustering has attracted significant research interest from both\ntheory and practice. In many practical applications, input data often contain\nbackground knowledge that can be used to improve clustering results. In this\nwork, we build on widely adopted $k$-center clustering and model its input\nbackground knowledge as must-link (ML) and cannot-link (CL) constraint sets.\nHowever, most clustering problems including $k$-center are inherently\n$\\mathcal{NP}$-hard, while the more complex constrained variants are known to\nsuffer severer approximation and computation barriers that significantly limit\ntheir applicability. By employing a suite of techniques including reverse\ndominating sets, linear programming (LP) integral polyhedron, and LP duality,\nwe arrive at the first efficient approximation algorithm for constrained\n$k$-center with the best possible ratio of 2. We also construct competitive\nbaseline algorithms and empirically evaluate our approximation algorithm\nagainst them on a variety of real datasets. The results validate our\ntheoretical findings and demonstrate the great advantages of our algorithm in\nterms of clustering cost, clustering quality, and running time.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.12535", "title": "Self-Supervised Vision Transformers Are Efficient Segmentation Learners\n  for Imperfect Labels", "abstract": "This study demonstrates a cost-effective approach to semantic segmentation\nusing self-supervised vision transformers (SSVT). By freezing the SSVT backbone\nand training a lightweight segmentation head, our approach effectively utilizes\nimperfect labels, thereby improving robustness to label imperfections.\nEmpirical experiments show significant performance improvements over existing\nmethods for various annotation types, including scribble, point-level, and\nimage-level labels. The research highlights the effectiveness of\nself-supervised vision transformers in dealing with imperfect labels, providing\na practical and efficient solution for semantic segmentation while reducing\nannotation costs. Through extensive experiments, we confirm that our method\noutperforms baseline models for all types of imperfect labels. Especially under\nthe zero-shot vision-language-model-based label, our model exhibits 11.5\\%p\nperformance gain compared to the baseline.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.12538", "title": "Multi-Sources Information Fusion Learning for Multi-Points NLOS\n  Localization", "abstract": "Accurate localization of mobile terminals is crucial for integrated sensing\nand communication systems. Existing fingerprint localization methods, which\ndeduce coordinates from channel information in pre-defined rectangular areas,\nstruggle with the heterogeneous fingerprint distribution inherent in\nnon-line-of-sight (NLOS) scenarios. To address the problem, we introduce a\nnovel multi-source information fusion learning framework referred to as the\nAutosync Multi-Domain NLOS Localization (AMDNLoc). Specifically, AMDNLoc\nemploys a two-stage matched filter fused with a target tracking algorithm and\niterative centroid-based clustering to automatically and irregularly segment\nNLOS regions, ensuring uniform fingerprint distribution within channel state\ninformation across frequency, power, and time-delay domains. Additionally, the\nframework utilizes a segment-specific linear classifier array, coupled with\ndeep residual network-based feature extraction and fusion, to establish the\ncorrelation function between fingerprint features and coordinates within these\nregions. Simulation results demonstrate that AMDNLoc significantly enhances\nlocalization accuracy by over 55% compared with traditional convolutional\nneural network on the wireless artificial intelligence research dataset.", "field": "Computer Science", "categories": "cs.IT,math.IT"}, {"arxiv_id": "2401.1254", "title": "DREditor: An Time-efficient Approach for Building a Domain-specific\n  Dense Retrieval Model", "abstract": "Deploying dense retrieval models efficiently is becoming increasingly\nimportant across various industries. This is especially true for enterprise\nsearch services, where customizing search engines to meet the time demands of\ndifferent enterprises in different domains is crucial. Motivated by this, we\ndevelop a time-efficient approach called DREditor to edit the matching rule of\nan off-the-shelf dense retrieval model to suit a specific domain. This is\nachieved by directly calibrating the output embeddings of the model using an\nefficient and effective linear mapping. This mapping is powered by an edit\noperator that is obtained by solving a specially constructed least squares\nproblem. Compared to implicit rule modification via long-time finetuning, our\nexperimental results show that DREditor provides significant advantages on\ndifferent domain-specific datasets, dataset sources, retrieval models, and\ncomputing devices. It consistently enhances time efficiency by 100-300 times\nwhile maintaining comparable or even superior retrieval performance. In a\nbroader context, we take the first step to introduce a novel embedding\ncalibration approach for the retrieval task, filling the technical blank in the\ncurrent field of embedding calibration. This approach also paves the way for\nbuilding domain-specific dense retrieval models efficiently and inexpensively.", "field": "Computer Science", "categories": "cs.IR,cs.CL"}, {"arxiv_id": "2401.12542", "title": "Multi-Party Private Set Intersection: A Circuit-Based Protocol with\n  Jaccard Similarity for Secure and Efficient Anomaly Detection in Network\n  Traffic", "abstract": "We present a new circuit-based protocol for multi-party private set\nintersection (PSI) that allows m parties to compute the intersection of their\ndatasets without revealing any additional information about the items outside\nthe intersection. Building upon the two-party Sort-Compare-Shuffle (SCS)\nprotocol, we seamlessly extend it to a multi-party setting. Demonstrating its\npracticality through implementation, our protocol exhibits acceptable\nperformance. Specifically, with 7 parties, each possessing a set size of\n2^{12}, our protocol completes in just 19 seconds. Moreover, circuit-based\nprotocols like ours have an advantage over using custom protocols to perform\nmore complex computation. We substantiate this advantage by incorporating a\nmodule for calculating the Jaccard similarity metric of the private sets which\ncan be used in the application domain of network traffic analysis for anomaly\ndetection. This extension showcases the versatility of our protocol beyond set\nintersection computations, demonstrating its efficacy in preserving privacy\nwhile efficiently identifying abnormal patterns in network flow.", "field": "Computer Science", "categories": "cs.CR"}, {"arxiv_id": "2401.12546", "title": "On Building Myopic MPC Policies using Supervised Learning", "abstract": "The application of supervised learning techniques in combination with model\npredictive control (MPC) has recently generated significant interest,\nparticularly in the area of approximate explicit MPC, where function\napproximators like deep neural networks are used to learn the MPC policy via\noptimal state-action pairs generated offline. While the aim of approximate\nexplicit MPC is to closely replicate the MPC policy, substituting online\noptimization with a trained neural network, the performance guarantees that\ncome with solving the online optimization problem are typically lost. This\npaper considers an alternative strategy, where supervised learning is used to\nlearn the optimal value function offline instead of learning the optimal\npolicy. This can then be used as the cost-to-go function in a myopic MPC with a\nvery short prediction horizon, such that the online computation burden reduces\nsignificantly without affecting the controller performance. This approach\ndiffers from existing work on value function approximations in the sense that\nit learns the cost-to-go function by using offline-collected state-value pairs,\nrather than closed-loop performance data. The cost of generating the\nstate-value pairs used for training is addressed using a sensitivity-based data\naugmentation scheme.", "field": "Computer Science", "categories": "cs.LG,cs.SY,eess.SY,math.OC"}, {"arxiv_id": "2401.1255", "title": "UR4NNV: Neural Network Verification, Under-approximation Reachability\n  Works!", "abstract": "Recently, formal verification of deep neural networks (DNNs) has garnered\nconsiderable attention, and over-approximation based methods have become\npopular due to their effectiveness and efficiency. However, these strategies\nface challenges in addressing the \"unknown dilemma\" concerning whether the\nexact output region or the introduced approximation error violates the property\nin question. To address this, this paper introduces the UR4NNV verification\nframework, which utilizes under-approximation reachability analysis for DNN\nverification for the first time. UR4NNV focuses on DNNs with Rectified Linear\nUnit (ReLU) activations and employs a binary tree branch-based\nunder-approximation algorithm. In each epoch, UR4NNV under-approximates a\nsub-polytope of the reachable set and verifies this polytope against the given\nproperty. Through a trial-and-error approach, UR4NNV effectively falsifies DNN\nproperties while providing confidence levels when reaching verification epoch\nbounds and failing falsifying properties. Experimental comparisons with\nexisting verification methods demonstrate the effectiveness and efficiency of\nUR4NNV, significantly reducing the impact of the \"unknown dilemma\".", "field": "Computer Science", "categories": "cs.AI,cs.LG,68Q60, 68T07,D.2.4; I.2.0"}, {"arxiv_id": "2401.12553", "title": "InfoRank: Unbiased Learning-to-Rank via Conditional Mutual Information\n  Minimization", "abstract": "Ranking items regarding individual user interests is a core technique of\nmultiple downstream tasks such as recommender systems. Learning such a\npersonalized ranker typically relies on the implicit feedback from users' past\nclick-through behaviors. However, collected feedback is biased toward\npreviously highly-ranked items and directly learning from it would result in a\n\"rich-get-richer\" phenomenon. In this paper, we propose a simple yet sufficient\nunbiased learning-to-rank paradigm named InfoRank that aims to simultaneously\naddress both position and popularity biases. We begin by consolidating the\nimpacts of those biases into a single observation factor, thereby providing a\nunified approach to addressing bias-related issues. Subsequently, we minimize\nthe mutual information between the observation estimation and the relevance\nestimation conditioned on the input features. By doing so, our relevance\nestimation can be proved to be free of bias. To implement InfoRank, we first\nincorporate an attention mechanism to capture latent correlations within\nuser-item features, thereby generating estimations of observation and\nrelevance. We then introduce a regularization term, grounded in conditional\nmutual information, to promote conditional independence between relevance\nestimation and observation estimation. Experimental evaluations conducted\nacross three extensive recommendation and search datasets reveal that InfoRank\nlearns more precise and unbiased ranking strategies.", "field": "Computer Science", "categories": "cs.IR"}, {"arxiv_id": "2401.12554", "title": "Can Large Language Models Write Parallel Code?", "abstract": "Large Language Models are becoming an increasingly popular tool for software\ndevelopment. Their ability to model and generate source code has been\ndemonstrated in a variety of contexts, including code completion,\nsummarization, translation, and lookup. However, they often struggle to\ngenerate code for more complex tasks. In this paper, we explore the ability of\nstate-of-the-art language models to generate parallel code. We propose a\nbenchmark, PCGBench, consisting of a set of 420 tasks for evaluating the\nability of language models to generate parallel code, and we evaluate the\nperformance of several state-of-the-art open- and closed-source language models\non these tasks. We introduce novel metrics for comparing parallel code\ngeneration performance and use them to explore how well each LLM performs on\nvarious parallel programming models and computational problem types.", "field": "Computer Science", "categories": "cs.DC,cs.AI"}, {"arxiv_id": "2401.12557", "title": "Balancing the AI Strength of Roles in Self-Play Training with Regret\n  Matching+", "abstract": "When training artificial intelligence for games encompassing multiple roles,\nthe development of a generalized model capable of controlling any character\nwithin the game presents a viable option. This strategy not only conserves\ncomputational resources and time during the training phase but also reduces\nresource requirements during deployment. training such a generalized model\noften encounters challenges related to uneven capabilities when controlling\ndifferent roles. A simple method is introduced based on Regret Matching+, which\nfacilitates a more balanced performance of strength by the model when\ncontrolling various roles.", "field": "Computer Science", "categories": "cs.AI"}, {"arxiv_id": "2401.12561", "title": "EndoGaussian: Gaussian Splatting for Deformable Surgical Scene\n  Reconstruction", "abstract": "Reconstructing deformable tissues from endoscopic stereo videos is essential\nin many downstream surgical applications. However, existing methods suffer from\nslow inference speed, which greatly limits their practical use. In this paper,\nwe introduce EndoGaussian, a real-time surgical scene reconstruction framework\nthat builds on 3D Gaussian Splatting. Our framework represents dynamic surgical\nscenes as canonical Gaussians and a time-dependent deformation field, which\npredicts Gaussian deformations at novel timestamps. Due to the efficient\nGaussian representation and parallel rendering pipeline, our framework\nsignificantly accelerates the rendering speed compared to previous methods. In\naddition, we design the deformation field as the combination of a lightweight\nencoding voxel and an extremely tiny MLP, allowing for efficient Gaussian\ntracking with a minor rendering burden. Furthermore, we design a holistic\nGaussian initialization method to fully leverage the surface distribution\nprior, achieved by searching informative points from across the input image\nsequence. Experiments on public endoscope datasets demonstrate that our method\ncan achieve real-time rendering speed (195 FPS real-time, 100$\\times$ gain)\nwhile maintaining the state-of-the-art reconstruction quality (35.925 PSNR) and\nthe fastest training speed (within 2 min/scene), showing significant promise\nfor intraoperative surgery applications. Code is available at:\n\\url{https://yifliu3.github.io/EndoGaussian/}.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.12562", "title": "Learning the cost-to-go for mixed-integer nonlinear model predictive\n  control", "abstract": "Application of nonlinear model predictive control (NMPC) to problems with\nhybrid dynamical systems, disjoint constraints, or discrete controls often\nresults in mixed-integer formulations with both continuous and discrete\ndecision variables. However, solving mixed-integer nonlinear programming\nproblems (MINLP) in real-time is challenging, which can be a limiting factor in\nmany applications. To address the computational complexity of solving mixed\ninteger nonlinear model predictive control problem in real-time, this paper\nproposes an approximate mixed integer NMPC formulation based on value function\napproximation. Leveraging Bellman's principle of optimality, the key idea here\nis to divide the prediction horizon into two parts, where the optimal value\nfunction of the latter part of the prediction horizon is approximated offline\nusing expert demonstrations. Doing so allows us to solve the MINMPC problem\nwith a considerably shorter prediction horizon online, thereby reducing the\nonline computation cost. The paper uses an inverted pendulum example with\ndiscrete controls to illustrate this approach.", "field": "Computer Science", "categories": "eess.SY,cs.SY,math.OC"}, {"arxiv_id": "2401.12564", "title": "Graph Contrastive Invariant Learning from the Causal Perspective", "abstract": "Graph contrastive learning (GCL), learning the node representation by\ncontrasting two augmented graphs in a self-supervised way, has attracted\nconsiderable attention. GCL is usually believed to learn the invariant\nrepresentation. However, does this understanding always hold in practice? In\nthis paper, we first study GCL from the perspective of causality. By analyzing\nGCL with the structural causal model (SCM), we discover that traditional GCL\nmay not well learn the invariant representations due to the non-causal\ninformation contained in the graph. How can we fix it and encourage the current\nGCL to learn better invariant representations? The SCM offers two requirements\nand motives us to propose a novel GCL method. Particularly, we introduce the\nspectral graph augmentation to simulate the intervention upon non-causal\nfactors. Then we design the invariance objective and independence objective to\nbetter capture the causal factors. Specifically, (i) the invariance objective\nencourages the encoder to capture the invariant information contained in causal\nvariables, and (ii) the independence objective aims to reduce the influence of\nconfounders on the causal variables. Experimental results demonstrate the\neffectiveness of our approach on node classification tasks.", "field": "Computer Science", "categories": "cs.LG,cs.SI"}, {"arxiv_id": "2401.12566", "title": "Automated Fact-Checking of Climate Change Claims with Large Language\n  Models", "abstract": "This paper presents Climinator, a novel AI-based tool designed to automate\nthe fact-checking of climate change claims. Utilizing an array of Large\nLanguage Models (LLMs) informed by authoritative sources like the IPCC reports\nand peer-reviewed scientific literature, Climinator employs an innovative\nMediator-Advocate framework. This design allows Climinator to effectively\nsynthesize varying scientific perspectives, leading to robust, evidence-based\nevaluations. Our model demonstrates remarkable accuracy when testing claims\ncollected from Climate Feedback and Skeptical Science. Notably, when\nintegrating an advocate with a climate science denial perspective in our\nframework, Climinator's iterative debate process reliably converges towards\nscientific consensus, underscoring its adeptness at reconciling diverse\nviewpoints into science-based, factual conclusions. While our research is\nsubject to certain limitations and necessitates careful interpretation, our\napproach holds significant potential. We hope to stimulate further research and\nencourage exploring its applicability in other contexts, including political\nfact-checking and legal domains.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.12568", "title": "NeRF-AD: Neural Radiance Field with Attention-based Disentanglement for\n  Talking Face Synthesis", "abstract": "Talking face synthesis driven by audio is one of the current research\nhotspots in the fields of multidimensional signal processing and multimedia.\nNeural Radiance Field (NeRF) has recently been brought to this research field\nin order to enhance the realism and 3D effect of the generated faces. However,\nmost existing NeRF-based methods either burden NeRF with complex learning tasks\nwhile lacking methods for supervised multimodal feature fusion, or cannot\nprecisely map audio to the facial region related to speech movements. These\nreasons ultimately result in existing methods generating inaccurate lip shapes.\nThis paper moves a portion of NeRF learning tasks ahead and proposes a talking\nface synthesis method via NeRF with attention-based disentanglement (NeRF-AD).\nIn particular, an Attention-based Disentanglement module is introduced to\ndisentangle the face into Audio-face and Identity-face using speech-related\nfacial action unit (AU) information. To precisely regulate how audio affects\nthe talking face, we only fuse the Audio-face with audio feature. In addition,\nAU information is also utilized to supervise the fusion of these two\nmodalities. Extensive qualitative and quantitative experiments demonstrate that\nour NeRF-AD outperforms state-of-the-art methods in generating realistic\ntalking face videos, including image quality and lip synchronization. To view\nvideo results, please refer to https://xiaoxingliu02.github.io/NeRF-AD.", "field": "Computer Science", "categories": "cs.CV,cs.MM"}, {"arxiv_id": "2401.12574", "title": "Backpropagation Through Agents", "abstract": "A fundamental challenge in multi-agent reinforcement learning (MARL) is to\nlearn the joint policy in an extremely large search space, which grows\nexponentially with the number of agents. Moreover, fully decentralized policy\nfactorization significantly restricts the search space, which may lead to\nsub-optimal policies. In contrast, the auto-regressive joint policy can\nrepresent a much richer class of joint policies by factorizing the joint policy\ninto the product of a series of conditional individual policies. While such\nfactorization introduces the action dependency among agents explicitly in\nsequential execution, it does not take full advantage of the dependency during\nlearning. In particular, the subsequent agents do not give the preceding agents\nfeedback about their decisions. In this paper, we propose a new framework\nBack-Propagation Through Agents (BPTA) that directly accounts for both agents'\nown policy updates and the learning of their dependent counterparts. This is\nachieved by propagating the feedback through action chains. With the proposed\nframework, our Bidirectional Proximal Policy Optimisation (BPPO) outperforms\nthe state-of-the-art methods. Extensive experiments on matrix games,\nStarCraftII v2, Multi-agent MuJoCo, and Google Research Football demonstrate\nthe effectiveness of the proposed method.", "field": "Computer Science", "categories": "cs.MA"}, {"arxiv_id": "2401.12576", "title": "LLMCheckup: Conversational Examination of Large Language Models via\n  Interpretability Tools", "abstract": "Interpretability tools that offer explanations in the form of a dialogue have\ndemonstrated their efficacy in enhancing users' understanding, as one-off\nexplanations may occasionally fall short in providing sufficient information to\nthe user. Current solutions for dialogue-based explanations, however, require\nmany dependencies and are not easily transferable to tasks they were not\ndesigned for. With LLMCheckup, we present an easily accessible tool that allows\nusers to chat with any state-of-the-art large language model (LLM) about its\nbehavior. We enable LLMs to generate all explanations by themselves and take\ncare of intent recognition without fine-tuning, by connecting them with a broad\nspectrum of Explainable AI (XAI) tools, e.g. feature attributions,\nembedding-based similarity, and prompting strategies for counterfactual and\nrationale generation. LLM (self-)explanations are presented as an interactive\ndialogue that supports follow-up questions and generates suggestions.\nLLMCheckup provides tutorials for operations available in the system, catering\nto individuals with varying levels of expertise in XAI and supports multiple\ninput modalities. We introduce a new parsing strategy called multi-prompt\nparsing substantially enhancing the parsing accuracy of LLMs. Finally, we\nshowcase the tasks of fact checking and commonsense question answering.", "field": "Computer Science", "categories": "cs.CL,cs.AI,cs.LG"}, {"arxiv_id": "2401.12578", "title": "ToDA: Target-oriented Diffusion Attacker against Recommendation System", "abstract": "Recommendation systems (RS) have become indispensable tools for web services\nto address information overload, thus enhancing user experiences and bolstering\nplatforms' revenues. However, with their increasing ubiquity, security concerns\nhave also emerged. As the public accessibility of RS, they are susceptible to\nspecific malicious attacks where adversaries can manipulate user profiles,\nleading to biased recommendations. Recent research often integrates additional\nmodules using generative models to craft these deceptive user profiles,\nensuring them are imperceptible while causing the intended harm. Albeit their\nefficacy, these models face challenges of unstable training and the\nexploration-exploitation dilemma, which can lead to suboptimal results. In this\npaper, we pioneer to investigate the potential of diffusion models (DMs), for\nshilling attacks. Specifically, we propose a novel Target-oriented Diffusion\nAttack model (ToDA). It incorporates a pre-trained autoencoder that transforms\nuser profiles into a high dimensional space, paired with a Latent Diffusion\nAttacker (LDA)-the core component of ToDA. LDA introduces noise into the\nprofiles within this latent space, adeptly steering the approximation towards\ntargeted items through cross-attention mechanisms. The global horizon,\nimplemented by a bipartite graph, is involved in LDA and derived from the\nencoded user profile feature. This makes LDA possible to extend the generation\noutwards the on-processing user feature itself, and bridges the gap between\ndiffused user features and target item features. Extensive experiments compared\nto several SOTA baselines demonstrate ToDA's effectiveness. Specific studies\nexploit the elaborative design of ToDA and underscore the potency of advanced\ngenerative models in such contexts.", "field": "Computer Science", "categories": "cs.CR"}, {"arxiv_id": "2401.12582", "title": "Investigation of FlexAlgo for User-driven Path Control", "abstract": "This paper examines the Flexible Algorithm (FlexAlgo) for its potential to\nenable user-driven path control in intra-domain Segment Routing (SR) enabled\nnetworks. FlexAlgo is a relatively new approach to intra-domain routing that\nallows multiple custom algorithms to coexist within a single domain. This\ncapability has the potential to provide users with greater control over the\npaths their data takes through a network. The research includes a thorough\ninvestigation of the FlexAlgo approach, including an examination of its\nunderlying techniques, as well as a practical implementation of a\nFlexAlgo-based solution. We depict performed experiments where we implemented\nFlexAlgo in three different scenarios. We also present how we developed an\nautomated tool for users to control traffic steering using preferred metrics\nand constraints. The results of this investigation demonstrate the capabilities\nof FlexAlgo as a means of enabling user-driven path control and therefore\nincrease security and trust of users towards the network.", "field": "Computer Science", "categories": "cs.NI,cs.CR"}, {"arxiv_id": "2401.12585", "title": "SLANG: New Concept Comprehension of Large Language Models", "abstract": "The dynamic nature of language, particularly evident in the realm of slang\nand memes on the Internet, poses serious challenges to the adaptability of\nlarge language models (LLMs). Traditionally anchored to static datasets, these\nmodels often struggle to keep up with the rapid linguistic evolution\ncharacteristic of online communities. This research addresses the critical need\nto bridge this gap, aiming to enhance LLMs' comprehension of evolving new\nconcepts on the internet, without the high cost and impracticality of continual\nretraining. To address this issue, we propose a new benchmark $\\textbf{SLANG}$\nto assess LLMs' proficiency in comprehending emerging linguistic trends and a\nbaseline approach $\\textbf{FOCUS}$, which uses causal inference to enhance LLMs\nto understand new phrases and usage patterns. This approach involves\nscrutinizing real-world instances of linguistic shifts, serving as contextual\nbeacons, to form more precise and contextually relevant connections between\nnewly emerging expressions and their intended meanings. The empirical analysis\nshows that our causal inference-based approach outperforms the traditional\nmodels in terms of precision and relevance in the interpretation of Internet\nslang and memes.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.12586", "title": "C2Ideas: Supporting Creative Interior Color Design Ideation with Large\n  Language Model", "abstract": "Interior color design is a creative process that endeavors to allocate colors\nto furniture and other elements within an interior space. While much research\nfocuses on generating realistic interior designs, these automated approaches\noften misalign with user intention and disregard design rationales. Informed by\na need-finding preliminary study, we develop C2Ideas, an innovative system for\ndesigners to creatively ideate color schemes enabled by an intent-aligned and\ndomain-oriented large language model. C2Ideas integrates a three-stage process:\nIdea Prompting stage distills user intentions into color linguistic prompts;\nWord-Color Association stage transforms the prompts into semantically and\nstylistically coherent color schemes; and Interior Coloring stage assigns\ncolors to interior elements complying with design principles. We also develop\nan interactive interface that enables flexible user refinement and\ninterpretable reasoning. C2Ideas has undergone a series of indoor cases and\nuser studies, demonstrating its effectiveness and high recognition of\ninteractive functionality by designers.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.12588", "title": "Interpreting Equivariant Representations", "abstract": "Latent representations are used extensively for downstream tasks, such as\nvisualization, interpolation or feature extraction of deep learning models.\nInvariant and equivariant neural networks are powerful and well-established\nmodels for enforcing inductive biases. In this paper, we demonstrate that the\ninductive bias imposed on the by an equivariant model must also be taken into\naccount when using latent representations. We show how not accounting for the\ninductive biases leads to decreased performance on downstream tasks, and vice\nversa, how accounting for inductive biases can be done effectively by using an\ninvariant projection of the latent representations. We propose principles for\nhow to choose such a projection, and show the impact of using these principles\nin two common examples: First, we study a permutation equivariant variational\nauto-encoder trained for molecule graph generation; here we show that invariant\nprojections can be designed that incur no loss of information in the resulting\ninvariant representation. Next, we study a rotation-equivariant representation\nused for image classification. Here, we illustrate how random invariant\nprojections can be used to obtain an invariant representation with a high\ndegree of retained information. In both cases, the analysis of invariant latent\nrepresentations proves superior to their equivariant counterparts. Finally, we\nillustrate that the phenomena documented here for equivariant neural networks\nhave counterparts in standard neural networks where invariance is encouraged\nvia augmentation. Thus, while these ambiguities may be known by experienced\ndevelopers of equivariant models, we make both the knowledge as well as\neffective tools to handle the ambiguities available to the broader community.", "field": "Computer Science", "categories": "cs.LG,stat.ML"}, {"arxiv_id": "2401.12589", "title": "Superconvergent postprocessing of $C^0$ interior penalty method", "abstract": "This paper focuses on the superconvergence analysis of the Hessian recovery\ntechnique for the $C^0$ Interior Penalty Method (C0IP) in solving the\nbiharmonic equation. We establish interior error estimates for C0IP method that\nserve as the superconvergent analysis tool. Using the argument of\nsuperconvergence by difference quotient, we prove superconvergent results of\nthe recovered Hessian matrix on translation-invariant meshes. The Hessian\nrecovery technique enables us to construct an asymptotically exact ${\\it a\\,\nposteriori}$ error estimator for the C0IP method. Numerical experiments are\nprovided to support our theoretical results.", "field": "Computer Science", "categories": "math.NA,cs.NA,65N30, 65N25, 65N15, 65N50"}, {"arxiv_id": "2401.1259", "title": "PolyCF: Towards the Optimal Spectral Graph Filters for Collaborative\n  Filtering", "abstract": "Collaborative Filtering (CF) is a pivotal research area in recommender\nsystems that capitalizes on collaborative similarities between users and items\nto provide personalized recommendations. With the remarkable achievements of\nnode embedding-based Graph Neural Networks (GNNs), we explore the upper bounds\nof expressiveness inherent to embedding-based methodologies and tackle the\nchallenges by reframing the CF task as a graph signal processing problem. To\nthis end, we propose PolyCF, a flexible graph signal filter that leverages\npolynomial graph filters to process interaction signals. PolyCF exhibits the\ncapability to capture spectral features across multiple eigenspaces through a\nseries of Generalized Gram filters and is able to approximate the optimal\npolynomial response function for recovering missing interactions. A graph\noptimization objective and a pair-wise ranking objective are jointly used to\noptimize the parameters of the convolution kernel. Experiments on three widely\nadopted datasets demonstrate the superiority of PolyCF over current\nstate-of-the-art CF methods. Moreover, comprehensive studies empirically\nvalidate each component's efficacy in the proposed PolyCF.", "field": "Computer Science", "categories": "cs.IR"}, {"arxiv_id": "2401.12592", "title": "RGBD Objects in the Wild: Scaling Real-World 3D Object Learning from\n  RGB-D Videos", "abstract": "We introduce a new RGB-D object dataset captured in the wild called\nWildRGB-D. Unlike most existing real-world object-centric datasets which only\ncome with RGB capturing, the direct capture of the depth channel allows better\n3D annotations and broader downstream applications. WildRGB-D comprises\nlarge-scale category-level RGB-D object videos, which are taken using an iPhone\nto go around the objects in 360 degrees. It contains around 8500 recorded\nobjects and nearly 20000 RGB-D videos across 46 common object categories. These\nvideos are taken with diverse cluttered backgrounds with three setups to cover\nas many real-world scenarios as possible: (i) a single object in one video;\n(ii) multiple objects in one video; and (iii) an object with a static hand in\none video. The dataset is annotated with object masks, real-world scale camera\nposes, and reconstructed aggregated point clouds from RGBD videos. We benchmark\nfour tasks with WildRGB-D including novel view synthesis, camera pose\nestimation, object 6d pose estimation, and object surface reconstruction. Our\nexperiments show that the large-scale capture of RGB-D objects provides a large\npotential to advance 3D object learning. Our project page is\nhttps://wildrgbd.github.io/.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.12593", "title": "MOReGIn: Multi-Objective Recommendation at the Global and Individual\n  Levels", "abstract": "Multi-Objective Recommender Systems (MORSs) emerged as a paradigm to\nguarantee multiple (often conflicting) goals. Besides accuracy, a MORS can\noperate at the global level, where additional beyond-accuracy goals are met for\nthe system as a whole, or at the individual level, meaning that the\nrecommendations are tailored to the needs of each user. The state-of-the-art\nMORSs either operate at the global or individual level, without assuming the\nco-existence of the two perspectives. In this study, we show that when global\nand individual objectives co-exist, MORSs are not able to meet both types of\ngoals. To overcome this issue, we present an approach that regulates the\nrecommendation lists so as to guarantee both global and individual\nperspectives, while preserving its effectiveness. Specifically, as individual\nperspective, we tackle genre calibration and, as global perspective, provider\nfairness. We validate our approach on two real-world datasets, publicly\nreleased with this paper.", "field": "Computer Science", "categories": "cs.IR,cs.AI"}, {"arxiv_id": "2401.12594", "title": "SCORPION Cyber Range: Fully Customizable Cyberexercises, Gamification\n  and Learning Analytics to Train Cybersecurity Competencies", "abstract": "It is undeniable that we are witnessing an unprecedented digital revolution.\nHowever, recent years have been characterized by the explosion of cyberattacks,\nmaking cybercrime one of the most profitable businesses on the planet. That is\nwhy training in cybersecurity is increasingly essential to protect the assets\nof cyberspace. One of the most vital tools to train cybersecurity competencies\nis the Cyber Range, a virtualized environment that simulates realistic\nnetworks. The paper at hand introduces SCORPION, a fully functional and\nvirtualized Cyber Range, which manages the authoring and automated deployment\nof scenarios. In addition, SCORPION includes several elements to improve\nstudent motivation, such as a gamification system with medals, points, or\nrankings, among other elements. Such a gamification system includes an adaptive\nlearning module that is able to adapt the cyberexercise based on the users'\nperformance. Moreover, SCORPION leverages learning analytics that collects and\nprocesses telemetric and biometric user data, including heart rate through a\nsmartwatch, which is available through a dashboard for instructors. Finally, we\ndeveloped a case study where SCORPION obtained 82.10\\% in usability and 4.57\nout of 5 in usefulness from the viewpoint of a student and an instructor. The\npositive evaluation results are promising, indicating that SCORPION can become\nan effective, motivating, and advanced cybersecurity training tool to help fill\ncurrent gaps in this context.", "field": "Computer Science", "categories": "cs.CR,cs.CY"}, {"arxiv_id": "2401.12596", "title": "UniHDA: Towards Universal Hybrid Domain Adaptation of Image Generators", "abstract": "Generative domain adaptation has achieved remarkable progress, enabling us to\nadapt a pre-trained generator to a new target domain. However, existing methods\nsimply adapt the generator to a single target domain and are limited to a\nsingle modality, either text-driven or image-driven. Moreover, they are prone\nto overfitting domain-specific attributes, which inevitably compromises\ncross-domain consistency. In this paper, we propose UniHDA, a unified and\nversatile framework for generative hybrid domain adaptation with multi-modal\nreferences from multiple domains. We use CLIP encoder to project multi-modal\nreferences into a unified embedding space and then linear interpolate the\ndirection vectors from multiple target domains to achieve hybrid domain\nadaptation. To ensure the cross-domain consistency, we propose a novel\ncross-domain spatial structure (CSS) loss that maintains detailed spatial\nstructure information between source and target generator. Experiments show\nthat the adapted generator can synthesise realistic images with various\nattribute compositions. Additionally, our framework is versatile to multiple\ngenerators, \\eg, StyleGAN2 and Diffusion Models.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.12597", "title": "Towards Privacy-, Budget-, and Deadline-Aware Service Optimization for\n  Large Medical Image Processing across Hybrid Clouds", "abstract": "Efficiently processing medical images, such as whole slide images in digital\npathology, is essential for timely diagnosing high-risk diseases. However, this\ndemands advanced computing infrastructure, e.g., GPU servers for deep learning\ninferencing, and local processing is time-consuming and costly. Besides,\nprivacy concerns further complicate the employment of remote cloud\ninfrastructures. While previous research has explored privacy and\nsecurity-aware workflow scheduling in hybrid clouds for distributed processing,\nprivacy-preserving data splitting, optimizing the service allocation of\noutsourcing computation on split data to the cloud, and privacy evaluation for\nlarge medical images still need to be addressed. This study focuses on\ntailoring a virtual infrastructure within a hybrid cloud environment and\nscheduling the image processing services while preserving privacy. We aim to\nminimize the use of untrusted nodes, lower monetary costs, and reduce execution\ntime under privacy, budget, and deadline requirements. We consider a two-phase\nsolution and develop 1) a privacy-preserving data splitting algorithm and 2) a\ngreedy Pareto front-based algorithm for optimizing the service allocation. We\nconducted experiments with real and simulated data to validate and compare our\nmethod with a baseline. The results show that our privacy mechanism design\noutperforms the baseline regarding the average lower band on individual privacy\nand information gain for privacy evaluation. In addition, our approach can\nobtain various Pareto optimal-based allocations with users' preferences on the\nmaximum number of untrusted nodes, budget, and time threshold. Our solutions\noften dominate the baseline's solution and are superior on a tight budget.\nSpecifically, our approach has been ahead of baseline, up to 85.2% and 6.8% in\nterms of the total financial and time costs, respectively.", "field": "Computer Science", "categories": "cs.DC"}, {"arxiv_id": "2401.12599", "title": "Revolutionizing Retrieval-Augmented Generation with Enhanced PDF\n  Structure Recognition", "abstract": "With the rapid development of Large Language Models (LLMs),\nRetrieval-Augmented Generation (RAG) has become a predominant method in the\nfield of professional knowledge-based question answering. Presently, major\nfoundation model companies have opened up Embedding and Chat API interfaces,\nand frameworks like LangChain have already integrated the RAG process. It\nappears that the key models and steps in RAG have been resolved, leading to the\nquestion: are professional knowledge QA systems now approaching perfection?\nThis article discovers that current primary methods depend on the premise of\naccessing high-quality text corpora. However, since professional documents are\nmainly stored in PDFs, the low accuracy of PDF parsing significantly impacts\nthe effectiveness of professional knowledge-based QA. We conducted an empirical\nRAG experiment across hundreds of questions from the corresponding real-world\nprofessional documents. The results show that, ChatDOC, a RAG system equipped\nwith a panoptic and pinpoint PDF parser, retrieves more accurate and complete\nsegments, and thus better answers. Empirical experiments show that ChatDOC is\nsuperior to baseline on nearly 47% of questions, ties for 38% of cases, and\nfalls short on only 15% of cases. It shows that we may revolutionize RAG with\nenhanced PDF structure recognition.", "field": "Computer Science", "categories": "cs.AI"}, {"arxiv_id": "2401.126", "title": "EEND-M2F: Masked-attention mask transformers for speaker diarization", "abstract": "In this paper, we make the explicit connection between image segmentation\nmethods and end-to-end diarization methods. From these insights, we propose a\nnovel, fully end-to-end diarization model, EEND-M2F, based on the Mask2Former\narchitecture. Speaker representations are computed in parallel using a stack of\ntransformer decoders, in which irrelevant frames are explicitly masked from the\ncross attention using predictions from previous layers. EEND-M2F is\nlightweight, efficient, and truly end-to-end, as it does not require any\nadditional diarization, speaker verification, or segmentation models to run,\nnor does it require running any clustering algorithms. Our model achieves\nstate-of-the-art performance on several public datasets, such as AMI,\nAliMeeting and RAMC. Most notably our DER of 16.07% on DIHARD-III is the first\nmajor improvement upon the challenge winning system.", "field": "Computer Science", "categories": "cs.SD,eess.AS"}, {"arxiv_id": "2401.12602", "title": "A coupling concept for Stokes-Darcy systems: the ICDD method", "abstract": "We present a coupling framework for Stokes-Darcy systems valid for arbitrary\nflow direction at low Reynolds numbers and for isotropic porous media. The\nproposed method is based on an overlapping domain decomposition concept to\nrepresent the transition region between the free-fluid and the porous-medium\nregimes. Matching conditions at the interfaces of the decomposition impose the\ncontinuity of velocity (on one interface) and pressure (on the other one) and\nthe resulting algorithm can be easily implemented in a non-intrusive way. The\nnumerical approximations of the fluid velocity and pressure obtained by the\nstudied method converge to the corresponding counterparts computed by direct\nnumerical simulation at the microscale, with convergence rates equal to\nsuitable powers of the scale separation parameter $\\varepsilon$ in agreement\nwith classical results in homogenization.", "field": "Computer Science", "categories": "math.NA,cs.NA,physics.flu-dyn"}, {"arxiv_id": "2401.12603", "title": "ASAP (Automatic Software for ASL Processing): A toolbox for processing\n  Arterial Spin Labeling images", "abstract": "The method of Arterial Spin Labeling (ASL) has experienced a significant rise\nin its application to functional imaging, since it is the only technique\ncapable of measuring blood perfusion in a truly non-invasive manner. Currently,\nthere are no commercial packages for processing ASL data and there is no\nrecognised standard for normalising ASL data to a common frame of reference.\nThis work describes a new Automated Software for ASL Processing (ASAP) that can\nautomatically process several ASL datasets. ASAP includes functions for all\nstages of image pre-processing: quantification, skull-stripping,\nco-registration, partial volume correction and normalization. To assess the\napplicability and validity of the toolbox, this work shows its application in\nthe study of hypoperfusion in a sample of healthy subjects at risk of\nprogressing to Alzheimer's Disease. ASAP requires limited user intervention,\nminimising the possibility of random and systematic errors, and produces\ncerebral blood flow maps that are ready for statistical group analysis. The\nsoftware is easy to operate and results in excellent quality of spatial\nnormalisation. The results found in this evaluation study are consistent with\nprevious studies that find decreased perfusion", "field": "Computer Science", "categories": "cs.SE"}, {"arxiv_id": "2401.12604", "title": "On Pigeonhole Principles and Ramsey in TFNP", "abstract": "The generalized pigeonhole principle says that if tN + 1 pigeons are put into\nN holes then there must be a hole containing at least t + 1 pigeons. Let t-PPP\ndenote the class of all total NP-search problems reducible to finding such a\nt-collision of pigeons. We introduce a new hierarchy of classes defined by the\nproblems t-PPP. In addition to being natural problems in TFNP, we show that\nclasses in and above the hierarchy are related to the notion of multi-collision\nresistance in cryptography, and contain the problem underlying the breakthrough\naverage-case quantum advantage result shown by Yamakawa & Zhandry (FOCS 2022).\n  Finally, we give lower bound techniques for the black-box versions of t-PPP\nfor any t. In particular, we prove that RAMSEY is not in t-PPP, for any t that\nis sub-polynomial in log (N), in the black-box setting. Goldberg and\nPapadimitriou conjectured that RAMSEY reduces to 2-PPP, we thus refute it and\nmore in the black-box setting. We also provide an ensemble of black-box\nseparations which resolve the relative complexity of the t-PPP classes with\nother well-known TFNP classes.", "field": "Computer Science", "categories": "cs.CC"}, {"arxiv_id": "2401.12609", "title": "Fast Semi-supervised Unmixing using Non-convex Optimization", "abstract": "In this paper, we introduce a novel linear model tailored for\nsemisupervised/library-based unmixing. Our model incorporates considerations\nfor library mismatch while enabling the enforcement of the abundance sum-to-one\nconstraint (ASC). Unlike conventional sparse unmixing methods, this model\ninvolves nonconvex optimization, presenting significant computational\nchallenges. We demonstrate the efficacy of Alternating Methods of Multipliers\n(ADMM) in cyclically solving these intricate problems. We propose two\nsemisupervised unmixing approaches, each relying on distinct priors applied to\nthe new model in addition to the ASC: sparsity prior and convexity constraint.\nOur experimental results validate that enforcing the convexity constraint\noutperforms the sparsity prior for the endmember library. These results are\ncorroborated across three simulated datasets (accounting for spectral\nvariability and varying pixel purity levels) and the Cuprite dataset.\nAdditionally, our comparison with conventional sparse unmixing methods\nshowcases considerable advantages of our proposed model, which entails\nnonconvex optimization. Notably, our implementations of the proposed\nalgorithms-fast semisupervised unmixing (FaSUn) and sparse unmixing using\nsoft-shrinkage (SUnS)-prove considerably more efficient than traditional sparse\nunmixing methods. SUnS and FaSUn were implemented using PyTorch and provided in\na dedicated Python package called Fast Semisupervised Unmixing (FUnmix), which\nis open-source and available at https://github.com/BehnoodRasti/FUnmix", "field": "Computer Science", "categories": "cs.CV,cs.LG,eess.IV"}, {"arxiv_id": "2401.1261", "title": "The twin peaks of learning neural networks", "abstract": "Recent works demonstrated the existence of a double-descent phenomenon for\nthe generalization error of neural networks, where highly overparameterized\nmodels escape overfitting and achieve good test performance, at odds with the\nstandard bias-variance trade-off described by statistical learning theory. In\nthe present work, we explore a link between this phenomenon and the increase of\ncomplexity and sensitivity of the function represented by neural networks. In\nparticular, we study the Boolean mean dimension (BMD), a metric developed in\nthe context of Boolean function analysis. Focusing on a simple teacher-student\nsetting for the random feature model, we derive a theoretical analysis based on\nthe replica method that yields an interpretable expression for the BMD, in the\nhigh dimensional regime where the number of data points, the number of\nfeatures, and the input size grow to infinity. We find that, as the degree of\noverparameterization of the network is increased, the BMD reaches an evident\npeak at the interpolation threshold, in correspondence with the generalization\nerror peak, and then slowly approaches a low asymptotic value. The same\nphenomenology is then traced in numerical experiments with different model\nclasses and training setups. Moreover, we find empirically that adversarially\ninitialized models tend to show higher BMD values, and that models that are\nmore robust to adversarial attacks exhibit a lower BMD.", "field": "Computer Science", "categories": "cs.LG,cond-mat.dis-nn,math.PR,math.ST,stat.TH"}, {"arxiv_id": "2401.12611", "title": "Prompt Smells: An Omen for Undesirable Generative AI Outputs", "abstract": "Recent Generative Artificial Intelligence (GenAI) trends focus on various\napplications, including creating stories, illustrations, poems, articles,\ncomputer code, music compositions, and videos. Extrinsic hallucinations are a\ncritical limitation of such GenAI, which can lead to significant challenges in\nachieving and maintaining the trustworthiness of GenAI. In this paper, we\npropose two new concepts that we believe will aid the research community in\naddressing limitations associated with the application of GenAI models. First,\nwe propose a definition for the \"desirability\" of GenAI outputs and three\nfactors which are observed to influence it. Second, drawing inspiration from\nMartin Fowler's code smells, we propose the concept of \"prompt smells\" and the\nadverse effects they are observed to have on the desirability of GenAI outputs.\nWe expect our work will contribute to the ongoing conversation about the\ndesirability of GenAI outputs and help advance the field in a meaningful way.", "field": "Computer Science", "categories": "cs.LG,cs.SE"}, {"arxiv_id": "2401.12617", "title": "The Joint Effect of Task Similarity and Overparameterization on\n  Catastrophic Forgetting -- An Analytical Model", "abstract": "In continual learning, catastrophic forgetting is affected by multiple\naspects of the tasks. Previous works have analyzed separately how forgetting is\naffected by either task similarity or overparameterization. In contrast, our\npaper examines how task similarity and overparameterization jointly affect\nforgetting in an analyzable model. Specifically, we focus on two-task continual\nlinear regression, where the second task is a random orthogonal transformation\nof an arbitrary first task (an abstraction of random permutation tasks). We\nderive an exact analytical expression for the expected forgetting - and uncover\na nuanced pattern. In highly overparameterized models, intermediate task\nsimilarity causes the most forgetting. However, near the interpolation\nthreshold, forgetting decreases monotonically with the expected task\nsimilarity. We validate our findings with linear regression on synthetic data,\nand with neural networks on established permutation task benchmarks.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.12618", "title": "Computation of classical and $v$-adic $L$-series of $t$-motives", "abstract": "We design an algorithm for computing the $L$-series associated to an Anderson\n$t$-motives, exhibiting quasilinear complexity with respect to the target\nprecision. Based on experiments, we conjecture that the order of vanishing at\n$T=1$ of the $v$-adic $L$-series of a given Anderson $t$-motive with good\nreduction does not depend on the finite place $v$.", "field": "Computer Science", "categories": "cs.SC,math.NT"}, {"arxiv_id": "2401.12624", "title": "Knowledge Distillation from Language-Oriented to Emergent Communication\n  for Multi-Agent Remote Control", "abstract": "In this work, we compare emergent communication (EC) built upon multi-agent\ndeep reinforcement learning (MADRL) and language-oriented semantic\ncommunication (LSC) empowered by a pre-trained large language model (LLM) using\nhuman language. In a multi-agent remote navigation task, with multimodal input\ndata comprising location and channel maps, it is shown that EC incurs high\ntraining cost and struggles when using multimodal data, whereas LSC yields high\ninference computing cost due to the LLM's large size. To address their\nrespective bottlenecks, we propose a novel framework of language-guided EC\n(LEC) by guiding the EC training using LSC via knowledge distillation (KD).\nSimulations corroborate that LEC achieves faster travel time while avoiding\nareas with poor channel conditions, as well as speeding up the MADRL training\nconvergence by up to 61.8% compared to EC.", "field": "Computer Science", "categories": "cs.AI,cs.IT,cs.LG,cs.NI,math.IT"}, {"arxiv_id": "2401.12627", "title": "Blind Channel Estimation and Joint Symbol Detection with Data-Driven\n  Factor Graphs", "abstract": "We investigate the application of the factor graph framework for blind joint\nchannel estimation and symbol detection on time-variant linear inter-symbol\ninterference channels. In particular, we consider the expectation maximization\n(EM) algorithm for maximum likelihood estimation, which typically suffers from\nhigh complexity as it requires the computation of the symbol-wise posterior\ndistributions in every iteration. We address this issue by efficiently\napproximating the posteriors using the belief propagation (BP) algorithm on a\nsuitable factor graph. By interweaving the iterations of BP and EM, the\ndetection complexity can be further reduced to a single BP iteration per EM\nstep. In addition, we propose a data-driven version of our algorithm that\nintroduces momentum in the BP updates and learns a suitable EM parameter update\nschedule, thereby significantly improving the performance-complexity tradeoff\nwith a few offline training samples. Our numerical experiments demonstrate the\nexcellent performance of the proposed blind detector and show that it even\noutperforms coherent BP detection in high signal-to-noise scenarios.", "field": "Computer Science", "categories": "cs.IT,cs.LG,eess.SP,math.IT"}, {"arxiv_id": "2401.1263", "title": "Full-Stack Optimization for CAM-Only DNN Inference", "abstract": "The accuracy of neural networks has greatly improved across various domains\nover the past years. Their ever-increasing complexity, however, leads to\nprohibitively high energy demands and latency in von Neumann systems. Several\ncomputing-in-memory (CIM) systems have recently been proposed to overcome this,\nbut trade-offs involving accuracy, hardware reliability, and scalability for\nlarge models remain a challenge. Additionally, for some CIM designs, the\nactivation movement still requires considerable time and energy. This paper\nexplores the combination of algorithmic optimizations for ternary weight neural\nnetworks and associative processors (APs) implemented using racetrack memory\n(RTM). We propose a novel compilation flow to optimize convolutions on APs by\nreducing their arithmetic intensity. By leveraging the benefits of RTM-based\nAPs, this approach substantially reduces data transfers within the memory while\naddressing accuracy, energy efficiency, and reliability concerns. Concretely,\nour solution improves the energy efficiency of ResNet-18 inference on ImageNet\nby 7.5x compared to crossbar in-memory accelerators while retaining software\naccuracy.", "field": "Computer Science", "categories": "cs.AR,cs.ET,cs.LG"}, {"arxiv_id": "2401.12631", "title": "A Reply to Makelov et al. (2023)'s \"Interpretability Illusion\" Arguments", "abstract": "We respond to the recent paper by Makelov et al. (2023), which reviews\nsubspace interchange intervention methods like distributed alignment search\n(DAS; Geiger et al. 2023) and claims that these methods potentially cause\n\"interpretability illusions\". We first review Makelov et al. (2023)'s technical\nnotion of what an \"interpretability illusion\" is, and then we show that even\nintuitive and desirable explanations can qualify as illusions in this sense. As\na result, their method of discovering \"illusions\" can reject explanations they\nconsider \"non-illusory\". We then argue that the illusions Makelov et al. (2023)\nsee in practice are artifacts of their training and evaluation paradigms. We\nclose by emphasizing that, though we disagree with their core characterization,\nMakelov et al. (2023)'s examples and discussion have undoubtedly pushed the\nfield of interpretability forward.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.CL"}, {"arxiv_id": "2401.12632", "title": "Modeling Resilience of Collaborative AI Systems", "abstract": "A Collaborative Artificial Intelligence System (CAIS) performs actions in\ncollaboration with the human to achieve a common goal. CAISs can use a trained\nAI model to control human-system interaction, or they can use human interaction\nto dynamically learn from humans in an online fashion. In online learning with\nhuman feedback, the AI model evolves by monitoring human interaction through\nthe system sensors in the learning state, and actuates the autonomous\ncomponents of the CAIS based on the learning in the operational state.\nTherefore, any disruptive event affecting these sensors may affect the AI\nmodel's ability to make accurate decisions and degrade the CAIS performance.\nConsequently, it is of paramount importance for CAIS managers to be able to\nautomatically track the system performance to understand the resilience of the\nCAIS upon such disruptive events. In this paper, we provide a new framework to\nmodel CAIS performance when the system experiences a disruptive event. With our\nframework, we introduce a model of performance evolution of CAIS. The model is\nequipped with a set of measures that aim to support CAIS managers in the\ndecision process to achieve the required resilience of the system. We tested\nour framework on a real-world case study of a robot collaborating online with\nthe human, when the system is experiencing a disruptive event. The case study\nshows that our framework can be adopted in CAIS and integrated into the online\nexecution of the CAIS activities.", "field": "Computer Science", "categories": "cs.SE,cs.AI,cs.RO"}, {"arxiv_id": "2401.12633", "title": "Heterogeneity- and homophily-induced vulnerability of a P2P network\n  formation model: the IOTA auto-peering protocol", "abstract": "IOTA is a distributed ledger technology that relies on a peer-to-peer (P2P)\nnetwork for communications. Recently an auto-peering algorithm was proposed to\nbuild connections among IOTA peers according to their \"Mana\" endowment, which\nis an IOTA internal reputation system. This paper's goal is to detect potential\nvulnerabilities and evaluate the resilience of the P2P network generated using\nIOTA auto-peering algorithm against eclipse attacks. In order to do so, we\ninterpret IOTA's auto-peering algorithm as a random network formation model and\nemploy different network metrics to identify cost-efficient partitions of the\nnetwork. As a result, we present a potential strategy that an attacker can use\nto eclipse a significant part of the network, providing estimates of costs and\npotential damage caused by the attack. On the side, we provide an analysis of\nthe properties of IOTA auto-peering network ensemble, as an interesting class\nof homophile random networks in between 1D lattices and regular Poisson graphs.", "field": "Computer Science", "categories": "cs.SI,cs.CR"}, {"arxiv_id": "2401.12634", "title": "Assisted Requirements Selection by Clustering", "abstract": "Requirements selection is a decision-making process that enables project\nmanagers to focus on the deliverables that add most value to the project\noutcome. This task is performed to define which features or requirements will\nbe developed in the next release. It is a complex multi-criteria decision\nprocess that has been focused by many research works because a balance between\nbusiness profits and investment is needed. The spectrum of prioritization\ntechniques spans from simple and qualitative to elaborated analytic\nprioritization approaches that fall into the category of optimization\nalgorithms. This work studies the combination of the qualitative MoSCoW method\nand cluster analysis for requirements selection. The feasibility of our\nmethodology has been tested on three case studies (with 20, 50 and 100\nrequirements). In each of them, the requirements have been clustered, then the\nclustering configurations found have been evaluated using internal validation\nmeasures for the compactness, connectivity and separability of the clusters.\nThe experimental results show the validity of clustering strategies for the\nidentification of the core set of requirements for the software product, being\nthe number of categories proposed by MoSCoW a good starting point in\nrequirements prioritization and negotiation.", "field": "Computer Science", "categories": "cs.SE"}, {"arxiv_id": "2401.12636", "title": "Stability prediction of the software requirements specification", "abstract": "Complex decision-making is a prominent aspect of Requirements Engineering.\nThis work presents the Bayesian network Requisites that predicts whether the\nrequirements specification documents have to be revised. We show how to\nvalidate Requisites by means of metrics obtained from a large complex software\nproject. Besides, this Bayesian network has been integrated into a software\ntool by defining a communication interface inside a multilayer architecture to\nadd this a new decision making functionality. It provides requirements\nengineers a way of exploring the software requirement specification by\ncombining requirement metrics and the probability values estimated by the\nBayesian network.", "field": "Computer Science", "categories": "cs.SE"}, {"arxiv_id": "2401.12638", "title": "On The Axioms Of $\\mathcal{M},\\mathcal{N}$-Adhesive Categories", "abstract": "Adhesive and quasiadhesive categories provide a general framework for the\nstudy of algebraic graph rewriting systems. In a quasiadhesive category any two\nregular subobjects have a join which is again a regular subobject. Vice versa,\nif regular monos are adhesive, then the existence of a regular join for any\npair of regular subobjects entails quasiadhesivity. It is also known\n(quasi)adhesive categories can be embedded in a Grothendieck topos via a\nfunctor preserving pullbacks and pushouts along (regular) monomorphisms. In\nthis paper we extend these results to $\\mathcal{M}, \\mathcal{N}$-adhesive\ncategories, a concept recently introduced to generalize the notion of\n(quasi)adhesivity. We introduce the notion of $\\mathcal{N}$-adhesive morphism,\nwhich allows us to express $\\mathcal{M}, \\mathcal{N}$-adhesivity as a condition\non the subobjects's posets. Moreover, $\\mathcal{N}$-adhesive morphisms allows\nus to show how an $\\mathcal{M},\\mathcal{N}$-adhesive category can be embedded\ninto a Grothendieck topos, preserving pullbacks and $\\mathcal{M},\n\\mathcal{N}$-pushouts.", "field": "Computer Science", "categories": "cs.LO,math.CT,F.4.1"}, {"arxiv_id": "2401.12639", "title": "Efficient Matching with Memoization for Regexes with Look-around and\n  Atomic Grouping (Extended Version)", "abstract": "Regular expression (regex) matching is fundamental in many applications,\nespecially in web services. However, matching by backtracking -- preferred by\nmost real-world implementations for its practical performance and backward\ncompatibility -- can suffer from so-called catastrophic backtracking, which\nmakes the number of backtracking super-linear and leads to the well-known ReDoS\nvulnerability. Inspired by a recent algorithm by Davis et al. that runs in\nlinear time for (non-extended) regexes, we study efficient backtracking\nmatching for regexes with two common extensions, namely look-around and atomic\ngrouping. We present linear-time backtracking matching algorithms for these\nextended regexes. Their efficiency relies on memoization, much like the one by\nDavis et al.; we also strive for smaller memoization tables by carefully\ntrimming their range. Our experiments -- we used some real-world regexes with\nthe aforementioned extensions -- confirm the performance advantage of our\nalgorithms.", "field": "Computer Science", "categories": "cs.PL"}, {"arxiv_id": "2401.12643", "title": "Gray-Box Fuzzing via Gradient Descent and Boolean Expression Coverage\n  (Technical Report)", "abstract": "We present a novel gray-box fuzzing algorithm monitoring executions of\ninstructions converting numerical values to Boolean ones. An important class of\nsuch instructions evaluate predicates, e.g., *cmp in LLVM. That alone allows us\nto infer the input dependency (c.f. the taint analysis) during the fuzzing\non-the-fly with reasonable accuracy, which in turn enables an effective use of\nthe gradient descent on these instructions (to invert the result of their\nevaluation). Although the fuzzing attempts to maximize the coverage of the\ninstructions, there is an interesting correlation with the standard branch\ncoverage, which we are able to achieve indirectly. The evaluation on Test-Comp\n2023 benchmarks shows that our approach, despite being a pure gray-box fuzzing,\nis able to compete with the leading tools in the competition, which combine\nfuzzing with other powerful techniques like model checking, symbolic execution,\nor abstract interpretation.", "field": "Computer Science", "categories": "cs.PL"}, {"arxiv_id": "2401.12644", "title": "Binary Feature Mask Optimization for Feature Selection", "abstract": "We investigate feature selection problem for generic machine learning (ML)\nmodels. We introduce a novel framework that selects features considering the\npredictions of the model. Our framework innovates by using a novel feature\nmasking approach to eliminate the features during the selection process,\ninstead of completely removing them from the dataset. This allows us to use the\nsame ML model during feature selection, unlike other feature selection methods\nwhere we need to train the ML model again as the dataset has different\ndimensions on each iteration. We obtain the mask operator using the predictions\nof the ML model, which offers a comprehensive view on the subsets of the\nfeatures essential for the predictive performance of the model. A variety of\napproaches exist in the feature selection literature. However, no study has\nintroduced a training-free framework for a generic ML model to select features\nwhile considering the importance of the feature subsets as a whole, instead of\nfocusing on the individual features. We demonstrate significant performance\nimprovements on the real-life datasets under different settings using LightGBM\nand Multi-Layer Perceptron as our ML models. Additionally, we openly share the\nimplementation code for our methods to encourage the research and the\ncontributions in this area.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.12645", "title": "On the Robustness of Deep Learning-aided Symbol Detectors to Varying\n  Conditions and Imperfect Channel Knowledge", "abstract": "Recently, a data-driven Bahl-Cocke-Jelinek-Raviv (BCJR) algorithm tailored to\nchannels with intersymbol interference has been introduced. This so-called\nBCJRNet algorithm utilizes neural networks to calculate channel likelihoods.\nBCJRNet has demonstrated resilience against inaccurate channel tap estimations\nwhen applied to a time-invariant channel with ideal exponential decay profiles.\nHowever, its generalization capabilities for practically-relevant time-varying\nchannels, where the receiver can only access incorrect channel parameters,\nremain largely unexplored. The primary contribution of this paper is to expand\nupon the results from existing literature to encompass a variety of imperfect\nchannel knowledge cases that appear in real-world transmissions. Our findings\ndemonstrate that BCJRNet significantly outperforms the conventional BCJR\nalgorithm for stationary transmission scenarios when learning from noisy\nchannel data and with imperfect channel decay profiles. However, this advantage\nis shown to diminish when the operating channel is also rapidly time-varying.\nOur results also show the importance of memory assumptions for conventional\nBCJR and BCJRNet. An underestimation of the memory largely degrades the\nperformance of both BCJR and BCJRNet, especially in a slow-decaying channel. To\nmimic a situation closer to a practical scenario, we also combined channel tap\nuncertainty with imperfect channel memory knowledge. Somewhat surprisingly, our\nresults revealed improved performance when employing the conventional BCJR with\nan underestimated memory assumption. BCJRNet, on the other hand, showed a\nconsistent performance improvement as the level of accurate memory knowledge\nincreased.", "field": "Computer Science", "categories": "cs.IT,cs.LG,eess.SP,math.IT"}, {"arxiv_id": "2401.12646", "title": "Emergent Cooperation under Uncertain Incentive Alignment", "abstract": "Understanding the emergence of cooperation in systems of computational agents\nis crucial for the development of effective cooperative AI. Interaction among\nindividuals in real-world settings are often sparse and occur within a broad\nspectrum of incentives, which often are only partially known. In this work, we\nexplore how cooperation can arise among reinforcement learning agents in\nscenarios characterised by infrequent encounters, and where agents face\nuncertainty about the alignment of their incentives with those of others. To do\nso, we train the agents under a wide spectrum of environments ranging from\nfully competitive, to fully cooperative, to mixed-motives. Under this type of\nuncertainty we study the effects of mechanisms, such as reputation and\nintrinsic rewards, that have been proposed in the literature to foster\ncooperation in mixed-motives environments. Our findings show that uncertainty\nsubstantially lowers the agents' ability to engage in cooperative behaviour,\nwhen that would be the best course of action. In this scenario, the use of\neffective reputation mechanisms and intrinsic rewards boosts the agents'\ncapability to act nearly-optimally in cooperative environments, while greatly\nenhancing cooperation in mixed-motive environments as well.", "field": "Computer Science", "categories": "cs.MA,cs.AI,cs.GT"}, {"arxiv_id": "2401.12648", "title": "Consistency Enhancement-Based Deep Multiview Clustering via Contrastive\n  Learning", "abstract": "Multiview clustering (MVC) segregates data samples into meaningful clusters\nby synthesizing information across multiple views. Moreover, deep\nlearning-based methods have demonstrated their strong feature learning\ncapabilities in MVC scenarios. However, effectively generalizing feature\nrepresentations while maintaining consistency is still an intractable problem.\nIn addition, most existing deep clustering methods based on contrastive\nlearning overlook the consistency of the clustering representations during the\nclustering process. In this paper, we show how the above problems can be\novercome and propose a consistent enhancement-based deep MVC method via\ncontrastive learning (CCEC). Specifically, semantic connection blocks are\nincorporated into a feature representation to preserve the consistent\ninformation among multiple views. Furthermore, the representation process for\nclustering is enhanced through spectral clustering, and the consistency across\nmultiple views is improved. Experiments conducted on five datasets demonstrate\nthe effectiveness and superiority of our method in comparison with the\nstate-of-the-art (SOTA) methods. The code for this method can be accessed at\nhttps://anonymous.4open.science/r/CCEC-E84E/.", "field": "Computer Science", "categories": "cs.LG,cs.CV"}, {"arxiv_id": "2401.12649", "title": "Space-time unfitted finite elements on moving explicit geometry\n  representations", "abstract": "This work proposes a novel variational approximation of partial differential\nequations on moving geometries determined by explicit boundary representations.\nThe benefits of the proposed formulation are the ability to handle large\ndisplacements of explicitly represented domain boundaries without generating\nbody-fitted meshes and remeshing techniques. For the space discretization, we\nuse a background mesh and an unfitted method that relies on integration on cut\ncells only. We perform this intersection by using clipping algorithms. To deal\nwith the mesh movement, we pullback the equations to a reference configuration\n(the spatial mesh at the initial time slab times the time interval) that is\nconstant in time. This way, the geometrical intersection algorithm is only\nrequired in 3D, another key property of the proposed scheme. At the end of the\ntime slab, we compute the deformed mesh, intersect the deformed boundary with\nthe background mesh, and consider an exact transfer operator between meshes to\ncompute jump terms in the time discontinuous Galerkin integration. The transfer\nis also computed using geometrical intersection algorithms. We demonstrate the\napplicability of the method to fluid problems around rotating (2D and 3D)\ngeometries described by oriented boundary meshes. We also provide a set of\nnumerical experiments that show the optimal convergence of the method.", "field": "Computer Science", "categories": "cs.CE,cs.NA,math.NA"}, {"arxiv_id": "2401.12652", "title": "From Numbers to Words: Multi-Modal Bankruptcy Prediction Using the ECL\n  Dataset", "abstract": "In this paper, we present ECL, a novel multi-modal dataset containing the\ntextual and numerical data from corporate 10K filings and associated binary\nbankruptcy labels. Furthermore, we develop and critically evaluate several\nclassical and neural bankruptcy prediction models using this dataset. Our\nfindings suggest that the information contained in each data modality is\ncomplementary for bankruptcy prediction. We also see that the binary bankruptcy\nprediction target does not enable our models to distinguish next year\nbankruptcy from an unhealthy financial situation resulting in bankruptcy in\nlater years. Finally, we explore the use of LLMs in the context of our task. We\nshow how GPT-based models can be used to extract meaningful summaries from the\ntextual data but zero-shot bankruptcy prediction results are poor. All\nresources required to access and update the dataset or replicate our\nexperiments are available on github.com/henriarnoUG/ECL.", "field": "Computer Science", "categories": "cs.CE,q-fin.CP"}, {"arxiv_id": "2401.12653", "title": "Robust Popular Matchings", "abstract": "We study popularity for matchings under preferences. This solution concept\ncaptures matchings that do not lose against any other matching in a majority\nvote by the agents. A popular matching is said to be robust if it is popular\namong multiple instances. We present a polynomial-time algorithm for deciding\nwhether there exists a robust popular matching if instances only differ with\nrespect to the preferences of a single agent while obtaining NP-completeness if\ntwo instances differ only by a downward shift of one alternative by four\nagents. Moreover, we find a complexity dichotomy based on preference\ncompleteness for the case where instances differ by making some options\nunavailable.", "field": "Computer Science", "categories": "cs.DS,cs.GT"}, {"arxiv_id": "2401.12656", "title": "MoodLoopGP: Generating Emotion-Conditioned Loop Tablature Music with\n  Multi-Granular Features", "abstract": "Loopable music generation systems enable diverse applications, but they often\nlack controllability and customization capabilities. We argue that enhancing\ncontrollability can enrich these models, with emotional expression being a\ncrucial aspect for both creators and listeners. Hence, building upon LooperGP,\na loopable tablature generation model, this paper explores endowing systems\nwith control over conveyed emotions. To enable such conditional generation, we\npropose integrating musical knowledge by utilizing multi-granular semantic and\nmusical features during model training and inference. Specifically, we\nincorporate song-level features (Emotion Labels, Tempo, and Mode) and bar-level\nfeatures (Tonal Tension) together to guide emotional expression. Through\nalgorithmic and human evaluations, we demonstrate the approach's effectiveness\nin producing music conveying two contrasting target emotions, happiness and\nsadness. An ablation study is also conducted to clarify the contributing\nfactors behind our approach's results.", "field": "Computer Science", "categories": "cs.SD,eess.AS"}, {"arxiv_id": "2401.12662", "title": "Integrating Human Expertise in Continuous Spaces: A Novel Interactive\n  Bayesian Optimization Framework with Preference Expected Improvement", "abstract": "Interactive Machine Learning (IML) seeks to integrate human expertise into\nmachine learning processes. However, most existing algorithms cannot be applied\nto Realworld Scenarios because their state spaces and/or action spaces are\nlimited to discrete values. Furthermore, the interaction of all existing\nmethods is restricted to deciding between multiple proposals. We therefore\npropose a novel framework based on Bayesian Optimization (BO). Interactive\nBayesian Optimization (IBO) enables collaboration between machine learning\nalgorithms and humans. This framework captures user preferences and provides an\ninterface for users to shape the strategy by hand. Additionally, we've\nincorporated a new acquisition function, Preference Expected Improvement (PEI),\nto refine the system's efficiency using a probabilistic model of the user\npreferences. Our approach is geared towards ensuring that machines can benefit\nfrom human expertise, aiming for a more aligned and effective learning process.\nIn the course of this work, we applied our method to simulations and in a real\nworld task using a Franka Panda robot to show human-robot collaboration.", "field": "Computer Science", "categories": "cs.RO,cs.AI,cs.HC,cs.LG"}, {"arxiv_id": "2401.12664", "title": "Polynomial and rational interpolation: potential, barycentric weights,\n  and Lebesgue constants", "abstract": "In this paper, we focus on barycentric weights and Lebesgue constants for\nLagrange interpolation of arbitrary node distributions on \\([-1,1]\\). The\nfollowing three main works are included: estimates of upper and lower bounds on\nthe barycentric weights are given in terms of the logarithmic potential\nfunction; for interpolation of non-equilibrium potentials, lower bounds with\nexponentially growing parts of Lebesgue constants are given; and for\ninterpolation consistent with equilibrium potentials, non-exponentially growing\nupper bounds on their Lebesgue constants are given. Based on the work in this\npaper, we can discuss the behavior of the Lebesgue constant and the existence\nof exponential convergence in a unified manner in the framework of potential\ntheory.", "field": "Computer Science", "categories": "math.NA,cs.NA"}, {"arxiv_id": "2401.12665", "title": "ClipSAM: CLIP and SAM Collaboration for Zero-Shot Anomaly Segmentation", "abstract": "Recently, foundational models such as CLIP and SAM have shown promising\nperformance for the task of Zero-Shot Anomaly Segmentation (ZSAS). However,\neither CLIP-based or SAM-based ZSAS methods still suffer from non-negligible\nkey drawbacks: 1) CLIP primarily focuses on global feature alignment across\ndifferent inputs, leading to imprecise segmentation of local anomalous parts;\n2) SAM tends to generate numerous redundant masks without proper prompt\nconstraints, resulting in complex post-processing requirements. In this work,\nwe innovatively propose a CLIP and SAM collaboration framework called ClipSAM\nfor ZSAS. The insight behind ClipSAM is to employ CLIP's semantic understanding\ncapability for anomaly localization and rough segmentation, which is further\nused as the prompt constraints for SAM to refine the anomaly segmentation\nresults. In details, we introduce a crucial Unified Multi-scale Cross-modal\nInteraction (UMCI) module for interacting language with visual features at\nmultiple scales of CLIP to reason anomaly positions. Then, we design a novel\nMulti-level Mask Refinement (MMR) module, which utilizes the positional\ninformation as multi-level prompts for SAM to acquire hierarchical levels of\nmasks and merges them. Extensive experiments validate the effectiveness of our\napproach, achieving the optimal segmentation performance on the MVTec-AD and\nVisA datasets.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.12666", "title": "EL-VIT: Probing Vision Transformer with Interactive Visualization", "abstract": "Nowadays, Vision Transformer (ViT) is widely utilized in various computer\nvision tasks, owing to its unique self-attention mechanism. However, the model\narchitecture of ViT is complex and often challenging to comprehend, leading to\na steep learning curve. ViT developers and users frequently encounter\ndifficulties in interpreting its inner workings. Therefore, a visualization\nsystem is needed to assist ViT users in understanding its functionality. This\npaper introduces EL-VIT, an interactive visual analytics system designed to\nprobe the Vision Transformer and facilitate a better understanding of its\noperations. The system consists of four layers of visualization views. The\nfirst three layers include model overview, knowledge background graph, and\nmodel detail view. These three layers elucidate the operation process of ViT\nfrom three perspectives: the overall model architecture, detailed explanation,\nand mathematical operations, enabling users to understand the underlying\nprinciples and the transition process between layers. The fourth interpretation\nview helps ViT users and experts gain a deeper understanding by calculating the\ncosine similarity between patches. Our two usage scenarios demonstrate the\neffectiveness and usability of EL-VIT in helping ViT users understand the\nworking mechanism of ViT.", "field": "Computer Science", "categories": "cs.AI"}, {"arxiv_id": "2401.12671", "title": "Context Matters: Pushing the Boundaries of Open-Ended Answer Generation\n  with Graph-Structured Knowledge Context", "abstract": "In the continuously advancing AI landscape, crafting context-rich and\nmeaningful responses via Large Language Models (LLMs) is essential. Researchers\nare becoming more aware of the challenges that LLMs with fewer parameters\nencounter when trying to provide suitable answers to open-ended questions. To\naddress these hurdles, the integration of cutting-edge strategies, augmentation\nof rich external domain knowledge to LLMs, offers significant improvements.\nThis paper introduces a novel framework that combines graph-driven context\nretrieval in conjunction to knowledge graphs based enhancement, honing the\nproficiency of LLMs, especially in domain specific community question answering\nplatforms like AskUbuntu, Unix, and ServerFault. We conduct experiments on\nvarious LLMs with different parameter sizes to evaluate their ability to ground\nknowledge and determine factual accuracy in answers to open-ended questions.\nOur methodology GraphContextGen consistently outperforms dominant text-based\nretrieval systems, demonstrating its robustness and adaptability to a larger\nnumber of use cases. This advancement highlights the importance of pairing\ncontext rich data retrieval with LLMs, offering a renewed approach to knowledge\nsourcing and generation in AI systems. We also show that, due to rich\ncontextual data retrieval, the crucial entities, along with the generated\nanswer, remain factually coherent with the gold answer.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.12672", "title": "ChatGraph: Chat with Your Graphs", "abstract": "Graph analysis is fundamental in real-world applications. Traditional\napproaches rely on SPARQL-like languages or clicking-and-dragging interfaces to\ninteract with graph data. However, these methods either require users to\npossess high programming skills or support only a limited range of graph\nanalysis functionalities. To address the limitations, we propose a large\nlanguage model (LLM)-based framework called ChatGraph. With ChatGraph, users\ncan interact with graphs through natural language, making it easier to use and\nmore flexible than traditional approaches. The core of ChatGraph lies in\ngenerating chains of graph analysis APIs based on the understanding of the\ntexts and graphs inputted in the user prompts. To achieve this, ChatGraph\nconsists of three main modules: an API retrieval module that searches for\nrelevant APIs, a graph-aware LLM module that enables the LLM to comprehend\ngraphs, and an API chain-oriented finetuning module that guides the LLM in\ngenerating API chains.", "field": "Computer Science", "categories": "cs.AI"}, {"arxiv_id": "2401.12681", "title": "Non-Neighbors Also Matter to Kriging: A New Contrastive-Prototypical\n  Learning", "abstract": "Kriging aims at estimating the attributes of unsampled geo-locations from\nobservations in the spatial vicinity or physical connections, which helps\nmitigate skewed monitoring caused by under-deployed sensors. Existing works\nassume that neighbors' information offers the basis for estimating the\nattributes of the unobserved target while ignoring non-neighbors. However,\nnon-neighbors could also offer constructive information, and neighbors could\nalso be misleading. To this end, we propose ``Contrastive-Prototypical''\nself-supervised learning for Kriging (KCP) to refine valuable information from\nneighbors and recycle the one from non-neighbors. As a pre-trained paradigm, we\nconduct the Kriging task from a new perspective of representation: we aim to\nfirst learn robust and general representations and then recover attributes from\nrepresentations. A neighboring contrastive module is designed that coarsely\nlearns the representations by narrowing the representation distance between the\ntarget and its neighbors while pushing away the non-neighbors. In parallel, a\nprototypical module is introduced to identify similar representations via\nexchanged prediction, thus refining the misleading neighbors and recycling the\nuseful non-neighbors from the neighboring contrast component. As a result, not\nall the neighbors and some of the non-neighbors will be used to infer the\ntarget. To encourage the two modules above to learn general and robust\nrepresentations, we design an adaptive augmentation module that incorporates\ndata-driven attribute augmentation and centrality-based topology augmentation\nover the spatiotemporal Kriging graph data. Extensive experiments on real-world\ndatasets demonstrate the superior performance of KCP compared to its peers with\n6% improvements and exceptional transferability and robustness. The code is\navailable at https://github.com/bonaldli/KCP", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.12683", "title": "LLpowershap: Logistic Loss-based Automated Shapley Values Feature\n  Selection Method", "abstract": "Shapley values have been used extensively in machine learning, not only to\nexplain black box machine learning models, but among other tasks, also to\nconduct model debugging, sensitivity and fairness analyses and to select\nimportant features for robust modelling and for further follow-up analyses.\nShapley values satisfy certain axioms that promote fairness in distributing\ncontributions of features toward prediction or reducing error, after accounting\nfor non-linear relationships and interactions when complex machine learning\nmodels are employed. Recently, a number of feature selection methods utilising\nShapley values have been introduced. Here, we present a novel feature selection\nmethod, LLpowershap, which makes use of loss-based Shapley values to identify\ninformative features with minimal noise among the selected sets of features.\nOur simulation results show that LLpowershap not only identifies higher number\nof informative features but outputs fewer noise features compared to other\nstate-of-the-art feature selection methods. Benchmarking results on four\nreal-world datasets demonstrate higher or at par predictive performance of\nLLpowershap compared to other Shapley based wrapper methods, or filter methods.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.12686", "title": "Learning Mean Field Games on Sparse Graphs: A Hybrid Graphex Approach", "abstract": "Learning the behavior of large agent populations is an important task for\nnumerous research areas. Although the field of multi-agent reinforcement\nlearning (MARL) has made significant progress towards solving these systems,\nsolutions for many agents often remain computationally infeasible and lack\ntheoretical guarantees. Mean Field Games (MFGs) address both of these issues\nand can be extended to Graphon MFGs (GMFGs) to include network structures\nbetween agents. Despite their merits, the real world applicability of GMFGs is\nlimited by the fact that graphons only capture dense graphs. Since most\nempirically observed networks show some degree of sparsity, such as power law\ngraphs, the GMFG framework is insufficient for capturing these network\ntopologies. Thus, we introduce the novel concept of Graphex MFGs (GXMFGs) which\nbuilds on the graph theoretical concept of graphexes. Graphexes are the\nlimiting objects to sparse graph sequences that also have other desirable\nfeatures such as the small world property. Learning equilibria in these games\nis challenging due to the rich and sparse structure of the underlying graphs.\nTo tackle these challenges, we design a new learning algorithm tailored to the\nGXMFG setup. This hybrid graphex learning approach leverages that the system\nmainly consists of a highly connected core and a sparse periphery. After\ndefining the system and providing a theoretical analysis, we state our learning\napproach and demonstrate its learning capabilities on both synthetic graphs and\nreal-world networks. This comparison shows that our GXMFG learning algorithm\nsuccessfully extends MFGs to a highly relevant class of hard, realistic\nlearning problems that are not accurately addressed by current MARL and MFG\nmethods.", "field": "Computer Science", "categories": "cs.MA,cs.AI,cs.GT,cs.LG"}, {"arxiv_id": "2401.12687", "title": "DVL Calibration using Data-driven Methods", "abstract": "Autonomous underwater vehicles (AUVs) are used in a wide range of underwater\napplications, ranging from seafloor mapping to industrial operations. While\nunderwater, the AUV navigation solution commonly relies on the fusion between\ninertial sensors and Doppler velocity logs (DVL). To achieve accurate DVL\nmeasurements a calibration procedure should be conducted before the mission\nbegins. Model-based calibration approaches include filtering approaches\nutilizing global navigation satellite system signals. In this paper, we propose\nan end-to-end deep-learning framework for the calibration procedure. Using\nstimulative data, we show that our proposed approach outperforms model-based\napproaches by 35% in accuracy and 80% in the required calibration time.", "field": "Computer Science", "categories": "cs.RO,cs.LG"}, {"arxiv_id": "2401.12689", "title": "Energy-based Automated Model Evaluation", "abstract": "The conventional evaluation protocols on machine learning models rely heavily\non a labeled, i.i.d-assumed testing dataset, which is not often present in real\nworld applications. The Automated Model Evaluation (AutoEval) shows an\nalternative to this traditional workflow, by forming a proximal prediction\npipeline of the testing performance without the presence of ground-truth\nlabels. Despite its recent successes, the AutoEval frameworks still suffer from\nan overconfidence issue, substantial storage and computational cost. In that\nregard, we propose a novel measure -- Meta-Distribution Energy (MDE) -- that\nallows the AutoEval framework to be both more efficient and effective. The core\nof the MDE is to establish a meta-distribution statistic, on the information\n(energy) associated with individual samples, then offer a smoother\nrepresentation enabled by energy-based learning. We further provide our\ntheoretical insights by connecting the MDE with the classification loss. We\nprovide extensive experiments across modalities, datasets and different\narchitectural backbones to validate MDE's validity, together with its\nsuperiority compared with prior approaches. We also prove MDE's versatility by\nshowing its seamless integration with large-scale models, and easy adaption to\nlearning scenarios with noisy- or imbalanced- labels.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.CL,cs.CV"}, {"arxiv_id": "2401.1269", "title": "Availability-aware Service Placement Policy in Fog Computing Based on\n  Graph Partitions", "abstract": "This paper presents a policy for service placement of fog applications\ninspired on complex networks and graph theory. We propose a twofold partition\nprocess based on communities for the partition of the fog devices and based on\ntransitive closures for the application services partition. The allocation of\nthe services is performed sequentially by, firstly, mapping applications to\ndevice communities and, secondly, mapping service transitive closures to fog\ndevices in the community. The underlying idea is to place as many inter-related\nservices as possible in the most nearby devices to the users. The optimization\nobjectives are the availability of the applications and the Quality of Service\n(QoS) of the system, measured as the number of requests that are executed\nbefore the application deadlines. We compared our solution with an Integer\nLinear Programming approach, and the simulation results showed that our\nproposal obtains higher QoS and availability when fails in the nodes are\nconsidered.", "field": "Computer Science", "categories": "cs.NI"}, {"arxiv_id": "2401.12694", "title": "Pragmatic Communication in Multi-Agent Collaborative Perception", "abstract": "Collaborative perception allows each agent to enhance its perceptual\nabilities by exchanging messages with others. It inherently results in a\ntrade-off between perception ability and communication costs. Previous works\ntransmit complete full-frame high-dimensional feature maps among agents,\nresulting in substantial communication costs. To promote communication\nefficiency, we propose only transmitting the information needed for the\ncollaborator's downstream task. This pragmatic communication strategy focuses\non three key aspects: i) pragmatic message selection, which selects\ntask-critical parts from the complete data, resulting in spatially and\ntemporally sparse feature vectors; ii) pragmatic message representation, which\nachieves pragmatic approximation of high-dimensional feature vectors with a\ntask-adaptive dictionary, enabling communicating with integer indices; iii)\npragmatic collaborator selection, which identifies beneficial collaborators,\npruning unnecessary communication links. Following this strategy, we first\nformulate a mathematical optimization framework for the\nperception-communication trade-off and then propose PragComm, a multi-agent\ncollaborative perception system with two key components: i) single-agent\ndetection and tracking and ii) pragmatic collaboration. The proposed PragComm\npromotes pragmatic communication and adapts to a wide range of communication\nconditions. We evaluate PragComm for both collaborative 3D object detection and\ntracking tasks in both real-world, V2V4Real, and simulation datasets, OPV2V and\nV2X-SIM2.0. PragComm consistently outperforms previous methods with more than\n32.7K times lower communication volume on OPV2V. Code is available at\ngithub.com/PhyllisH/PragComm.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.12698", "title": "Genetic Algorithm for Multi-Objective Optimization of Container\n  Allocation in Cloud Architecture", "abstract": "The use of containers in cloud architectures has become widespread because of\nadvantages such as limited overhead, easier and faster deployment and higher\nportability. Moreover, they are a suitable architectural solution for\ndeployment of applications created using a microservices development pattern.\nDespite the large number of solutions and implementations, open issues have not\nbeen addressed in container automation and management. Container resource\nallocation influences system performance and resource consumption so it is a\nkey factor for cloud providers. We propose a genetic algorithm approach, using\nthe Non-dominated Sorting Genetic Algorithm-II (NSGA-II), to optimize container\nallocation and elasticity management due to the good results obtained with this\nalgorithm in other resource management optimization problems in cloud\narchitectures. The optimization has been focused on a tight use of the\nresources and a reduction of the network overhead and system failure rate. A\nmodel for cloud cluster, containers, microservices and four optimization\nobjectives is presented. Experimental results have shown that our approach is a\nsuitable solution to address the problem of container allocation and elasticity\nand it obtains better objectives values than the container management policies\nimplemented in Kubernetes.", "field": "Computer Science", "categories": "cs.NI"}, {"arxiv_id": "2401.12699", "title": "A lightweight decentralized service placement policy for performance\n  optimization in fog computing", "abstract": "A decentralized optimization policy for service placement in fog computing is\npresented. The optimization is addressed to place most popular services as\ncloser to the users as possible. The experimental validation is done in the\niFogSim simulator and by comparing our algorithm with the simulator's built-in\npolicy. The simulation is characterized by modeling a microservice-based\napplication for different experiment sizes. Results showed that our\ndecentralized algorithm places most popular services closer to users, improving\nnetwork usage and service latency of the most requested applications, at the\nexpense of a latency increment for the less requested services and a greater\nnumber of service migrations.", "field": "Computer Science", "categories": "cs.NI"}, {"arxiv_id": "2401.127", "title": "Securing Recommender System via Cooperative Training", "abstract": "Recommender systems are often susceptible to well-crafted fake profiles,\nleading to biased recommendations. Among existing defense methods,\ndata-processing-based methods inevitably exclude normal samples, while\nmodel-based methods struggle to enjoy both generalization and robustness. To\nthis end, we suggest integrating data processing and the robust model to\npropose a general framework, Triple Cooperative Defense (TCD), which employs\nthree cooperative models that mutually enhance data and thereby improve\nrecommendation robustness. Furthermore, Considering that existing attacks\nstruggle to balance bi-level optimization and efficiency, we revisit poisoning\nattacks in recommender systems and introduce an efficient attack strategy,\nCo-training Attack (Co-Attack), which cooperatively optimizes the attack\noptimization and model training, considering the bi-level setting while\nmaintaining attack efficiency. Moreover, we reveal a potential reason for the\ninsufficient threat of existing attacks is their default assumption of\noptimizing attacks in undefended scenarios. This overly optimistic setting\nlimits the potential of attacks. Consequently, we put forth a Game-based\nCo-training Attack (GCoAttack), which frames the proposed CoAttack and TCD as a\ngame-theoretic process, thoroughly exploring CoAttack's attack potential in the\ncooperative training of attack and defense. Extensive experiments on three real\ndatasets demonstrate TCD's superiority in enhancing model robustness.\nAdditionally, we verify that the two proposed attack strategies significantly\noutperform existing attacks, with game-based GCoAttack posing a greater\npoisoning threat than CoAttack.", "field": "Computer Science", "categories": "cs.AI"}, {"arxiv_id": "2401.12703", "title": "Small Test Suites for Active Automata Learning", "abstract": "A bottleneck in modern active automata learning is to test whether a\nhypothesized Mealy machine correctly describes the system under learning. The\nsearch space for possible counterexamples is given by so-called test suites,\nconsisting of input sequences that have to be checked to decide whether a\ncounterexample exists. This paper shows that significantly smaller test suites\nsuffice under reasonable assumptions on the structure of the black box. These\nsmaller test suites help to refute false hypotheses during active automata\nlearning, even when the assumptions do not hold. We combine multiple test\nsuites using a multi-armed bandit setup that adaptively selects a test suite.\nAn extensive empirical evaluation shows the efficacy of our approach. For small\nto medium-sized models, the performance gain is limited. However, the approach\nallows learning models from large, industrial case studies that were beyond the\nreach of known methods.", "field": "Computer Science", "categories": "cs.LO"}, {"arxiv_id": "2401.12707", "title": "Localized Data-driven Consensus Control", "abstract": "This paper considers a localized data-driven consensus problem for\nleader-follower multi-agent systems with unknown discrete-time agent dynamics,\nwhere each follower computes its local control gain using only their locally\ncollected state and input data. Both noiseless and noisy data-driven consensus\nprotocols are presented, which can handle the challenge of the heterogeneity in\ncontrol gains caused by the localized data sampling and achieve leader-follower\nconsensus. The design of these data-driven consensus protocols involves\nlow-dimensional linear matrix inequalities. In addition, the results are\nextended to the case where only the leader's data are collected and exploited.\nThe effectiveness of the proposed methods is illustrated via simulation\nexamples.", "field": "Computer Science", "categories": "eess.SY,cs.SY"}, {"arxiv_id": "2401.12708", "title": "Deep Neural Network Benchmarks for Selective Classification", "abstract": "With the increasing deployment of machine learning models in many\nsocially-sensitive tasks, there is a growing demand for reliable and\ntrustworthy predictions. One way to accomplish these requirements is to allow a\nmodel to abstain from making a prediction when there is a high risk of making\nan error. This requires adding a selection mechanism to the model, which\nselects those examples for which the model will provide a prediction. The\nselective classification framework aims to design a mechanism that balances the\nfraction of rejected predictions (i.e., the proportion of examples for which\nthe model does not make a prediction) versus the improvement in predictive\nperformance on the selected predictions. Multiple selective classification\nframeworks exist, most of which rely on deep neural network architectures.\nHowever, the empirical evaluation of the existing approaches is still limited\nto partial comparisons among methods and settings, providing practitioners with\nlittle insight into their relative merits. We fill this gap by benchmarking 18\nbaselines on a diverse set of 44 datasets that includes both image and tabular\ndata. Moreover, there is a mix of binary and multiclass tasks. We evaluate\nthese approaches using several criteria, including selective error rate,\nempirical coverage, distribution of rejected instance's classes, and\nperformance on out-of-distribution instances. The results indicate that there\nis not a single clear winner among the surveyed baselines, and the best method\ndepends on the users' objectives.", "field": "Computer Science", "categories": "cs.LG,cs.AI,stat.ML"}, {"arxiv_id": "2401.12711", "title": "When Redundancy Matters: Machine Teaching of Representations", "abstract": "In traditional machine teaching, a teacher wants to teach a concept to a\nlearner, by means of a finite set of examples, the witness set. But concepts\ncan have many equivalent representations. This redundancy strongly affects the\nsearch space, to the extent that teacher and learner may not be able to easily\ndetermine the equivalence class of each representation. In this common\nsituation, instead of teaching concepts, we explore the idea of teaching\nrepresentations. We work with several teaching schemas that exploit\nrepresentation and witness size (Eager, Greedy and Optimal) and analyze the\ngains in teaching effectiveness for some representational languages (DNF\nexpressions and Turing-complete P3 programs). Our theoretical and experimental\nresults indicate that there are various types of redundancy, handled better by\nthe Greedy schema introduced here than by the Eager schema, although both can\nbe arbitrarily far away from the Optimal. For P3 programs we found that witness\nsets are usually smaller than the programs they identify, which is an\nilluminating justification of why machine teaching from examples makes sense at\nall.", "field": "Computer Science", "categories": "cs.LG,68T05,I.2.6"}, {"arxiv_id": "2401.12713", "title": "Generating Unsupervised Abstractive Explanations for Rumour Verification", "abstract": "The task of rumour verification in social media concerns assessing the\nveracity of a claim on the basis of conversation threads that result from it.\nWhile previous work has focused on predicting a veracity label, here we\nreformulate the task to generate model-centric, free-text explanations of a\nrumour's veracity. We follow an unsupervised approach by first utilising\npost-hoc explainability methods to score the most important posts within a\nthread and then we use these posts to generate informative explanatory\nsummaries by employing template-guided summarisation. To evaluate the\ninformativeness of the explanatory summaries, we exploit the few-shot learning\ncapabilities of a large language model (LLM). Our experiments show that LLMs\ncan have similar agreement to humans in evaluating summaries. Importantly, we\nshow that explanatory abstractive summaries are more informative and better\nreflect the predicted rumour veracity than just using the highest ranking posts\nin the thread.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.12714", "title": "Evaluation of large language models for assessing code maintainability", "abstract": "Increased availability of open-source software repositories and recent\nadvances in code analysis using large language models (LLMs) has triggered a\nwave of new work to automate software engineering tasks that were previously\nvery difficult to automate. In this paper, we investigate a recent line of work\nthat hypothesises that comparing the probability of code generated by LLMs with\nthe probability the current code would have had can indicate potential quality\nproblems. We investigate the association between the cross-entropy of code\ngenerated by ten different models (based on GPT2 and Llama2) and the following\nquality aspects: readability, understandability, complexity, modularisation,\nand overall maintainability assessed by experts and available in an benchmark\ndataset. Our results show that, controlling for the number of logical lines of\ncodes (LLOC), cross-entropy computed by LLMs is indeed a predictor of\nmaintainability on a class level (the higher the cross-entropy the lower the\nmaintainability). However, this relation is reversed when one does not control\nfor LLOC (e.g., comparing small classes with longer ones). Furthermore, while\nthe complexity of LLMs affects the range of cross-entropy (smaller models tend\nto have a wider range of cross-entropy), this plays a significant role in\npredicting maintainability aspects. Our study limits itself on ten different\npretrained models (based on GPT2 and Llama2) and on maintainability aspects\ncollected by Schnappinger et al. When controlling for logical lines of code\n(LLOC), cross-entropy is a predictor of maintainability. However, while related\nwork has shown the potential usefulness of cross-entropy at the level of tokens\nor short sequences, at the class level this criterion alone may prove\ninsufficient to predict maintainability and further research is needed to make\nbest use of this information in practice.", "field": "Computer Science", "categories": "cs.SE,cs.AI,68,D.2.7"}, {"arxiv_id": "2401.1272", "title": "A Comprehensive View of the Biases of Toxicity and Sentiment Analysis\n  Methods Towards Utterances with African American English Expressions", "abstract": "Language is a dynamic aspect of our culture that changes when expressed in\ndifferent technologies/communities. Online social networks have enabled the\ndiffusion and evolution of different dialects, including African American\nEnglish (AAE). However, this increased usage is not without barriers. One\nparticular barrier is how sentiment (Vader, TextBlob, and Flair) and toxicity\n(Google's Perspective and the open-source Detoxify) methods present biases\ntowards utterances with AAE expressions. Consider Google's Perspective to\nunderstand bias. Here, an utterance such as ``All n*ggers deserve to die\nrespectfully. The police murder us.'' it reaches a higher toxicity than\n``African-Americans deserve to die respectfully. The police murder us.''. This\nscore difference likely arises because the tool cannot understand the\nre-appropriation of the term ``n*gger''. One explanation for this bias is that\nAI models are trained on limited datasets, and using such a term in training\ndata is more likely to appear in a toxic utterance. While this may be\nplausible, the tool will make mistakes regardless. Here, we study bias on two\nWeb-based (YouTube and Twitter) datasets and two spoken English datasets. Our\nanalysis shows how most models present biases towards AAE in most settings. We\nisolate the impact of AAE expression usage via linguistic control features from\nthe Linguistic Inquiry and Word Count (LIWC) software, grammatical control\nfeatures extracted via Part-of-Speech (PoS) tagging from Natural Language\nProcessing (NLP) models, and the semantic of utterances by comparing sentence\nembeddings from recent language models. We present consistent results on how a\nheavy usage of AAE expressions may cause the speaker to be considered\nsubstantially more toxic, even when speaking about nearly the same subject. Our\nstudy complements similar analyses focusing on small datasets and/or one method\nonly.", "field": "Computer Science", "categories": "cs.CL,cs.SI"}, {"arxiv_id": "2401.12722", "title": "Falcon: Fair Active Learning using Multi-armed Bandits", "abstract": "Biased data can lead to unfair machine learning models, highlighting the\nimportance of embedding fairness at the beginning of data analysis,\nparticularly during dataset curation and labeling. In response, we propose\nFalcon, a scalable fair active learning framework. Falcon adopts a data-centric\napproach that improves machine learning model fairness via strategic sample\nselection. Given a user-specified group fairness measure, Falcon identifies\nsamples from \"target groups\" (e.g., (attribute=female, label=positive)) that\nare the most informative for improving fairness. However, a challenge arises\nsince these target groups are defined using ground truth labels that are not\navailable during sample selection. To handle this, we propose a novel\ntrial-and-error method, where we postpone using a sample if the predicted label\nis different from the expected one and falls outside the target group. We also\nobserve the trade-off that selecting more informative samples results in higher\nlikelihood of postponing due to undesired label prediction, and the optimal\nbalance varies per dataset. We capture the trade-off between informativeness\nand postpone rate as policies and propose to automatically select the best\npolicy using adversarial multi-armed bandit methods, given their computational\nefficiency and theoretical guarantees. Experiments show that Falcon\nsignificantly outperforms existing fair active learning approaches in terms of\nfairness and accuracy and is more efficient. In particular, only Falcon\nsupports a proper trade-off between accuracy and fairness where its maximum\nfairness score is 1.8-4.5x higher than the second-best results.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.12724", "title": "A Multi-scale Yarn Appearance Model with Fiber Details", "abstract": "Rendering realistic cloth has always been a challenge due to its intricate\nstructure. Cloth is made up of fibers, plies, and yarns, and previous\ncurved-based models, while detailed, were computationally expensive and\ninflexible for large cloth. To address this, we propose a simplified approach.\n  We introduce a geometric aggregation technique that reduces ray-tracing\ncomputation by using fewer curves, focusing only on yarn curves. Our model\ngenerates ply and fiber shapes implicitly, compensating for the lack of\nexplicit geometry with a novel shadowing component. We also present a shading\nmodel that simplifies light interactions among fibers by categorizing them into\nfour components, accurately capturing specular and scattered light in both\nforward and backward directions.\n  To render large cloth efficiently, we propose a multi-scale solution based on\npixel coverage. Our yarn shading model outperforms previous methods, achieving\nrendering speeds 3-5 times faster with less memory in near-field views.\nAdditionally, our multi-scale solution offers a 20% speed boost for distant\ncloth observation.", "field": "Computer Science", "categories": "cs.GR"}, {"arxiv_id": "2401.12729", "title": "Enhancing Object Detection Performance for Small Objects through\n  Synthetic Data Generation and Proportional Class-Balancing Technique: A\n  Comparative Study in Industrial Scenarios", "abstract": "Object Detection (OD) has proven to be a significant computer vision method\nin extracting localized class information and has multiple applications in the\nindustry. Although many of the state-of-the-art (SOTA) OD models perform well\non medium and large sized objects, they seem to under perform on small objects.\nIn most of the industrial use cases, it is difficult to collect and annotate\ndata for small objects, as it is time-consuming and prone to human errors.\nAdditionally, those datasets are likely to be unbalanced and often result in an\ninefficient model convergence. To tackle this challenge, this study presents a\nnovel approach that injects additional data points to improve the performance\nof the OD models. Using synthetic data generation, the difficulties in data\ncollection and annotations for small object data points can be minimized and to\ncreate a dataset with balanced distribution. This paper discusses the effects\nof a simple proportional class-balancing technique, to enable better anchor\nmatching of the OD models. A comparison was carried out on the performances of\nthe SOTA OD models: YOLOv5, YOLOv7 and SSD, for combinations of real and\nsynthetic datasets within an industrial use case.", "field": "Computer Science", "categories": "cs.CV,cs.LG"}, {"arxiv_id": "2401.12731", "title": "The Distributional Uncertainty of the SHAP score in Explainable Machine\n  Learning", "abstract": "Attribution scores reflect how important the feature values in an input\nentity are for the output of a machine learning model. One of the most popular\nattribution scores is the SHAP score, which is an instantiation of the general\nShapley value used in coalition game theory. The definition of this score\nrelies on a probability distribution on the entity population. Since the exact\ndistribution is generally unknown, it needs to be assigned subjectively or be\nestimated from data, which may lead to misleading feature scores. In this\npaper, we propose a principled framework for reasoning on SHAP scores under\nunknown entity population distributions. In our framework, we consider an\nuncertainty region that contains the potential distributions, and the SHAP\nscore of a feature becomes a function defined over this region. We study the\nbasic problems of finding maxima and minima of this function, which allows us\nto determine tight ranges for the SHAP scores of all features. In particular,\nwe pinpoint the complexity of these problems, and other related ones, showing\nthem to be NP-complete. Finally, we present experiments on a real-world\ndataset, showing that our framework may contribute to a more robust feature\nscoring.", "field": "Computer Science", "categories": "cs.AI,cs.LG,cs.LO,68T37, 68T27"}, {"arxiv_id": "2401.12732", "title": "CDRNP: Cross-Domain Recommendation to Cold-Start Users via Neural\n  Process", "abstract": "Cross-domain recommendation (CDR) has been proven as a promising way to\ntackle the user cold-start problem, which aims to make recommendations for\nusers in the target domain by transferring the user preference derived from the\nsource domain. Traditional CDR studies follow the embedding and mapping (EMCDR)\nparadigm, which transfers user representations from the source to target domain\nby learning a user-shared mapping function, neglecting the user-specific\npreference. Recent CDR studies attempt to learn user-specific mapping functions\nin meta-learning paradigm, which regards each user's CDR as an individual task,\nbut neglects the preference correlations among users, limiting the beneficial\ninformation for user representations. Moreover, both of the paradigms neglect\nthe explicit user-item interactions from both domains during the mapping\nprocess. To address the above issues, this paper proposes a novel CDR framework\nwith neural process (NP), termed as CDRNP. Particularly, it develops the\nmeta-learning paradigm to leverage user-specific preference, and further\nintroduces a stochastic process by NP to capture the preference correlations\namong the overlapping and cold-start users, thus generating more powerful\nmapping functions by mapping the user-specific preference and common preference\ncorrelations to a predictive probability distribution. In addition, we also\nintroduce a preference remainer to enhance the common preference from the\noverlapping users, and finally devises an adaptive conditional decoder with\npreference modulation to make prediction for cold-start users with items in the\ntarget domain. Experimental results demonstrate that CDRNP outperforms previous\nSOTA methods in three real-world CDR scenarios.", "field": "Computer Science", "categories": "cs.IR,cs.SI"}, {"arxiv_id": "2401.12733", "title": "TNANet: A Temporal-Noise-Aware Neural Network for Suicidal Ideation\n  Prediction with Noisy Physiological Data", "abstract": "The robust generalization of deep learning models in the presence of inherent\nnoise remains a significant challenge, especially when labels are subjective\nand noise is indiscernible in natural settings. This problem is particularly\npronounced in many practical applications. In this paper, we address a special\nand important scenario of monitoring suicidal ideation, where time-series data,\nsuch as photoplethysmography (PPG), is susceptible to such noise. Current\nmethods predominantly focus on image and text data or address artificially\nintroduced noise, neglecting the complexities of natural noise in time-series\nanalysis. To tackle this, we introduce a novel neural network model tailored\nfor analyzing noisy physiological time-series data, named TNANet, which merges\nadvanced encoding techniques with confidence learning, enhancing prediction\naccuracy. Another contribution of our work is the collection of a specialized\ndataset of PPG signals derived from real-world environments for suicidal\nideation prediction. Employing this dataset, our TNANet achieves the prediction\naccuracy of 63.33% in a binary classification task, outperforming\nstate-of-the-art models. Furthermore, comprehensive evaluations were conducted\non three other well-known public datasets with artificially introduced noise to\nrigorously test the TNANet's capabilities. These tests consistently\ndemonstrated TNANet's superior performance by achieving an accuracy improvement\nof more than 10% compared to baseline methods.", "field": "Computer Science", "categories": "cs.CY,cs.LG"}, {"arxiv_id": "2401.12734", "title": "On the improved convergence of lifted distributional Gauss curvature\n  from Regge elements", "abstract": "Although Regge finite element functions are not continuous, useful\ngeneralizations of nonlinear derivatives like the curvature, can be defined\nusing them. This paper is devoted to studying the convergence of the finite\nelement lifting of a generalized (distributional) Gauss curvature defined using\na metric tensor in the Regge finite element space. Specifically, we investigate\nthe interplay between the polynomial degree of the curvature lifting by\nLagrange elements and the degree of the metric tensor in the Regge finite\nelement space. Previously, a superconvergence result, where convergence rate of\none order higher than expected, was obtained when the metric is the canonical\nRegge interpolant of the exact metric. In this work, we show that an even\nhigher order can be obtained if the degree of the curvature lifting is reduced\nby one polynomial degre and if at least linear Regge elements are used. These\nimproved convergence rates are confirmed by numerical examples.", "field": "Computer Science", "categories": "math.NA,cs.NA,math.DG,65N30 (Primary) 53A70, 83C27 (Secondary)"}, {"arxiv_id": "2401.12736", "title": "Shift-ConvNets: Small Convolutional Kernel with Large Kernel Effects", "abstract": "Recent studies reveal that the remarkable performance of Vision transformers\n(ViTs) benefits from large receptive fields. For this reason, the large\nconvolutional kernel design becomes an ideal solution to make Convolutional\nNeural Networks (CNNs) great again. However, the typical large convolutional\nkernels turn out to be hardware-unfriendly operators, resulting in discount\ncompatibility of various hardware platforms. Thus, it is unwise to simply\nenlarge the convolutional kernel size. In this paper, we reveal that small\nconvolutional kernels and convolution operations can achieve the closing\neffects of large kernel sizes. Then, we propose a shift-wise operator that\nensures the CNNs capture long-range dependencies with the help of the sparse\nmechanism, while remaining hardware-friendly. Experimental results show that\nour shift-wise operator significantly improves the accuracy of a regular CNN\nwhile markedly reducing computational requirements. On the ImageNet-1k, our\nshift-wise enhanced CNN model outperforms the state-of-the-art models. Code &\nmodels at https://github.com/lidc54/shift-wiseConv.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.12739", "title": "Decoding University Hierarchy and Prestige in China through Domestic\n  Ph.D. Hiring Network", "abstract": "The academic job market for fresh Ph.D. students to pursue postdoctoral and\njunior faculty positions plays a crucial role in shaping the future\norientations, developments, and status of the global academic system. In this\nwork, we focus on the domestic Ph.D. hiring network among universities in China\nby exploring the doctoral education and academic employment of nearly 28,000\nscientists across all Ph.D.-granting Chinese universities over three decades.\nWe employ the minimum violation rankings algorithm to decode the rankings for\nuniversities based on the Ph.D. hiring network, which offers a deep\nunderstanding of the structure and dynamics within the network. Our results\nuncover a consistent, highly structured hierarchy within this hiring network,\nindicating the imbalances wherein a limited number of universities serve as the\nmain sources of fresh Ph.D. across diverse disciplines. Furthermore, over time,\nit has become increasingly challenging for Chinese Ph.D. graduates to secure\npositions at institutions more prestigious than their alma maters. This study\nquantitatively captures the evolving structure of talent circulation in the\ndomestic environment, providing valuable insights to enhance the organization,\ndiversity, and talent distribution in China's academic enterprise.", "field": "Computer Science", "categories": "cs.DL"}, {"arxiv_id": "2401.12743", "title": "Correlation-Embedded Transformer Tracking: A Single-Branch Framework", "abstract": "Developing robust and discriminative appearance models has been a\nlong-standing research challenge in visual object tracking. In the prevalent\nSiamese-based paradigm, the features extracted by the Siamese-like networks are\noften insufficient to model the tracked targets and distractor objects, thereby\nhindering them from being robust and discriminative simultaneously. While most\nSiamese trackers focus on designing robust correlation operations, we propose a\nnovel single-branch tracking framework inspired by the transformer. Unlike the\nSiamese-like feature extraction, our tracker deeply embeds cross-image feature\ncorrelation in multiple layers of the feature network. By extensively matching\nthe features of the two images through multiple layers, it can suppress\nnon-target features, resulting in target-aware feature extraction. The output\nfeatures can be directly used for predicting target locations without\nadditional correlation steps. Thus, we reformulate the two-branch Siamese\ntracking as a conceptually simple, fully transformer-based Single-Branch\nTracking pipeline, dubbed SBT. After conducting an in-depth analysis of the SBT\nbaseline, we summarize many effective design principles and propose an improved\ntracker dubbed SuperSBT. SuperSBT adopts a hierarchical architecture with a\nlocal modeling layer to enhance shallow-level features. A unified relation\nmodeling is proposed to remove complex handcrafted layer pattern designs.\nSuperSBT is further improved by masked image modeling pre-training, integrating\ntemporal modeling, and equipping with dedicated prediction heads. Thus,\nSuperSBT outperforms the SBT baseline by 4.7%,3.0%, and 4.5% AUC scores in\nLaSOT, TrackingNet, and GOT-10K. Notably, SuperSBT greatly raises the speed of\nSBT from 37 FPS to 81 FPS. Extensive experiments show that our method achieves\nsuperior results on eight VOT benchmarks.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.12744", "title": "Monadic Intersection Types, Relationally (Extended Version)", "abstract": "We extend intersection types to a computational $\\lambda$-calculus with\nalgebraic operations \\`a la Plotkin and Power. We achieve this by considering\nmonadic intersections, whereby computational effects appear not only in the\noperational semantics, but also in the type system. Since in the effectful\nsetting termination is not anymore the only property of interest, we want to\nanalyze the interactive behavior of typed programs with the environment.\nIndeed, our type system is able to characterize the natural notion of\nobservation, both in the finite and in the infinitary setting, and for a wide\nclass of effects, such as output, cost, pure and probabilistic nondeterminism,\nand combinations thereof. The main technical tool is a novel combination of\nsyntactic techniques with abstract relational reasoning, which allows us to\nlift all the required notions, e.g. of typability and logical relation, to the\nmonadic setting.", "field": "Computer Science", "categories": "cs.PL,cs.LO"}, {"arxiv_id": "2401.12745", "title": "On the Utility of Probing Trajectories for Algorithm-Selection", "abstract": "Machine-learning approaches to algorithm-selection typically take data\ndescribing an instance as input. Input data can take the form of features\nderived from the instance description or fitness landscape, or can be a direct\nrepresentation of the instance itself, i.e. an image or textual description.\nRegardless of the choice of input, there is an implicit assumption that\ninstances that are similar will elicit similar performance from algorithm, and\nthat a model is capable of learning this relationship. We argue that viewing\nalgorithm-selection purely from an instance perspective can be misleading as it\nfails to account for how an algorithm `views' similarity between instances. We\npropose a novel `algorithm-centric' method for describing instances that can be\nused to train models for algorithm-selection: specifically, we use short\nprobing trajectories calculated by applying a solver to an instance for a very\nshort period of time. The approach is demonstrated to be promising, providing\ncomparable or better results to computationally expensive landscape-based\nfeature-based approaches. Furthermore, projecting the trajectories into a\n2-dimensional space illustrates that functions that are similar from an\nalgorithm-perspective do not necessarily correspond to the accepted\ncategorisation of these functions from a human perspective.", "field": "Computer Science", "categories": "cs.LG,cs.NE"}, {"arxiv_id": "2401.12747", "title": "COOCK project Smart Port 2025 D3.1: \"To Twin Or Not To Twin\"", "abstract": "This document is a result of the COOCK project \"Smart Port 2025: improving\nand accelerating the operational efficiency of a harbour eco-system through the\napplication of intelligent technologies\". It reports on the needs of companies\nfor modelling and simulation and AI-based techniques, with twinning systems in\nparticular. This document categorizes the purposes and Properties of Interest\nfor the use of Digital Twins. It further illustrates some of the twinning\nusages, and touches on some of the potential architectural compositions for\ntwins. This last topic will be further elaborated in a followup report.", "field": "Computer Science", "categories": "eess.SY,cs.SE,cs.SY"}, {"arxiv_id": "2401.12751", "title": "PSDF: Prior-Driven Neural Implicit Surface Learning for Multi-view\n  Reconstruction", "abstract": "Surface reconstruction has traditionally relied on the Multi-View Stereo\n(MVS)-based pipeline, which often suffers from noisy and incomplete geometry.\nThis is due to that although MVS has been proven to be an effective way to\nrecover the geometry of the scenes, especially for locally detailed areas with\nrich textures, it struggles to deal with areas with low texture and large\nvariations of illumination where the photometric consistency is unreliable.\nRecently, Neural Implicit Surface Reconstruction (NISR) combines surface\nrendering and volume rendering techniques and bypasses the MVS as an\nintermediate step, which has emerged as a promising alternative to overcome the\nlimitations of traditional pipelines. While NISR has shown impressive results\non simple scenes, it remains challenging to recover delicate geometry from\nuncontrolled real-world scenes which is caused by its underconstrained\noptimization. To this end, the framework PSDF is proposed which resorts to\nexternal geometric priors from a pretrained MVS network and internal geometric\npriors inherent in the NISR model to facilitate high-quality neural implicit\nsurface learning. Specifically, the visibility-aware feature consistency loss\nand depth prior-assisted sampling based on external geometric priors are\nintroduced. These proposals provide powerfully geometric consistency\nconstraints and aid in locating surface intersection points, thereby\nsignificantly improving the accuracy and delicate reconstruction of NISR.\nMeanwhile, the internal prior-guided importance rendering is presented to\nenhance the fidelity of the reconstructed surface mesh by mitigating the biased\nrendering issue in NISR. Extensive experiments on the Tanks and Temples dataset\nshow that PSDF achieves state-of-the-art performance on complex uncontrolled\nscenes.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.12755", "title": "Towards Risk Analysis of the Impact of AI on the Deliberate Biological\n  Threat Landscape", "abstract": "The perception that the convergence of biological engineering and artificial\nintelligence (AI) could enable increased biorisk has recently drawn attention\nto the governance of biotechnology and artificial intelligence. The 2023\nExecutive Order, Executive Order on the Safe, Secure, and Trustworthy\nDevelopment and Use of Artificial Intelligence, requires an assessment of how\nartificial intelligence can increase biorisk. Within this perspective, we\npresent a simplistic framework for evaluating biorisk and demonstrate how this\nframework falls short in achieving actionable outcomes for a biorisk manager.\nWe then suggest a potential path forward that builds upon existing risk\ncharacterization work and justify why characterization efforts of AI-enabled\ntools for engineering biology is needed.", "field": "Computer Science", "categories": "cs.CY"}, {"arxiv_id": "2401.12756", "title": "What the Weight?! A Unified Framework for Zero-Shot Knowledge\n  Composition", "abstract": "The knowledge encapsulated in a model is the core factor determining its\nfinal performance on downstream tasks. Much research in NLP has focused on\nefficient methods for storing and adapting different types of knowledge, e.g.,\nin dedicated modularized structures, and on how to effectively combine these,\ne.g., by learning additional parameters. However, given the many possible\noptions, a thorough understanding of the mechanisms involved in these\ncompositions is missing, and hence it remains unclear which strategies to\nutilize. To address this research gap, we propose a novel framework for\nzero-shot module composition, which encompasses existing and some novel\nvariations for selecting, weighting, and combining parameter modules under a\nsingle unified notion. Focusing on the scenario of domain knowledge and adapter\nlayers, our framework provides a systematic unification of concepts, allowing\nus to conduct the first comprehensive benchmarking study of various zero-shot\nknowledge composition strategies. In particular, we test two module combination\nmethods and five selection and weighting strategies for their effectiveness and\nefficiency in an extensive experimental setup. Our results highlight the\nefficacy of ensembling but also hint at the power of simple though\noften-ignored weighting methods. Further in-depth analyses allow us to\nunderstand the role of weighting vs. top-k selection, and show that, to a\ncertain extent, the performance of adapter composition can even be predicted.", "field": "Computer Science", "categories": "cs.CL,cs.AI"}, {"arxiv_id": "2401.12761", "title": "MUSES: The Multi-Sensor Semantic Perception Dataset for Driving under\n  Uncertainty", "abstract": "Achieving level-5 driving automation in autonomous vehicles necessitates a\nrobust semantic visual perception system capable of parsing data from different\nsensors across diverse conditions. However, existing semantic perception\ndatasets often lack important non-camera modalities typically used in\nautonomous vehicles, or they do not exploit such modalities to aid and improve\nsemantic annotations in challenging conditions. To address this, we introduce\nMUSES, the MUlti-SEnsor Semantic perception dataset for driving in adverse\nconditions under increased uncertainty. MUSES includes synchronized multimodal\nrecordings with 2D panoptic annotations for 2500 images captured under diverse\nweather and illumination. The dataset integrates a frame camera, a lidar, a\nradar, an event camera, and an IMU/GNSS sensor. Our new two-stage panoptic\nannotation protocol captures both class-level and instance-level uncertainty in\nthe ground truth and enables the novel task of uncertainty-aware panoptic\nsegmentation we introduce, along with standard semantic and panoptic\nsegmentation. MUSES proves both effective for training and challenging for\nevaluating models under diverse visual conditions, and it opens new avenues for\nresearch in multimodal and uncertainty-aware dense semantic perception. Our\ndataset and benchmark will be made publicly available.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.12763", "title": "The State-Dependent Channel with a Rate-Limited Cribbing Helper", "abstract": "The capacity of a memoryless state-dependent channel is derived for a setting\nin which the encoder is provided with rate-limited assistance from a cribbing\nhelper that observes the state sequence causally and the past channel inputs\nstrictly-causally. Said cribbing may increase capacity but not to the level\nachievable by a message-cognizant helper.", "field": "Computer Science", "categories": "cs.IT,math.IT"}, {"arxiv_id": "2401.12768", "title": "What Can Self-Admitted Technical Debt Tell Us About Security? A\n  Mixed-Methods Study", "abstract": "Self-Admitted Technical Debt (SATD) encompasses a wide array of sub-optimal\ndesign and implementation choices reported in software artefacts (e.g., code\ncomments and commit messages) by developers themselves. Such reports have been\ncentral to the study of software maintenance and evolution over the last\ndecades. However, they can also be deemed as dreadful sources of information on\npotentially exploitable vulnerabilities and security flaws. This work\ninvestigates the security implications of SATD from a technical and\ndeveloper-centred perspective. On the one hand, it analyses whether security\npointers disclosed inside SATD sources can be used to characterise\nvulnerabilities in Open-Source Software (OSS) projects and repositories. On the\nother hand, it delves into developers' perspectives regarding the motivations\nbehind this practice, its prevalence, and its potential negative consequences.\nWe followed a mixed-methods approach consisting of (i) the analysis of a\npreexisting dataset containing 94,455 SATD instances and (ii) an online survey\nwith 222 OSS practitioners. We gathered 201 SATD instances through the dataset\nanalysis and mapped them to different Common Weakness Enumeration (CWE)\nidentifiers. Overall, 25 different types of CWEs were spotted across commit\nmessages, pull requests, code comments, and issue sections, from which 8 appear\namong MITRE's Top-25 most dangerous ones. The survey shows that software\npractitioners often place security pointers across SATD artefacts to promote a\nsecurity culture among their peers and help them spot flaky code sections,\namong other motives. However, they also consider such a practice risky as it\nmay facilitate vulnerability exploits. Our findings suggest that preserving the\ncontextual integrity of security pointers disseminated across SATD artefacts is\ncritical to safeguard both commercial and OSS solutions against zero-day\nattacks.", "field": "Computer Science", "categories": "cs.SE,cs.HC"}, {"arxiv_id": "2401.1278", "title": "DeepRicci: Self-supervised Graph Structure-Feature Co-Refinement for\n  Alleviating Over-squashing", "abstract": "Graph Neural Networks (GNNs) have shown great power for learning and mining\non graphs, and Graph Structure Learning (GSL) plays an important role in\nboosting GNNs with a refined graph. In the literature, most GSL solutions\neither primarily focus on structure refinement with task-specific supervision\n(i.e., node classification), or overlook the inherent weakness of GNNs\nthemselves (e.g., over-squashing), resulting in suboptimal performance despite\nsophisticated designs. In light of these limitations, we propose to study\nself-supervised graph structure-feature co-refinement for effectively\nalleviating the issue of over-squashing in typical GNNs. In this paper, we take\na fundamentally different perspective of the Ricci curvature in Riemannian\ngeometry, in which we encounter the challenges of modeling, utilizing and\ncomputing Ricci curvature. To tackle these challenges, we present a\nself-supervised Riemannian model, DeepRicci. Specifically, we introduce a\nlatent Riemannian space of heterogeneous curvatures to model various Ricci\ncurvatures, and propose a gyrovector feature mapping to utilize Ricci curvature\nfor typical GNNs. Thereafter, we refine node features by geometric contrastive\nlearning among different geometric views, and simultaneously refine graph\nstructure by backward Ricci flow based on a novel formulation of differentiable\nRicci curvature. Finally, extensive experiments on public datasets show the\nsuperiority of DeepRicci, and the connection between backward Ricci flow and\nover-squashing. Codes of our work are given in https://github.com/RiemanGraph/.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.12783", "title": "A Review of Deep Learning Methods for Photoplethysmography Data", "abstract": "Photoplethysmography (PPG) is a highly promising device due to its advantages\nin portability, user-friendly operation, and non-invasive capabilities to\nmeasure a wide range of physiological information. Recent advancements in deep\nlearning have demonstrated remarkable outcomes by leveraging PPG signals for\ntasks related to personal health management and other multifaceted\napplications. In this review, we systematically reviewed papers that applied\ndeep learning models to process PPG data between January 1st of 2017 and July\n31st of 2023 from Google Scholar, PubMed and Dimensions. Each paper is analyzed\nfrom three key perspectives: tasks, models, and data. We finally extracted 193\npapers where different deep learning frameworks were used to process PPG\nsignals. Based on the tasks addressed in these papers, we categorized them into\ntwo major groups: medical-related, and non-medical-related. The medical-related\ntasks were further divided into seven subgroups, including blood pressure\nanalysis, cardiovascular monitoring and diagnosis, sleep health, mental health,\nrespiratory monitoring and analysis, blood glucose analysis, as well as others.\nThe non-medical-related tasks were divided into four subgroups, which encompass\nsignal processing, biometric identification, electrocardiogram reconstruction,\nand human activity recognition. In conclusion, significant progress has been\nmade in the field of using deep learning methods to process PPG data recently.\nThis allows for a more thorough exploration and utilization of the information\ncontained in PPG signals. However, challenges remain, such as limited quantity\nand quality of publicly available databases, a lack of effective validation in\nreal-world scenarios, and concerns about the interpretability, scalability, and\ncomplexity of deep learning models. Moreover, there are still emerging research\nareas that require further investigation.", "field": "Computer Science", "categories": "cs.AI,cs.LG,eess.SP"}, {"arxiv_id": "2401.12789", "title": "Multilingual and Fully Non-Autoregressive ASR with Large Language Model\n  Fusion: A Comprehensive Study", "abstract": "In the era of large models, the autoregressive nature of decoding often\nresults in latency serving as a significant bottleneck. We propose a\nnon-autoregressive LM-fused ASR system that effectively leverages the\nparallelization capabilities of accelerator hardware. Our approach combines the\nUniversal Speech Model (USM) and the PaLM 2 language model in per-segment\nscoring mode, achieving an average relative WER improvement across all\nlanguages of 10.8% on FLEURS and 3.6% on YouTube captioning. Furthermore, our\ncomprehensive ablation study analyzes key parameters such as LLM size, context\nlength, vocabulary size, fusion methodology. For instance, we explore the\nimpact of LLM size ranging from 128M to 340B parameters on ASR performance.\nThis study provides valuable insights into the factors influencing the\neffectiveness of practical large-scale LM-fused speech recognition systems.", "field": "Computer Science", "categories": "cs.CL,cs.SD,eess.AS"}, {"arxiv_id": "2401.1279", "title": "MORPH: Towards Automated Concept Drift Adaptation for Malware Detection", "abstract": "Concept drift is a significant challenge for malware detection, as the\nperformance of trained machine learning models degrades over time, rendering\nthem impractical. While prior research in malware concept drift adaptation has\nprimarily focused on active learning, which involves selecting representative\nsamples to update the model, self-training has emerged as a promising approach\nto mitigate concept drift. Self-training involves retraining the model using\npseudo labels to adapt to shifting data distributions. In this research, we\npropose MORPH -- an effective pseudo-label-based concept drift adaptation\nmethod specifically designed for neural networks. Through extensive\nexperimental analysis of Android and Windows malware datasets, we demonstrate\nthe efficacy of our approach in mitigating the impact of concept drift. Our\nmethod offers the advantage of reducing annotation efforts when combined with\nactive learning. Furthermore, our method significantly improves over existing\nworks in automated concept drift adaptation for malware detection.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.12794", "title": "Benchmarking LLMs via Uncertainty Quantification", "abstract": "The proliferation of open-source Large Language Models (LLMs) from various\ninstitutions has highlighted the urgent need for comprehensive evaluation\nmethods. However, current evaluation platforms, such as the widely recognized\nHuggingFace open LLM leaderboard, neglect a crucial aspect -- uncertainty,\nwhich is vital for thoroughly assessing LLMs. To bridge this gap, we introduce\na new benchmarking approach for LLMs that integrates uncertainty\nquantification. Our examination involves eight LLMs (LLM series) spanning five\nrepresentative natural language processing tasks. Additionally, we introduce an\nuncertainty-aware evaluation metric, UAcc, which takes into account both\nprediction accuracy and prediction uncertainty. Our findings reveal that: I)\nLLMs with higher accuracy may exhibit lower certainty; II) Larger-scale LLMs\nmay display greater uncertainty compared to their smaller counterparts; and\nIII) Instruction-finetuning tends to increase the uncertainty of LLMs. By\ntaking uncertainty into account, our new UAcc metric can either amplify or\ndiminish the relative improvement of one LLM over another and may even change\nthe relative ranking of two LLMs. These results underscore the significance of\nincorporating uncertainty in the evaluation of LLMs.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.12798", "title": "Gradient Flow of Energy: A General and Efficient Approach for Entity\n  Alignment Decoding", "abstract": "Entity alignment (EA), a pivotal process in integrating multi-source\nKnowledge Graphs (KGs), seeks to identify equivalent entity pairs across these\ngraphs. Most existing approaches regard EA as a graph representation learning\ntask, concentrating on enhancing graph encoders. However, the decoding process\nin EA - essential for effective operation and alignment accuracy - has received\nlimited attention and remains tailored to specific datasets and model\narchitectures, necessitating both entity and additional explicit relation\nembeddings. This specificity limits its applicability, particularly in\nGNN-based models. To address this gap, we introduce a novel, generalized, and\nefficient decoding approach for EA, relying solely on entity embeddings. Our\nmethod optimizes the decoding process by minimizing Dirichlet energy, leading\nto the gradient flow within the graph, to promote graph homophily. The\ndiscretization of the gradient flow produces a fast and scalable approach,\ntermed Triple Feature Propagation (TFP). TFP innovatively channels gradient\nflow through three views: entity-to-entity, entity-to-relation, and\nrelation-to-entity. This generalized gradient flow enables TFP to harness the\nmulti-view structural information of KGs. Rigorous experimentation on diverse\nreal-world datasets demonstrates that our approach significantly enhances\nvarious EA methods. Notably, the approach achieves these advancements with less\nthan 6 seconds of additional computational time, establishing a new benchmark\nin efficiency and adaptability for future EA methods.", "field": "Computer Science", "categories": "cs.IR,cs.CL"}, {"arxiv_id": "2401.12799", "title": "Some convergence analysis for multicontinuum homogenization", "abstract": "In this paper, we provide an analysis of a recently proposed multicontinuum\nhomogenization technique. The analysis differs from those used in classical\nhomogenization methods for several reasons. First, the cell problems in\nmulticontinuum homogenization use constraint problems and can not be directly\nsubstituted into the differential operator. Secondly, the problem contains high\ncontrast that remains in the homogenized problem. The homogenized problem\naverages the microstructure while containing the small parameter. In this\nanalysis, we first based on our previous techniques, CEM-GMsFEM, to define a\nCEM-downscaling operator that maps the multicontinuum quantities to an\napproximated microscopic solution. Following the regularity assumption of the\nmulticontinuum quantities, we construct a downscaling operator and the\nhomogenized multicontinuum equations using the information of linear\napproximation of the multicontinuum quantities. The error analysis is given by\nthe residual estimate of the homogenized equations and the well-posedness\nassumption of the homogenized equations.", "field": "Computer Science", "categories": "math.NA,cs.NA"}, {"arxiv_id": "2401.128", "title": "Deep Learning in Physical Layer: Review on Data Driven End-to-End\n  Communication Systems and their Enabling Semantic Applications", "abstract": "Deep Learning (DL) has enabled a paradigm shift in wireless communication\nsystem with data driven end-to-end (E2E) learning and optimization of the\nPhysical Layer (PHY). By leveraging the representation learning of DL, E2E\nsystems exhibit enhanced adaptability and performance in complex wireless\nenvironments, fulfilling the demands of 5G and beyond network systems and\napplications. The evolution of data-driven techniques in the PHY has enabled\nadvanced semantic applications across various modalities including text, image,\naudio, video, and multi-modal transmissions. These applications transcend from\ntraditional bit-level communication to semantic-level intelligent communication\nsystems, which are capable of understanding and adapting to the context and\nintent of the data transmission. Although PHY as a DL architecture for\ndata-driven E2E communication is a key factor in enabling semantic\ncommunication systems (SemCom), and various studies in recent years have\nsurveyed them separately, their combination has not been thoroughly reviewed.\nAdditionally, these are emerging fields that are still in their infancy, with\nseveral techniques having been developed and evolved in recent years.\nTherefore, this article provides a holistic review of data-driven PHY for E2E\ncommunication system, and their enabling semantic applications across different\nmodalities. Furthermore, it identifies critical challenges and prospective\nresearch directions, providing a pivotal reference for future development of DL\nin PHY and SemCom.", "field": "Computer Science", "categories": "cs.NI,cs.LG"}, {"arxiv_id": "2401.12801", "title": "Deep Learning-based Target-To-User Association in Integrated Sensing and\n  Communication Systems", "abstract": "In Integrated Sensing and Communication (ISAC) systems, matching the radar\ntargets with communication user equipments (UEs) is functional to several\ncommunication tasks, such as proactive handover and beam prediction. In this\npaper, we consider a radar-assisted communication system where a base station\n(BS) is equipped with a multiple-input-multiple-output (MIMO) radar that has a\ndouble aim: (i) associate vehicular radar targets to vehicular equipments (VEs)\nin the communication beamspace and (ii) predict the beamforming vector for each\nVE from radar data. The proposed target-to-user (T2U) association consists of\ntwo stages. First, vehicular radar targets are detected from range-angle\nimages, and, for each, a beamforming vector is estimated. Then, the inferred\nper-target beamforming vectors are matched with the ones utilized at the BS for\ncommunication to perform target-to-user (T2U) association. Joint multi-target\ndetection and beam inference is obtained by modifying the you only look once\n(YOLO) model, which is trained over simulated range-angle radar images.\nSimulation results over different urban vehicular mobility scenarios show that\nthe proposed T2U method provides a probability of correct association that\nincreases with the size of the BS antenna array, highlighting the respective\nincrease of the separability of the VEs in the beamspace. Moreover, we show\nthat the modified YOLO architecture can effectively perform both beam\nprediction and radar target detection, with similar performance in mean average\nprecision on the latter over different antenna array sizes.", "field": "Computer Science", "categories": "cs.NI,cs.LG,eess.SP"}, {"arxiv_id": "2401.12803", "title": "Enhancements for 5G NR PRACH Reception: An AI/ML Approach", "abstract": "Random Access is an important step in enabling the initial attachment of a\nUser Equipment (UE) to a Base Station (gNB). The UE identifies itself by\nembedding a Preamble Index (RAPID) in the phase rotation of a known base\nsequence, which it transmits on the Physical Random Access Channel (PRACH). The\nsignal on the PRACH also enables the estimation of propagation delay, often\nknown as Timing Advance (TA), which is induced by virtue of the UE's position.\nTraditional receivers estimate the RAPID and TA using correlation-based\ntechniques. This paper presents an alternative receiver approach that uses\nAI/ML models, wherein two neural networks are proposed, one for the RAPID and\none for the TA. Different from other works, these two models can run in\nparallel as opposed to sequentially. Experiments with both simulated data and\nover-the-air hardware captures highlight the improved performance of the\nproposed AI/ML-based techniques compared to conventional correlation methods.", "field": "Computer Science", "categories": "cs.IT,cs.AI,cs.LG,eess.SP,math.IT"}, {"arxiv_id": "2401.12806", "title": "Binary structured physics-informed neural networks for solving equations\n  with rapidly changing solutions", "abstract": "Physics-informed neural networks (PINNs), rooted in deep learning, have\nemerged as a promising approach for solving partial differential equations\n(PDEs). By embedding the physical information described by PDEs into\nfeedforward neural networks, PINNs are trained as surrogate models to\napproximate solutions without the need for label data. Nevertheless, even\nthough PINNs have shown remarkable performance, they can face difficulties,\nespecially when dealing with equations featuring rapidly changing solutions.\nThese difficulties encompass slow convergence, susceptibility to becoming\ntrapped in local minima, and reduced solution accuracy. To address these\nissues, we propose a binary structured physics-informed neural network (BsPINN)\nframework, which employs binary structured neural network (BsNN) as the neural\nnetwork component. By leveraging a binary structure that reduces inter-neuron\nconnections compared to fully connected neural networks, BsPINNs excel in\ncapturing the local features of solutions more effectively and efficiently.\nThese features are particularly crucial for learning the rapidly changing in\nthe nature of solutions. In a series of numerical experiments solving Burgers\nequation, Euler equation, Helmholtz equation, and high-dimension Poisson\nequation, BsPINNs exhibit superior convergence speed and heightened accuracy\ncompared to PINNs. From these experiments, we discover that BsPINNs resolve the\nissues caused by increased hidden layers in PINNs resulting in over-smoothing,\nand prevent the decline in accuracy due to non-smoothness of PDEs solutions.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.12808", "title": "A Robot Expressing Emotions Through Gestures: Everyone Outside of Italy\n  Would Understand this?", "abstract": "In the context of our research activities on affective computing and\nhuman-robot interaction we are working on both the recognition of human's\nemotions and the expression of emotions by robots. In our vision, robots will\nbe increasingly present in schools, factories, and homes, and their empathetic\nbehavior may foster their acceptance. In particular, in one of our research, we\nsought to replicate gestures associated with specific emotions on a social\nrobot, NAO. Our focus was on Ekman's six primary emotions, along with five\nemotions selected from Plutchik's wheel of emotions. In our opinion the\ncultural component linked to the expression of emotions through gestures\ncertainly influenced both us and the participants. Thus, we would like to\ninvestigate the influence of our culture in the gestural expression of emotion.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.12815", "title": "COREC: Concurrent Non-Blocking Single-Queue Receive Driver for Low\n  Latency Networking", "abstract": "Existing network stacks tackle performance and scalability aspects by relying\non multiple receive queues. However, at software level, each queue is processed\nby a single thread, which prevents simultaneous work on the same queue and\nlimits performance in terms of tail latency. To overcome this limitation, we\nintroduce COREC, the first software implementation of a concurrent non-blocking\nsingle-queue receive driver. By sharing a single queue among multiple threads,\nworkload distribution is improved, leading to a work-conserving policy for\nnetwork stacks. On the technical side, instead of relying on traditional\ncritical sections - which would sequentialize the operations by threads - COREC\ncoordinates the threads that concurrently access the same receive queue in\nnon-blocking manner via atomic machine instructions from the Read-Modify-Write\n(RMW) class. These instructions allow threads to access and update memory\nlocations atomically, based on specific conditions, such as the matching of a\ntarget value selected by the thread. Also, they enable making any update\nglobally visible in the memory hierarchy, bypassing interference on memory\nconsistency caused by the CPU store buffers. Extensive evaluation results\ndemonstrate that the possible additional reordering, which our approach may\noccasionally cause, is non-critical and has minimal impact on performance, even\nin the worst-case scenario of a single large TCP flow, with performance\nimpairments accounting to at most 2-3 percent. Conversely, substantial latency\ngains are achieved when handling UDP traffic, real-world traffic mix, and\nmultiple shorter TCP flows.", "field": "Computer Science", "categories": "cs.NI,cs.DC"}, {"arxiv_id": "2401.12818", "title": "Binomial Channel: On the Capacity-Achieving Distribution and Bounds on\n  the Capacity", "abstract": "This work considers a binomial noise channel. The paper can be roughly\ndivided into two parts. The first part is concerned with the properties of the\ncapacity-achieving distribution. In particular, for the binomial channel, it is\nnot known if the capacity-achieving distribution is unique since the output\nspace is finite (i.e., supported on integers $0, \\ldots, n)$ and the input\nspace is infinite (i.e., supported on the interval $[0,1]$), and there are\nmultiple distributions that induce the same output distribution. This paper\nshows that the capacity-achieving distribution is unique by appealing to the\ntotal positivity property of the binomial kernel. In addition, we provide upper\nand lower bounds on the cardinality of the support of the capacity-achieving\ndistribution. Specifically, an upper bound of order $ \\frac{n}{2}$ is shown,\nwhich improves on the previous upper bound of order $n$ due to Witsenhausen.\nMoreover, a lower bound of order $\\sqrt{n}$ is shown. Finally, additional\ninformation about the locations and probability values of the support points is\nestablished.\n  The second part of the paper focuses on deriving upper and lower bounds on\ncapacity. In particular, firm bounds are established for all $n$ that show that\nthe capacity scales as $\\frac{1}{2} \\log(n)$.", "field": "Computer Science", "categories": "cs.IT,math.IT"}, {"arxiv_id": "2401.12819", "title": "Dynamic Layer Tying for Parameter-Efficient Transformers", "abstract": "In the pursuit of reducing the number of trainable parameters in deep\ntransformer networks, we employ Reinforcement Learning to dynamically select\nlayers during training and tie them together. Every few iterations, the RL\nagent is asked whether to train each layer $i$ independently or to copy the\nweights of a previous layer $j<i$. This facilitates weight sharing, reduces the\nnumber of trainable parameters, and also serves as an effective regularization\ntechnique. Experimental evaluations validate that our model modestly\noutperforms the baseline transformer model with regard to perplexity and\ndrastically reduces the number of trainable parameters. In particular, the\nmemory consumption during training is up to one order of magnitude less than\nthe conventional training method.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.1282", "title": "DatUS^2: Data-driven Unsupervised Semantic Segmentation with Pre-trained\n  Self-supervised Vision Transformer", "abstract": "Successive proposals of several self-supervised training schemes continue to\nemerge, taking one step closer to developing a universal foundation model. In\nthis process, the unsupervised downstream tasks are recognized as one of the\nevaluation methods to validate the quality of visual features learned with a\nself-supervised training scheme. However, unsupervised dense semantic\nsegmentation has not been explored as a downstream task, which can utilize and\nevaluate the quality of semantic information introduced in patch-level feature\nrepresentations during self-supervised training of a vision transformer.\nTherefore, this paper proposes a novel data-driven approach for unsupervised\nsemantic segmentation (DatUS^2) as a downstream task. DatUS^2 generates\nsemantically consistent and dense pseudo annotate segmentation masks for the\nunlabeled image dataset without using any visual-prior or synchronized data. We\ncompare these pseudo-annotated segmentation masks with ground truth masks for\nevaluating recent self-supervised training schemes to learn shared semantic\nproperties at the patch level and discriminative semantic properties at the\nsegment level. Finally, we evaluate existing state-of-the-art self-supervised\ntraining schemes with our proposed downstream task, i.e., DatUS^2. Also, the\nbest version of DatUS^2 outperforms the existing state-of-the-art method for\nthe unsupervised dense semantic segmentation task with 15.02% MiOU and 21.47%\nPixel accuracy on the SUIM dataset. It also achieves a competitive level of\naccuracy for a large-scale and complex dataset, i.e., the COCO dataset.", "field": "Computer Science", "categories": "cs.CV,cs.LG,I.4; I.5"}, {"arxiv_id": "2401.12822", "title": "Deep Learning Based Simulators for the Phosphorus Removal Process\n  Control in Wastewater Treatment via Deep Reinforcement Learning Algorithms", "abstract": "Phosphorus removal is vital in wastewater treatment to reduce reliance on\nlimited resources. Deep reinforcement learning (DRL) is a machine learning\ntechnique that can optimize complex and nonlinear systems, including the\nprocesses in wastewater treatment plants, by learning control policies through\ntrial and error. However, applying DRL to chemical and biological processes is\nchallenging due to the need for accurate simulators. This study trained six\nmodels to identify the phosphorus removal process and used them to create a\nsimulator for the DRL environment. Although the models achieved high accuracy\n(>97%), uncertainty and incorrect prediction behavior limited their performance\nas simulators over longer horizons. Compounding errors in the models'\npredictions were identified as one of the causes of this problem. This approach\nfor improving process control involves creating simulation environments for DRL\nalgorithms, using data from supervisory control and data acquisition (SCADA)\nsystems with a sufficient historical horizon without complex system modeling or\nparameter estimation.", "field": "Computer Science", "categories": "eess.SY,cs.AI,cs.LG,cs.SY"}, {"arxiv_id": "2401.12824", "title": "MAPPING: Debiasing Graph Neural Networks for Fair Node Classification\n  with Limited Sensitive Information Leakage", "abstract": "Despite remarkable success in diverse web-based applications, Graph Neural\nNetworks(GNNs) inherit and further exacerbate historical discrimination and\nsocial stereotypes, which critically hinder their deployments in high-stake\ndomains such as online clinical diagnosis, financial crediting, etc. However,\ncurrent fairness research that primarily craft on i.i.d data, cannot be\ntrivially replicated to non-i.i.d. graph structures with topological dependence\namong samples. Existing fair graph learning typically favors pairwise\nconstraints to achieve fairness but fails to cast off dimensional limitations\nand generalize them into multiple sensitive attributes; besides, most studies\nfocus on in-processing techniques to enforce and calibrate fairness,\nconstructing a model-agnostic debiasing GNN framework at the pre-processing\nstage to prevent downstream misuses and improve training reliability is still\nlargely under-explored. Furthermore, previous work on GNNs tend to enhance\neither fairness or privacy individually but few probe into their interplays. In\nthis paper, we propose a novel model-agnostic debiasing framework named MAPPING\n(\\underline{M}asking \\underline{A}nd \\underline{P}runing and\nMessage-\\underline{P}assing train\\underline{ING}) for fair node classification,\nin which we adopt the distance covariance($dCov$)-based fairness constraints to\nsimultaneously reduce feature and topology biases in arbitrary dimensions, and\ncombine them with adversarial debiasing to confine the risks of attribute\ninference attacks. Experiments on real-world datasets with different GNN\nvariants demonstrate the effectiveness and flexibility of MAPPING. Our results\nshow that MAPPING can achieve better trade-offs between utility and fairness,\nand mitigate privacy risks of sensitive information leakage.", "field": "Computer Science", "categories": "cs.LG,stat.ML"}, {"arxiv_id": "2401.12826", "title": "Digital Twin-Based Network Management for Better QoE in Multicast Short\n  Video Streaming", "abstract": "Multicast short video streaming can enhance bandwidth utilization by enabling\nsimultaneous video transmission to multiple users over shared wireless\nchannels. The existing network management schemes mainly rely on the sequential\nbuffering principle and general quality of experience (QoE) model, which may\ndeteriorate QoE when users' swipe behaviors exhibit distinct spatiotemporal\nvariation. In this paper, we propose a digital twin (DT)-based network\nmanagement scheme to enhance QoE. Firstly, user status emulated by the DT is\nutilized to estimate the transmission capabilities and watching probability\ndistributions of sub-multicast groups (SMGs) for an adaptive segment buffering.\nThe SMGs' buffers are aligned to the unique virtual buffers managed by the DT\nfor a fine-grained buffer update. Then, a multicast QoE model consisting of\nrebuffering time, video quality, and quality variation is developed, by\nconsidering the mutual influence of segment buffering among SMGs. Finally, a\njoint optimization problem of segment version selection and slot division is\nformulated to maximize QoE. To efficiently solve the problem, a\ndata-model-driven algorithm is proposed by integrating a convex optimization\nmethod and a deep reinforcement learning algorithm. Simulation results based on\nthe real-world dataset demonstrate that the proposed DT-based network\nmanagement scheme outperforms benchmark schemes in terms of QoE improvement.", "field": "Computer Science", "categories": "cs.NI,eess.IV"}, {"arxiv_id": "2401.1283", "title": "Enhancing Next Destination Prediction: A Novel LSTM Approach Using\n  Real-World Airline Data", "abstract": "In the modern transportation industry, accurate prediction of travelers' next\ndestinations brings multiple benefits to companies, such as customer\nsatisfaction and targeted marketing. This study focuses on developing a precise\nmodel that captures the sequential patterns and dependencies in travel data,\nenabling accurate predictions of individual travelers' future destinations. To\nachieve this, a novel model architecture with a sliding window approach based\non Long Short-Term Memory (LSTM) is proposed for destination prediction in the\ntransportation industry. The experimental results highlight satisfactory\nperformance and high scores achieved by the proposed model across different\ndata sizes and performance metrics. This research contributes to advancing\ndestination prediction methods, empowering companies to deliver personalized\nrecommendations and optimize customer experiences in the dynamic travel\nlandscape.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.12832", "title": "Numerical approximation of the stochastic Cahn-Hilliard equation with\n  space-time white noise near the sharp interface limit", "abstract": "We consider the stochastic Cahn-Hilliard equation with additive space-time\nwhite noise $\\epsilon^{\\gamma}\\dot{W}$ in dimension $d=2,3$, where $\\epsilon>0$\nis an interfacial width parameter. We study numerical approximation of the\nequation which combines a structure preserving implicit time-discretization\nscheme with a discrete approximation of the space-time white noise. We derive a\nstrong error estimate for the considered numerical approximation which is\nrobust with respect to the inverse of the interfacial width parameter\n$\\epsilon$. Furthermore, by a splitting approach, we show that for sufficiently\nlarge scaling parameter $\\gamma$, the numerical approximation of the stochastic\nCahn-Hilliard equation converges uniformly to the deterministic\nHele-Shaw/Mullins-Sekerka problem in the sharp interface limit\n$\\epsilon\\rightarrow 0$.", "field": "Computer Science", "categories": "math.NA,cs.NA"}, {"arxiv_id": "2401.12835", "title": "SGTR+: End-to-end Scene Graph Generation with Transformer", "abstract": "Scene Graph Generation (SGG) remains a challenging visual understanding task\ndue to its compositional property. Most previous works adopt a bottom-up,\ntwo-stage or point-based, one-stage approach, which often suffers from high\ntime complexity or suboptimal designs. In this work, we propose a novel SGG\nmethod to address the aforementioned issues, formulating the task as a\nbipartite graph construction problem. To address the issues above, we create a\ntransformer-based end-to-end framework to generate the entity and entity-aware\npredicate proposal set, and infer directed edges to form relation triplets.\nMoreover, we design a graph assembling module to infer the connectivity of the\nbipartite scene graph based on our entity-aware structure, enabling us to\ngenerate the scene graph in an end-to-end manner. Based on bipartite graph\nassembling paradigm, we further propose a new technical design to address the\nefficacy of entity-aware modeling and optimization stability of graph\nassembling. Equipped with the enhanced entity-aware design, our method achieves\noptimal performance and time-complexity. Extensive experimental results show\nthat our design is able to achieve the state-of-the-art or comparable\nperformance on three challenging benchmarks, surpassing most of the existing\napproaches and enjoying higher efficiency in inference. Code is available:\nhttps://github.com/Scarecrow0/SGTR", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.12842", "title": "Iterated Relevance Matrix Analysis (IRMA) for the identification of\n  class-discriminative subspaces", "abstract": "We introduce and investigate the iterated application of Generalized Matrix\nLearning Vector Quantizaton for the analysis of feature relevances in\nclassification problems, as well as for the construction of\nclass-discriminative subspaces. The suggested Iterated Relevance Matrix\nAnalysis (IRMA) identifies a linear subspace representing the classification\nspecific information of the considered data sets using Generalized Matrix\nLearning Vector Quantization (GMLVQ). By iteratively determining a new\ndiscriminative subspace while projecting out all previously identified ones, a\ncombined subspace carrying all class-specific information can be found. This\nfacilitates a detailed analysis of feature relevances, and enables improved\nlow-dimensional representations and visualizations of labeled data sets.\nAdditionally, the IRMA-based class-discriminative subspace can be used for\ndimensionality reduction and the training of robust classifiers with\npotentially improved performance.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.12843", "title": "An embedding-based distance for temporal graphs", "abstract": "We define a distance between temporal graphs based on graph embeddings built\nusing time-respecting random walks. We study both the case of matched graphs,\nwhen there exists a known relation between the nodes, and the unmatched case,\nwhen such a relation is unavailable and the graphs may be of different sizes.\nWe illustrate the interest of our distance definition, using both real and\nsynthetic temporal network data, by showing its ability to discriminate between\ngraphs with different structural and temporal properties. Leveraging\nstate-of-the-art machine learning techniques, we propose an efficient\nimplementation of distance computation that is viable for large-scale temporal\ngraphs.", "field": "Computer Science", "categories": "cs.SI,cs.LG"}, {"arxiv_id": "2401.12846", "title": "How well can large language models explain business processes?", "abstract": "Large Language Models (LLMs) are likely to play a prominent role in future\nAI-augmented business process management systems (ABPMSs) catering\nfunctionalities across all system lifecycle stages. One such system's\nfunctionality is Situation-Aware eXplainability (SAX), which relates to\ngenerating causally sound and yet human-interpretable explanations that take\ninto account the process context in which the explained condition occurred. In\nthis paper, we present the SAX4BPM framework developed to generate SAX\nexplanations. The SAX4BPM suite consists of a set of services and a central\nknowledge repository. The functionality of these services is to elicit the\nvarious knowledge ingredients that underlie SAX explanations. A key innovative\ncomponent among these ingredients is the causal process execution view. In this\nwork, we integrate the framework with an LLM to leverage its power to\nsynthesize the various input ingredients for the sake of improved SAX\nexplanations. Since the use of LLMs for SAX is also accompanied by a certain\ndegree of doubt related to its capacity to adequately fulfill SAX along with\nits tendency for hallucination and lack of inherent capacity to reason, we\npursued a methodological evaluation of the quality of the generated\nexplanations. To this aim, we developed a designated scale and conducted a\nrigorous user study. Our findings show that the input presented to the LLMs\naided with the guard-railing of its performance, yielding SAX explanations\nhaving better-perceived fidelity. This improvement is moderated by the\nperception of trust and curiosity. More so, this improvement comes at the cost\nof the perceived interpretability of the explanation.", "field": "Computer Science", "categories": "cs.AI,68T01"}, {"arxiv_id": "2401.12848", "title": "Optimal Evasion from a Sensing-Limited Pursuer", "abstract": "This paper investigates a partial-information pursuit evasion game in which\nthe Pursuer has a limited-range sensor to detect the Evader. Given a fixed\nfinal time, we derive the optimal evasion strategy for the Evader to maximize\nits distance from the pursuer at the end. Our analysis reveals that in certain\nparametric regimes, the optimal Evasion strategy involves a 'risky' maneuver,\nwhere the Evader's trajectory comes extremely close to the pursuer's sensing\nboundary before moving behind the Pursuer. Additionally, we explore a special\ncase in which the Pursuer can choose the final time. In this scenario, we\ndetermine a (Nash) equilibrium pair for both the final time and the evasion\nstrategy.", "field": "Computer Science", "categories": "cs.GT,cs.SY,eess.SY"}, {"arxiv_id": "2401.12849", "title": "Learning safety critics via a non-contractive binary bellman operator", "abstract": "The inability to naturally enforce safety in Reinforcement Learning (RL),\nwith limited failures, is a core challenge impeding its use in real-world\napplications. One notion of safety of vast practical relevance is the ability\nto avoid (unsafe) regions of the state space. Though such a safety goal can be\ncaptured by an action-value-like function, a.k.a. safety critics, the\nassociated operator lacks the desired contraction and uniqueness properties\nthat the classical Bellman operator enjoys. In this work, we overcome the\nnon-contractiveness of safety critic operators by leveraging that safety is a\nbinary property. To that end, we study the properties of the binary safety\ncritic associated with a deterministic dynamical system that seeks to avoid\nreaching an unsafe region. We formulate the corresponding binary Bellman\nequation (B2E) for safety and study its properties. While the resulting\noperator is still non-contractive, we fully characterize its fixed points\nrepresenting--except for a spurious solution--maximal persistently safe regions\nof the state space that can always avoid failure. We provide an algorithm that,\nby design, leverages axiomatic knowledge of safe data to avoid spurious fixed\npoints.", "field": "Computer Science", "categories": "cs.LG,cs.SY,eess.SY"}, {"arxiv_id": "2401.12851", "title": "Classification of grapevine varieties using UAV hyperspectral imaging", "abstract": "The classification of different grapevine varieties is a relevant phenotyping\ntask in Precision Viticulture since it enables estimating the growth of\nvineyard rows dedicated to different varieties, among other applications\nconcerning the wine industry. This task can be performed with destructive\nmethods that require time-consuming tasks, including data collection and\nanalysis in the laboratory. However, Unmanned Aerial Vehicles (UAV) provide a\nmore efficient and less prohibitive approach to collecting hyperspectral data,\ndespite acquiring noisier data. Therefore, the first task is the processing of\nthese data to correct and downsample large amounts of data. In addition, the\nhyperspectral signatures of grape varieties are very similar. In this work, a\nConvolutional Neural Network (CNN) is proposed for classifying seventeen\nvarieties of red and white grape variants. Rather than classifying single\nsamples, these are processed together with their neighbourhood. Hence, the\nextraction of spatial and spectral features is addressed with 1) a spatial\nattention layer and 2) Inception blocks. The pipeline goes from processing to\ndataset elaboration, finishing with the training phase. The fitted model is\nevaluated in terms of response time, accuracy and data separability, and\ncompared with other state-of-the-art CNNs for classifying hyperspectral data.\nOur network was proven to be much more lightweight with a reduced number of\ninput bands, a lower number of trainable weights and therefore, reduced\ntraining time. Despite this, the evaluated metrics showed much better results\nfor our network (~99% overall accuracy), in comparison with previous works\nbarely achieving 81% OA.", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.LG"}, {"arxiv_id": "2401.12852", "title": "Control-Aware Trajectory Predictions for Communication-Efficient Drone\n  Swarm Coordination in Cluttered Environments", "abstract": "Swarms of Unmanned Aerial Vehicles (UAV) have demonstrated enormous potential\nin many industrial and commercial applications. However, before deploying UAVs\nin the real world, it is essential to ensure they can operate safely in complex\nenvironments, especially with limited communication capabilities. To address\nthis challenge, we propose a control-aware learning-based trajectory prediction\nalgorithm that can enable communication-efficient UAV swarm control in a\ncluttered environment. Specifically, our proposed algorithm can enable each UAV\nto predict the planned trajectories of its neighbors in scenarios with various\nlevels of communication capabilities. The predicted planned trajectories will\nserve as input to a distributed model predictive control (DMPC) approach. The\nproposed algorithm combines (1) a trajectory compression and reconstruction\nmodel based on Variational Auto-Encoder, (2) a trajectory prediction model\nbased on EvolveGCN, a graph convolutional network (GCN) that can handle dynamic\ngraphs, and (3) a KKT-informed training approach that applies the\nKarush-Kuhn-Tucker (KKT) conditions in the training process to encode DMPC\ninformation into the trained neural network. We evaluate our proposed algorithm\nin a funnel-like environment. Results show that the proposed algorithm\noutperforms state-of-the-art benchmarks, providing close-to-optimal control\nperformance and robustness to limited communication capabilities and\nmeasurement noises.", "field": "Computer Science", "categories": "cs.RO,I.2.9"}, {"arxiv_id": "2401.12853", "title": "Hyper-Realist Rendering: A Theoretical Framework", "abstract": "This is the first paper in a series on hyper-realist rendering. In this\npaper, we introduce the concept of hyper-realist rendering and present a\ntheoretical framework to obtain hyper-realist images. We are using the term\nHyper-realism as an umbrella word that captures all types of visual artifacts\nthat can evoke an impression of reality. The hyper-realist artifacts are visual\nrepresentations that are not necessarily created by following logical and\nphysical principles and can still be perceived as representations of reality.\nThis idea stems from the principles of representational arts, which attain\nvisually acceptable renderings of scenes without implementing strict physical\nlaws of optics and materials. The objective of this work is to demonstrate that\nit is possible to obtain visually acceptable illusions of reality by employing\nsuch artistic approaches. With representational art methods, we can even obtain\nan alternate illusion of reality that looks more real even when it is not real.\nThis paper demonstrates that it is common to create illusions of reality in\nvisual arts with examples of paintings by representational artists. We propose\nan approach to obtain expressive local and global illuminations to obtain these\nstylistic illusions with a set of well-defined and formal methods.", "field": "Computer Science", "categories": "cs.GR"}, {"arxiv_id": "2401.12857", "title": "Simultaneous exercise recognition and evaluation in prescribed routines:\n  Approach to virtual coaches", "abstract": "Home-based physical therapies are effective if the prescribed exercises are\ncorrectly executed and patients adhere to these routines. This is specially\nimportant for older adults who can easily forget the guidelines from\ntherapists. Inertial Measurement Units (IMUs) are commonly used for tracking\nexercise execution giving information of patients' motion data. In this work,\nwe propose the use of Machine Learning techniques to recognize which exercise\nis being carried out and to assess if the recognized exercise is properly\nexecuted by using data from four IMUs placed on the person limbs. To the best\nof our knowledge, both tasks have never been addressed together as a unique\ncomplex task before. However, their combination is needed for the complete\ncharacterization of the performance of physical therapies. We evaluate the\nperformance of six machine learning classifiers in three contexts: recognition\nand evaluation in a single classifier, recognition of correct exercises,\nexcluding the wrongly performed exercises, and a two-stage approach that first\nrecognizes the exercise and then evaluates it. We apply our proposal to a set\nof 8 exercises of the upper-and lower-limbs designed for maintaining elderly\npeople health status. To do so, the motion of volunteers were monitored with 4\nIMUs. We obtain accuracies of 88.4 \\% and the 91.4 \\% in the two initial\nscenarios. In the third one, the recognition provides an accuracy of 96.2 \\%,\nwhereas the exercise evaluation varies between 93.6 \\% and 100.0 \\%. This work\nproves the feasibility of IMUs for a complete monitoring of physical therapies\nin which we can get information of which exercise is being performed and its\nquality, as a basis for designing virtual coaches.", "field": "Computer Science", "categories": "cs.HC,eess.SP,I.2.1"}, {"arxiv_id": "2401.12862", "title": "FedRSU: Federated Learning for Scene Flow Estimation on Roadside Units", "abstract": "Roadside unit (RSU) can significantly improve the safety and robustness of\nautonomous vehicles through Vehicle-to-Everything (V2X) communication.\nCurrently, the usage of a single RSU mainly focuses on real-time inference and\nV2X collaboration, while neglecting the potential value of the high-quality\ndata collected by RSU sensors. Integrating the vast amounts of data from\nnumerous RSUs can provide a rich source of data for model training. However,\nthe absence of ground truth annotations and the difficulty of transmitting\nenormous volumes of data are two inevitable barriers to fully exploiting this\nhidden value. In this paper, we introduce FedRSU, an innovative federated\nlearning framework for self-supervised scene flow estimation. In FedRSU, we\npresent a recurrent self-supervision training paradigm, where for each RSU, the\nscene flow prediction of points at every timestamp can be supervised by its\nsubsequent future multi-modality observation. Another key component of FedRSU\nis federated learning, where multiple devices collaboratively train an ML model\nwhile keeping the training data local and private. With the power of the\nrecurrent self-supervised learning paradigm, FL is able to leverage innumerable\nunderutilized data from RSU. To verify the FedRSU framework, we construct a\nlarge-scale multi-modality dataset RSU-SF. The dataset consists of 17 RSU\nclients, covering various scenarios, modalities, and sensor settings. Based on\nRSU-SF, we show that FedRSU can greatly improve model performance in ITS and\nprovide a comprehensive benchmark under diverse FL scenarios. To the best of\nour knowledge, we provide the first real-world LiDAR-camera multi-modal dataset\nand benchmark for the FL community.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.12863", "title": "KAM-CoT: Knowledge Augmented Multimodal Chain-of-Thoughts Reasoning", "abstract": "Large Language Models (LLMs) have demonstrated impressive performance in\nnatural language processing tasks by leveraging chain of thought (CoT) that\nenables step-by-step thinking. Extending LLMs with multimodal capabilities is\nthe recent interest, but incurs computational cost and requires substantial\nhardware resources. To address these challenges, we propose KAM-CoT a framework\nthat integrates CoT reasoning, Knowledge Graphs (KGs), and multiple modalities\nfor a comprehensive understanding of multimodal tasks. KAM-CoT adopts a\ntwo-stage training process with KG grounding to generate effective rationales\nand answers. By incorporating external knowledge from KGs during reasoning, the\nmodel gains a deeper contextual understanding reducing hallucinations and\nenhancing the quality of answers. This knowledge-augmented CoT reasoning\nempowers the model to handle questions requiring external context, providing\nmore informed answers. Experimental findings show KAM-CoT outperforms the\nstate-of-the-art methods. On the ScienceQA dataset, we achieve an average\naccuracy of 93.87%, surpassing GPT-3.5 (75.17%) by 18% and GPT-4 (83.99%) by\n10%. Remarkably, KAM-CoT achieves these results with only 280M trainable\nparameters at a time, demonstrating its cost-efficiency and effectiveness.", "field": "Computer Science", "categories": "cs.CL,cs.AI"}, {"arxiv_id": "2401.12866", "title": "Evaluating Collaborative and Autonomous Agents in Data-Stream-Supported\n  Coordination of Mobile Crowdsourcing", "abstract": "Mobile crowdsourcing refers to systems where the completion of tasks\nnecessarily requires physical movement of crowdworkers in an on-demand\nworkforce. Evidence suggests that in such systems, tasks often get assigned to\ncrowdworkers who struggle to complete those tasks successfully, resulting in\nhigh failure rates and low service quality. A promising solution to ensure\nhigher quality of service is to continuously adapt the assignment and respond\nto failure-causing events by transferring tasks to better-suited workers who\nuse different routes or vehicles. However, implementing task transfers in\nmobile crowdsourcing is difficult because workers are autonomous and may reject\ntransfer requests. Moreover, task outcomes are uncertain and need to be\npredicted. In this paper, we propose different mechanisms to achieve outcome\nprediction and task coordination in mobile crowdsourcing. First, we analyze\ndifferent data stream learning approaches for the prediction of task outcomes.\nSecond, based on the suggested prediction model, we propose and evaluate two\ndifferent approaches for task coordination with different degrees of autonomy:\nan opportunistic approach for crowdshipping with collaborative, but\nnon-autonomous workers, and a market-based model with autonomous workers for\ncrowdsensing.", "field": "Computer Science", "categories": "cs.AI,cs.LG,cs.MA"}, {"arxiv_id": "2401.12869", "title": "TroVE: Inducing Verifiable and Efficient Toolboxes for Solving\n  Programmatic Tasks", "abstract": "Language models (LMs) can solve tasks such as answering questions about\ntables or images by writing programs. However, using primitive functions often\nleads to verbose and error-prone programs, and higher-level functions require\nexpert design. To enable better solutions without human labor, we ask code LMs\nto curate reusable high-level functions, and use them to write solutions. We\npresent TROVE, a training-free method of inducing a verifiable and efficient\ntoolbox of functions, by generating via using, growing, and periodically\ntrimming the toolbox. On 11 datasets from math, table question answering, and\nimage reasoning tasks, TROVE consistently yields simpler solutions with higher\naccuracy than baselines using CODELLAMA and previous methods using GPT, while\nusing 79-98% smaller toolboxes. TROVE further enables 31% faster and 13% more\naccurate human verification than baselines. With the same pipeline, it creates\ndiverse functions for varied tasks and datasets, providing insights into their\nindividual characteristics.", "field": "Computer Science", "categories": "cs.AI"}, {"arxiv_id": "2401.1287", "title": "Unlocking the Potential: Multi-task Deep Learning for Spaceborne\n  Quantitative Monitoring of Fugitive Methane Plumes", "abstract": "With the intensification of global warming, the monitoring of methane\nemission and detection of gas plumes from landfills have increasingly received\nattention. We decompose methane emission monitoring into three sub-tasks:\nmethane concentration inversion, plume segmentation, and emission rate\nestimation. Conventional algorithms have limitations: methane concentration\ninversion usually uses the matched filter, which is sensitive to global\nspectrum distribution and contains a large amount of noises. There is limited\nresearch on plume segmentation, with many studies resorting to manual\nsegmentation that is likely to be subjective. The estimation of methane\nemission rate often utilizes IME algorithm, which relies on obtaining\nmeteorological measurement data. Using the WENT landfill site in Hong Kong and\nPRISMA hyperspectral satellite imagery, we propose a new deep learning-based\nframework for quantitative monitoring of methane emissions from remote sensing\nimages based on physical simulation. We generate simulated methane plumes using\nlarge eddy simulation (LES) and different concentration maps of fugitive\nemission using the radiative transfer equation (RTE), while combining\naugmentation techniques to create a simulated PRISMA dataset. We train a U-Net\nnetwork for methane concentration inversion, a Mask R-CNN network for methane\nplume segmentation, and a ResNet-50 network for methane emission rate\nestimation. All three deep networks achieve higher validation accuracy compared\nto conventional algorithms. We further respectively combine the first two\nsub-tasks and the last two sub-tasks to design the multi-task learning models -\nMTL-01 and MTL-02, both of which achieve higher accuracy than single-task\nmodels. Our research serves as a demonstration of applying multi-task deep\nlearning to quantitative methane monitoring and can be extended to a broad\nrange of methane monitoring tasks.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.12872", "title": "FocusFlow: 3D Gaze-Depth Interaction in Virtual Reality Leveraging\n  Active Visual Depth Manipulation", "abstract": "Gaze interaction presents a promising avenue in Virtual Reality (VR) due to\nits intuitive and efficient user experience. Yet, the depth control inherent in\nour visual system remains underutilized in current methods. In this study, we\nintroduce FocusFlow, a hands-free interaction method that capitalizes on human\nvisual depth perception within the 3D scenes of Virtual Reality. We first\ndevelop a binocular visual depth detection algorithm to understand eye input\ncharacteristics. We then propose a layer-based user interface and introduce the\nconcept of 'Virtual Window' that offers an intuitive and robust gaze-depth VR\ninteraction, despite the constraints of visual depth accuracy and precision\nspatially at further distances. Finally, to help novice users actively\nmanipulate their visual depth, we propose two learning strategies that use\ndifferent visual cues to help users master visual depth control. Our user\nstudies on 24 participants demonstrate the usability of our proposed virtual\nwindow concept as a gaze-depth interaction method. In addition, our findings\nreveal that the user experience can be enhanced through an effective learning\nprocess with adaptive visual cues, helping users to develop muscle memory for\nthis brand-new input mechanism. We conclude the paper by discussing strategies\nto optimize learning and potential research topics of gaze-depth interaction.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.12873", "title": "Improving Machine Translation with Human Feedback: An Exploration of\n  Quality Estimation as a Reward Model", "abstract": "Insufficient modeling of human preferences within the reward model is a major\nobstacle for leveraging human feedback to improve translation quality.\nFortunately, quality estimation (QE), which predicts the quality of a given\ntranslation without reference, has achieved impressive alignment with human\nevaluations in the last two years. In this work, we investigate the potential\nof employing the QE model as the reward model (the QE-based reward model) to\npredict human preferences for feedback training. We first identify the\noveroptimization problem during QE-based feedback training, manifested as an\nincrease in reward while translation quality declines. We examine the problem\nand argue that the vulnerability of the QE model might lead to high rewards for\nincorrect translations, resulting in overoptimization and error propagation. To\naddress the problem, we adopt a simple yet effective method that uses heuristic\nrules to detect the incorrect translations and assigns a penalty term to the\nQE-based rewards for the detected incorrect translations. Experimental results\nshow that the proposed QE-based feedback training achieves consistent and\nsignificant improvements across various settings, further verified through\nhuman preference studies. Our subsequent analysis demonstrates the high data\nefficiency of the proposed QE-based feedback training: the proposed approach\nusing a small amount of monolingual data can outperform systems using larger\nparallel corpora.", "field": "Computer Science", "categories": "cs.CL,cs.AI"}, {"arxiv_id": "2401.12874", "title": "From Understanding to Utilization: A Survey on Explainability for Large\n  Language Models", "abstract": "This survey paper delves into the burgeoning field of explainability for\nLarge Language Models (LLMs), a critical yet challenging aspect of natural\nlanguage processing. With LLMs playing a pivotal role in various applications,\ntheir \"black-box\" nature raises concerns about transparency and ethical use.\nThis paper emphasizes the necessity for enhanced explainability in LLMs,\naddressing both the general public's trust and the technical community's need\nfor a deeper understanding of these models. We concentrate on pre-trained\nTransformer-based LLMs, such as LLaMA, which present unique interpretability\nchallenges due to their scale and complexity. Our review categorizes existing\nexplainability methods and discusses their application in improving model\ntransparency and reliability. We also discuss representative evaluation\nmethods, highlighting their strengths and limitations. The goal of this survey\nis to bridge the gap between theoretical understanding and practical\napplication, offering insights for future research and development in the field\nof LLM explainability.", "field": "Computer Science", "categories": "cs.CL,cs.AI"}, {"arxiv_id": "2401.1288", "title": "Adaptive Uncertainty Quantification for Stochastic Hyperbolic\n  Conservation Laws", "abstract": "We propose a predictor-corrector adaptive method for the study of hyperbolic\npartial differential equations (PDEs) under uncertainty. Constructed around the\nframework of stochastic finite volume (SFV) methods, our approach circumvents\nsampling schemes or simulation ensembles while also preserving fundamental\nproperties, in particular hyperbolicity of the resulting systems and\nconservation of the discrete solutions. Furthermore, we augment the existing\nSFV theory with a priori convergence results for statistical quantities, in\nparticular push-forward densities, which we demonstrate through numerical\nexperiments. By linking refinement indicators to regions of the physical and\nstochastic spaces, we drive anisotropic refinements of the discretizations,\nintroducing new degrees of freedom (DoFs) where deemed profitable. To\nillustrate our proposed method, we consider a series of numerical examples for\nnon-linear hyperbolic PDEs based on Burgers' and Euler's equations.", "field": "Computer Science", "categories": "math.NA,cs.NA,35L60, 35L67, 65C30, 65M50, 65M60"}, {"arxiv_id": "2401.12881", "title": "Computing Diameter+2 in Truly Subquadratic Time for Unit-Disk Graphs", "abstract": "Finding the diameter of a graph in general cannot be done in truly\nsubquadratic assuming the Strong Exponential Time Hypothesis (SETH), even when\nthe underlying graph is unweighted and sparse. When restricting to concrete\nclasses of graphs and assuming SETH, planar graphs and minor-free graphs admit\ntruly subquadratic algorithms, while geometric intersection graphs of unit\nballs, congruent equilateral triangles, and unit segments do not. Unit-disk\ngraphs are one of the major open cases where the complexity of diameter\ncomputation remains unknown. More generally, it is conjectured that a truly\nsubquadratic time algorithm exists for pseudo-disk graphs.\n  In this paper, we show a truly subquadratic algorithm of running time\n$\\tilde{O}(n^{2-1/18})$, for finding the diameter in a unit-disk graph, whose\noutput differs from the optimal solution by at most 2. This is the first\nalgorithm that provides an additive guarantee in distortion, independent of the\nsize or the diameter of the graph. Our algorithm requires two important\ntechnical elements. First, we show that for the intersection graph of\npseudo-disks, the graph VC-dimension, either of $k$-hop balls or the distance\nencoding vectors, is 4. This contracts to the VC dimension of the pseudo-disks\nthemselves as geometric ranges (which is known to be 3). Second, we introduce a\nclique-based $r$-clustering for geometric intersection graphs, which is an\nanalog of the $r$-division construction for planar graphs. We also showcase the\nnew techniques by establishing new results for distance oracles for unit-disk\ngraphs with subquadratic storage and $O(1)$ query time. The results naturally\nextend to unit $L_1$ or $L_\\infty$-disks and fat pseudo-disks of similar size.\nLast, if the pseudo-disks additionally have bounded ply, we have a truly\nsubquadratic algorithm to find the exact diameter.", "field": "Computer Science", "categories": "cs.DS,cs.CG"}, {"arxiv_id": "2401.12882", "title": "Model-Free $\u03b4$-Policy Iteration Based on Damped Newton Method for\n  Nonlinear Continuous-Time H$\\infty$ Tracking Control", "abstract": "This paper presents a {\\delta}-PI algorithm which is based on damped Newton\nmethod for the H{\\infty} tracking control problem of unknown continuous-time\nnonlinear system. A discounted performance function and an augmented system are\nused to get the tracking Hamilton-Jacobi-Isaac (HJI) equation. Tracking HJI\nequation is a nonlinear partial differential equation, traditional\nreinforcement learning methods for solving the tracking HJI equation are mostly\nbased on the Newton method, which usually only satisfies local convergence and\nneeds a good initial guess. Based upon the damped Newton iteration operator\nequation, a generalized tracking Bellman equation is derived firstly. The\n{\\delta}-PI algorithm can seek the optimal solution of the tracking HJI\nequation by iteratively solving the generalized tracking Bellman equation.\nOn-policy learning and off-policy learning {\\delta}-PI reinforcement learning\nmethods are provided, respectively. Off-policy version {\\delta}-PI algorithm is\na model-free algorithm which can be performed without making use of a priori\nknowledge of the system dynamics. NN-based implementation scheme for the\noff-policy {\\delta}-PI algorithms is shown. The suitability of the model-free\n{\\delta}-PI algorithm is illustrated with a nonlinear system simulation.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.12888", "title": "Data-Centric Evolution in Autonomous Driving: A Comprehensive Survey of\n  Big Data System, Data Mining, and Closed-Loop Technologies", "abstract": "The aspiration of the next generation's autonomous driving (AD) technology\nrelies on the dedicated integration and interaction among intelligent\nperception, prediction, planning, and low-level control. There has been a huge\nbottleneck regarding the upper bound of autonomous driving algorithm\nperformance, a consensus from academia and industry believes that the key to\nsurmount the bottleneck lies in data-centric autonomous driving technology.\nRecent advancement in AD simulation, closed-loop model training, and AD big\ndata engine have gained some valuable experience. However, there is a lack of\nsystematic knowledge and deep understanding regarding how to build efficient\ndata-centric AD technology for AD algorithm self-evolution and better AD big\ndata accumulation. To fill in the identified research gaps, this article will\nclosely focus on reviewing the state-of-the-art data-driven autonomous driving\ntechnologies, with an emphasis on the comprehensive taxonomy of autonomous\ndriving datasets characterized by milestone generations, key features, data\nacquisition settings, etc. Furthermore, we provide a systematic review of the\nexisting benchmark closed-loop AD big data pipelines from the industrial\nfrontier, including the procedure of closed-loop frameworks, key technologies,\nand empirical studies. Finally, the future directions, potential applications,\nlimitations and concerns are discussed to arouse efforts from both academia and\nindustry for promoting the further development of autonomous driving.", "field": "Computer Science", "categories": "cs.RO,cs.CV"}, {"arxiv_id": "2401.12895", "title": "ESC: Edge-attributed Skyline Community Search in Large-scale Bipartite\n  Graphs", "abstract": "Due to the ability of modeling relationships between two different types of\nentities, bipartite graphs are naturally employed in many real-world\napplications. Community Search in bipartite graphs is a fundamental problem and\nhas gained much attention. However, existing studies focus on measuring the\nstructural cohesiveness between two sets of vertices, while either completely\nignoring the edge attributes or only considering one-dimensional importance in\nforming communities. In this paper, we introduce a novel community model, named\nedge-attributed skyline community (ESC), which not only preserves the\nstructural cohesiveness but unravels the inherent dominance brought about by\nmulti-dimensional attributes on the edges of bipartite graphs. To search the\nESCs, we develop an elegant peeling algorithm by iteratively deleting edges\nwith the minimum attribute in each dimension. In addition, we also devise a\nmore efficient expanding algorithm to further reduce the search space and speed\nup the filtering of unpromising vertices, where a upper bound is proposed and\nproven. Extensive experiments on real-world large-scale datasets demonstrate\nthe efficiency, effectiveness, and scalability of the proposed ESC search\nalgorithms. A case study was conducted to compare with existing community\nmodels, substantiating that our approach facilitates the precision and\ndiversity of results.", "field": "Computer Science", "categories": "cs.SI,cs.GR"}, {"arxiv_id": "2401.129", "title": "PSAvatar: A Point-based Morphable Shape Model for Real-Time Head Avatar\n  Creation with 3D Gaussian Splatting", "abstract": "Despite much progress, creating real-time high-fidelity head avatar is still\ndifficult and existing methods have to trade-off between speed and quality.\n3DMM based methods often fail to model non-facial structures such as eyeglasses\nand hairstyles, while neural implicit models suffer from deformation\ninflexibility and rendering inefficiency.\n  Although 3D Gaussian has been demonstrated to possess promising capability\nfor geometry representation and radiance field reconstruction, applying 3D\nGaussian in head avatar creation remains a major challenge since it is\ndifficult for 3D Gaussian to model the head shape variations caused by changing\nposes and expressions. In this paper, we introduce PSAvatar, a novel framework\nfor animatable head avatar creation that utilizes discrete geometric primitive\nto create a parametric morphable shape model and employs 3D Gaussian for fine\ndetail representation and high fidelity rendering. The parametric morphable\nshape model is a Point-based Morphable Shape Model (PMSM) which uses points\ninstead of meshes for 3D representation to achieve enhanced representation\nflexibility. The PMSM first converts the FLAME mesh to points by sampling on\nthe surfaces as well as off the meshes to enable the reconstruction of not only\nsurface-like structures but also complex geometries such as eyeglasses and\nhairstyles. By aligning these points with the head shape in an\nanalysis-by-synthesis manner, the PMSM makes it possible to utilize 3D Gaussian\nfor fine detail representation and appearance modeling, thus enabling the\ncreation of high-fidelity avatars. We show that PSAvatar can reconstruct\nhigh-fidelity head avatars of a variety of subjects and the avatars can be\nanimated in real-time ($\\ge$ 25 fps at a resolution of 512 x 512 )", "field": "Computer Science", "categories": "cs.GR,cs.CV"}, {"arxiv_id": "2401.12901", "title": "Secure Spatial Signal Design for ISAC in a Cell-Free MIMO Network", "abstract": "In this paper, we study a cell-free multiple-input multiple-output network\nequipped with integrated sensing and communication (ISAC) access points (APs).\nThe distributed APs are used to jointly serve the communication needs of user\nequipments (UEs) while sensing a target, assumed to be an eavesdropper (Eve).\nTo increase the system's robustness towards said Eve, we develop an ISAC\nwaveform model that includes artificial noise (AN) aimed at degrading the Eve\nchannel quality. The central processing unit receives the observations from\neach AP and calculates the optimal precoding and AN covariance matrices by\nsolving a semi-definite relaxation of a constrained Cramer-Rao bound (CRB)\nminimization problem. Simulation results highlight an underlying trade-off\nbetween sensing and communication performances: in particular, the UEs\nsignal-to-noise and interference ratio and the maximum Eve's signal to noise\nratio are directly proportional to the CRB. Furthermore, the optimal AN\ncovariance matrix is rank-1 and has a peak in the eve's direction, leading to a\nsurprising inverse-proportionality between the UEs-Eve distance and optimal-CRB\nmagnitude.", "field": "Computer Science", "categories": "cs.IT,eess.SP,math.IT"}, {"arxiv_id": "2401.12902", "title": "Facing the Elephant in the Room: Visual Prompt Tuning or Full\n  Finetuning?", "abstract": "As the scale of vision models continues to grow, the emergence of Visual\nPrompt Tuning (VPT) as a parameter-efficient transfer learning technique has\ngained attention due to its superior performance compared to traditional\nfull-finetuning. However, the conditions favoring VPT (the ``when\") and the\nunderlying rationale (the ``why\") remain unclear. In this paper, we conduct a\ncomprehensive analysis across 19 distinct datasets and tasks. To understand the\n``when\" aspect, we identify the scenarios where VPT proves favorable by two\ndimensions: task objectives and data distributions. We find that VPT is\npreferrable when there is 1) a substantial disparity between the original and\nthe downstream task objectives (e.g., transitioning from classification to\ncounting), or 2) a similarity in data distributions between the two tasks\n(e.g., both involve natural images). In exploring the ``why\" dimension, our\nresults indicate VPT's success cannot be attributed solely to overfitting and\noptimization considerations. The unique way VPT preserves original features and\nadds parameters appears to be a pivotal factor. Our study provides insights\ninto VPT's mechanisms, and offers guidance for its optimal utilization.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.12914", "title": "Emergent Communication Protocol Learning for Task Offloading in\n  Industrial Internet of Things", "abstract": "In this paper, we leverage a multi-agent reinforcement learning (MARL)\nframework to jointly learn a computation offloading decision and multichannel\naccess policy with corresponding signaling. Specifically, the base station and\nindustrial Internet of Things mobile devices are reinforcement learning agents\nthat need to cooperate to execute their computation tasks within a deadline\nconstraint. We adopt an emergent communication protocol learning framework to\nsolve this problem. The numerical results illustrate the effectiveness of\nemergent communication in improving the channel access success rate and the\nnumber of successfully computed tasks compared to contention-based,\ncontention-free, and no-communication approaches. Moreover, the proposed task\noffloading policy outperforms remote and local computation baselines.", "field": "Computer Science", "categories": "cs.IT,cs.AI,cs.MA,math.IT"}, {"arxiv_id": "2401.12915", "title": "Red Teaming Visual Language Models", "abstract": "VLMs (Vision-Language Models) extend the capabilities of LLMs (Large Language\nModels) to accept multimodal inputs. Since it has been verified that LLMs can\nbe induced to generate harmful or inaccurate content through specific test\ncases (termed as Red Teaming), how VLMs perform in similar scenarios,\nespecially with their combination of textual and visual inputs, remains a\nquestion. To explore this problem, we present a novel red teaming dataset\nRTVLM, which encompasses 10 subtasks (e.g., image misleading, multi-modal\njail-breaking, face fairness, etc) under 4 primary aspects (faithfulness,\nprivacy, safety, fairness). Our RTVLM is the first red-teaming dataset to\nbenchmark current VLMs in terms of these 4 different aspects. Detailed analysis\nshows that 10 prominent open-sourced VLMs struggle with the red teaming in\ndifferent degrees and have up to 31% performance gap with GPT-4V. Additionally,\nwe simply apply red teaming alignment to LLaVA-v1.5 with Supervised Fine-tuning\n(SFT) using RTVLM, and this bolsters the models' performance with 10% in RTVLM\ntest set, 13% in MM-Hal, and without noticeable decline in MM-Bench,\noverpassing other LLaVA-based models with regular alignment data. This reveals\nthat current open-sourced VLMs still lack red teaming alignment. Our code and\ndatasets will be open-source.", "field": "Computer Science", "categories": "cs.AI,cs.CL,cs.CV"}, {"arxiv_id": "2401.12917", "title": "Active Inference as a Model of Agency", "abstract": "Is there a canonical way to think of agency beyond reward maximisation? In\nthis paper, we show that any type of behaviour complying with physically sound\nassumptions about how macroscopic biological agents interact with the world\ncanonically integrates exploration and exploitation in the sense of minimising\nrisk and ambiguity about states of the world. This description, known as active\ninference, refines the free energy principle, a popular descriptive framework\nfor action and perception originating in neuroscience. Active inference\nprovides a normative Bayesian framework to simulate and model agency that is\nwidely used in behavioural neuroscience, reinforcement learning (RL) and\nrobotics. The usefulness of active inference for RL is three-fold. \\emph{a})\nActive inference provides a principled solution to the exploration-exploitation\ndilemma that usefully simulates biological agency. \\emph{b}) It provides an\nexplainable recipe to simulate behaviour, whence behaviour follows as an\nexplainable mixture of exploration and exploitation under a generative world\nmodel, and all differences in behaviour are explicit in differences in world\nmodel. \\emph{c}) This framework is universal in the sense that it is\ntheoretically possible to rewrite any RL algorithm conforming to the\ndescriptive assumptions of active inference as an active inference algorithm.\nThus, active inference can be used as a tool to uncover and compare the\ncommitments and assumptions of more specific models of agency.", "field": "Computer Science", "categories": "cs.AI"}, {"arxiv_id": "2401.12919", "title": "Inertial Sensors for Human Motion Analysis: A Comprehensive Review", "abstract": "Inertial motion analysis is having a growing interest during the last decades\ndue to its advantages over classical optical systems. The technological\nsolution based on inertial measurement units allows the measurement of\nmovements in daily living environments, such as in everyday life, which is key\nfor a realistic assessment and understanding of movements. This is why research\nin this field is still developing and different approaches are proposed. This\npresents a systematic review of the different proposals for inertial motion\nanalysis found in the literature. The search strategy has been carried out on\neight different platforms, including journal articles and conference\nproceedings, which are written in English and published until August 2022. The\nresults are analyzed in terms of the publishers, the sensors used, the\napplications, the monitored units, the algorithms of use, the participants of\nthe studies, and the validation systems employed. In addition, we delve deeply\ninto the machine learning techniques proposed in recent years and in the\napproaches to reduce the estimation error. In this way, we show an overview of\nthe research carried out in this field, going into more detail in recent years,\nand providing some research directions for future work", "field": "Computer Science", "categories": "eess.SY,cs.SY,A.1"}, {"arxiv_id": "2401.1292", "title": "Truck Parking Usage Prediction with Decomposed Graph Neural Networks", "abstract": "Truck parking on freight corridors faces various challenges, such as\ninsufficient parking spaces and compliance with Hour-of-Service (HOS)\nregulations. These constraints often result in unauthorized parking practices,\ncausing safety concerns. To enhance the safety of freight operations, providing\naccurate parking usage prediction proves to be a cost-effective solution.\nDespite the existing research demonstrating satisfactory accuracy for\npredicting individual truck parking site usage, few approaches have been\nproposed for predicting usage with spatial dependencies of multiple truck\nparking sites. We present the Regional Temporal Graph Neural Network (RegT-GCN)\nas a predictive framework for assessing parking usage across the entire state\nto provide better truck parking information and mitigate unauthorized parking.\nThe framework leverages the topological structures of truck parking site\ndistributions and historical parking data to predict occupancy rates across a\nstate. To achieve this, we introduce a Regional Decomposition approach, which\neffectively captures the geographical characteristics. We also introduce the\nspatial module working efficiently with the temporal module. Evaluation results\ndemonstrate that the proposed model surpasses other baseline models, improving\nthe performance by more than $20\\%$ compared with the original model. The\nproposed model allows truck parking sites' percipience of the topological\nstructures and provides higher performance.", "field": "Computer Science", "categories": "cs.AI"}, {"arxiv_id": "2401.12921", "title": "A hypocoercivity-exploiting stabilised finite element method for\n  Kolmogorov equation", "abstract": "We propose a new stabilised finite element method for the classical\nKolmogorov equation. The latter serves as a basic model problem for large\nclasses of kinetic-type equations and, crucially, is characterised by\ndegenerate diffusion. The stabilisation is constructed so that the resulting\nmethod admits a \\emph{numerical hypocoercivity} property, analogous to the\ncorresponding property of the PDE problem. More specifically, the stabilisation\nis constructed so that spectral gap is possible in the resulting\n``stronger-than-energy'' stabilisation norm, despite the degenerate nature of\nthe diffusion in Kolmogorov, thereby the method has a provably robust behaviour\nas the ``time'' variable goes to infinity. We consider both a spatially\ndiscrete version of the stabilised finite element method and a fully discrete\nversion, with the time discretisation realised by discontinuous Galerkin\ntimestepping. Both stability and a priori error bounds are proven in all cases.\nNumerical experiments verify the theoretical findings.", "field": "Computer Science", "categories": "math.NA,cs.NA,65N30"}, {"arxiv_id": "2401.12925", "title": "Emotion-Aware Contrastive Adaptation Network for Source-Free\n  Cross-Corpus Speech Emotion Recognition", "abstract": "Cross-corpus speech emotion recognition (SER) aims to transfer emotional\nknowledge from a labeled source corpus to an unlabeled corpus. However, prior\nmethods require access to source data during adaptation, which is unattainable\nin real-life scenarios due to data privacy protection concerns. This paper\ntackles a more practical task, namely source-free cross-corpus SER, where a\npre-trained source model is adapted to the target domain without access to\nsource data. To address the problem, we propose a novel method called\nemotion-aware contrastive adaptation network (ECAN). The core idea is to\ncapture local neighborhood information between samples while considering the\nglobal class-level adaptation. Specifically, we propose a nearest neighbor\ncontrastive learning to promote local emotion consistency among features of\nhighly similar samples. Furthermore, relying solely on nearest neighborhoods\nmay lead to ambiguous boundaries between clusters. Thus, we incorporate\nsupervised contrastive learning to encourage greater separation between\nclusters representing different emotions, thereby facilitating improved\nclass-level adaptation. Extensive experiments indicate that our proposed ECAN\nsignificantly outperforms state-of-the-art methods under the source-free\ncross-corpus SER setting on several speech emotion corpora.", "field": "Computer Science", "categories": "cs.SD,eess.AS"}, {"arxiv_id": "2401.12926", "title": "DsDm: Model-Aware Dataset Selection with Datamodels", "abstract": "When selecting data for training large-scale models, standard practice is to\nfilter for examples that match human notions of data quality. Such filtering\nyields qualitatively clean datapoints that intuitively should improve model\nbehavior. However, in practice the opposite can often happen: we find that\nselecting according to similarity with \"high quality\" data sources may not\nincrease (and can even hurt) performance compared to randomly selecting data.\n  To develop better methods for selecting data, we start by framing dataset\nselection as an optimization problem that we can directly solve for: given\ntarget tasks, a learning algorithm, and candidate data, select the subset that\nmaximizes model performance. This framework thus avoids handpicked notions of\ndata quality, and instead models explicitly how the learning process uses train\ndatapoints to predict on the target tasks. Our resulting method greatly\nimproves language model (LM) performance on both pre-specified tasks and\npreviously unseen tasks. Specifically, choosing target tasks representative of\nstandard LM problems and evaluating on diverse held-out benchmarks, our\nselected datasets provide a 2x compute multiplier over baseline methods.", "field": "Computer Science", "categories": "cs.LG,stat.ML"}, {"arxiv_id": "2401.1293", "title": "pyAKI - An Open Source Solution to Automated KDIGO classification", "abstract": "Acute Kidney Injury (AKI) is a frequent complication in critically ill\npatients, affecting up to 50% of patients in the intensive care units. The lack\nof standardized and open-source tools for applying the Kidney Disease Improving\nGlobal Outcomes (KDIGO) criteria to time series data has a negative impact on\nworkload and study quality. This project introduces pyAKI, an open-source\npipeline addressing this gap by providing a comprehensive solution for\nconsistent KDIGO criteria implementation.\n  The pyAKI pipeline was developed and validated using a subset of the Medical\nInformation Mart for Intensive Care (MIMIC)-IV database, a commonly used\ndatabase in critical care research. We defined a standardized data model in\norder to ensure reproducibility. Validation against expert annotations\ndemonstrated pyAKI's robust performance in implementing KDIGO criteria.\nComparative analysis revealed its ability to surpass the quality of human\nlabels.\n  This work introduces pyAKI as an open-source solution for implementing the\nKDIGO criteria for AKI diagnosis using time series data with high accuracy and\nperformance.", "field": "Computer Science", "categories": "cs.LG,cs.SE"}, {"arxiv_id": "2401.12941", "title": "Multicultural Name Recognition For Previously Unseen Names", "abstract": "State of the art Named Entity Recognition (NER) models have achieved an\nimpressive ability to extract common phrases from text that belong to labels\nsuch as location, organization, time, and person. However, typical NER systems\nthat rely on having seen a specific entity in their training data in order to\nlabel an entity perform poorly on rare or unseen entities ta in order to label\nan entity perform poorly on rare or unseen entities (Derczynski et al., 2017).\nThis paper attempts to improve recognition of person names, a diverse category\nthat can grow any time someone is born or changes their name. In order for\ndownstream tasks to not exhibit bias based on cultural background, a model\nshould perform well on names from a variety of backgrounds. In this paper I\nexperiment with the training data and input structure of an English Bi-LSTM\nname recognition model. I look at names from 103 countries to compare how well\nthe model performs on names from different cultures, specifically in the\ncontext of a downstream task where extracted names will be matched to\ninformation on file. I find that a model with combined character and word input\noutperforms word-only models and may improve on accuracy compared to classical\nNER models that are not geared toward identifying unseen entity values.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.12942", "title": "Nonlinear dynamics in neuromorphic photonic networks: physical\n  simulation in Verilog-A", "abstract": "Advances in silicon photonics technology have enabled the field of\nneuromorphic photonics, where analog neuron-like processing elements are\nimplemented in silicon photonics technology. Accurate and scalable simulation\ntools for photonic integrated circuits are critical for designing neuromorphic\nphotonic circuits. This is especially important when designing networks with\nrecurrent connections, where the dynamics of the system may give rise to\nunstable and oscillatory solutions which need to be accurately modelled. These\ntools must simultaneously simulate the analog electronics and the multi-channel\n(wavelength-division-multiplexed) photonics contained in a photonic neuron to\naccurately predict on-chip behaviour. In this paper, we utilize a Verilog-A\nmodel of the photonic neural network to investigate the dynamics of recurrent\nintegrated circuits. We begin by reviewing the theory of continuous-time\nrecurrent neural networks as dynamical systems and the relation of these\ndynamics to important physical features of photonic neurons such as\ncascadability. We then present the neural dynamics of systems of one and two\nneurons in the simulated Verilog-A circuit, which are compared to the expected\ndynamics of the abstract CTRNN model. Due to the presence of parasitic circuit\nelements in the Verilog-A simulation, it is seen that there is a topological\nequivalence, but not an exact isomorphism, between the theoretical model and\nthe simulated model. The implications of these discrepancies for the design of\nneuromorphic photonic circuits are discussed. Our findings pave the way for the\npractical implementation of large-scale silicon photonic recurrent neural\nnetworks.", "field": "Computer Science", "categories": "cs.ET,physics.app-ph,physics.optics"}, {"arxiv_id": "2401.12943", "title": "On Simplified 3D Finite Element Simulations of Three-core Armored Power\n  Cables", "abstract": "This paper analyzes different ways to simulate electromagnetically three-core\narmored cables in 3D by means of the finite element method. Full periodic\nmodels, as lengthy as 36 m, are developed to evaluate the accuracy when\nsimulating only a small portion of the cable, as commonly employed in the\nliterature. The adequate length and boundary conditions for having the same\naccuracy of full periodic models are also studied. To this aim, five medium\nvoltage and high voltage armored cables are analyzed, obtaining the minimum\nlength of the cable that may be simulated for having accurate results in\nshorter time and with less computational burden. This also results in the\nproposal of a new method comprising the advantages of short geometries and the\napplicability of periodic boundary conditions. Its accuracy is compared with\nexperimental measurements and the IEC standard for 145 kV and 245 kV cables.\nThe results show a very good agreement between simulations and measurements\n(errors below 4 %), obtaining a reduction in the computation time of about 90\n%. This new method brings a more effective tool for saving time and\ncomputational resources in cable design and the development of new analytical\nexpressions for improving the IEC standard.", "field": "Computer Science", "categories": "eess.SY,cs.SY"}, {"arxiv_id": "2401.12945", "title": "Lumiere: A Space-Time Diffusion Model for Video Generation", "abstract": "We introduce Lumiere -- a text-to-video diffusion model designed for\nsynthesizing videos that portray realistic, diverse and coherent motion -- a\npivotal challenge in video synthesis. To this end, we introduce a Space-Time\nU-Net architecture that generates the entire temporal duration of the video at\nonce, through a single pass in the model. This is in contrast to existing video\nmodels which synthesize distant keyframes followed by temporal super-resolution\n-- an approach that inherently makes global temporal consistency difficult to\nachieve. By deploying both spatial and (importantly) temporal down- and\nup-sampling and leveraging a pre-trained text-to-image diffusion model, our\nmodel learns to directly generate a full-frame-rate, low-resolution video by\nprocessing it in multiple space-time scales. We demonstrate state-of-the-art\ntext-to-video generation results, and show that our design easily facilitates a\nwide range of content creation tasks and video editing applications, including\nimage-to-video, video inpainting, and stylized generation.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.12946", "title": "Coverage Axis++: Efficient Inner Point Selection for 3D Shape\n  Skeletonization", "abstract": "We introduce Coverage Axis++, a novel and efficient approach to 3D shape\nskeletonization. The current state-of-the-art approaches for this task often\nrely on the watertightness of the input or suffer from substantial\ncomputational costs, thereby limiting their practicality. To address this\nchallenge, Coverage Axis++ proposes a heuristic algorithm to select skeletal\npoints, offering a high-accuracy approximation of the Medial Axis Transform\n(MAT) while significantly mitigating computational intensity for various shape\nrepresentations. We introduce a simple yet effective strategy that considers\nboth shape coverage and uniformity to derive skeletal points. The selection\nprocedure enforces consistency with the shape structure while favoring the\ndominant medial balls, which thus introduces a compact underlying shape\nrepresentation in terms of MAT. As a result, Coverage Axis++ allows for\nskeletonization for various shape representations (e.g., water-tight meshes,\ntriangle soups, point clouds), specification of the number of skeletal points,\nfew hyperparameters, and highly efficient computation with improved\nreconstruction accuracy. Extensive experiments across a wide range of 3D shapes\nvalidate the efficiency and effectiveness of Coverage Axis++. The code will be\npublicly available once the paper is published.", "field": "Computer Science", "categories": "cs.CV,cs.CG,cs.GR"}, {"arxiv_id": "2401.12947", "title": "Transformer-Based Models Are Not Yet Perfect At Learning to Emulate\n  Structural Recursion", "abstract": "This paper investigates the ability of transformer-based models to learn\nstructural recursion from examples. Recursion is a universal concept in both\nnatural and formal languages. Structural recursion is central to the\nprogramming language and formal mathematics tasks where symbolic tools\ncurrently excel beyond neural models, such as inferring semantic relations\nbetween datatypes and emulating program behavior. We introduce a general\nframework that nicely connects the abstract concepts of structural recursion in\nthe programming language domain to concrete sequence modeling problems and\nlearned models' behavior. The framework includes a representation that captures\nthe general \\textit{syntax} of structural recursion, coupled with two different\nframeworks for understanding their \\textit{semantics} -- one that is more\nnatural from a programming languages perspective and one that helps bridge that\nperspective with a mechanistic understanding of the underlying transformer\narchitecture.\n  With our framework as a powerful conceptual tool, we identify different\nissues under various set-ups. The models trained to emulate recursive\ncomputations cannot fully capture the recursion yet instead fit short-cut\nalgorithms and thus cannot solve certain edge cases that are under-represented\nin the training distribution. In addition, it is difficult for state-of-the-art\nlarge language models (LLMs) to mine recursive rules from in-context\ndemonstrations. Meanwhile, these LLMs fail in interesting ways when emulating\nreduction (step-wise computation) of the recursive function.", "field": "Computer Science", "categories": "cs.CL,cs.AI,cs.FL,cs.LO,cs.PL"}, {"arxiv_id": "2401.1295", "title": "Bayesian Semi-structured Subspace Inference", "abstract": "Semi-structured regression models enable the joint modeling of interpretable\nstructured and complex unstructured feature effects. The structured model part\nis inspired by statistical models and can be used to infer the input-output\nrelationship for features of particular importance. The complex unstructured\npart defines an arbitrary deep neural network and thereby provides enough\nflexibility to achieve competitive prediction performance. While these models\ncan also account for aleatoric uncertainty, there is still a lack of work on\naccounting for epistemic uncertainty. In this paper, we address this problem by\npresenting a Bayesian approximation for semi-structured regression models using\nsubspace inference. To this end, we extend subspace inference for joint\nposterior sampling from a full parameter space for structured effects and a\nsubspace for unstructured effects. Apart from this hybrid sampling scheme, our\nmethod allows for tunable complexity of the subspace and can capture multiple\nminima in the loss landscape. Numerical experiments validate our approach's\nefficacy in recovering structured effect parameter posteriors in\nsemi-structured models and approaching the full-space posterior distribution of\nMCMC for increasing subspace dimension. Further, our approach exhibits\ncompetitive predictive performance across simulated and real-world datasets.", "field": "Computer Science", "categories": "cs.LG,stat.ML"}, {"arxiv_id": "2401.12952", "title": "A unifying framework for perturbative exponential factorizations", "abstract": "We propose a framework where Fer and Wilcox expansions for the solution of\ndifferential equations are derived from two particular choices for the initial\ntransformation that seeds the product expansion. In this scheme intermediate\nexpansions can also be envisaged. Recurrence formulas are developed. A new\nlower bound for the convergence of the Wilcox expansion is provided as well as\nsome applications of the results. In particular, two examples are worked out up\nto high order of approximation to illustrate the behavior of the Wilcox\nexpansion.", "field": "Computer Science", "categories": "math.NA,cs.NA"}, {"arxiv_id": "2401.12954", "title": "Meta-Prompting: Enhancing Language Models with Task-Agnostic Scaffolding", "abstract": "We introduce meta-prompting, an effective scaffolding technique designed to\nenhance the functionality of language models (LMs). This approach transforms a\nsingle LM into a multi-faceted conductor, adept at managing and integrating\nmultiple independent LM queries. By employing high-level instructions,\nmeta-prompting guides the LM to break down complex tasks into smaller, more\nmanageable subtasks. These subtasks are then handled by distinct \"expert\"\ninstances of the same LM, each operating under specific, tailored instructions.\nCentral to this process is the LM itself, in its role as the conductor, which\nensures seamless communication and effective integration of the outputs from\nthese expert models. It additionally employs its inherent critical thinking and\nrobust verification processes to refine and authenticate the end result. This\ncollaborative prompting approach empowers a single LM to simultaneously act as\na comprehensive orchestrator and a panel of diverse experts, significantly\nenhancing its performance across a wide array of tasks. The zero-shot,\ntask-agnostic nature of meta-prompting greatly simplifies user interaction by\nobviating the need for detailed, task-specific instructions. Furthermore, our\nresearch demonstrates the seamless integration of external tools, such as a\nPython interpreter, into the meta-prompting framework, thereby broadening its\napplicability and utility. Through rigorous experimentation with GPT-4, we\nestablish the superiority of meta-prompting over conventional scaffolding\nmethods: When averaged across all tasks, including the Game of 24,\nCheckmate-in-One, and Python Programming Puzzles, meta-prompting, augmented\nwith a Python interpreter functionality, surpasses standard prompting by 17.1%,\nexpert (dynamic) prompting by 17.3%, and multipersona prompting by 15.2%.", "field": "Computer Science", "categories": "cs.CL,cs.AI,cs.HC"}, {"arxiv_id": "2401.12955", "title": "Exponential perturbative expansions and coordinate transformations", "abstract": "We propose a unified approach for different exponential perturbation\ntechniques used in the treatment of time-dependent quantum mechanical problems,\nnamely the Magnus expansion, the Floquet--Magnus expansion for periodic\nsystems, the quantum averaging technique and the Lie--Deprit perturbative\nalgorithms. Even the standard perturbation theory fits in this framework. The\napproach is based on carrying out an appropriate change of coordinates (or\npicture) in each case, and can be formulated for any time-dependent linear\nsystem of ordinary differential equations. All the procedures (except the\nstandard perturbation theory) lead to approximate solutions preserving by\nconstruction unitarity when applied to the time-dependent Schr\\\"odinger\nequation.", "field": "Computer Science", "categories": "math.NA,cs.NA"}, {"arxiv_id": "2401.12956", "title": "Examining the Role of Peer Acknowledgements on Social Annotations:\n  Unraveling the Psychological Underpinnings", "abstract": "This study explores the impact of peer acknowledgement on learner engagement\nand implicit psychological attributes in written annotations on an online\nsocial reading platform. Participants included 91 undergraduates from a large\nNorth American University. Using log file data, we analyzed the relationship\nbetween learners' received peer acknowledgement and their subsequent annotation\nbehaviours using cross-lag regression. Higher peer acknowledgements correlate\nwith increased initiation of annotations and responses to peer annotations. By\napplying text mining techniques and calculating Shapley values to analyze 1,969\nsocial annotation entries, we identified prominent psychological themes within\nthree dimensions (i.e., affect, cognition, and motivation) that foster peer\nacknowledgment in digital social annotation. These themes include positive\naffect, openness to learning and discussion, and expression of motivation. The\nfindings assist educators in improving online learning communities and provide\nguidance to technology developers in designing effective prompts, drawing from\nboth implicit psychological cues and explicit learning behaviours.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.12959", "title": "Understanding Emojis :) in Useful Code Review Comments", "abstract": "Emojis and emoticons serve as non-verbal cues and are increasingly prevalent\nacross various platforms, including Modern Code Review. These cues often carry\nemotive or instructive weight for developers. Our study dives into the utility\nof Code Review comments (CR comments) by scrutinizing the sentiments and\nsemantics conveyed by emojis within these comments. To assess the usefulness of\nCR comments, we augment traditional 'textual' features and pre-trained\nembeddings with 'emoji-specific' features and pre-trained embeddings. To\nfortify our inquiry, we expand an existing dataset with emoji annotations,\nguided by existing research on GitHub emoji usage, and re-evaluate the CR\ncomments accordingly. Our models, which incorporate textual and emoji-based\nsentiment features and semantic understandings of emojis, substantially\noutperform baseline metrics. The often-overlooked emoji elements in CR comments\nemerge as key indicators of usefulness, suggesting that these symbols carry\nsignificant weight.", "field": "Computer Science", "categories": "cs.SE"}, {"arxiv_id": "2401.12961", "title": "Chatterbox: Robust Transport for LLM Token Streaming under Unstable\n  Network", "abstract": "To render each generated token in real time, the LLM server generates\nresponse tokens one by one and streams each generated token (or group of a few\ntokens) through the network to the user right after it is generated, which we\nrefer to as LLM token streaming. However, under unstable network conditions,\nthe LLM token streaming experience could suffer greatly from stalls since one\npacket loss could block the rendering of tokens contained in subsequent packets\neven if they arrive on time. With a real-world measurement study, we show that\ncurrent applications including ChatGPT, Claude, and Bard all suffer from\nincreased stall under unstable network.\n  For this emerging token streaming problem in LLM Chatbots, we propose a novel\ntransport layer scheme, called Chatterbox, which puts new generated tokens as\nwell as currently unacknowledged tokens in the next outgoing packet. This\nensures that each packet contains some new tokens and can be independently\nrendered when received, thus avoiding aforementioned stalls caused by missing\npackets. Through simulation under various network conditions, we show\nChatterbox reduces stall ratio (proportion of token rendering wait time) by\n71.0% compared to the token streaming method commonly used by real chatbot\napplications and by 31.6% compared to a custom packet duplication scheme. By\ntailoring Chatterbox to fit the token-by-token generation of LLM, we enable the\nChatbots to respond like an eloquent speaker for users to better enjoy\npervasive AI.", "field": "Computer Science", "categories": "cs.NI,cs.LG"}, {"arxiv_id": "2401.12962", "title": "Minimizing the Age of Two Heterogeneous Sources With Packet Drops Via\n  Cyclic Schedulers", "abstract": "In a communication setting where multiple sources share a single channel to\nprovide status updates to a remote monitor, source transmissions need to be\nscheduled appropriately to maintain timely communication between each of the\nsources and the monitor. We consider age-agnostic scheduling policies which are\nadvantageous due to their simplicity of implementation. Further, we focus on a\nspecial class of age-agnostic policies, called cyclic schedulers, where each\nsource is scheduled based on a fixed cyclic pattern. We use weighted average\nage of information (AoI) to quantify the timeliness of communication. We\ndevelop a Markov chain formulation to compute the exact mean AoI for the case\nof two-source cyclic schedulers. Based on the obtained age expression, we\ndevelop an algorithm that generates near-optimal cyclic schedulers to minimize\nthe weighted average AoI for two heterogeneous sources, in the presence of\nchannel errors.", "field": "Computer Science", "categories": "cs.IT,cs.NI,cs.SY,eess.SY,math.IT"}, {"arxiv_id": "2401.12963", "title": "AutoRT: Embodied Foundation Models for Large Scale Orchestration of\n  Robotic Agents", "abstract": "Foundation models that incorporate language, vision, and more recently\nactions have revolutionized the ability to harness internet scale data to\nreason about useful tasks. However, one of the key challenges of training\nembodied foundation models is the lack of data grounded in the physical world.\nIn this paper, we propose AutoRT, a system that leverages existing foundation\nmodels to scale up the deployment of operational robots in completely unseen\nscenarios with minimal human supervision. AutoRT leverages vision-language\nmodels (VLMs) for scene understanding and grounding, and further uses large\nlanguage models (LLMs) for proposing diverse and novel instructions to be\nperformed by a fleet of robots. Guiding data collection by tapping into the\nknowledge of foundation models enables AutoRT to effectively reason about\nautonomy tradeoffs and safety while significantly scaling up data collection\nfor robot learning. We demonstrate AutoRT proposing instructions to over 20\nrobots across multiple buildings and collecting 77k real robot episodes via\nboth teleoperation and autonomous robot policies. We experimentally show that\nsuch \"in-the-wild\" data collected by AutoRT is significantly more diverse, and\nthat AutoRT's use of LLMs allows for instruction following data collection\nrobots that can align to human preferences.", "field": "Computer Science", "categories": "cs.RO,cs.AI,cs.CL,cs.CV,cs.LG"}, {"arxiv_id": "2401.12965", "title": "Workspace Optimization Techniques to Improve Prediction of Human Motion\n  During Human-Robot Collaboration", "abstract": "Understanding human intentions is critical for safe and effective human-robot\ncollaboration. While state of the art methods for human goal prediction utilize\nlearned models to account for the uncertainty of human motion data, that data\nis inherently stochastic and high variance, hindering those models' utility for\ninteractions requiring coordination, including safety-critical or\nclose-proximity tasks. Our key insight is that robot teammates can deliberately\nconfigure shared workspaces prior to interaction in order to reduce the\nvariance in human motion, realizing classifier-agnostic improvements in goal\nprediction. In this work, we present an algorithmic approach for a robot to\narrange physical objects and project \"virtual obstacles\" using augmented\nreality in shared human-robot workspaces, optimizing for human legibility over\na given set of tasks. We compare our approach against other workspace\narrangement strategies using two human-subjects studies, one in a virtual 2D\nnavigation domain and the other in a live tabletop manipulation domain\ninvolving a robotic manipulator arm. We evaluate the accuracy of human motion\nprediction models learned from each condition, demonstrating that our workspace\noptimization technique with virtual obstacles leads to higher robot prediction\naccuracy using less training data.", "field": "Computer Science", "categories": "cs.RO"}, {"arxiv_id": "2401.1297", "title": "Raidar: geneRative AI Detection viA Rewriting", "abstract": "We find that large language models (LLMs) are more likely to modify\nhuman-written text than AI-generated text when tasked with rewriting. This\ntendency arises because LLMs often perceive AI-generated text as high-quality,\nleading to fewer modifications. We introduce a method to detect AI-generated\ncontent by prompting LLMs to rewrite text and calculating the editing distance\nof the output. We dubbed our geneRative AI Detection viA Rewriting method\nRaidar. Raidar significantly improves the F1 detection scores of existing AI\ncontent detection models -- both academic and commercial -- across various\ndomains, including News, creative writing, student essays, code, Yelp reviews,\nand arXiv papers, with gains of up to 29 points. Operating solely on word\nsymbols without high-dimensional features, our method is compatible with black\nbox LLMs, and is inherently robust on new content. Our results illustrate the\nunique imprint of machine-generated text through the lens of the machines\nthemselves.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.12972", "title": "On the Efficacy of Text-Based Input Modalities for Action Anticipation", "abstract": "Although the task of anticipating future actions is highly uncertain,\ninformation from additional modalities help to narrow down plausible action\nchoices. Each modality provides different environmental context for the model\nto learn from. While previous multi-modal methods leverage information from\nmodalities such as video and audio, we primarily explore how text inputs for\nactions and objects can also enable more accurate action anticipation.\nTherefore, we propose a Multi-modal Anticipative Transformer (MAT), an\nattention-based video transformer architecture that jointly learns from\nmulti-modal features and text captions. We train our model in two-stages, where\nthe model first learns to predict actions in the video clip by aligning with\ncaptions, and during the second stage, we fine-tune the model to predict future\nactions. Compared to existing methods, MAT has the advantage of learning\nadditional environmental context from two kinds of text inputs: action\ndescriptions during the pre-training stage, and the text inputs for detected\nobjects and actions during modality feature fusion. Through extensive\nexperiments, we evaluate the effectiveness of the pre-training stage, and show\nthat our model outperforms previous methods on all datasets. In addition, we\nexamine the impact of object and action information obtained via text and\nperform extensive ablations. We evaluate the performance on on three datasets:\nEpicKitchens-100, EpicKitchens-55 and EGTEA GAZE+; and show that text\ndescriptions do indeed aid in more effective action anticipation.", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.LG,eess.IV"}, {"arxiv_id": "2401.12973", "title": "In-Context Language Learning: Arhitectures and Algorithms", "abstract": "Large-scale neural language models exhibit a remarkable capacity for\nin-context learning (ICL): they can infer novel functions from datasets\nprovided as input. Most of our current understanding of when and how ICL arises\ncomes from LMs trained on extremely simple learning problems like linear\nregression and associative recall. There remains a significant gap between\nthese model problems and the \"real\" ICL exhibited by LMs trained on large text\ncorpora, which involves not just retrieval and function approximation but\nfree-form generation of language and other structured outputs. In this paper,\nwe study ICL through the lens of a new family of model problems we term in\ncontext language learning (ICLL). In ICLL, LMs are presented with a set of\nstrings from a formal language, and must generate additional strings from the\nsame language. We focus on in-context learning of regular languages generated\nby random finite automata. We evaluate a diverse set of neural sequence models\n(including several RNNs, Transformers, and state-space model variants) on\nregular ICLL tasks, aiming to answer three questions: (1) Which model classes\nare empirically capable of ICLL? (2) What algorithmic solutions do successful\nmodels implement to perform ICLL? (3) What architectural changes can improve\nICLL in less performant models? We first show that Transformers significantly\noutperform neural sequence models with recurrent or convolutional\nrepresentations on ICLL tasks. Next, we provide evidence that their ability to\ndo so relies on specialized \"n-gram heads\" (higher-order variants of induction\nheads) that compute input-conditional next-token distributions. Finally, we\nshow that hard-wiring these heads into recurrent and convolutional models\nimproves performance not just on ICLL, but natural language modeling --\nimproving the perplexity of 340M-parameter models by up to 1.14 points (6.7%)\non the SlimPajama dataset.", "field": "Computer Science", "categories": "cs.CL,cs.LG"}, {"arxiv_id": "2401.12975", "title": "HAZARD Challenge: Embodied Decision Making in Dynamically Changing\n  Environments", "abstract": "Recent advances in high-fidelity virtual environments serve as one of the\nmajor driving forces for building intelligent embodied agents to perceive,\nreason and interact with the physical world. Typically, these environments\nremain unchanged unless agents interact with them. However, in real-world\nscenarios, agents might also face dynamically changing environments\ncharacterized by unexpected events and need to rapidly take action accordingly.\nTo remedy this gap, we propose a new simulated embodied benchmark, called\nHAZARD, specifically designed to assess the decision-making abilities of\nembodied agents in dynamic situations. HAZARD consists of three unexpected\ndisaster scenarios, including fire, flood, and wind, and specifically supports\nthe utilization of large language models (LLMs) to assist common sense\nreasoning and decision-making. This benchmark enables us to evaluate autonomous\nagents' decision-making capabilities across various pipelines, including\nreinforcement learning (RL), rule-based, and search-based methods in\ndynamically changing environments. As a first step toward addressing this\nchallenge using large language models, we further develop an LLM-based agent\nand perform an in-depth analysis of its promise and challenge of solving these\nchallenging tasks. HAZARD is available at https://vis-www.cs.umass.edu/hazard/.", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.CL"}, {"arxiv_id": "2401.12977", "title": "IRIS: Inverse Rendering of Indoor Scenes from Low Dynamic Range Images", "abstract": "While numerous 3D reconstruction and novel-view synthesis methods allow for\nphotorealistic rendering of a scene from multi-view images easily captured with\nconsumer cameras, they bake illumination in their representations and fall\nshort of supporting advanced applications like material editing, relighting,\nand virtual object insertion. The reconstruction of physically based material\nproperties and lighting via inverse rendering promises to enable such\napplications.\n  However, most inverse rendering techniques require high dynamic range (HDR)\nimages as input, a setting that is inaccessible to most users. We present a\nmethod that recovers the physically based material properties and\nspatially-varying HDR lighting of a scene from multi-view, low-dynamic-range\n(LDR) images. We model the LDR image formation process in our inverse rendering\npipeline and propose a novel optimization strategy for material, lighting, and\na camera response model. We evaluate our approach with synthetic and real\nscenes compared to the state-of-the-art inverse rendering methods that take\neither LDR or HDR input. Our method outperforms existing methods taking LDR\nimages as input, and allows for highly realistic relighting and object\ninsertion.", "field": "Computer Science", "categories": "cs.CV,cs.GR"}, {"arxiv_id": "2401.12978", "title": "Zero-Shot Learning for the Primitives of 3D Affordance in General\n  Objects", "abstract": "One of the major challenges in AI is teaching machines to precisely respond\nand utilize environmental functionalities, thereby achieving the affordance\nawareness that humans possess. Despite its importance, the field has been\nlagging in terms of learning, especially in 3D, as annotating affordance\naccompanies a laborious process due to the numerous variations of human-object\ninteraction. The low availability of affordance data limits the learning in\nterms of generalization for object categories, and also simplifies the\nrepresentation of affordance, capturing only a fraction of the affordance. To\novercome these challenges, we propose a novel, self-supervised method to\ngenerate the 3D affordance examples given only a 3D object, without any manual\nannotations. The method starts by capturing the 3D object into images and\ncreating 2D affordance images by inserting humans into the image via inpainting\ndiffusion models, where we present the Adaptive Mask algorithm to enable human\ninsertion without altering the original details of the object. The method\nconsequently lifts inserted humans back to 3D to create 3D human-object pairs,\nwhere the depth ambiguity is resolved within a depth optimization framework\nthat utilizes pre-generated human postures from multiple viewpoints. We also\nprovide a novel affordance representation defined on relative orientations and\nproximity between dense human and object points, that can be easily aggregated\nfrom any 3D HOI datasets. The proposed representation serves as a primitive\nthat can be manifested to conventional affordance representations via simple\ntransformations, ranging from physically exerted affordances to nonphysical\nones. We demonstrate the efficacy of our method and representation by\ngenerating the 3D affordance samples and deriving high-quality affordance\nexamples from the representation, including contact, orientation, and spatial\noccupancies.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.12979", "title": "GALA: Generating Animatable Layered Assets from a Single Scan", "abstract": "We present GALA, a framework that takes as input a single-layer clothed 3D\nhuman mesh and decomposes it into complete multi-layered 3D assets. The outputs\ncan then be combined with other assets to create novel clothed human avatars\nwith any pose. Existing reconstruction approaches often treat clothed humans as\na single-layer of geometry and overlook the inherent compositionality of humans\nwith hairstyles, clothing, and accessories, thereby limiting the utility of the\nmeshes for downstream applications. Decomposing a single-layer mesh into\nseparate layers is a challenging task because it requires the synthesis of\nplausible geometry and texture for the severely occluded regions. Moreover,\neven with successful decomposition, meshes are not normalized in terms of poses\nand body shapes, failing coherent composition with novel identities and poses.\nTo address these challenges, we propose to leverage the general knowledge of a\npretrained 2D diffusion model as geometry and appearance prior for humans and\nother assets. We first separate the input mesh using the 3D surface\nsegmentation extracted from multi-view 2D segmentations. Then we synthesize the\nmissing geometry of different layers in both posed and canonical spaces using a\nnovel pose-guided Score Distillation Sampling (SDS) loss. Once we complete\ninpainting high-fidelity 3D geometry, we also apply the same SDS loss to its\ntexture to obtain the complete appearance including the initially occluded\nregions. Through a series of decomposition steps, we obtain multiple layers of\n3D assets in a shared canonical space normalized in terms of poses and human\nshapes, hence supporting effortless composition to novel identities and\nreanimation with novel poses. Our experiments demonstrate the effectiveness of\nour approach for decomposition, canonicalization, and composition tasks\ncompared to existing solutions.", "field": "Computer Science", "categories": "cs.CV"}]}