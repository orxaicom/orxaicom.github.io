{"embeddings": [[4.679254055023193, 11.702930450439453], [4.614563941955566, 10.270334243774414], [3.5317060947418213, 8.270662307739258], [4.05088472366333, 9.14084529876709], [2.4386487007141113, 8.392265319824219], [3.0246033668518066, 8.457475662231445], [4.064467906951904, 9.941097259521484], [3.920912265777588, 9.868703842163086], [6.242861747741699, 6.930124282836914], [3.7861568927764893, 10.230274200439453], [3.769817352294922, 10.213509559631348], [4.092588424682617, 7.996190547943115], [4.746482849121094, 9.49660587310791], [4.210801601409912, 10.198796272277832], [4.728776931762695, 10.447715759277344], [3.408352851867676, 7.026586055755615], [5.730035305023193, 10.073136329650879], [5.143094539642334, 9.270026206970215], [4.959413051605225, 9.630596160888672], [4.475153923034668, 6.394276142120361], [6.883525848388672, 6.496646404266357], [4.053455829620361, 6.269250869750977], [3.788113832473755, 10.111104965209961], [4.81104040145874, 8.266770362854004], [4.2170305252075195, 8.108409881591797], [4.313675880432129, 11.543737411499023], [4.038825035095215, 6.796356678009033], [6.352787494659424, 7.454540252685547], [6.607195854187012, 6.778697967529297], [5.159651756286621, 10.751988410949707], [3.236389398574829, 7.26250696182251], [3.2064762115478516, 7.276930332183838], [3.335347890853882, 8.6573486328125], [4.650745868682861, 9.554795265197754], [4.389949798583984, 6.307881832122803], [5.988785266876221, 7.400905132293701], [3.731186866760254, 6.785978317260742], [3.3108177185058594, 7.1411542892456055], [5.254672527313232, 11.422720909118652], [2.1840522289276123, 8.60473346710205], [3.436248540878296, 7.3145647048950195], [7.417407035827637, 9.108266830444336], [7.772805213928223, 8.928319931030273], [3.537846326828003, 7.4482550621032715], [5.183357238769531, 11.297490119934082], [3.9119935035705566, 7.867073059082031], [8.134332656860352, 8.63484001159668], [3.3526957035064697, 8.057303428649902], [6.064780235290527, 8.102320671081543], [4.0209455490112305, 7.6235032081604], [8.227012634277344, 9.248720169067383], [7.384693145751953, 8.918062210083008], [6.273070335388184, 8.044020652770996], [7.235006809234619, 8.500006675720215], [7.144906520843506, 6.787222862243652], [6.826061725616455, 9.443463325500488], [4.31185245513916, 9.911483764648438], [4.710764408111572, 10.74917221069336], [7.978824615478516, 8.569305419921875], [5.043780326843262, 10.123470306396484], [5.40609884262085, 9.697836875915527], [7.945770263671875, 9.432987213134766], [5.505231857299805, 9.276808738708496], [6.995524883270264, 6.50651741027832], [5.289481163024902, 9.64851188659668], [6.704409599304199, 6.324780464172363], [7.68329381942749, 9.20937442779541], [6.680196285247803, 9.613719940185547], [3.441972017288208, 8.566685676574707], [3.8849308490753174, 11.191307067871094], [4.410421848297119, 7.737296104431152], [7.542471408843994, 7.667485237121582], [3.82315993309021, 10.26893138885498], [6.633998870849609, 9.711088180541992], [5.564789295196533, 7.678738117218018], [5.4206037521362305, 10.53542423248291], [3.1743383407592773, 7.163941860198975], [4.553258895874023, 7.646660804748535], [4.961016654968262, 10.208014488220215], [7.912859916687012, 10.009820938110352], [5.44093132019043, 9.985445976257324], [4.096106052398682, 11.018195152282715], [5.215581893920898, 10.672865867614746], [5.012798309326172, 10.946076393127441], [4.650541305541992, 11.443995475769043], [8.043588638305664, 8.587520599365234], [8.10567569732666, 9.20695972442627], [4.16484260559082, 10.355809211730957], [6.108748435974121, 8.252662658691406], [7.884668827056885, 10.073287010192871], [7.0271806716918945, 8.693122863769531], [6.65321159362793, 6.35509729385376], [7.573166847229004, 7.672894477844238], [5.443554878234863, 9.403867721557617], [4.288324356079102, 11.276055335998535], [2.2958505153656006, 8.551372528076172], [4.973144054412842, 11.315258026123047], [6.797983169555664, 10.201972961425781], [4.499629020690918, 7.894760608673096], [7.168087482452393, 9.436919212341309], [8.013395309448242, 9.752821922302246], [5.3908843994140625, 8.801185607910156], [7.8142290115356445, 9.880996704101562], [6.622334003448486, 10.652585983276367], [3.874356985092163, 10.48149585723877], [4.2395548820495605, 10.864524841308594], [7.867063999176025, 9.951683044433594], [3.2745959758758545, 8.188182830810547], [3.9274682998657227, 7.271164894104004], [4.402504920959473, 7.879055976867676], [5.8333306312561035, 9.486408233642578], [6.863292694091797, 7.023483753204346], [6.539736747741699, 6.988292217254639], [4.852278232574463, 10.550430297851562], [5.145130157470703, 6.637599945068359], [4.785039901733398, 6.629907131195068], [5.174649238586426, 9.904003143310547], [7.140159606933594, 9.398977279663086], [6.095363140106201, 9.91504192352295], [4.733608245849609, 9.79947280883789], [3.1884231567382812, 7.76069974899292], [6.96754264831543, 9.854090690612793], [5.678672790527344, 9.808598518371582], [6.432816505432129, 8.73460865020752], [7.19157600402832, 8.662276268005371], [6.979987621307373, 6.834166526794434], [2.396450996398926, 8.616127014160156], [6.539327144622803, 10.805707931518555], [6.255903720855713, 10.421464920043945], [5.6143670082092285, 6.598222255706787], [6.3153157234191895, 10.655057907104492], [5.191080570220947, 8.5363130569458], [6.52379035949707, 6.997430324554443], [6.449952602386475, 6.189277172088623], [5.09686279296875, 9.96036434173584], [4.505923271179199, 7.865202903747559], [7.724527835845947, 9.733684539794922], [6.495790958404541, 7.259603977203369], [6.351012706756592, 10.421603202819824], [5.489181995391846, 10.064823150634766], [7.066193580627441, 7.25823974609375], [5.395545482635498, 9.404898643493652], [4.219766139984131, 10.407317161560059], [8.205521583557129, 9.184842109680176], [4.3638916015625, 6.252491474151611], [7.401515483856201, 8.83411693572998], [7.015345573425293, 6.29962158203125], [4.529240608215332, 11.043499946594238], [4.221927165985107, 11.34871768951416], [4.01227331161499, 10.353694915771484], [4.854896068572998, 7.581801414489746], [4.134398460388184, 11.335162162780762], [3.2980947494506836, 7.220677852630615], [5.611478328704834, 9.332777976989746], [6.434033393859863, 6.617260456085205], [7.341198921203613, 9.989641189575195], [3.6235458850860596, 7.696007251739502], [6.073534965515137, 7.360251426696777], [4.278526782989502, 6.238968372344971], [3.8626792430877686, 8.27532958984375], [4.670159816741943, 7.822075366973877], [7.316474914550781, 9.095429420471191], [4.685063362121582, 7.794018268585205], [6.532449245452881, 10.158819198608398], [7.453802108764648, 9.022947311401367], [6.670424461364746, 6.438633441925049], [8.038202285766602, 8.33459186553955], [7.773113250732422, 9.20470905303955], [6.31523323059082, 10.379547119140625], [4.295905590057373, 10.887433052062988], [4.351990699768066, 6.34013032913208], [4.6145501136779785, 6.460635185241699], [5.61364221572876, 9.167522430419922], [3.049121141433716, 8.609390258789062], [3.368035078048706, 8.438040733337402], [5.672252655029297, 8.6012544631958], [4.854562759399414, 9.090458869934082], [5.899351119995117, 7.490300178527832], [6.685344696044922, 10.014249801635742], [6.7112345695495605, 10.663994789123535], [7.711447238922119, 9.958304405212402], [7.517233371734619, 9.503475189208984], [6.803759574890137, 6.441592216491699], [5.4614973068237305, 10.098465919494629], [4.160524845123291, 8.023477554321289], [7.467639923095703, 9.073663711547852], [8.217001914978027, 9.636307716369629], [8.041460990905762, 8.449426651000977], [5.560254096984863, 10.22337532043457], [4.3863654136657715, 10.034445762634277], [6.503795623779297, 8.942449569702148], [3.9615023136138916, 6.807464122772217], [3.0083389282226562, 7.447780609130859], [5.268353462219238, 8.087813377380371], [4.891811847686768, 9.48951244354248], [8.105627059936523, 9.867709159851074], [6.912224292755127, 9.844473838806152], [4.691941261291504, 9.871200561523438], [5.585115909576416, 9.234672546386719], [3.7585561275482178, 7.10651969909668], [4.745469570159912, 7.860057353973389], [4.179366111755371, 6.228001117706299], [3.6642754077911377, 9.046258926391602], [8.08891773223877, 9.056843757629395], [7.771241188049316, 8.098761558532715], [7.666148662567139, 9.663622856140137], [5.0856614112854, 11.294156074523926], [4.72058629989624, 11.602967262268066], [3.756465435028076, 9.735197067260742], [4.752378940582275, 11.438249588012695], [7.5370988845825195, 9.229103088378906], [6.184759140014648, 8.80004596710205], [4.588991641998291, 10.750001907348633], [3.6581838130950928, 8.434860229492188], [4.078839302062988, 6.683743000030518], [5.4991631507873535, 6.430128574371338], [4.330450057983398, 6.190831184387207], [5.505468845367432, 9.473572731018066], [6.518703937530518, 6.718966960906982], [7.877171993255615, 8.371190071105957], [5.849115371704102, 9.14710521697998], [2.1548025608062744, 8.440003395080566], [5.3571929931640625, 7.8323869705200195], [7.562833786010742, 7.739731311798096], [7.327419281005859, 9.724369049072266], [3.6354098320007324, 8.868905067443848], [2.128537654876709, 8.513866424560547], [8.015762329101562, 9.289161682128906], [4.554932594299316, 10.651627540588379], [5.192114353179932, 11.384389877319336], [4.252108573913574, 6.1516265869140625], [7.77363395690918, 9.555047035217285], [8.202925682067871, 9.194969177246094], [5.707423210144043, 9.527997970581055], [3.2960519790649414, 9.261872291564941], [5.957127571105957, 7.350619316101074], [2.239143133163452, 8.581884384155273], [4.2774882316589355, 10.100606918334961], [5.838441848754883, 7.239058017730713], [3.650162696838379, 9.924098014831543], [3.417341709136963, 8.270092964172363], [2.3144407272338867, 8.560820579528809], [5.417938709259033, 6.995126247406006], [5.9811296463012695, 8.949914932250977], [4.363393306732178, 11.46428108215332], [4.50262975692749, 6.201977252960205], [2.758262872695923, 8.330794334411621], [3.4805009365081787, 8.322660446166992], [3.8486695289611816, 11.00291919708252], [6.893595218658447, 7.455467224121094], [3.139247179031372, 9.817699432373047], [6.377939224243164, 9.683011054992676], [4.795942783355713, 11.356466293334961], [6.969723701477051, 7.415850639343262], [8.193440437316895, 9.057074546813965], [3.3545820713043213, 9.454715728759766], [5.327724933624268, 6.3862762451171875], [8.163518905639648, 8.70438003540039], [8.175150871276855, 8.574759483337402], [5.057793617248535, 9.215217590332031], [5.055874824523926, 10.557369232177734], [6.347901344299316, 9.511190414428711], [7.40419340133667, 8.07357120513916], [6.61161994934082, 7.120116233825684], [4.140774726867676, 9.964963912963867], [5.251811981201172, 8.879606246948242], [6.1923112869262695, 9.326912879943848], [5.9297966957092285, 9.108978271484375], [4.769490718841553, 11.179386138916016], [2.6932873725891113, 8.523725509643555], [6.107899188995361, 7.666993618011475], [6.35093879699707, 10.874741554260254], [5.231388092041016, 6.766131401062012], [6.69741153717041, 6.327803611755371], [7.456664562225342, 9.960755348205566], [8.006376266479492, 10.010590553283691], [4.511166095733643, 6.068387031555176], [5.747783184051514, 10.958577156066895], [5.887097358703613, 7.396243572235107], [5.061955451965332, 8.452547073364258], [5.194568157196045, 6.463170528411865], [5.757999420166016, 10.978321075439453], [6.7753825187683105, 7.729938983917236], [4.8982133865356445, 9.461015701293945], [4.942157745361328, 9.581016540527344], [3.5138182640075684, 8.924247741699219], [5.977722644805908, 7.457210540771484], [3.934448480606079, 7.598798751831055], [3.9834845066070557, 6.551494598388672], [4.0247697830200195, 8.170145034790039], [8.293463706970215, 9.68024730682373], [4.1299614906311035, 10.013140678405762], [7.938231945037842, 8.993510246276855], [5.25631856918335, 8.130416870117188], [3.8595871925354004, 11.057966232299805], [4.299925804138184, 6.3033342361450195], [5.005109786987305, 8.247052192687988], [4.0799407958984375, 8.400701522827148], [2.513502359390259, 8.330245018005371], [5.927157878875732, 9.074872970581055], [5.308731555938721, 8.970658302307129], [5.377712249755859, 7.2060699462890625], [6.699103355407715, 7.824606895446777], [3.9173388481140137, 10.315969467163086], [7.088439464569092, 7.920454025268555], [7.312709331512451, 7.505978107452393], [5.105835914611816, 7.992960453033447], [6.893287181854248, 6.877740859985352], [5.782440662384033, 6.385606288909912], [3.4405760765075684, 7.06572961807251], [4.013212203979492, 7.938286781311035], [7.179636001586914, 9.312477111816406], [7.009807586669922, 6.915773868560791], [5.978891849517822, 6.771697998046875], [5.655884742736816, 11.330769538879395], [3.211465835571289, 9.633108139038086], [3.685666561126709, 7.618295192718506], [3.2328109741210938, 7.854193210601807], [2.341111183166504, 8.75944995880127], [7.244309902191162, 9.201559066772461], [4.2594475746154785, 10.338068962097168], [4.628448486328125, 9.047207832336426], [7.559696197509766, 9.90671157836914], [3.1165575981140137, 9.482226371765137], [3.898359775543213, 7.859763145446777], [8.082244873046875, 9.960771560668945], [7.8527374267578125, 8.144798278808594], [4.505161285400391, 10.96222972869873], [8.222908020019531, 8.88144302368164], [2.1549601554870605, 8.438894271850586], [6.076664924621582, 10.040106773376465], [3.958526134490967, 8.454710006713867], [6.368617057800293, 7.204749584197998], [5.440343856811523, 6.844711780548096], [6.800084590911865, 6.766626358032227], [7.158629417419434, 7.874343395233154], [2.2375710010528564, 8.647391319274902], [3.560075044631958, 7.605432033538818], [5.997183322906494, 8.475625991821289], [3.3585054874420166, 8.918903350830078], [7.11748743057251, 6.587123870849609], [4.581488609313965, 11.704438209533691], [4.350974082946777, 11.485750198364258], [3.8099124431610107, 7.32697868347168], [3.6446139812469482, 9.171504974365234], [7.799764156341553, 8.250445365905762], [8.243232727050781, 9.593850135803223], [7.382011413574219, 9.094527244567871], [5.679086685180664, 7.429015159606934], [4.2794880867004395, 10.870138168334961], [5.41433572769165, 11.342132568359375], [5.126984596252441, 8.131722450256348], [4.590254306793213, 11.601594924926758], [4.658176422119141, 9.99781322479248], [3.9615495204925537, 11.163583755493164], [6.683049201965332, 6.4777750968933105]], "keys": ["2401.08579", "2401.08581", "2401.08583", "2401.08584", "2401.08586", "2401.08587", "2401.08588", "2401.08593", "2401.08595", "2401.08598", "2401.08599", "2401.08602", "2401.08603", "2401.08604", "2401.08609", "2401.08613", "2401.08615", "2401.08619", "2401.08623", "2401.08624", "2401.08625", "2401.08628", "2401.08629", "2401.08631", "2401.08632", "2401.08633", "2401.08634", "2401.08636", "2401.08637", "2401.08639", "2401.0864", "2401.08643", "2401.08647", "2401.08649", "2401.08651", "2401.08652", "2401.08653", "2401.08654", "2401.08655", "2401.08656", "2401.08658", "2401.08659", "2401.0866", "2401.08661", "2401.08662", "2401.08663", "2401.08664", "2401.08666", "2401.08668", "2401.08669", "2401.08671", "2401.08672", "2401.08673", "2401.08682", "2401.08683", "2401.08685", "2401.08686", "2401.08687", "2401.08688", "2401.08689", "2401.0869", "2401.08694", "2401.08695", "2401.08696", "2401.08703", "2401.0871", "2401.08711", "2401.08714", "2401.08715", "2401.08717", "2401.08718", "2401.08719", "2401.0872", "2401.08721", "2401.08723", "2401.08725", "2401.08727", "2401.08728", "2401.08732", "2401.08733", "2401.08734", "2401.08739", "2401.0874", "2401.08741", "2401.08742", "2401.08743", "2401.08772", "2401.08787", "2401.08788", "2401.08789", "2401.08804", "2401.08806", "2401.08807", "2401.08808", "2401.08809", "2401.08814", "2401.08815", "2401.08818", "2401.08819", "2401.08822", "2401.08825", "2401.0883", "2401.08832", "2401.08835", "2401.08837", "2401.0884", "2401.08841", "2401.08844", "2401.08846", "2401.0885", "2401.08851", "2401.08858", "2401.08859", "2401.0886", "2401.08861", "2401.08863", "2401.08865", "2401.08866", "2401.08867", "2401.08868", "2401.0887", "2401.08875", "2401.08876", "2401.08878", "2401.08879", "2401.08881", "2401.08886", "2401.08887", "2401.08889", "2401.0889", "2401.08891", "2401.08893", "2401.08895", "2401.08896", "2401.08897", "2401.08898", "2401.08899", "2401.08901", "2401.08902", "2401.08903", "2401.08908", "2401.08909", "2401.08913", "2401.08919", "2401.08921", "2401.08922", "2401.08925", "2401.08926", "2401.0893", "2401.08932", "2401.08936", "2401.08937", "2401.08939", "2401.0894", "2401.08943", "2401.08947", "2401.08948", "2401.08953", "2401.08956", "2401.08957", "2401.08959", "2401.0896", "2401.08961", "2401.08962", "2401.08964", "2401.08965", "2401.08967", "2401.08968", "2401.08972", "2401.08973", "2401.08974", "2401.08976", "2401.08977", "2401.08981", "2401.08982", "2401.08984", "2401.08986", "2401.08988", "2401.08991", "2401.08992", "2401.08993", "2401.08994", "2401.08996", "2401.08998", "2401.08999", "2401.09001", "2401.09002", "2401.09003", "2401.09006", "2401.09008", "2401.09011", "2401.09013", "2401.09014", "2401.09016", "2401.09018", "2401.09023", "2401.09025", "2401.09029", "2401.09031", "2401.09032", "2401.09034", "2401.09036", "2401.09038", "2401.09041", "2401.09042", "2401.09044", "2401.09047", "2401.09048", "2401.09049", "2401.0905", "2401.09051", "2401.09052", "2401.09057", "2401.09059", "2401.0906", "2401.09062", "2401.09064", "2401.09067", "2401.09068", "2401.0907", "2401.09071", "2401.09072", "2401.09073", "2401.09074", "2401.09075", "2401.09077", "2401.0908", "2401.09082", "2401.09083", "2401.09084", "2401.09089", "2401.0909", "2401.09092", "2401.09093", "2401.09101", "2401.09102", "2401.09105", "2401.09109", "2401.0911", "2401.09112", "2401.09115", "2401.09118", "2401.09124", "2401.09125", "2401.09126", "2401.09127", "2401.09129", "2401.09132", "2401.09133", "2401.09135", "2401.0914", "2401.09145", "2401.09146", "2401.09149", "2401.0915", "2401.0916", "2401.09162", "2401.09168", "2401.09175", "2401.09176", "2401.0918", "2401.09181", "2401.09185", "2401.09186", "2401.0919", "2401.09191", "2401.09192", "2401.09193", "2401.09195", "2401.09198", "2401.09199", "2401.092", "2401.09204", "2401.09207", "2401.09209", "2401.0921", "2401.09217", "2401.0922", "2401.09221", "2401.09229", "2401.09231", "2401.09232", "2401.09234", "2401.09235", "2401.09237", "2401.09239", "2401.0924", "2401.09241", "2401.09242", "2401.09243", "2401.09244", "2401.09245", "2401.09248", "2401.09251", "2401.09252", "2401.09256", "2401.09257", "2401.09258", "2401.09259", "2401.09261", "2401.09266", "2401.09267", "2401.0927", "2401.09271", "2401.09273", "2401.09275", "2401.09278", "2401.09281", "2401.09284", "2401.09285", "2401.09286", "2401.09289", "2401.0929", "2401.09292", "2401.09294", "2401.09296", "2401.09321", "2401.09322", "2401.09323", "2401.09324", "2401.09325", "2401.09328", "2401.09329", "2401.09331", "2401.09332", "2401.09333", "2401.09334", "2401.0934", "2401.09343", "2401.09348", "2401.0935", "2401.09352", "2401.09356", "2401.09358", "2401.09359", "2401.09366", "2401.09372", "2401.09375", "2401.09376", "2401.09382", "2401.09383", "2401.09384", "2401.09386", "2401.09387", "2401.09388", "2401.09395", "2401.09407", "2401.0941", "2401.09412", "2401.09413", "2401.09414", "2401.09415", "2401.09416", "2401.09417", "2401.09419", "2401.0942"], "additional_info": [{"arxiv_id": "2401.08579", "title": "Curve-based Neural Style Transfer", "abstract": "This research presents a new parametric style transfer framework specifically\ndesigned for curve-based design sketches. In this research, traditional\nchallenges faced by neural style transfer methods in handling binary sketch\ntransformations are effectively addressed through the utilization of parametric\nshape-editing rules, efficient curve-to-pixel conversion techniques, and the\nfine-tuning of VGG19 on ImageNet-Sketch, enhancing its role as a feature\npyramid network for precise style extraction. By harmonizing intuitive\ncurve-based imagery with rule-based editing, this study holds the potential to\nsignificantly enhance design articulation and elevate the practice of style\ntransfer within the realm of product design.", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.GR"}, {"arxiv_id": "2401.08581", "title": "Temporal Embeddings: Scalable Self-Supervised Temporal Representation\n  Learning from Spatiotemporal Data for Multimodal Computer Vision", "abstract": "There exists a correlation between geospatial activity temporal patterns and\ntype of land use. A novel self-supervised approach is proposed to stratify\nlandscape based on mobility activity time series. First, the time series signal\nis transformed to the frequency domain and then compressed into task-agnostic\ntemporal embeddings by a contractive autoencoder, which preserves cyclic\ntemporal patterns observed in time series. The pixel-wise embeddings are\nconverted to image-like channels that can be used for task-based, multimodal\nmodeling of downstream geospatial tasks using deep semantic segmentation.\nExperiments show that temporal embeddings are semantically meaningful\nrepresentations of time series data and are effective across different tasks\nsuch as classifying residential area and commercial areas. Temporal embeddings\ntransform sequential, spatiotemporal motion trajectory data into semantically\nmeaningful image-like tensor representations that can be combined (multimodal\nfusion) with other data modalities that are or can be transformed into\nimage-like tensor representations (for e.g., RBG imagery, graph embeddings of\nroad networks, passively collected imagery like SAR, etc.) to facilitate\nmultimodal learning in geospatial computer vision. Multimodal computer vision\nis critical for training machine learning models for geospatial feature\ndetection to keep a geospatial mapping service up-to-date in real-time and can\nsignificantly improve user experience and above all, user safety.", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.LG"}, {"arxiv_id": "2401.08583", "title": "Development of Control Framework for Spine Surgery Robot Using EtherCAT", "abstract": "As the more sensors and actuators are used in the robotic systems to provide\nmore features, complexity of the system is increasing. When it comes to medical\nrobotics, it becomes harder to ensure safety and determinism in the system. To\ndeal with increasing complexity and ensure precise periodicity and execution\ntiming for a medical robot, in this paper we report development of EtherCAT\nmaster as a part of software framework for spine surgery robot. We implemented\nmulti-axis controller using open-source EtherCAT master running in real-time\npreemptive Linux. We evaluated the real-time performance of the system in terms\nof periodicity, jitter and execution time in our first prototype of spine\nsurgery robot.", "field": "Computer Science", "categories": "cs.RO"}, {"arxiv_id": "2401.08584", "title": "Nahid: AI-based Algorithm for operating fully-automatic surgery", "abstract": "In this paper, for the first time, a method is presented that can provide a\nfully automated surgery based on software and computer vision techniques. Then,\nthe advantages and challenges of computerization of medical surgery are\nexamined. Finally, the surgery related to isolated ovarian endometriosis\ndisease has been examined, and based on the presented method, a more detailed\nalgorithm is presented that is capable of automatically diagnosing and treating\nthis disease during surgery as proof of our proposed method where a U-net is\ntrained to detect the endometriosis during surgery.", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.LG,cs.NE,cs.RO,eess.IV"}, {"arxiv_id": "2401.08586", "title": "A GPU accelerated mixed-precision Smoothed Particle Hydrodynamics\n  framework with cell-based relative coordinates", "abstract": "Smoothed Particle Hydrodynamics (SPH) is essential for modeling complex\nlarge-deformation problems across various applications, requiring significant\ncomputational power. A major portion of SPH computation time is dedicated to\nthe Nearest Neighboring Particle Search (NNPS) process. While advanced NNPS\nalgorithms have been developed to enhance SPH efficiency, the potential\nefficiency gains from modern computation hardware remain underexplored. This\nstudy investigates the impact of GPU parallel architecture, low-precision\ncomputing on GPUs, and GPU memory management on NNPS efficiency. Our approach\nemploys a GPU-accelerated mixed-precision SPH framework, utilizing\nlow-precision float-point 16 (FP16) for NNPS while maintaining high precision\nfor other components. To ensure FP16 accuracy in NNPS, we introduce a Relative\nCoordinated-based Link List (RCLL) algorithm, storing FP16 relative coordinates\nof particles within background cells. Our testing results show three\nsignificant speedup rounds for CPU-based NNPS algorithms. The first comes from\nparallel GPU computations, with up to a 1000x efficiency gain. The second is\nachieved through low-precision GPU computing, where the proposed FP16-based\nRCLL algorithm offers a 1.5x efficiency improvement over the FP64-based\napproach on GPUs. By optimizing GPU memory bandwidth utilization, the\nefficiency of the FP16 RCLL algorithm can be further boosted by 2.7x, as\ndemonstrated in an example with 1 million particles. Our code is released at\nhttps://github.com/pnnl/lpNNPS4SPH.", "field": "Computer Science", "categories": "cs.DC"}, {"arxiv_id": "2401.08587", "title": "Automatic extraction and 3D reconstruction of split wire from point\n  cloud data based on improved DPC algorithm", "abstract": "In order to solve the problem of point cloud data splitting improved by DPC\nalgorithm, a research on automatic separation and 3D reconstruction of point\ncloud data split lines is proposed. First, the relative coordinates of each\npoint in the cloud point are calculated. Second, it is planned to develop a\nrelative ensemble-based DPC swarm algorithm for analyzing the number of\nseparation lines to determine all parts in the cloud content. Finally, fit each\nseparator using the least squares method. iron. The cloud point of the\nresulting split subconductors has a clear demarcation line, and the distance\nbetween adjacent split subconductors is 0.45 m, divided by the four vertices of\nthe square.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.08588", "title": "Improved Pothole Detection Using YOLOv7 and ESRGAN", "abstract": "Potholes are common road hazards that is causing damage to vehicles and\nposing a safety risk to drivers. The introduction of Convolutional Neural\nNetworks (CNNs) is widely used in the industry for object detection based on\nDeep Learning methods and has achieved significant progress in hardware\nimprovement and software implementations. In this paper, a unique better\nalgorithm is proposed to warrant the use of low-resolution cameras or\nlow-resolution images and video feed for automatic pothole detection using\nSuper Resolution (SR) through Super Resolution Generative Adversarial Networks\n(SRGANs). Then we have proceeded to establish a baseline pothole detection\nperformance on low quality and high quality dashcam images using a You Only\nLook Once (YOLO) network, namely the YOLOv7 network. We then have illustrated\nand examined the speed and accuracy gained above the benchmark after having\nupscaling implementation on the low quality images.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.08593", "title": "Automatic measurement of coverage area of water-based\n  pesticides-surfactant formulation on plant leaves using deep learning tools", "abstract": "A method to efficiently and quantitatively study the delivery of a\npesticide-surfactant formulation in water solution over plants leaves is\npresented. Instead of measuring the contact angle, the surface of the leaves\nwet area is used as key parameter. To this goal, a deep learning model has been\ntrained and tested, to automatically measure the surface of area wet with water\nsolution over cucumber leaves, processing the frames of video footage. We have\nindividuated an existing deep learning model, reported in literature for other\napplications, and we have applied it to this different task. We present the\nmeasurement technique, some details of the deep learning model, its training\nprocedure and its image segmentation performance. Finally, we report the\nresults of the wet areas surface measurement as a function of the concentration\nof a surfactant in the pesticide solution.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.08595", "title": "Node Compass: Multilevel Tracing and Debugging of Request Executions in\n  JavaScript-Based Web-Servers", "abstract": "Adequate consideration is crucial to ensure that services in a distributed\napplication context are running satisfactorily with the resources available.\nDue to the asynchronous nature of tasks and the need to work with multiple\nlayers that deliver coordinated results in a single-threaded context, analysing\nperformance is a challenging task in event-loop-based systems.\n  The existing performance analysis methods for environments such as Node.js\nrely on higher-level instrumentation but lack precision, as they cannot capture\nthe relevant underlying application flow. As a solution, we propose a\nstreamlined method for recovering the asynchronous execution path of requests\ncalled the Nested Bounded Context Algorithm. The proposed technique tracks the\napplication execution flow through multiple layers and showcases it on an\ninteractive interface for further assessment.\n  Furthermore, we introduce the vertical span concept. This representation of a\nspan as a multidimensional object (horizontal and vertical) with a start and\nend of execution, along with its sub-layers and triggered operations, enables\nthe granular identification and diagnosis of performance issues. We proposed a\nnew technique called the Bounded Context Tracking Algorithm for event matching\nand request reassembling in a multi-layer trace . The two techniques allow\naligning the executions of the request in a tree-based data structure for\ndeveloped visualisations. These visualisations permit performance debugging of\ncomplex performance issues in Node.js.", "field": "Computer Science", "categories": "cs.DC,cs.PF"}, {"arxiv_id": "2401.08598", "title": "NutritionVerse-Real: An Open Access Manually Collected 2D Food Scene\n  Dataset for Dietary Intake Estimation", "abstract": "Dietary intake estimation plays a crucial role in understanding the\nnutritional habits of individuals and populations, aiding in the prevention and\nmanagement of diet-related health issues. Accurate estimation requires\ncomprehensive datasets of food scenes, including images, segmentation masks,\nand accompanying dietary intake metadata. In this paper, we introduce\nNutritionVerse-Real, an open access manually collected 2D food scene dataset\nfor dietary intake estimation with 889 images of 251 distinct dishes and 45\nunique food types. The NutritionVerse-Real dataset was created by manually\ncollecting images of food scenes in real life, measuring the weight of every\ningredient and computing the associated dietary content of each dish using the\ningredient weights and nutritional information from the food packaging or the\nCanada Nutrient File. Segmentation masks were then generated through human\nlabelling of the images. We provide further analysis on the data diversity to\nhighlight potential biases when using this data to develop models for dietary\nintake estimation. NutritionVerse-Real is publicly available at\nhttps://www.kaggle.com/datasets/nutritionverse/nutritionverse-real as part of\nan open initiative to accelerate machine learning for dietary sensing.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.08599", "title": "An annotated grain kernel image database for visual quality inspection", "abstract": "We present a machine vision-based database named GrainSet for the purpose of\nvisual quality inspection of grain kernels. The database contains more than\n350K single-kernel images with experts' annotations. The grain kernels used in\nthe study consist of four types of cereal grains including wheat, maize,\nsorghum and rice, and were collected from over 20 regions in 5 countries. The\nsurface information of each kernel is captured by our custom-built device\nequipped with high-resolution optic sensor units, and corresponding sampling\ninformation and annotations include collection location and time, morphology,\nphysical size, weight, and Damage & Unsound grain categories provided by senior\ninspectors. In addition, we employed a commonly used deep learning model to\nprovide classification results as a benchmark. We believe that our GrainSet\nwill facilitate future research in fields such as assisting inspectors in grain\nquality inspections, providing guidance for grain storage and trade, and\ncontributing to applications of smart agriculture.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.08602", "title": "Learning with Chemical versus Electrical Synapses -- Does it Make a\n  Difference?", "abstract": "Bio-inspired neural networks have the potential to advance our understanding\nof neural computation and improve the state-of-the-art of AI systems.\nBio-electrical synapses directly transmit neural signals, by enabling fast\ncurrent flow between neurons. In contrast, bio-chemical synapses transmit\nneural signals indirectly, through neurotransmitters. Prior work showed that\ninterpretable dynamics for complex robotic control, can be achieved by using\nchemical synapses, within a sparse, bio-inspired architecture, called Neural\nCircuit Policies (NCPs). However, a comparison of these two synaptic models,\nwithin the same architecture, remains an unexplored area. In this work we aim\nto determine the impact of using chemical synapses compared to electrical\nsynapses, in both sparse and all-to-all connected networks. We conduct\nexperiments with autonomous lane-keeping through a photorealistic autonomous\ndriving simulator to evaluate their performance under diverse conditions and in\nthe presence of noise. The experiments highlight the substantial influence of\nthe architectural and synaptic-model choices, respectively. Our results show\nthat employing chemical synapses yields noticeable improvements compared to\nelectrical synapses, and that NCPs lead to better results in both synaptic\nmodels.", "field": "Computer Science", "categories": "cs.NE,cs.LG"}, {"arxiv_id": "2401.08603", "title": "Representation Learning in a Decomposed Encoder Design for Bio-inspired\n  Hebbian Learning", "abstract": "Modern data-driven machine learning system designs exploit inductive biases\non architectural structure, invariance and equivariance requirements, task\nspecific loss functions, and computational optimization tools. Previous works\nhave illustrated that inductive bias in the early layers of the encoder in the\nform of human specified quasi-invariant filters can serve as a powerful\ninductive bias to attain better robustness and transparency in learned\nclassifiers. This paper explores this further in the context of representation\nlearning with local plasticity rules i.e. bio-inspired Hebbian learning . We\npropose a modular framework trained with a bio-inspired variant of contrastive\npredictive coding (Hinge CLAPP Loss). Our framework is composed of parallel\nencoders each leveraging a different invariant visual descriptor as an\ninductive bias. We evaluate the representation learning capacity of our system\nin a classification scenario on image data of various difficulties (GTSRB,\nSTL10, CODEBRIM) as well as video data (UCF101). Our findings indicate that\nthis form of inductive bias can be beneficial in closing the gap between models\nwith local plasticity rules and backpropagation models as well as learning more\nrobust representations in general.", "field": "Computer Science", "categories": "cs.NE,cs.LG"}, {"arxiv_id": "2401.08604", "title": "SAM4UDASS: When SAM Meets Unsupervised Domain Adaptive Semantic\n  Segmentation in Intelligent Vehicles", "abstract": "Semantic segmentation plays a critical role in enabling intelligent vehicles\nto comprehend their surrounding environments. However, deep learning-based\nmethods usually perform poorly in domain shift scenarios due to the lack of\nlabeled data for training. Unsupervised domain adaptation (UDA) techniques have\nemerged to bridge the gap across different driving scenes and enhance model\nperformance on unlabeled target environments. Although self-training UDA\nmethods have achieved state-of-the-art results, the challenge of generating\nprecise pseudo-labels persists. These pseudo-labels tend to favor majority\nclasses, consequently sacrificing the performance of rare classes or small\nobjects like traffic lights and signs. To address this challenge, we introduce\nSAM4UDASS, a novel approach that incorporates the Segment Anything Model (SAM)\ninto self-training UDA methods for refining pseudo-labels. It involves\nSemantic-Guided Mask Labeling, which assigns semantic labels to unlabeled SAM\nmasks using UDA pseudo-labels. Furthermore, we devise fusion strategies aimed\nat mitigating semantic granularity inconsistency between SAM masks and the\ntarget domain. SAM4UDASS innovatively integrate SAM with UDA for semantic\nsegmentation in driving scenes and seamlessly complements existing\nself-training UDA methodologies. Extensive experiments on synthetic-to-real and\nnormal-to-adverse driving datasets demonstrate its effectiveness. It brings\nmore than 3% mIoU gains on GTA5-to-Cityscapes, SYNTHIA-to-Cityscapes, and\nCityscapes-to-ACDC when using DAFormer and achieves SOTA when using MIC. The\ncode will be available at https://github.com/ywher/SAM4UDASS.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.08609", "title": "F4D: Factorized 4D Convolutional Neural Network for Efficient\n  Video-level Representation Learning", "abstract": "Recent studies have shown that video-level representation learning is crucial\nto the capture and understanding of the long-range temporal structure for video\naction recognition. Most existing 3D convolutional neural network (CNN)-based\nmethods for video-level representation learning are clip-based and focus only\non short-term motion and appearances. These CNN-based methods lack the capacity\nto incorporate and model the long-range spatiotemporal representation of the\nunderlying video and ignore the long-range video-level context during training.\nIn this study, we propose a factorized 4D CNN architecture with attention (F4D)\nthat is capable of learning more effective, finer-grained, long-term\nspatiotemporal video representations. We demonstrate that the proposed F4D\narchitecture yields significant performance improvements over the conventional\n2D, and 3D CNN architectures proposed in the literature. Experiment evaluation\non five action recognition benchmark datasets, i.e., Something-Something-v1,\nSomethingSomething-v2, Kinetics-400, UCF101, and HMDB51 demonstrate the\neffectiveness of the proposed F4D network architecture for video-level action\nrecognition.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.08613", "title": "Digital Infrastructure for Connected and Automated Vehicles", "abstract": "Connected and automated vehicles (CAV) are expected to deliver a much safer,\nmore efficient, and eco-friendlier mobility. Being an indispensable component\nof the future transportation, their key driving features of CAVs include not\nonly the automated functionality but also the cooperative capability. Despite\nthe CAVs themselves are emerging and active research areas, there is a lack of\na comprehensive literature review on the digital infrastructure that enables\nthem. In this paper, we review the requirements and benefits of digital\ninfrastructures for the CAVs including the vehicle built-in, roadside-based,\noperational and planning infrastructures. We then highlight challenges and\nopportunities on digital infrastructure research for the CAVs. Our study sheds\nlights on seamless integration of digital infrastructure for safe operations of\nCAVs.", "field": "Computer Science", "categories": "cs.NI"}, {"arxiv_id": "2401.08615", "title": "Online Anomaly Detection over Live Social Video Streaming", "abstract": "Social video anomaly is an observation in video streams that does not conform\nto a common pattern of dataset's behaviour. Social video anomaly detection\nplays a critical role in applications from e-commerce to e-learning.\nTraditionally, anomaly detection techniques are applied to find anomalies in\nvideo broadcasting. However, they neglect the live social video streams which\ncontain interactive talk, speech, or lecture with audience. In this paper, we\npropose a generic framework for effectively online detecting Anomalies Over\nsocial Video LIve Streaming (AOVLIS). Specifically, we propose a novel deep\nneural network model called Coupling Long Short-Term Memory (CLSTM) that\nadaptively captures the history behaviours of the presenters and audience, and\ntheir mutual interactions to predict their behaviour at next time point over\nstreams. Then we well integrate the CLSTM with a decoder layer, and propose a\nnew reconstruction error-based scoring function $RE_{IA}$ to calculate the\nanomaly score of each video segment for anomaly detection. After that, we\npropose a novel model update scheme that incrementally maintains CLSTM and\ndecoder. Moreover, we design a novel upper bound and ADaptive Optimisation\nStrategy (ADOS) for improving the efficiency of our solution. Extensive\nexperiments are conducted to prove the superiority of AOVLIS.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.08619", "title": "MATE-Pred: Multimodal Attention-based TCR-Epitope interaction Predictor", "abstract": "An accurate binding affinity prediction between T-cell receptors and epitopes\ncontributes decisively to develop successful immunotherapy strategies. Some\nstate-of-the-art computational methods implement deep learning techniques by\nintegrating evolutionary features to convert the amino acid residues of cell\nreceptors and epitope sequences into numerical values, while some other methods\nemploy pre-trained language models to summarize the embedding vectors at the\namino acid residue level to obtain sequence-wise representations.\n  Here, we propose a highly reliable novel method, MATE-Pred, that performs\nmulti-modal attention-based prediction of T-cell receptors and epitopes binding\naffinity. The MATE-Pred is compared and benchmarked with other deep learning\nmodels that leverage multi-modal representations of T-cell receptors and\nepitopes. In the proposed method, the textual representation of proteins is\nembedded with a pre-trained bi-directional encoder model and combined with two\nadditional modalities: a) a comprehensive set of selected physicochemical\nproperties; b) predicted contact maps that estimate the 3D distances between\namino acid residues in the sequences.\n  The MATE-Pred demonstrates the potential of multi-modal model in achieving\nstate-of-the-art performance (+8.4\\% MCC, +5.5\\% AUC compared to baselines) and\nefficiently capturing contextual, physicochemical, and structural information\nfrom amino acid residues. The performance of MATE-Pred projects its potential\napplication in various drug discovery regimes.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.08623", "title": "Wake-Sleep Consolidated Learning", "abstract": "We propose Wake-Sleep Consolidated Learning (WSCL), a learning strategy\nleveraging Complementary Learning System theory and the wake-sleep phases of\nthe human brain to improve the performance of deep neural networks for visual\nclassification tasks in continual learning settings. Our method learns\ncontinually via the synchronization between distinct wake and sleep phases.\nDuring the wake phase, the model is exposed to sensory input and adapts its\nrepresentations, ensuring stability through a dynamic parameter freezing\nmechanism and storing episodic memories in a short-term temporary memory\n(similarly to what happens in the hippocampus). During the sleep phase, the\ntraining process is split into NREM and REM stages. In the NREM stage, the\nmodel's synaptic weights are consolidated using replayed samples from the\nshort-term and long-term memory and the synaptic plasticity mechanism is\nactivated, strengthening important connections and weakening unimportant ones.\nIn the REM stage, the model is exposed to previously-unseen realistic visual\nsensory experience, and the dreaming process is activated, which enables the\nmodel to explore the potential feature space, thus preparing synapses to future\nknowledge. We evaluate the effectiveness of our approach on three benchmark\ndatasets: CIFAR-10, Tiny-ImageNet and FG-ImageNet. In all cases, our method\noutperforms the baselines and prior work, yielding a significant performance\ngain on continual visual classification tasks. Furthermore, we demonstrate the\nusefulness of all processing stages and the importance of dreaming to enable\npositive forward transfer.", "field": "Computer Science", "categories": "cs.NE,cs.AI,cs.CV,cs.LG"}, {"arxiv_id": "2401.08624", "title": "Towards Practical Cell-Free 6G Network Deployments: An Open-Source\n  End-to-End Ray Tracing Simulator", "abstract": "The advent of 6G wireless communication marks a transformative era in\ntechnological connectivity, bringing forth challenges and opportunities alike.\nThis paper unveils an innovative, open-source simulator, meticulously crafted\nfor cell-free 6G wireless networks. This simulator is not just a tool but a\ngateway to the future, blending cutting-edge channel models with the simulation\nof both physical propagation effects and intricate system-level protocols. It\nstands at the forefront of technological advancement by integrating LIS and\nMIMO technologies, harnessing the power of the Unity game engine for efficient\nray-tracing and GPU-accelerated computations. The unparalleled flexibility in\nscenario configuration, coupled with its unique ability to dynamically simulate\ninteractions across network layers, establishes this simulator as an\nindispensable asset in pioneering &G systems' research and development.", "field": "Computer Science", "categories": "cs.NI,eess.SP"}, {"arxiv_id": "2401.08625", "title": "Conditional Flood Fill Method in Logic Synthesis", "abstract": "In the field of Electronic Design Automation (EDA), logic synthesis plays a\npivotal role in optimizing hardware resources. Traditional logic synthesis\nalgorithms, such as the Quine-McCluskey method, face challenges in scalability\nand efficiency, particularly for higher-dimension problems. This paper\nintroduces a novel heuristic algorithm based on Conditional Flood Fill Method\naimed at addressing these limitations. Our method employs count-based adjacent\nelement handling and introduces nine new theorems to guide the logic synthesis\nprocess. Experimental results validate the efficacy of our approach, showing\nsignificant improvements in computational efficiency and scalability compared\nto existing algorithms. The algorithm holds potential for future advancements\nin circuit development and Boolean function optimization.", "field": "Computer Science", "categories": "cs.AR"}, {"arxiv_id": "2401.08628", "title": "Monostatic imaging of an extended target with MCMC sampling", "abstract": "We consider the imaging of a planar extended target from far-field data under\na monostatic measurement configuration, in which the data is measured by a\nsingle moving transducer, as frequently encountered in practical application.\nIn this paper, we develop a Bayesian approach to recover the shape of the\nextended target with MCMC sampling, where a new shape basis selection is\nproposed based on the shape derivative analysis for the measurement data. In\norder to optimize the center and radius of the initial disk, we use the\nmonostatic sampling method for the center and the explicit scattered field\nexpression for disks for the radius. Numerical simulations are presented to\nvalidate the proposed method.", "field": "Computer Science", "categories": "math.NA,cs.NA,math-ph,math.MP"}, {"arxiv_id": "2401.08629", "title": "Immature Green Apple Detection and Sizing in Commercial Orchards using\n  YOLOv8 and Shape Fitting Techniques", "abstract": "Detecting and estimating size of apples during the early stages of growth is\ncrucial for predicting yield, pest management, and making informed decisions\nrelated to crop-load management, harvest and post-harvest logistics, and\nmarketing. Traditional fruit size measurement methods are laborious and\ntime-consuming. This study employs the state-of-the-art YOLOv8 object detection\nand instance segmentation algorithm in conjunction with geometric shape fitting\ntechniques on 3D point cloud data to accurately determine the size of immature\ngreen apples (or fruitlet) in a commercial orchard environment. The methodology\nutilized two RGB-D sensors: the Intel RealSense D435i and the Microsoft Azure\nKinect DK. Notably, the YOLOv8 instance segmentation models exhibited\nproficiency in immature green apple detection, with the YOLOv8m-seg model\nclinching the highest AP@0.5 and AP@0.75 scores of 0.94 and 0.91, respectively.\nLeveraging the ellipsoid fitting technique on images from the Azure Kinect, we\nobserved remarkable metrics, including an RMSE of 2.35, MAE of 1.66, MAPE of\n6.15, and an R-squared value of 0.9. Challenges such as partial occlusion,\nwhere YOLOv8 sometimes misinterpreted immature green apple clusters, were\nrecognized. In a comparison of 102 outdoor samples, the Microsoft Azure Kinect\nshowed better performance than the Intel Realsense D435i, as supported by the\nMAE data. This study emphasizes the combined effectiveness of shape-fitting\nmethods and 3D sensors in improving fruitlet sizing for agriculture.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.08631", "title": "The Conquest of Quantum Genetic Algorithms: The Adventure to Cross the\n  Valley of Death", "abstract": "In recent years, the emergence of the first quantum computers at a time when\nAI is undergoing a fruitful era has led many AI researchers to be tempted into\nadapting their algorithms to run on a quantum computer. However, in many cases\nthe initial enthusiasm has ended in frustration, since the features and\nprinciples underlying quantum computing are very different from traditional\ncomputers. In this paper, we present a discussion of the difficulties arising\nwhen designing a quantum version of an evolutionary algorithm based on Darwin's\nevolutionary mechanism, the so-called genetic algorithms. The paper includes\nthe code in both Python and QISKIT of the quantum version of one of these\nevolutionary algorithms allowing the reader to experience the setbacks arising\nwhen translating a classical algorithm to its quantum version. The algorithm\nstudied in this paper, termed RQGA (Reduced Quantum Genetic Algorithm), has\nbeen chosen as an example that clearly shows these difficulties, which are\ncommon to other AI algorithms.", "field": "Computer Science", "categories": "cs.NE,cs.ET"}, {"arxiv_id": "2401.08632", "title": "Synergizing Quality-Diversity with Descriptor-Conditioned Reinforcement\n  Learning", "abstract": "A fundamental trait of intelligence involves finding novel and creative\nsolutions to address a given challenge or to adapt to unforeseen situations.\nReflecting this, Quality-Diversity optimization is a family of Evolutionary\nAlgorithms, that generates collections of both diverse and high-performing\nsolutions. Among these, MAP-Elites is a prominent example, that has been\nsuccessfully applied to a variety of domains, including evolutionary robotics.\nHowever, MAP-Elites performs a divergent search with random mutations\noriginating from Genetic Algorithms, and thus, is limited to evolving\npopulations of low-dimensional solutions. PGA-MAP-Elites overcomes this\nlimitation using a gradient-based variation operator inspired by deep\nreinforcement learning which enables the evolution of large neural networks.\nAlthough high-performing in many environments, PGA-MAP-Elites fails on several\ntasks where the convergent search of the gradient-based variation operator\nhinders diversity. In this work, we present three contributions: (1) we enhance\nthe Policy Gradient variation operator with a descriptor-conditioned critic\nthat reconciles diversity search with gradient-based methods, (2) we leverage\nthe actor-critic training to learn a descriptor-conditioned policy at no\nadditional cost, distilling the knowledge of the population into one single\nversatile policy that can execute a diversity of behaviors, (3) we exploit the\ndescriptor-conditioned actor by injecting it in the population, despite network\narchitecture differences. Our method, DCG-MAP-Elites, achieves equal or higher\nQD score and coverage compared to all baselines on seven challenging continuous\ncontrol locomotion tasks.", "field": "Computer Science", "categories": "cs.NE,cs.AI,cs.LG,cs.RO"}, {"arxiv_id": "2401.08633", "title": "Creating Visual Effects with Neural Radiance Fields", "abstract": "We present a pipeline for integrating NeRFs into traditional compositing VFX\npipelines using Nerfstudio, an open-source framework for training and rendering\nNeRFs. Our approach involves using Blender, a widely used open-source 3D\ncreation software, to align camera paths and composite NeRF renders with meshes\nand other NeRFs, allowing for seamless integration of NeRFs into traditional\nVFX pipelines. Our NeRF Blender add-on allows for more controlled camera\ntrajectories of photorealistic scenes, compositing meshes and other\nenvironmental effects with NeRFs, and compositing multiple NeRFs in a single\nscene.This approach of generating NeRF aligned camera paths can be adapted to\nother 3D tool sets and workflows, enabling a more seamless integration of NeRFs\ninto visual effects and film production. Documentation can be found here:\nhttps://docs.nerf.studio/extensions/blender_addon.html", "field": "Computer Science", "categories": "cs.CV,cs.GR"}, {"arxiv_id": "2401.08634", "title": "Resilient Path Planning for UAVs in Data Collection under Adversarial\n  Attacks", "abstract": "In this paper, we investigate jamming-resilient UAV path planning strategies\nfor data collection in Internet of Things (IoT) networks, in which the typical\nUAV can learn the optimal trajectory to elude such jamming attacks.\nSpecifically, the typical UAV is required to collect data from multiple\ndistributed IoT nodes under collision avoidance, mission completion deadline,\nand kinematic constraints in the presence of jamming attacks. We first design a\nfixed ground jammer with continuous jamming attack and periodical jamming\nattack strategies to jam the link between the typical UAV and IoT nodes.\nDefensive strategies involving a reinforcement learning (RL) based virtual\njammer and the adoption of higher SINR thresholds are proposed to counteract\nagainst such attacks. Secondly, we design an intelligent UAV jammer, which\nutilizes the RL algorithm to choose actions based on its observation. Then, an\nintelligent UAV anti-jamming strategy is constructed to deal with such attacks,\nand the optimal trajectory of the typical UAV is obtained via dueling double\ndeep Q-network (D3QN). Simulation results show that both non-intelligent and\nintelligent jamming attacks have significant influence on the UAV's\nperformance, and the proposed defense strategies can recover the performance\nclose to that in no-jammer scenarios.", "field": "Computer Science", "categories": "cs.NI,eess.SP"}, {"arxiv_id": "2401.08636", "title": "MLCommons Cloud Masking Benchmark with Early Stopping", "abstract": "In this paper, we report on work performed for the MLCommons Science Working\nGroup on the cloud masking benchmark. MLCommons is a consortium that develops\nand maintains several scientific benchmarks that aim to benefit developments in\nAI. The benchmarks are conducted on the High Performance Computing (HPC)\nClusters of New York University and University of Virginia, as well as a\ncommodity desktop. We provide a description of the cloud masking benchmark, as\nwell as a summary of our submission to MLCommons on the benchmark experiment we\nconducted. It includes a modification to the reference implementation of the\ncloud masking benchmark enabling early stopping. This benchmark is executed on\nthe NYU HPC through a custom batch script that runs the various experiments\nthrough the batch queuing system while allowing for variation on the number of\nepochs trained. Our submission includes the modified code, a custom batch\nscript to modify epochs, documentation, and the benchmark results. We report\nthe highest accuracy (scientific metric) and the average time taken\n(performance metric) for training and inference that was achieved on NYU HPC\nGreene. We also provide a comparison of the compute capabilities between\ndifferent systems by running the benchmark for one epoch. Our submission can be\nfound in a Globus repository that is accessible to MLCommons Science Working\nGroup.", "field": "Computer Science", "categories": "cs.DC,cs.AI"}, {"arxiv_id": "2401.08637", "title": "Collaborative Inference via Dynamic Composition of Tiny AI Accelerators\n  on MCUs", "abstract": "The advent of tiny AI accelerators opens opportunities for deep neural\nnetwork deployment at the extreme edge, offering reduced latency, lower power\ncost, and improved privacy in on-device ML inference. Despite these\nadvancements, challenges persist due to inherent limitations of these\naccelerators, such as restricted onboard memory and single-device focus. This\npaper introduces Synergy, a system that dynamically composes tiny AI\naccelerators for multi-tenant models, effectively addressing tinyML's critical\nchallenges for the increasing demand for on-device AI. A key feature of Synergy\nis its virtual computing space, providing a unified, virtualized view of\nresources and enabling efficient task mapping to physical devices. Synergy's\nruntime orchestration module ensures optimal inference across dynamic and\nheterogeneous accelerators. Our evaluations with 7 baselines and 8 models\ndemonstrate that Synergy improves throughput by an average of 8.0X compared to\nbaselines.", "field": "Computer Science", "categories": "cs.DC,cs.LG"}, {"arxiv_id": "2401.08639", "title": "One-Step Diffusion Distillation via Deep Equilibrium Models", "abstract": "Diffusion models excel at producing high-quality samples but naively require\nhundreds of iterations, prompting multiple attempts to distill the generation\nprocess into a faster network. However, many existing approaches suffer from a\nvariety of challenges: the process for distillation training can be complex,\noften requiring multiple training stages, and the resulting models perform\npoorly when utilized in single-step generative applications. In this paper, we\nintroduce a simple yet effective means of distilling diffusion models directly\nfrom initial noise to the resulting image. Of particular importance to our\napproach is to leverage a new Deep Equilibrium (DEQ) model as the distilled\narchitecture: the Generative Equilibrium Transformer (GET). Our method enables\nfully offline training with just noise/image pairs from the diffusion model\nwhile achieving superior performance compared to existing one-step methods on\ncomparable training budgets. We demonstrate that the DEQ architecture is\ncrucial to this capability, as GET matches a $5\\times$ larger ViT in terms of\nFID scores while striking a critical balance of computational cost and image\nquality. Code, checkpoints, and datasets are available.", "field": "Computer Science", "categories": "cs.CV,cs.LG"}, {"arxiv_id": "2401.0864", "title": "Typification of Driver Models Using Clustering Methods", "abstract": "The rapid development of automated driving systems in recent years has led to\nimprovements in road safety and travel comfort. One typical function of these\nsystems is Lane Keep Assist, which generally does not take human driving\npreferences into account. In our previous work, we have demonstrated that it is\npossible to implement a Lane Keep Assist function that is appropriate to human\npreferences using a trajectory planning algorithm based on a linear driving\nmodel. In our current work, we investigated how to separate the driving styles\nof individual drivers. We assumed that there are three driving styles: sporty,\nneutral and defensive. To prove these relations, clustering methods were\napplied to previously recorded measurements . Simulations with parameters\ndescribing the average behaviour of the classes (re-simulated with clustered\ntypes) showed that the resulting paths successfully classified drivers, that\nthe 3 classes are distinct in their behaviour and that our model reproduces\nthese behaviours.", "field": "Computer Science", "categories": "cs.RO,cs.SY,eess.SY"}, {"arxiv_id": "2401.08643", "title": "Exploratory Driving Performance and Car-Following Modeling for\n  Autonomous Shuttles Based on Field Data", "abstract": "Autonomous shuttles (AS) operate in several cities and have shown potential\nto improve the public transport network. However, there is no car following\nmodel that is based on field data and allows decision-makers to assess and plan\nfor AS operations. To fill this gap, this study collected field data from AS,\nanalyzed their driving performance, and suggested changes in the AS trajectory\nmodel to improve passenger comfort. A sample was collected with more than 4000\nseconds of AS following a conventional car. The sample contained GPS positions\nfrom both AS and conventional vehicles. Latitude and longitude positions were\nused to calculate the speed, acceleration, and jerk of the leader and follower.\nThe data analyses indicated that AS have higher jerk values that may impact the\npassengers comfort. Several existing models were evaluated, and the researchers\nconcluded that the calibrated ACC model resulted in lower errors for AS spacing\nand speed. The results of the calibration indicate that the AS has lower peak\nacceleration and higher deceleration than the parameters that were calibrated\nfor autonomous vehicle models in other research", "field": "Computer Science", "categories": "cs.RO,stat.AP"}, {"arxiv_id": "2401.08647", "title": "The \"Pac-Man'' Gripper: Tactile Sensing and Grasping through Thin-Shell\n  Buckling", "abstract": "Soft and lightweight grippers have greatly enhanced the performance of\nrobotic manipulators in handling complex objects with varying shape, texture,\nand stiffness. However, the combination of universal grasping with passive\nsensing capabilities still presents challenges. To overcome this limitation, we\nintroduce a fluidic soft gripper, named the ``Pac-Man'' gripper, based on the\nbuckling of soft, thin hemispherical shells. Leveraging a single fluidic\npressure input, the soft gripper can encapsulate slippery and delicate objects\nwhile passively providing information on this physical interaction. Guided by\nanalytical, numerical, and experimental tools, we explore the novel grasping\nprinciple of this mechanics-based soft gripper. First, we characterize the\nbuckling behavior of a free hemisphere as a function of its geometric\nparameters. Inspired by the free hemisphere's two-lobe mode shape ideal for\ngrasping purposes, we demonstrate that the gripper can perform dexterous\nmanipulation and gentle gripping of fragile objects in confined environments.\nLast, we prove the soft gripper's embedded capability of detecting contact,\ngrasping, and release conditions during the interaction with an unknown object.\nThis simple buckling-based soft gripper opens new avenues for the design of\nadaptive gripper morphologies with applications ranging from medical and\nagricultural robotics to space and underwater exploration.", "field": "Computer Science", "categories": "cs.RO"}, {"arxiv_id": "2401.08649", "title": "Deep Pulse-Coupled Neural Networks", "abstract": "Spiking Neural Networks (SNNs) capture the information processing mechanism\nof the brain by taking advantage of spiking neurons, such as the Leaky\nIntegrate-and-Fire (LIF) model neuron, which incorporates temporal dynamics and\ntransmits information via discrete and asynchronous spikes. However, the\nsimplified biological properties of LIF ignore the neuronal coupling and\ndendritic structure of real neurons, which limits the spatio-temporal dynamics\nof neurons and thus reduce the expressive power of the resulting SNNs. In this\nwork, we leverage a more biologically plausible neural model with complex\ndynamics, i.e., a pulse-coupled neural network (PCNN), to improve the\nexpressiveness and recognition performance of SNNs for vision tasks. The PCNN\nis a type of cortical model capable of emulating the complex neuronal\nactivities in the primary visual cortex. We construct deep pulse-coupled neural\nnetworks (DPCNNs) by replacing commonly used LIF neurons in SNNs with PCNN\nneurons. The intra-coupling in existing PCNN models limits the coupling between\nneurons only within channels. To address this limitation, we propose\ninter-channel coupling, which allows neurons in different feature maps to\ninteract with each other. Experimental results show that inter-channel coupling\ncan efficiently boost performance with fewer neurons, synapses, and less\ntraining time compared to widening the networks. For instance, compared to the\nLIF-based SNN with wide VGG9, DPCNN with VGG9 uses only 50%, 53%, and 73% of\nneurons, synapses, and training time, respectively. Furthermore, we propose\nreceptive field and time dependent batch normalization (RFTD-BN) to speed up\nthe convergence and performance of DPCNNs.", "field": "Computer Science", "categories": "cs.NE,cs.LG"}, {"arxiv_id": "2401.08651", "title": "Towards Near-Field 3D Spot Beamfocusing: Possibilities, Challenges, and\n  Use-cases", "abstract": "Spot beamfocusing (SBF) is the process of focusing the signal power in a\nsmall spot-like region in the 3D space, which can be either hard-tuned (HT)\nusing traditional tools like lenses and mirrors or electronically reconfigured\n(ER) using modern large-scale intelligent surface phased arrays. ER-SBF can be\na key enabling technology (KET) for the next-generation 6G wireless networks\noffering benefits to many future wireless application areas such as wireless\ncommunication and security, mid-range wireless chargers, medical and health,\nphysics, etc. Although near-field HT-SBF and ER-beamfocusing have been studied\nin the literature and applied in the industry, there is no comprehensive study\nof different aspects of ER-SBF and its future applications, especially for\nnonoptical (mmWave, sub-THz, and THz) electromagnetic waves in the next\ngeneration wireless technology, which is the aim of this paper. The theoretical\nconcepts behind ER-SBF, different antenna technologies for implementing ER-SBF,\nemploying machine learning (ML)-based schemes for enabling\nchannel-state-information (CSI)-independent ER-SBF, and different practical\napplication areas that can benefit from ER-SBF will be explored.", "field": "Computer Science", "categories": "cs.IT,cs.SY,eess.SY,math.IT"}, {"arxiv_id": "2401.08652", "title": "An Efficient Dynamic Transaction Storage Mechanism for Sustainable High\n  Throughput Bitcoin", "abstract": "As coin-based rewards dwindle, transaction fees play an important role as\nmining incentives in Bitcoin. In this paper, we propose a novel mechanism\ncalled Efficient Dynamic Transaction Storage (EDTS) for dynamically allocating\ntransactions among blocks to achieve efficient storage utilization. By\nleveraging a combination of Cuckoo Filter and Dynamic Transaction Storage (DTS)\nstrategies, EDTS is able to improve the scalability while remaining sustainable\neven after the Bitcoin enters a transaction-fee regime. In addition to\npreventing deviant mining behaviors under the transaction-fee regime, EDTS can\nalso provide differentiated transmission priorities based on transaction fees\nwhile allowing the investors to engage in pledging more transaction fees. In\nEDTS, we applied the multi-objective optimization algorithm U-NSGA-III to find\nthe best DTS strategy and its corresponding attributes. Experimental results\nshow that the EDTS mechanism together with the optimized DTS strategy can\nachieve a throughput of 325.3 TPS. The experimental results reveal that the\nscalability improvement of EDTS is superior to the performance of Bitcoin NG,\nwhich is the best known on-chain scaling solution, while maintaining the\nsustainability under the transaction-fee regime.", "field": "Computer Science", "categories": "cs.NI,cs.GT"}, {"arxiv_id": "2401.08653", "title": "Digital Twins for Autonomous Driving: A Comprehensive Implementation and\n  Demonstration", "abstract": "The concept of a digital twin (DT) plays a pivotal role in the ongoing\ndigital transformation and has achieved significant strides for various\nwireless applications in recent years. In particular, the field of autonomous\nvehicles is a domain that is ripe for exploiting the concept of DT.\nNevertheless, there are many challenges that include holistic consideration and\nintegration of hardware, software, communication methods, and collaboration of\nedge/cloud computing. In this paper, an end-to-end (E2E) real-world smart\nmobility DT is designed and implemented for the purpose of autonomous driving.\nThe proposed system utilizes roadside units (RSUs) and edge computing to\ncapture real-world traffic information, which is then processed in the cloud to\ncreate a DT model. This DT model is then exploited to enable route planning\nservices for the autonomous vehicle to avoid heavy traffic. Real-world\nexperimental results show that the system reliability can reach 99.53% while\nachieving a latency that is 3.36% below the 3GPP recommended value of 100 ms\nfor autonomous driving. These results clearly validate the effectiveness of the\nsystem according to practical 3GPP standards for sensor and state map sharing\n(SSMS) and information sharing.", "field": "Computer Science", "categories": "cs.NI"}, {"arxiv_id": "2401.08654", "title": "Smart Mobility Digital Twin for Automated Driving: Design and\n  Proof-of-Concept", "abstract": "During the past decade, smart mobility and intelligent vehicles have\nattracted increasing attention, because they promise to create a highly\nefficient and safe transportation system in the future. Meanwhile, digital\ntwin, as an emerging technology, will play an important role in automated\ndriving and intelligent transportation systems. This technology is applied in\nthis paper to design a platform for smart mobility, providing large-scale route\nplanning services. Utilizing sensing technologies and cloud/edge computing, we\nbuild a digital twin system model that reflects the static and dynamic objects\nfrom the real world in real time. With the smart mobility platform, we realize\ntraffic monitoring and route planning through cooperative environment\nperception to help automated vehicles circumvent jams. A proof-of-concept test\nwith a real vehicle in real traffic is conducted to validate the functions and\nthe delay performance of the proposed platform.", "field": "Computer Science", "categories": "cs.RO,cs.SY,eess.SY"}, {"arxiv_id": "2401.08655", "title": "SAiD: Speech-driven Blendshape Facial Animation with Diffusion", "abstract": "Speech-driven 3D facial animation is challenging due to the scarcity of\nlarge-scale visual-audio datasets despite extensive research. Most prior works,\ntypically focused on learning regression models on a small dataset using the\nmethod of least squares, encounter difficulties generating diverse lip\nmovements from speech and require substantial effort in refining the generated\noutputs. To address these issues, we propose a speech-driven 3D facial\nanimation with a diffusion model (SAiD), a lightweight Transformer-based U-Net\nwith a cross-modality alignment bias between audio and visual to enhance lip\nsynchronization. Moreover, we introduce BlendVOCA, a benchmark dataset of pairs\nof speech audio and parameters of a blendshape facial model, to address the\nscarcity of public resources. Our experimental results demonstrate that the\nproposed approach achieves comparable or superior performance in lip\nsynchronization to baselines, ensures more diverse lip movements, and\nstreamlines the animation editing process.", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.GR,cs.LG,cs.MM"}, {"arxiv_id": "2401.08656", "title": "Convergence of double step scheme for a class of parabolic Clarke\n  subdifferential inclusions", "abstract": "In this paper we deal with a first order evolution inclusion involving a\nmultivalued term generated by a Clarke subdifferential of a locally Lipschitz\npotential. For this problem we construct a double step time-semidiscrete\napproximation, known as the Rothe scheme. We study a sequence of solutions of\nthe semidiscrete approximate problems and provide its weak convergence to a\nlimit element that is a solution of the original problem.", "field": "Computer Science", "categories": "math.NA,cs.NA,math.AP"}, {"arxiv_id": "2401.08658", "title": "End-To-End Planning of Autonomous Driving in Industry and Academia:\n  2022-2023", "abstract": "This paper aims to provide a quick review of the methods including the\ntechnologies in detail that are currently reported in industry and academia.\nSpecifically, this paper reviews the end-to-end planning, including Tesla FSD\nV12, Momenta 2023, Horizon Robotics 2023, Motional RoboTaxi 2022, Woven Planet\n(Toyota): Urban Driver, and Nvidia. In addition, we review the state-of-the-art\nacademic studies that investigate end-to-end planning of autonomous driving.\nThis paper provides readers with a concise structure and fast learning of\nstate-of-the-art end-to-end planning for 2022-2023. This article provides a\nmeaningful overview as introductory material for beginners to follow the\nstate-of-the-art end-to-end planning of autonomous driving in industry and\nacademia, as well as supplementary material for advanced researchers.", "field": "Computer Science", "categories": "cs.RO,cs.AI"}, {"arxiv_id": "2401.08659", "title": "Generative AI and Its Educational Implications", "abstract": "We discuss the implications of generative AI on education across four\ncritical sections: the historical development of AI in education, its\ncontemporary applications in learning, societal repercussions, and strategic\nrecommendations for researchers. We propose ways in which generative AI can\ntransform the educational landscape, primarily via its ability to conduct\nassessment of complex cognitive performances and create personalized content.\nWe also address the challenges of effective educational tool deployment, data\nbias, design transparency, and accurate output verification. Acknowledging the\nsocietal impact, we emphasize the need for updating curricula, redefining\ncommunicative trust, and adjusting to transformed social norms. We end by\noutlining the ways in which educational stakeholders can actively engage with\ngenerative AI, develop fluency with its capacities and limitations, and apply\nthese insights to steer educational practices in a rapidly advancing digital\nlandscape.", "field": "Computer Science", "categories": "cs.CY"}, {"arxiv_id": "2401.0866", "title": "Gemini Pro Defeated by GPT-4V: Evidence from Education", "abstract": "This study compared the classification performance of Gemini Pro and GPT-4V\nin educational settings. Employing visual question answering (VQA) techniques,\nthe study examined both models' abilities to read text-based rubrics and then\nautomatically score student-drawn models in science education. We employed both\nquantitative and qualitative analyses using a dataset derived from\nstudent-drawn scientific models and employing NERIF (Notation-Enhanced Rubrics\nfor Image Feedback) prompting methods. The findings reveal that GPT-4V\nsignificantly outperforms Gemini Pro in terms of scoring accuracy and Quadratic\nWeighted Kappa. The qualitative analysis reveals that the differences may be\ndue to the models' ability to process fine-grained texts in images and overall\nimage classification performance. Even adapting the NERIF approach by further\nde-sizing the input images, Gemini Pro seems not able to perform as well as\nGPT-4V. The findings suggest GPT-4V's superior capability in handling complex\nmultimodal educational tasks. The study concludes that while both models\nrepresent advancements in AI, GPT-4V's higher performance makes it a more\nsuitable tool for educational applications involving multimodal data\ninterpretation.", "field": "Computer Science", "categories": "cs.AI,cs.CL"}, {"arxiv_id": "2401.08661", "title": "Risk-anticipatory autonomous driving strategies considering vehicles'\n  weights, based on hierarchical deep reinforcement learning", "abstract": "Autonomous vehicles (AVs) have the potential to prevent accidents caused by\ndrivers' error and reduce road traffic risks. Due to the nature of heavy\nvehicles, whose collisions cause more serious crashes, the weights of vehicles\nneed to be considered when making driving strategies aimed at reducing the\npotential risks and their consequences in the context of autonomous driving.\nThis study develops an autonomous driving strategy based on risk anticipation,\nconsidering the weights of surrounding vehicles and using hierarchical deep\nreinforcement learning. A risk indicator integrating surrounding vehicles'\nweights, based on the risk field theory, is proposed and incorporated into\nautonomous driving decisions. A hybrid action space is designed to allow for\nleft lane changes, right lane changes and car-following, which enables AVs to\nact more freely and realistically whenever possible. To solve the above hybrid\ndecision-making problem, a hierarchical proximal policy optimization (HPPO)\nalgorithm is developed and an attention mechanism is incorporated, providing\ngreat advantages in maintaining stable performance. An indicator, potential\ncollision energy in conflicts (PCEC), is newly proposed to evaluate the\nperformance of the developed AV driving strategy from both the perspectives of\nthe likelihood and the consequences of potential accidents. An application is\ncarried out and the simulation results demonstrate that our model provides\ndriving strategies that reduce both the likelihood and consequences of\npotential accidents, at the same time maintaining driving efficiency. The\ndeveloped method is especially meaningful for AVs driving on highways, where\nheavy vehicles make up a high proportion of the traffic.", "field": "Computer Science", "categories": "cs.RO,cs.LG"}, {"arxiv_id": "2401.08662", "title": "Mobile Edge Generation: A New Era to 6G", "abstract": "A conception of mobile edge generation (MEG) is proposed, where generative\nartificial intelligence (GAI) models are distributed at edge servers (ESs) and\nuser equipment (UE), enabling joint execution of generation tasks. Various\ndistributed deployment schemes of the GAI model are proposed to alleviate the\nimmense network load and long user queuing times for accessing GAI models. Two\nMEG frameworks are proposed, namely the single-ES framework and the multi-ESs\nframework. 1) A one-to-one joint generation framework between an ES and a UE is\nproposed, including four specific single-ES MEG protocols. These protocols\nallow distributed GAI models to transmit seeds or sketches for delivering\ninformation efficiently. 2) Several protocols are proposed for multi-ESs MEG,\nwhich enable multiple ESs to perform the generation task cooperatively or in\nparallel. Finally, a case study of a text-guided-image-to-image generation is\nprovided, where a latent diffusion model is distributed at an ES and a UE. The\nsimulation results demonstrate that the proposed protocols are able to generate\nhigh-quality images at extremely low signal-to-noise ratios. The proposed\nprotocols can significantly reduce the communication overhead compared to the\ncentralized model.", "field": "Computer Science", "categories": "cs.NI,eess.SP"}, {"arxiv_id": "2401.08663", "title": "An Integrated Imitation and Reinforcement Learning Methodology for\n  Robust Agile Aircraft Control with Limited Pilot Demonstration Data", "abstract": "In this paper, we present a methodology for constructing data-driven maneuver\ngeneration models for agile aircraft that can generalize across a wide range of\ntrim conditions and aircraft model parameters. Maneuver generation models play\na crucial role in the testing and evaluation of aircraft prototypes, providing\ninsights into the maneuverability and agility of the aircraft. However,\nconstructing the models typically requires extensive amounts of real pilot\ndata, which can be time-consuming and costly to obtain. Moreover, models built\nwith limited data often struggle to generalize beyond the specific flight\nconditions covered in the original dataset. To address these challenges, we\npropose a hybrid architecture that leverages a simulation model, referred to as\nthe source model. This open-source agile aircraft simulator shares similar\ndynamics with the target aircraft and allows us to generate unlimited data for\nbuilding a proxy maneuver generation model. We then fine-tune this model to the\ntarget aircraft using a limited amount of real pilot data. Our approach\ncombines techniques from imitation learning, transfer learning, and\nreinforcement learning to achieve this objective. To validate our methodology,\nwe utilize real agile pilot data provided by Turkish Aerospace Industries\n(TAI). By employing the F-16 as the source model, we demonstrate that it is\npossible to construct a maneuver generation model that generalizes across\nvarious trim conditions and aircraft parameters without requiring any\nadditional real pilot data. Our results showcase the effectiveness of our\napproach in developing robust and adaptable models for agile aircraft.", "field": "Computer Science", "categories": "cs.AI,cs.LG,cs.RO,cs.SY,eess.SY"}, {"arxiv_id": "2401.08664", "title": "Adapting Large Language Models for Education: Foundational Capabilities,\n  Potentials, and Challenges", "abstract": "Online education platforms, leveraging the internet to distribute education\nresources, seek to provide convenient education but often fall short in\nreal-time communication with students. They often struggle to offer\npersonalized education resources due to the challenge of addressing the diverse\nobstacles students encounter throughout their learning journey. Recently, the\nemergence of large language models (LLMs), such as ChatGPT, offers the\npossibility for resolving this issue by comprehending individual requests.\nAlthough LLMs have been successful in various fields, creating an LLM-based\neducation system is still challenging for the wide range of educational skills\nrequired. This paper reviews the recently emerged LLM researches related to\neducational capabilities, including mathematics, writing, programming,\nreasoning, and knowledge-based question answering, with the aim to explore\ntheir potential in constructing the next-generation intelligent education\nsystem. Based on the current development status, we further outline two\napproaches for an LLM-based education system: a unified approach and a\nmixture-of-expert (MoE) approach. Finally, we explore the challenges and future\ndirections, providing new research opportunities and perspectives on adapting\nLLMs for education.", "field": "Computer Science", "categories": "cs.AI,cs.CL"}, {"arxiv_id": "2401.08666", "title": "Modeling and control of the rodwheel", "abstract": "The rodwheel is a wheel equipped with a rod motorized on the axle. This paper\nproposes a Lagrangian approach to find the state equations of the rodwheel\nrolling on a plane without friction. The approach takes advantage of a symbolic\ncomputation. A controller is proposed to stabilize the rodwheel with the rod\nupward and going straight at a desired speed.", "field": "Computer Science", "categories": "math.NA,cs.NA"}, {"arxiv_id": "2401.08668", "title": "Thermodynamic Perspectives on Computational Complexity: Exploring the P\n  vs. NP Problem", "abstract": "The P vs. NP problem, a cornerstone of computational theory, continues to\nelude resolution, traditionally approached through mathematical logic and\nalgorithmic theory. This paper ventures beyond these confines, weaving together\ninformation theory, thermodynamics, and computational complexity to unveil a\nrich landscape of interdisciplinary intersections. Central to our discourse is\nthe concept of entropy, examined through its information-theoretic subtleties\nand thermodynamic implications, particularly in relation to computational\n'hardness'. We introduce Entropy-Driven Annealing (EDA) as a novel mechanism to\nelucidate the energy landscapes underlying computational problems, focusing on\nthe inherent nature of NP problems. This approach hypothesizes a distinct\nthermodynamic profile for NP problems compared to P problems and speculates on\npossible thermodynamic pathways for polynomial-time solutions to NP challenges.\nThe exploration extends to the practical application of EDA in studying\nprotein-DNA complexes, grounding theoretical constructs in a biological\ncontext. While the P vs. NP conundrum remains unsolved, this interdisciplinary\nforay offers a fresh and insightful perspective on fundamental computational\ndilemmas, marking a step towards unraveling this complex puzzle.", "field": "Computer Science", "categories": "cs.IT,math.IT"}, {"arxiv_id": "2401.08669", "title": "Deep Reinforcement Learning for Multi-Truck Vehicle Routing Problems\n  with Multi-Leg Demand Routes", "abstract": "Deep reinforcement learning (RL) has been shown to be effective in producing\napproximate solutions to some vehicle routing problems (VRPs), especially when\nusing policies generated by encoder-decoder attention mechanisms. While these\ntechniques have been quite successful for relatively simple problem instances,\nthere are still under-researched and highly complex VRP variants for which no\neffective RL method has been demonstrated. In this work we focus on one such\nVRP variant, which contains multiple trucks and multi-leg routing requirements.\nIn these problems, demand is required to move along sequences of nodes, instead\nof just from a start node to an end node. With the goal of making deep RL a\nviable strategy for real-world industrial-scale supply chain logistics, we\ndevelop new extensions to existing encoder-decoder attention models which allow\nthem to handle multiple trucks and multi-leg routing requirements. Our models\nhave the advantage that they can be trained for a small number of trucks and\nnodes, and then embedded into a large supply chain to yield solutions for\nlarger numbers of trucks and nodes. We test our approach on a real supply chain\nenvironment arising in the operations of Japanese automotive parts manufacturer\nAisin Corporation, and find that our algorithm outperforms Aisin's previous\nbest solution.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.08671", "title": "DeepSpeed-FastGen: High-throughput Text Generation for LLMs via MII and\n  DeepSpeed-Inference", "abstract": "The deployment and scaling of large language models (LLMs) have become\ncritical as they permeate various applications, demanding high-throughput and\nlow-latency serving systems. Existing frameworks struggle to balance these\nrequirements, especially for workloads with long prompts. This paper introduces\nDeepSpeed-FastGen, a system that employs Dynamic SplitFuse, a novel prompt and\ngeneration composition strategy, to deliver up to 2.3x higher effective\nthroughput, 2x lower latency on average, and up to 3.7x lower (token-level)\ntail latency, compared to state-of-the-art systems like vLLM. We leverage a\nsynergistic combination of DeepSpeed-MII and DeepSpeed-Inference to provide an\nefficient and easy-to-use serving system for LLMs. DeepSpeed-FastGen's advanced\nimplementation supports a range of models and offers both non-persistent and\npersistent deployment options, catering to diverse user scenarios from\ninteractive sessions to long-running applications. We present a detailed\nbenchmarking methodology, analyze the performance through latency-throughput\ncurves, and investigate scalability via load balancing. Our evaluations\ndemonstrate substantial improvements in throughput and latency across various\nmodels and hardware configurations. We discuss our roadmap for future\nenhancements, including broader model support and new hardware backends. The\nDeepSpeed-FastGen code is readily available for community engagement and\ncontribution.", "field": "Computer Science", "categories": "cs.PF,cs.LG"}, {"arxiv_id": "2401.08672", "title": "Concept Alignment", "abstract": "Discussion of AI alignment (alignment between humans and AI systems) has\nfocused on value alignment, broadly referring to creating AI systems that share\nhuman values. We argue that before we can even attempt to align values, it is\nimperative that AI systems and humans align the concepts they use to understand\nthe world. We integrate ideas from philosophy, cognitive science, and deep\nlearning to explain the need for concept alignment, not just value alignment,\nbetween humans and machines. We summarize existing accounts of how humans and\nmachines currently learn concepts, and we outline opportunities and challenges\nin the path towards shared concepts. Finally, we explain how we can leverage\nthe tools already being developed in cognitive science and AI research to\naccelerate progress towards concept alignment.", "field": "Computer Science", "categories": "cs.LG,cs.AI,q-bio.NC"}, {"arxiv_id": "2401.08673", "title": "Standard energy data competition procedure: A comprehensive review with\n  a case study of the ADRENALIN load disaggregation competition", "abstract": "Crowdsourcing data science competitions has become popular as a\ncost-effective alternative to solving complex energy-related challenges.\nHow-ever, comprehensive reviews on hosting processes remain scarce. Therefore,\nthis paper undertakes a detailed review of 33 existing data competitions and 12\nhosting platforms, complemented by an in-depth case study of the ADRENALIN load\ndisaggregation competition. The review identifies essential elements of\ncompetition procedure, including platform selection, timeline, datasets, and\nsubmission and evaluation mechanisms. Based on proposed 16 evaluation criteria,\nthe similarities and differences between data competition hosting platforms can\nbe categorized into platform scoring and popularity, platform features,\ncommunity engagement, open-source platforms, region-specific platforms,\nplatform-specific purposes, and multi-purpose platforms. The case study\nunderscores strategic planning's critical role, particularly platform\nselection. The case study also shows the importance of defining competition\nscope which influences the whole com-petition content and procedure, especially\nthe datasets.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.08682", "title": "Visualizing the genealogy of video game specifications of video game\n  genres -- through a case study of the raising up game genre", "abstract": "Although several methodologies for identifying the genealogy of video game\ngenres and showing their relationships have been proposed in existing research,\nthere have been few attempts to visualize the genealogy of a genre in a\nquantitative and qualitative manner. In this study, we propose a methodology to\nidentify the scope of a specific game genre and to show how game specifications\nspecific to that genre are related to each other.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.08683", "title": "Zero-Shot RTL Code Generation with Attention Sink Augmented Large\n  Language Models", "abstract": "The design and optimization of hardware have traditionally been\nresource-intensive, demanding considerable expertise and dependence on\nestablished design automation tools. This paper discusses the possibility of\nexploiting large language models to streamline the code generation process in\nhardware design. In contrast to earlier studies, this paper aims to use large\nlanguage models that accepts high-level design specifications through a single\nprompt to generate corresponding Register-Transfer Level (RTL) code. The\nability to use large language models on RTL code generation not only expedites\ndesign iteration cycles but also facilitates the exploration of design spaces\nthat have computational challenges for conventional techniques. Through our\nevaluation, we demonstrate the shortcoming of existing attention mechanisms,\nand present the abilities of language models to produce functional, optimized,\nand industry-standard compliant RTL code when a novel attention mechanism is\nused. These findings underscore the expanding role of large language models in\nshaping the future landscape of architectural exploration and automation in\nhardware design.", "field": "Computer Science", "categories": "cs.AR,cs.AI,cs.LG,cs.PL,cs.SE"}, {"arxiv_id": "2401.08685", "title": "Apple Vision Pro: Comments in Healthcare", "abstract": "This paper objectively analyzes the emerging discourse surrounding Apple\nVision Pro's application in healthcare and medical education. Released in June\n2023, Apple Vision Pro represents a significant advancement in spatial\ncomputing, combining augmented and virtual reality to create new possibilities\nin digital interaction. We aim to compile and present recent articles. We used\nPubMed, IEEE Xplore, Google Scholar, and JSTOR. Non-academic publications were\nexcluded. The results were six commentaries, one a pre-print. All were majorly\noptimistic, with one mentioning VR/AR sickness. For future research directions,\nwe stress the need for continued exploration of Apple Vision Pro's capabilities\nand limitations and expect expert opinions to englobe this discussion.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.08686", "title": "Attention Modules Improve Modern Image-Level Anomaly Detection: A\n  DifferNet Case Study", "abstract": "Within (semi-)automated visual inspection, learning-based approaches for\nassessing visual defects, including deep neural networks, enable the processing\nof otherwise small defect patterns in pixel size on high-resolution imagery.\nThe emergence of these often rarely occurring defect patterns explains the\ngeneral need for labeled data corpora. To not only alleviate this issue but to\nfurthermore advance the current state of the art in unsupervised visual\ninspection, this contribution proposes a DifferNet-based solution enhanced with\nattention modules utilizing SENet and CBAM as backbone - AttentDifferNet - to\nimprove the detection and classification capabilities on three different visual\ninspection and anomaly detection datasets: MVTec AD, InsPLAD-fault, and\nSemiconductor Wafer. In comparison to the current state of the art, it is shown\nthat AttentDifferNet achieves improved results, which are, in turn, highlighted\nthroughout our quantitative as well as qualitative evaluation, indicated by a\ngeneral improvement in AUC of 94.34 vs. 92.46, 96.67 vs. 94.69, and 90.20 vs.\n88.74%. As our variants to AttentDifferNet show great prospects in the context\nof currently investigated approaches, a baseline is formulated, emphasizing the\nimportance of attention for anomaly detection.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.08687", "title": "DA-BEV: Unsupervised Domain Adaptation for Bird's Eye View Perception", "abstract": "Camera-only Bird's Eye View (BEV) has demonstrated great potential in\nenvironment perception in a 3D space. However, most existing studies were\nconducted under a supervised setup which cannot scale well while handling\nvarious new data. Unsupervised domain adaptive BEV, which effective learning\nfrom various unlabelled target data, is far under-explored. In this work, we\ndesign DA-BEV, the first domain adaptive camera-only BEV framework that\naddresses domain adaptive BEV challenges by exploiting the complementary nature\nof image-view features and BEV features. DA-BEV introduces the idea of query\ninto the domain adaptation framework to derive useful information from\nimage-view and BEV features. It consists of two query-based designs, namely,\nquery-based adversarial learning (QAL) and query-based self-training (QST),\nwhich exploits image-view features or BEV features to regularize the adaptation\nof the other. Extensive experiments show that DA-BEV achieves superior domain\nadaptive BEV perception performance consistently across multiple datasets and\ntasks such as 3D object detection and 3D scene segmentation.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.08688", "title": "Automated Answer Validation using Text Similarity", "abstract": "Automated answer validation can help improve learning outcomes by providing\nappropriate feedback to learners, and by making question answering systems and\nonline learning solutions more widely available. There have been some works in\nscience question answering which show that information retrieval methods\noutperform neural methods, especially in the multiple choice version of this\nproblem. We implement Siamese neural network models and produce a generalised\nsolution to this problem. We compare our supervised model with other text\nsimilarity based solutions.", "field": "Computer Science", "categories": "cs.CL,cs.IR"}, {"arxiv_id": "2401.08689", "title": "NODI: Out-Of-Distribution Detection with Noise from Diffusion", "abstract": "Out-of-distribution (OOD) detection is a crucial part of deploying machine\nlearning models safely. It has been extensively studied with a plethora of\nmethods developed in the literature. This problem is tackled with an OOD score\ncomputation, however, previous methods compute the OOD scores with limited\nusage of the in-distribution dataset. For instance, the OOD scores are computed\nwith information from a small portion of the in-distribution data. Furthermore,\nthese methods encode images with a neural image encoder. The robustness of\nthese methods is rarely checked with respect to image encoders of different\ntraining methods and architectures. In this work, we introduce the diffusion\nprocess into the OOD task. The diffusion model integrates information on the\nwhole training set into the predicted noise vectors. What's more, we deduce a\nclosed-form solution for the noise vector (stable point). Then the noise vector\nis converted into our OOD score, we test both the deep model predicted noise\nvector and the closed-form noise vector on the OOD benchmarks \\cite{openood}.\nOur method outperforms previous OOD methods across all types of image encoders\n(Table. \\ref{main}). A $3.5\\%$ performance gain is achieved with the MAE-based\nimage encoder. Moreover, we studied the robustness of OOD methods by applying\ndifferent types of image encoders. Some OOD methods failed to generalize well\nwhen switching image encoders from ResNet to Vision Transformers, our method\nperforms exhibits good robustness with all the image encoders.", "field": "Computer Science", "categories": "cs.CV,cs.LG"}, {"arxiv_id": "2401.0869", "title": "Contrastive Learning with Negative Sampling Correction", "abstract": "As one of the most effective self-supervised representation learning methods,\ncontrastive learning (CL) relies on multiple negative pairs to contrast against\neach positive pair. In the standard practice of contrastive learning, data\naugmentation methods are utilized to generate both positive and negative pairs.\nWhile existing works have been focusing on improving the positive sampling, the\nnegative sampling process is often overlooked. In fact, the generated negative\nsamples are often polluted by positive samples, which leads to a biased loss\nand performance degradation. To correct the negative sampling bias, we propose\na novel contrastive learning method named Positive-Unlabeled Contrastive\nLearning (PUCL). PUCL treats the generated negative samples as unlabeled\nsamples and uses information from positive samples to correct bias in\ncontrastive loss. We prove that the corrected loss used in PUCL only incurs a\nnegligible bias compared to the unbiased contrastive loss. PUCL can be applied\nto general contrastive learning problems and outperforms state-of-the-art\nmethods on various image and graph classification tasks. The code of PUCL is in\nthe supplementary file.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.08694", "title": "Combining Confidence Elicitation and Sample-based Methods for\n  Uncertainty Quantification in Misinformation Mitigation", "abstract": "Large Language Models have emerged as prime candidates to tackle\nmisinformation mitigation. However, existing approaches struggle with\nhallucinations and overconfident predictions. We propose an uncertainty\nquantification framework that leverages both direct confidence elicitation and\nsampled-based consistency methods to provide better calibration for NLP\nmisinformation mitigation solutions. We first investigate the calibration of\nsample-based consistency methods that exploit distinct features of consistency\nacross sample sizes and stochastic levels. Next, we evaluate the performance\nand distributional shift of a robust numeric verbalization prompt across single\nvs. two-step confidence elicitation procedure. We also compare the performance\nof the same prompt with different versions of GPT and different numerical\nscales. Finally, we combine the sample-based consistency and verbalized methods\nto propose a hybrid framework that yields a better uncertainty estimation for\nGPT models. Overall, our work proposes novel uncertainty quantification methods\nthat will improve the reliability of Large Language Models in misinformation\nmitigation applications.", "field": "Computer Science", "categories": "cs.CL,cs.AI"}, {"arxiv_id": "2401.08695", "title": "Enabling Collaborative Clinical Diagnosis of Infectious Keratitis by\n  Integrating Expert Knowledge and Interpretable Data-driven Intelligence", "abstract": "Although data-driven artificial intelligence (AI) in medical image diagnosis\nhas shown impressive performance in silico, the lack of interpretability makes\nit difficult to incorporate the \"black box\" into clinicians' workflows. To make\nthe diagnostic patterns learned from data understandable by clinicians, we\ndevelop an interpretable model, knowledge-guided diagnosis model (KGDM), that\nprovides a visualized reasoning process containing AI-based biomarkers and\nretrieved cases that with the same diagnostic patterns. It embraces clinicians'\nprompts into the interpreted reasoning through human-AI interaction, leading to\npotentially enhanced safety and more accurate predictions. This study\ninvestigates the performance, interpretability, and clinical utility of KGDM in\nthe diagnosis of infectious keratitis (IK), which is the leading cause of\ncorneal blindness. The classification performance of KGDM is evaluated on a\nprospective validation dataset, an external testing dataset, and an publicly\navailable testing dataset. The diagnostic odds ratios (DOR) of the interpreted\nAI-based biomarkers are effective, ranging from 3.011 to 35.233 and exhibit\nconsistent diagnostic patterns with clinic experience. Moreover, a human-AI\ncollaborative diagnosis test is conducted and the participants with\ncollaboration achieved a performance exceeding that of both humans and AI. By\nsynergistically integrating interpretability and interaction, this study\nfacilitates the convergence of clinicians' expertise and data-driven\nintelligence. The promotion of inexperienced ophthalmologists with the aid of\nAI-based biomarkers, as well as increased AI prediction by intervention from\nexperienced ones, demonstrate a promising diagnostic paradigm for infectious\nkeratitis using KGDM, which holds the potential for extension to other diseases\nwhere experienced medical practitioners are limited and the safety of AI is\nconcerned.", "field": "Computer Science", "categories": "cs.AI,cs.CV,cs.HC"}, {"arxiv_id": "2401.08696", "title": "Hierarchical Source-to-Post-Route QoR Prediction in High-Level Synthesis\n  with GNNs", "abstract": "High-level synthesis (HLS) notably speeds up the hardware design process by\navoiding RTL programming. However, the turnaround time of HLS increases\nsignificantly when post-route quality of results (QoR) are considered during\noptimization. To tackle this issue, we propose a hierarchical post-route QoR\nprediction approach for FPGA HLS, which features: (1) a modeling flow that\ndirectly estimates latency and post-route resource usage from C/C++ programs;\n(2) a graph construction method that effectively represents the control and\ndata flow graph of source code and effects of HLS pragmas; and (3) a\nhierarchical GNN training and prediction method capable of capturing the impact\nof loop hierarchies. Experimental results show that our method presents a\nprediction error of less than 10% for different types of QoR metrics, which\ngains tremendous improvement compared with the state-of-the-art GNN methods. By\nadopting our proposed methodology, the runtime for design space exploration in\nHLS is shortened to tens of minutes and the achieved ADRS is reduced to 6.91%\non average.", "field": "Computer Science", "categories": "cs.AR,cs.AI,cs.LG"}, {"arxiv_id": "2401.08703", "title": "Decoupled Prototype Learning for Reliable Test-Time Adaptation", "abstract": "Test-time adaptation (TTA) is a task that continually adapts a pre-trained\nsource model to the target domain during inference. One popular approach\ninvolves fine-tuning model with cross-entropy loss according to estimated\npseudo-labels. However, its performance is significantly affected by noisy\npseudo-labels. This study reveals that minimizing the classification error of\neach sample causes the cross-entropy loss's vulnerability to label noise. To\naddress this issue, we propose a novel Decoupled Prototype Learning (DPL)\nmethod that features prototype-centric loss computation. First, we decouple the\noptimization of class prototypes. For each class prototype, we reduce its\ndistance with positive samples and enlarge its distance with negative samples\nin a contrastive manner. This strategy prevents the model from overfitting to\nnoisy pseudo-labels. Second, we propose a memory-based strategy to enhance\nDPL's robustness for the small batch sizes often encountered in TTA. We update\neach class's pseudo-feature from a memory in a momentum manner and insert an\nadditional DPL loss. Finally, we introduce a consistency regularization-based\napproach to leverage samples with unconfident pseudo-labels. This approach\ntransfers feature styles of samples with unconfident pseudo-labels to those\nwith confident pseudo-labels. Thus, more reliable samples for TTA are created.\nThe experimental results demonstrate that our methods achieve state-of-the-art\nperformance on domain generalization benchmarks, and reliably improve the\nperformance of self-training-based methods on image corruption benchmarks. The\ncode will be released.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.0871", "title": "Dynamic Voltage and Frequency Scaling for Intermittent Computing", "abstract": "We present hardware/software techniques to intelligently regulate supply\nvoltage and clock frequency of intermittently-computing devices. These devices\nrely on ambient energy harvesting to power their operation and small capacitors\nas energy buffers. Statically setting their clock frequency fails to capture\nthe unique relations these devices expose between capacitor voltage, energy\nefficiency at a given operating frequency, and the corresponding operating\nrange. Existing dynamic voltage and frequency scaling techniques are also\nlargely inapplicable due to extreme energy scarcity and peculiar hardware\nfeatures. We introduce two hardware/software co-designs that accommodate the\ndistinct hardware features and function within a constrained energy envelope,\noffering varied trade-offs and functionalities. Our experimental evaluation\ncombines tests on custom-manufactured hardware and detailed emulation\nexperiments. The data gathered indicate that our approaches result in up to\n3.75x reduced energy consumption and 12x swifter execution times compared to\nthe considered baselines, all while utilizing smaller capacitors to accomplish\nidentical workloads.", "field": "Computer Science", "categories": "cs.AR,cs.OS"}, {"arxiv_id": "2401.08711", "title": "Assistant, Parrot, or Colonizing Loudspeaker? ChatGPT Metaphors for\n  Developing Critical AI Literacies", "abstract": "This study explores how discussing metaphors for AI can help build awareness\nof the frames that shape our understanding of AI systems, particularly large\nlanguage models (LLMs) like ChatGPT. Given the pressing need to teach \"critical\nAI literacy\", discussion of metaphor provides an opportunity for inquiry and\ndialogue with space for nuance, playfulness, and critique. Using a\ncollaborative autoethnographic methodology, we analyzed metaphors from a range\nof sources, and reflected on them individually according to seven questions,\nthen met and discussed our interpretations. We then analyzed how our\nreflections contributed to the three kinds of literacies delineated in Selber's\nmultiliteracies framework: functional, critical, and rhetorical. These allowed\nus to analyze questions of ethics, equity, and accessibility in relation to AI.\nWe explored each metaphor along the dimension of whether or not it was\npromoting anthropomorphizing, and to what extent such metaphors imply that AI\nis sentient. Our findings highlight the role of metaphor reflection in\nfostering a nuanced understanding of AI, suggesting that our collaborative\nautoethnographic approach as well as the heuristic model of plotting AI\nmetaphors on dimensions of anthropomorphism and multiliteracies, might be\nuseful for educators and researchers in the pursuit of advancing critical AI\nliteracy.", "field": "Computer Science", "categories": "cs.HC,cs.AI,cs.CY,I.2.0; K.3.0; K.3.1; K.4.0; K.4.2; J.4; J.5"}, {"arxiv_id": "2401.08714", "title": "Training program on sign language: social inclusion through Virtual\n  Reality in ISENSE project", "abstract": "Structured hand gestures that incorporate visual motions and signs are used\nin sign language. Sign language is a valuable means of daily communication for\nindividuals who are deaf or have speech impairments, but it is still rare among\nhearing people, and fewer are capable of understand it. Within the academic\ncontext, parents and teachers play a crucial role in supporting deaf students\nfrom childhood by facilitating their learning of sign language. In the last\nyears, among all the teaching tools useful for learning sign language, the use\nof Virtual Reality (VR) has increased, as it has been demonstrated to improve\nretention, memory and attention during the learning process. The ISENSE project\nhas been created to assist students with deafness during their academic life by\nproposing different technological tools for teaching sign language to the\nhearing community in the academic context. As part of the ISENSE project, this\nwork aims to develop an application for Spanish and Italian sign language\nrecognition that exploits the VR environment to quickly and easily create a\ncomprehensive database of signs and an Artificial Intelligence (AI)-based\nsoftware to accurately classify and recognize static and dynamic signs: from\nletters to sentences.", "field": "Computer Science", "categories": "cs.HC,cs.AI,cs.CV,cs.GR"}, {"arxiv_id": "2401.08715", "title": "Selecting Subsets of Source Data for Transfer Learning with Applications\n  in Metal Additive Manufacturing", "abstract": "Considering data insufficiency in metal additive manufacturing (AM), transfer\nlearning (TL) has been adopted to extract knowledge from source domains (e.g.,\ncompleted printings) to improve the modeling performance in target domains\n(e.g., new printings). Current applications use all accessible source data\ndirectly in TL with no regard to the similarity between source and target data.\nThis paper proposes a systematic method to find appropriate subsets of source\ndata based on similarities between the source and target datasets for a given\nset of limited target domain data. Such similarity is characterized by the\nspatial and model distance metrics. A Pareto frontier-based source data\nselection method is developed, where the source data located on the Pareto\nfrontier defined by two similarity distance metrics are selected iteratively.\nThe method is integrated into an instance-based TL method (decision tree\nregression model) and a model-based TL method (fine-tuned artificial neural\nnetwork). Both models are then tested on several regression tasks in metal AM.\nComparison results demonstrate that 1) the source data selection method is\ngeneral and supports integration with various TL methods and distance metrics,\n2) compared with using all source data, the proposed method can find a small\nsubset of source data from the same domain with better TL performance in metal\nAM regression tasks involving different processes and machines, and 3) when\nmultiple source domains exist, the source data selection method could find the\nsubset from one source domain to obtain comparable or better TL performance\nthan the model constructed using data from all source domains.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.08717", "title": "Robust DOA estimation using deep acoustic imaging", "abstract": "Direction of arrival estimation (DoAE) aims at tracking a sound in azimuth\nand elevation. Recent advancements include data-driven models with inputs\nderived from ambisonics intensity vectors or correlations between channels in a\nmicrophone array. A spherical intensity map (SIM), or acoustic image, is an\nalternative input representation that remains underexplored. SIMs benefit from\nhigh-resolution microphone arrays, yet most DoAE datasets use low-resolution\nones. Therefore, we first propose a super-resolution method to upsample\nlow-resolution microphones. Next, we benchmark DoAE models that use SIMs as\ninput. We arrive to a model that uses SIMs for DoAE estimation and outperforms\na baseline and a state-of-the-art model. Our study highlights the relevance of\nacoustic imaging for DoAE tasks.", "field": "Computer Science", "categories": "cs.SD,eess.AS"}, {"arxiv_id": "2401.08718", "title": "Investigating Fouling Efficiency in Football Using Expected Booking (xB)\n  Model", "abstract": "This paper introduces the Expected Booking (xB) model, a novel metric\ndesigned to estimate the likelihood of a foul resulting in a yellow card in\nfootball. Through three iterative experiments, employing ensemble methods, the\nmodel demonstrates improved performance with additional features and an\nexpanded dataset. Analysis of FIFA World Cup 2022 data validates the model's\nefficacy in providing insights into team and player fouling tactics, aligning\nwith actual defensive performance. The xB model addresses a gap in fouling\nefficiency examination, emphasizing defensive strategies which often\noverlooked. Further enhancements are suggested through the incorporation of\ncomprehensive data and spatial features.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.08719", "title": "CodeComplex: A Time-Complexity Dataset for Bilingual Source Codes", "abstract": "Analyzing the worst-case time complexity of a code is a crucial task in\ncomputer science and software engineering for ensuring the efficiency,\nreliability, and robustness of software systems. However, it is well-known that\nthe problem of determining the worst-case time complexity of a given code\nwritten in general-purpose programming language is theoretically undecidable by\nthe famous Halting problem proven by Alan Turing. Thus, we move towards more\nrealistic scenarios where the inputs and outputs of a program exist. This\nallows us to discern the correctness of given codes, challenging to analyze\ntheir time complexity exhaustively. In response to this challenge, we introduce\nCodeComplex, a novel source code dataset where each code is manually annotated\nwith a corresponding worst-case time complexity. CodeComplex comprises 4,900\nJava codes and an equivalent number of Python codes, all sourced from\nprogramming competitions and annotated with complexity labels by a panel of\nalgorithmic experts. To the best of our knowledge, CodeComplex stands as the\nmost extensive code dataset tailored for predicting complexity. Subsequently,\nwe present the outcomes of our experiments employing various baseline models,\nleveraging state-of-the-art neural models in code comprehension like CodeBERT,\nGraphCodeBERT, UniXcoder, PLBART, CodeT5, CodeT5+, and ChatGPT. We analyze how\nthe dataset impacts the model's learning in predicting time complexity.", "field": "Computer Science", "categories": "cs.SE,cs.CC"}, {"arxiv_id": "2401.0872", "title": "Unsupervised Pre-Training for 3D Leaf Instance Segmentation", "abstract": "Crops for food, feed, fiber, and fuel are key natural resources for our\nsociety. Monitoring plants and measuring their traits is an important task in\nagriculture often referred to as plant phenotyping. Traditionally, this task is\ndone manually, which is time- and labor-intensive. Robots can automate\nphenotyping providing reproducible and high-frequency measurements. Today's\nperception systems use deep learning to interpret these measurements, but\nrequire a substantial amount of annotated data to work well. Obtaining such\nlabels is challenging as it often requires background knowledge on the side of\nthe labelers. This paper addresses the problem of reducing the labeling effort\nrequired to perform leaf instance segmentation on 3D point clouds, which is a\nfirst step toward phenotyping in 3D. Separating all leaves allows us to count\nthem and compute relevant traits as their areas, lengths, and widths. We\npropose a novel self-supervised task-specific pre-training approach to\ninitialize the backbone of a network for leaf instance segmentation. We also\nintroduce a novel automatic postprocessing that considers the difficulty of\ncorrectly segmenting the points close to the stem, where all the leaves petiole\noverlap. The experiments presented in this paper suggest that our approach\nboosts the performance over all the investigated scenarios. We also evaluate\nthe embeddings to assess the quality of the fully unsupervised approach and see\na higher performance of our domain-specific postprocessing.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.08721", "title": "A Telerehabilitation System for the Selection, Evaluation and Remote\n  Management of Therapies", "abstract": "Telerehabilitation systems that support physical therapy sessions anywhere\ncan help save healthcare costs while also improving the quality of life of the\nusers that need rehabilitation. The main contribution of this paper is to\npresent, as a whole, all the features supported by the innovative Kinect-based\nTelerehabilitation System (KiReS). In addition to the functionalities provided\nby current systems, it handles two new ones that could be incorporated into\nthem, in order to give a step forward towards a new generation of\ntelerehabilitation systems. The knowledge extraction functionality handles\nknowledge about the physical therapy record of patients and treatment protocols\ndescribed in an ontology, named TRHONT, to select the adequate exercises for\nthe rehabilitation of patients. The teleimmersion functionality provides a\nconvenient, effective and user-friendly experience when performing the\ntelerehabilitation, through a two-way real-time multimedia communication. The\nontology contains about 2300 classes and 100 properties, and the system allows\na reliable transmission of Kinect video depth, audio and skeleton data, being\nable to adapt to various network conditions. Moreover, the system has been\ntested with patients who suffered from shoulder disorders or total hip\nreplacement.", "field": "Computer Science", "categories": "cs.HC,cs.AI"}, {"arxiv_id": "2401.08723", "title": "HierSFL: Local Differential Privacy-aided Split Federated Learning in\n  Mobile Edge Computing", "abstract": "Federated Learning is a promising approach for learning from user data while\npreserving data privacy. However, the high requirements of the model training\nprocess make it difficult for clients with limited memory or bandwidth to\nparticipate. To tackle this problem, Split Federated Learning is utilized,\nwhere clients upload their intermediate model training outcomes to a cloud\nserver for collaborative server-client model training. This methodology\nfacilitates resource-constrained clients' participation in model training but\nalso increases the training time and communication overhead. To overcome these\nlimitations, we propose a novel algorithm, called Hierarchical Split Federated\nLearning (HierSFL), that amalgamates models at the edge and cloud phases,\npresenting qualitative directives for determining the best aggregation\ntimeframes to reduce computation and communication expenses. By implementing\nlocal differential privacy at the client and edge server levels, we enhance\nprivacy during local model parameter updates. Our experiments using CIFAR-10\nand MNIST datasets show that HierSFL outperforms standard FL approaches with\nbetter training accuracy, training time, and communication-computing\ntrade-offs. HierSFL offers a promising solution to mobile edge computing's\nchallenges, ultimately leading to faster content delivery and improved mobile\nservice quality.", "field": "Computer Science", "categories": "cs.CR,cs.CV,cs.DC,cs.LG"}, {"arxiv_id": "2401.08725", "title": "Revealing Vulnerabilities in Stable Diffusion via Targeted Attacks", "abstract": "Recent developments in text-to-image models, particularly Stable Diffusion,\nhave marked significant achievements in various applications. With these\nadvancements, there are growing safety concerns about the vulnerability of the\nmodel that malicious entities exploit to generate targeted harmful images.\nHowever, the existing methods in the vulnerability of the model mainly evaluate\nthe alignment between the prompt and generated images, but fall short in\nrevealing the vulnerability associated with targeted image generation. In this\nstudy, we formulate the problem of targeted adversarial attack on Stable\nDiffusion and propose a framework to generate adversarial prompts.\nSpecifically, we design a gradient-based embedding optimization method to craft\nreliable adversarial prompts that guide stable diffusion to generate specific\nimages. Furthermore, after obtaining successful adversarial prompts, we reveal\nthe mechanisms that cause the vulnerability of the model. Extensive experiments\non two targeted attack tasks demonstrate the effectiveness of our method in\ntargeted attacks. The code can be obtained in\nhttps://github.com/datar001/Revealing-Vulnerabilities-in-Stable-Diffusion-via-Targeted-Attacks.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.08727", "title": "MA2GCN: Multi Adjacency relationship Attention Graph Convolutional\n  Networks for Traffic Prediction using Trajectory data", "abstract": "The problem of traffic congestion not only causes a large amount of economic\nlosses, but also seriously endangers the urban environment. Predicting traffic\ncongestion has important practical significance. So far, most studies have been\nbased on historical data from sensors placed on different roads to predict\nfuture traffic flow and speed, to analyze the traffic congestion conditions of\na certain road segment. However, due to the fixed position of sensors, it is\ndifficult to mine new information. On the other hand, vehicle trajectory data\nis more flexible and can extract traffic information as needed. Therefore, we\nproposed a new traffic congestion prediction model - Multi Adjacency\nrelationship Attention Graph Convolutional Networks(MA2GCN). This model\ntransformed vehicle trajectory data into graph structured data in grid form,\nand proposed a vehicle entry and exit matrix based on the mobility between\ndifferent grids. At the same time, in order to improve the performance of the\nmodel, this paper also built a new adaptive adjacency matrix generation method\nand adjacency matrix attention module. This model mainly used gated temporal\nconvolution and graph convolution to extract temporal and spatial information,\nrespectively. Compared with multiple baselines, our model achieved the best\nperformance on Shanghai taxi GPS trajectory dataset. The code is available at\nhttps://github.com/zachysun/Taxi Traffic Benchmark.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.08728", "title": "AgentMixer: Multi-Agent Correlated Policy Factorization", "abstract": "Centralized training with decentralized execution (CTDE) is widely employed\nto stabilize partially observable multi-agent reinforcement learning (MARL) by\nutilizing a centralized value function during training. However, existing\nmethods typically assume that agents make decisions based on their local\nobservations independently, which may not lead to a correlated joint policy\nwith sufficient coordination. Inspired by the concept of correlated\nequilibrium, we propose to introduce a \\textit{strategy modification} to\nprovide a mechanism for agents to correlate their policies. Specifically, we\npresent a novel framework, AgentMixer, which constructs the joint fully\nobservable policy as a non-linear combination of individual partially\nobservable policies. To enable decentralized execution, one can derive\nindividual policies by imitating the joint policy. Unfortunately, such\nimitation learning can lead to \\textit{asymmetric learning failure} caused by\nthe mismatch between joint policy and individual policy information. To\nmitigate this issue, we jointly train the joint policy and individual policies\nand introduce \\textit{Individual-Global-Consistency} to guarantee mode\nconsistency between the centralized and decentralized policies. We then\ntheoretically prove that AgentMixer converges to an $\\epsilon$-approximate\nCorrelated Equilibrium. The strong experimental performance on three MARL\nbenchmarks demonstrates the effectiveness of our method.", "field": "Computer Science", "categories": "cs.MA,cs.AI"}, {"arxiv_id": "2401.08732", "title": "Bayes Conditional Distribution Estimation for Knowledge Distillation\n  Based on Conditional Mutual Information", "abstract": "It is believed that in knowledge distillation (KD), the role of the teacher\nis to provide an estimate for the unknown Bayes conditional probability\ndistribution (BCPD) to be used in the student training process. Conventionally,\nthis estimate is obtained by training the teacher using maximum log-likelihood\n(MLL) method. To improve this estimate for KD, in this paper we introduce the\nconcept of conditional mutual information (CMI) into the estimation of BCPD and\npropose a novel estimator called the maximum CMI (MCMI) method. Specifically,\nin MCMI estimation, both the log-likelihood and CMI of the teacher are\nsimultaneously maximized when the teacher is trained. Through Eigen-CAM, it is\nfurther shown that maximizing the teacher's CMI value allows the teacher to\ncapture more contextual information in an image cluster. Via conducting a\nthorough set of experiments, we show that by employing a teacher trained via\nMCMI estimation rather than one trained via MLL estimation in various\nstate-of-the-art KD frameworks, the student's classification accuracy\nconsistently increases, with the gain of up to 3.32\\%. This suggests that the\nteacher's BCPD estimate provided by MCMI method is more accurate than that\nprovided by MLL method. In addition, we show that such improvements in the\nstudent's accuracy are more drastic in zero-shot and few-shot settings.\nNotably, the student's accuracy increases with the gain of up to 5.72\\% when\n5\\% of the training samples are available to the student (few-shot), and\nincreases from 0\\% to as high as 84\\% for an omitted class (zero-shot). The\ncode is available at \\url{https://github.com/iclr2024mcmi/ICLRMCMI}.", "field": "Computer Science", "categories": "cs.LG,cs.CV,cs.IT,math.IT,68T30,I.2.6"}, {"arxiv_id": "2401.08733", "title": "In the Eyes of the Bystander: Are the Stances on Different Conflicts\n  Correlated?", "abstract": "Public opinion on international conflicts, such as the concurrent\nRussia-Ukraine and Israel-Palestine crises, often reflects a society's values,\nbeliefs, and history. These simultaneous conflicts have sparked heated global\nonline discussions, offering a unique opportunity to explore the dynamics of\npublic opinion in multiple international crises. This study investigates how\npublic opinions toward one conflict might influence or relate to another, a\nrelatively unexplored area in contemporary research. Focusing on Chinese\nnetizens, who represent a significant online population, this study examines\ntheir perspectives, which are increasingly influential in global discourse due\nto China's unique cultural and political landscape. The research finds a range\nof opinions, including neutral stances towards both conflicts and a statistical\ncorrelation between attitudes towards each, indicating interconnected or\nmutually influenced viewpoints. The study also highlights the significant role\nof news media, particularly in China, where state policies and global politics\nshape conflict portrayal, in impacting public opinion.", "field": "Computer Science", "categories": "cs.SI"}, {"arxiv_id": "2401.08734", "title": "Bag of Tricks to Boost Adversarial Transferability", "abstract": "Deep neural networks are widely known to be vulnerable to adversarial\nexamples. However, vanilla adversarial examples generated under the white-box\nsetting often exhibit low transferability across different models. Since\nadversarial transferability poses more severe threats to practical\napplications, various approaches have been proposed for better transferability,\nincluding gradient-based, input transformation-based, and model-related\nattacks, \\etc. In this work, we find that several tiny changes in the existing\nadversarial attacks can significantly affect the attack performance, \\eg, the\nnumber of iterations and step size. Based on careful studies of existing\nadversarial attacks, we propose a bag of tricks to enhance adversarial\ntransferability, including momentum initialization, scheduled step size, dual\nexample, spectral-based input transformation, and several ensemble strategies.\nExtensive experiments on the ImageNet dataset validate the high effectiveness\nof our proposed tricks and show that combining them can further boost\nadversarial transferability. Our work provides practical insights and\ntechniques to enhance adversarial transferability, and offers guidance to\nimprove the attack performance on the real-world application through simple\nadjustments.", "field": "Computer Science", "categories": "cs.CV,cs.LG"}, {"arxiv_id": "2401.08739", "title": "EgoGen: An Egocentric Synthetic Data Generator", "abstract": "Understanding the world in first-person view is fundamental in Augmented\nReality (AR). This immersive perspective brings dramatic visual changes and\nunique challenges compared to third-person views. Synthetic data has empowered\nthird-person-view vision models, but its application to embodied egocentric\nperception tasks remains largely unexplored. A critical challenge lies in\nsimulating natural human movements and behaviors that effectively steer the\nembodied cameras to capture a faithful egocentric representation of the 3D\nworld. To address this challenge, we introduce EgoGen, a new synthetic data\ngenerator that can produce accurate and rich ground-truth training data for\negocentric perception tasks. At the heart of EgoGen is a novel human motion\nsynthesis model that directly leverages egocentric visual inputs of a virtual\nhuman to sense the 3D environment. Combined with collision-avoiding motion\nprimitives and a two-stage reinforcement learning approach, our motion\nsynthesis model offers a closed-loop solution where the embodied perception and\nmovement of the virtual human are seamlessly coupled. Compared to previous\nworks, our model eliminates the need for a pre-defined global path, and is\ndirectly applicable to dynamic environments. Combined with our easy-to-use and\nscalable data generation pipeline, we demonstrate EgoGen's efficacy in three\ntasks: mapping and localization for head-mounted cameras, egocentric camera\ntracking, and human mesh recovery from egocentric views. EgoGen will be fully\nopen-sourced, offering a practical solution for creating realistic egocentric\ntraining data and aiming to serve as a useful tool for egocentric computer\nvision research. Refer to our project page: https://ego-gen.github.io/.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.0874", "title": "SiT: Exploring Flow and Diffusion-based Generative Models with Scalable\n  Interpolant Transformers", "abstract": "We present Scalable Interpolant Transformers (SiT), a family of generative\nmodels built on the backbone of Diffusion Transformers (DiT). The interpolant\nframework, which allows for connecting two distributions in a more flexible way\nthan standard diffusion models, makes possible a modular study of various\ndesign choices impacting generative models built on dynamical transport: using\ndiscrete vs. continuous time learning, deciding the objective for the model to\nlearn, choosing the interpolant connecting the distributions, and deploying a\ndeterministic or stochastic sampler. By carefully introducing the above\ningredients, SiT surpasses DiT uniformly across model sizes on the conditional\nImageNet 256x256 benchmark using the exact same backbone, number of parameters,\nand GFLOPs. By exploring various diffusion coefficients, which can be tuned\nseparately from learning, SiT achieves an FID-50K score of 2.06.", "field": "Computer Science", "categories": "cs.CV,cs.LG"}, {"arxiv_id": "2401.08741", "title": "Fixed Point Diffusion Models", "abstract": "We introduce the Fixed Point Diffusion Model (FPDM), a novel approach to\nimage generation that integrates the concept of fixed point solving into the\nframework of diffusion-based generative modeling. Our approach embeds an\nimplicit fixed point solving layer into the denoising network of a diffusion\nmodel, transforming the diffusion process into a sequence of closely-related\nfixed point problems. Combined with a new stochastic training method, this\napproach significantly reduces model size, reduces memory usage, and\naccelerates training. Moreover, it enables the development of two new\ntechniques to improve sampling efficiency: reallocating computation across\ntimesteps and reusing fixed point solutions between timesteps. We conduct\nextensive experiments with state-of-the-art models on ImageNet, FFHQ,\nCelebA-HQ, and LSUN-Church, demonstrating substantial improvements in\nperformance and efficiency. Compared to the state-of-the-art DiT model, FPDM\ncontains 87% fewer parameters, consumes 60% less memory during training, and\nimproves image generation quality in situations where sampling computation or\ntime is limited. Our code and pretrained models are available at\nhttps://lukemelas.github.io/fixed-point-diffusion-models.", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.LG"}, {"arxiv_id": "2401.08742", "title": "Fast Dynamic 3D Object Generation from a Single-view Video", "abstract": "Generating dynamic three-dimensional (3D) object from a single-view video is\nchallenging due to the lack of 4D labeled data. Existing methods extend\ntext-to-3D pipelines by transferring off-the-shelf image generation models such\nas score distillation sampling, but they are slow and expensive to scale (e.g.,\n150 minutes per object) due to the need for back-propagating the\ninformation-limited supervision signals through a large pretrained model. To\naddress this limitation, we propose an efficient video-to-4D object generation\nframework called Efficient4D. It generates high-quality spacetime-consistent\nimages under different camera views, and then uses them as labeled data to\ndirectly train a novel 4D Gaussian splatting model with explicit point cloud\ngeometry, enabling real-time rendering under continuous camera trajectories.\nExtensive experiments on synthetic and real videos show that Efficient4D offers\na remarkable 10-fold increase in speed when compared to prior art alternatives\nwhile preserving the same level of innovative view synthesis quality. For\nexample, Efficient4D takes only 14 minutes to model a dynamic object.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.08743", "title": "MMToM-QA: Multimodal Theory of Mind Question Answering", "abstract": "Theory of Mind (ToM), the ability to understand people's minds, is an\nessential ingredient for developing machines with human-level social\nintelligence. Recent machine learning models, particularly large language\nmodels, seem to show some aspects of ToM understanding. However, existing ToM\nbenchmarks use unimodal datasets - either video or text. Human ToM, on the\nother hand, is more than video or text understanding. People can flexibly\nreason about another person's mind based on conceptual representations (e.g.,\ngoals, beliefs, plans) extracted from any available data, which can include\nvisual cues, linguistic narratives, or both. To address this, we introduce a\nmultimodal Theory of Mind question answering (MMToM-QA) benchmark. MMToM-QA\ncomprehensively evaluates machine ToM both on multimodal data and on different\nkinds of unimodal data about a person's activity in a household environment. To\nengineer multimodal ToM capacity, we propose a novel method, BIP-ALM (Bayesian\nInverse Planning Accelerated by Language Models). BIP-ALM extracts unified\nrepresentations from multimodal data and utilizes language models for scalable\nBayesian inverse planning. We conducted a systematic comparison of human\nperformance, BIP-ALM, and state-of-the-art models, including GPT-4. The\nexperiments demonstrate that large language models and large multimodal models\nstill lack robust ToM capacity. BIP-ALM, on the other hand, shows promising\nresults, by leveraging the power of both model-based mental inference and\nlanguage models.", "field": "Computer Science", "categories": "cs.AI,cs.CL,cs.CV,cs.LG"}, {"arxiv_id": "2401.08772", "title": "HuixiangDou: Overcoming Group Chat Scenarios with LLM-based Technical\n  Assistance", "abstract": "In this work, we present HuixiangDou, a technical assistant powered by Large\nLanguage Models (LLM). This system is designed to assist algorithm developers\nby providing insightful responses to questions related to open-source algorithm\nprojects, such as computer vision and deep learning projects from OpenMMLab. We\nfurther explore the integration of this assistant into the group chats of\ninstant messaging (IM) tools such as WeChat and Lark. Through several iterative\nimprovements and trials, we have developed a sophisticated technical chat\nassistant capable of effectively answering users' technical questions without\ncausing message flooding. This paper's contributions include: 1) Designing an\nalgorithm pipeline specifically for group chat scenarios; 2) Verifying the\nreliable performance of text2vec in task rejection; 3) Identifying three\ncritical requirements for LLMs in technical-assistant-like products, namely\nscoring ability, In-Context Learning (ICL), and Long Context. We have made the\nsoftware and source code available at https://github.com/internlm/huixiangdou\nto aid in future research and application. HuixiangDou is applicable to any\ngroup chat within IM tools.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.08787", "title": "Segment Anything Model Can Not Segment Anything: Assessing AI Foundation\n  Model's Generalizability in Permafrost Mapping", "abstract": "This paper assesses trending AI foundation models, especially emerging\ncomputer vision foundation models and their performance in natural landscape\nfeature segmentation. While the term foundation model has quickly garnered\ninterest from the geospatial domain, its definition remains vague. Hence, this\npaper will first introduce AI foundation models and their defining\ncharacteristics. Built upon the tremendous success achieved by Large Language\nModels (LLMs) as the foundation models for language tasks, this paper discusses\nthe challenges of building foundation models for geospatial artificial\nintelligence (GeoAI) vision tasks. To evaluate the performance of large AI\nvision models, especially Meta's Segment Anything Model (SAM), we implemented\ndifferent instance segmentation pipelines that minimize the changes to SAM to\nleverage its power as a foundation model. A series of prompt strategies was\ndeveloped to test SAM's performance regarding its theoretical upper bound of\npredictive accuracy, zero-shot performance, and domain adaptability through\nfine-tuning. The analysis used two permafrost feature datasets, ice-wedge\npolygons and retrogressive thaw slumps because (1) these landform features are\nmore challenging to segment than manmade features due to their complicated\nformation mechanisms, diverse forms, and vague boundaries; (2) their presence\nand changes are important indicators for Arctic warming and climate change. The\nresults show that although promising, SAM still has room for improvement to\nsupport AI-augmented terrain mapping. The spatial and domain generalizability\nof this finding is further validated using a more general dataset EuroCrop for\nagricultural field mapping. Finally, we discuss future research directions that\nstrengthen SAM's applicability in challenging geospatial domains.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.08788", "title": "The Impact of Differential Feature Under-reporting on Algorithmic\n  Fairness", "abstract": "Predictive risk models in the public sector are commonly developed using\nadministrative data that is more complete for subpopulations that more greatly\nrely on public services. In the United States, for instance, information on\nhealth care utilization is routinely available to government agencies for\nindividuals supported by Medicaid and Medicare, but not for the privately\ninsured. Critiques of public sector algorithms have identified such\ndifferential feature under-reporting as a driver of disparities in algorithmic\ndecision-making. Yet this form of data bias remains understudied from a\ntechnical viewpoint. While prior work has examined the fairness impacts of\nadditive feature noise and features that are clearly marked as missing, the\nsetting of data missingness absent indicators (i.e. differential feature\nunder-reporting) has been lacking in research attention. In this work, we\npresent an analytically tractable model of differential feature under-reporting\nwhich we then use to characterize the impact of this kind of data bias on\nalgorithmic fairness. We demonstrate how standard missing data methods\ntypically fail to mitigate bias in this setting, and propose a new set of\nmethods specifically tailored to differential feature under-reporting. Our\nresults show that, in real world data settings, under-reporting typically leads\nto increasing disparities. The proposed solution methods show success in\nmitigating increases in unfairness.", "field": "Computer Science", "categories": "cs.LG,cs.CY,stat.ML"}, {"arxiv_id": "2401.08789", "title": "Moral Values Underpinning COVID-19 Online Communication Patterns", "abstract": "The COVID-19 pandemic has triggered profound societal changes, extending\nbeyond its health impacts to the moralization of behaviors. Leveraging insights\nfrom moral psychology, this study delves into the moral fabric shaping online\ndiscussions surrounding COVID-19 over a span of nearly two years. Our\ninvestigation identifies four distinct user groups characterized by differences\nin morality, political ideology, and communication styles. We underscore the\nintricate relationship between moral differences and political ideologies,\nrevealing a nuanced picture where moral orientations do not rigidly separate\nusers politically. Furthermore, we uncover patterns of moral homophily within\nthe social network, highlighting the existence of one potential moral echo\nchamber. Analyzing the moral themes embedded in messages, we observe that\nmessages featuring moral foundations not typically favored by their authors, as\nwell as those incorporating multiple moral foundations, resonate more\neffectively with out-group members. This research contributes valuable insights\ninto the complex interplay between moral foundations, communication dynamics,\nand network structures on Twitter.", "field": "Computer Science", "categories": "cs.SI"}, {"arxiv_id": "2401.08804", "title": "Towards a Quality Indicator for Research Data publications and Research\n  Software publications -- A vision from the Helmholtz Association", "abstract": "Research data and software are widely accepted as an outcome of scientific\nwork. However, in comparison to text-based publications, there is not yet an\nestablished process to assess and evaluate quality of research data and\nresearch software publications. This paper presents an attempt to fill this\ngap. Initiated by the Working Group Open Science of the Helmholtz Association\nthe Task Group Helmholtz Quality Indicators for Data and Software Publications\ncurrently develops a quality indicator for research data and research software\npublications to be used within the Association. This report summarizes the\nvision of the group of what all contributes to such an indicator. The proposed\napproach relies on generic well-established concepts for quality criteria, such\nas the FAIR Principles and the COBIT Maturity Model. It does - on purpose - not\nlimit itself to technical implementation possibilities to avoid using an\nexisting metric for a new purpose. The intention of this paper is to share the\ncurrent state for further discussion with all stakeholders, particularly with\nother groups also working on similar metrics but also with entities that use\nthe metrics.", "field": "Computer Science", "categories": "cs.DL,cs.CY"}, {"arxiv_id": "2401.08806", "title": "Energy-adaptive Buffering for Efficient, Responsive, and Persistent\n  Batteryless Systems", "abstract": "Batteryless energy harvesting systems enable a wide array of new sensing,\ncomputation, and communication platforms untethered by power delivery or\nbattery maintenance demands. Energy harvesters charge a buffer capacitor from\nan unreliable environmental source until enough energy is stored to guarantee a\nburst of operation despite changes in power input. Current platforms use a\nfixed-size buffer chosen at design time to meet constraints on charge time or\napplication longevity, but static energy buffers are a poor fit for the highly\nvolatile power sources found in real-world deployments: fixed buffers waste\nenergy both as heat when they reach capacity during a power surplus and as\nleakage when they fail to charge the system during a power deficit.\n  To maximize batteryless system performance in the face of highly dynamic\ninput power, we propose REACT: a responsive buffering circuit which varies\ntotal capacitance according to net input power. REACT uses a variable capacitor\nbank to expand capacitance to capture incoming energy during a power surplus\nand reconfigures internal capacitors to reclaim additional energy from each\ncapacitor as power input falls. Compared to fixed-capacity systems, REACT\ncaptures more energy, maximizes usable energy, and efficiently decouples system\nvoltage from stored charge -- enabling low-power and high-performance designs\npreviously limited by ambient power. Our evaluation on real-world platforms\nshows that REACT eliminates the tradeoff between responsiveness, efficiency,\nand longevity, increasing the energy available for useful work by an average\n25.6% over static buffers optimized for reactivity and capacity, improving\nevent responsiveness by an average 7.7x without sacrificing capacity, and\nenabling programmer directed longevity guarantees.", "field": "Computer Science", "categories": "cs.AR"}, {"arxiv_id": "2401.08807", "title": "SpecGen: Automated Generation of Formal Program Specifications via Large\n  Language Models", "abstract": "In software development, formal program specifications play a crucial role in\nvarious stages. However, manually crafting formal program specifications is\nrather difficult, making the job time-consuming and labor-intensive. Moreover,\nit is even more challenging to write specifications that correctly and\ncomprehensively describe the semantics of complex programs. To reduce the\nburden on software developers, automated specification generation methods have\nemerged. However, existing methods usually rely on predefined templates or\ngrammar, making them struggle to accurately describe the behavior and\nfunctionality of complex real-world programs. To tackle this challenge, we\nintroduce SpecGen, a novel technique for formal program specification\ngeneration based on Large Language Models. Our key insight is to overcome the\nlimitations of existing methods by leveraging the code comprehension capability\nof LLMs. The process of SpecGen consists of two phases. The first phase employs\na conversational approach that guides the LLM to generate appropriate\nspecifications for a given program. The second phase, designed for where the\nLLM fails to generate correct specifications, applies four mutation operators\nto the model-generated specifications and selects verifiable specifications\nfrom the mutated ones through a novel heuristic selection strategy by assigning\ndifferent weights of variants in an efficient manner. To evaluate the\nperformance of SpecGen, we manually construct a dataset containing 120 test\ncases. Our experimental results demonstrate that SpecGen succeeds in generating\nverifiable specifications for 100 out of 120 programs, outperforming the\nexisting purely LLM-based approaches and conventional specification generation\ntools. Further investigations on the quality of generated specifications\nindicate that SpecGen can comprehensively articulate the behaviors of the input\nprogram.", "field": "Computer Science", "categories": "cs.SE"}, {"arxiv_id": "2401.08808", "title": "Sample Relationship from Learning Dynamics Matters for Generalisation", "abstract": "Although much research has been done on proposing new models or loss\nfunctions to improve the generalisation of artificial neural networks (ANNs),\nless attention has been directed to the impact of the training data on\ngeneralisation. In this work, we start from approximating the interaction\nbetween samples, i.e. how learning one sample would modify the model's\nprediction on other samples. Through analysing the terms involved in weight\nupdates in supervised learning, we find that labels influence the interaction\nbetween samples. Therefore, we propose the labelled pseudo Neural Tangent\nKernel (lpNTK) which takes label information into consideration when measuring\nthe interactions between samples. We first prove that lpNTK asymptotically\nconverges to the empirical neural tangent kernel in terms of the Frobenius norm\nunder certain assumptions. Secondly, we illustrate how lpNTK helps to\nunderstand learning phenomena identified in previous work, specifically the\nlearning difficulty of samples and forgetting events during learning. Moreover,\nwe also show that using lpNTK to identify and remove poisoning training samples\ndoes not hurt the generalisation performance of ANNs.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.08809", "title": "Learning Implicit Representation for Reconstructing Articulated Objects", "abstract": "3D Reconstruction of moving articulated objects without additional\ninformation about object structure is a challenging problem. Current methods\novercome such challenges by employing category-specific skeletal models.\nConsequently, they do not generalize well to articulated objects in the wild.\nWe treat an articulated object as an unknown, semi-rigid skeletal structure\nsurrounded by nonrigid material (e.g., skin). Our method simultaneously\nestimates the visible (explicit) representation (3D shapes, colors, camera\nparameters) and the implicit skeletal representation, from motion cues in the\nobject video without 3D supervision. Our implicit representation consists of\nfour parts. (1) Skeleton, which specifies how semi-rigid parts are connected.\n(2) \\textcolor{black}{Skinning Weights}, which associates each surface vertex\nwith semi-rigid parts with probability. (3) Rigidity Coefficients, specifying\nthe articulation of the local surface. (4) Time-Varying Transformations, which\nspecify the skeletal motion and surface deformation parameters. We introduce an\nalgorithm that uses physical constraints as regularization terms and\niteratively estimates both implicit and explicit representations. Our method is\ncategory-agnostic, thus eliminating the need for category-specific skeletons,\nwe show that our method outperforms state-of-the-art across standard video\ndatasets.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.08814", "title": "Inviscid Burgers as a degenerate elliptic problem", "abstract": "We demonstrate the feasibility of a scheme to obtain approximate weak\nsolutions to the (inviscid) Burgers equation in conservation and\nHamilton-Jacobi form, treated as degenerate elliptic problems. We show\ndifferent variants recover non-unique weak solutions as appropriate, and also\nspecific constructive approaches to recover the corresponding entropy\nsolutions.", "field": "Computer Science", "categories": "math.NA,cs.NA,math-ph,math.AP,math.MP"}, {"arxiv_id": "2401.08815", "title": "Adversarial Supervision Makes Layout-to-Image Diffusion Models Thrive", "abstract": "Despite the recent advances in large-scale diffusion models, little progress\nhas been made on the layout-to-image (L2I) synthesis task. Current L2I models\neither suffer from poor editability via text or weak alignment between the\ngenerated image and the input layout. This limits their usability in practice.\nTo mitigate this, we propose to integrate adversarial supervision into the\nconventional training pipeline of L2I diffusion models (ALDM). Specifically, we\nemploy a segmentation-based discriminator which provides explicit feedback to\nthe diffusion generator on the pixel-level alignment between the denoised image\nand the input layout. To encourage consistent adherence to the input layout\nover the sampling steps, we further introduce the multistep unrolling strategy.\nInstead of looking at a single timestep, we unroll a few steps recursively to\nimitate the inference process, and ask the discriminator to assess the\nalignment of denoised images with the layout over a certain time window. Our\nexperiments show that ALDM enables layout faithfulness of the generated images,\nwhile allowing broad editability via text prompts. Moreover, we showcase its\nusefulness for practical applications: by synthesizing target distribution\nsamples via text control, we improve domain generalization of semantic\nsegmentation models by a large margin (~12 mIoU points).", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.LG"}, {"arxiv_id": "2401.08818", "title": "Link Me Baby One More Time: Social Music Discovery on Spotify", "abstract": "We explore the social and contextual factors that influence the outcome of\nperson-to-person music recommendations and discovery. Specifically, we use data\nfrom Spotify to investigate how a link sent from one user to another results in\nthe receiver engaging with the music of the shared artist. We consider several\nfactors that may influence this process, such as the strength of the\nsender-receiver relationship, the user's role in the Spotify social network,\ntheir music social cohesion, and how similar the new artist is to the\nreceiver's taste. We find that the receiver of a link is more likely to engage\nwith a new artist when (1) they have similar music taste to the sender and the\nshared track is a good fit for their taste, (2) they have a stronger and more\nintimate tie with the sender, and (3) the shared artist is popular with the\nreceiver's connections. Finally, we use these findings to build a Random Forest\nclassifier to predict whether a shared music track will result in the\nreceiver's engagement with the shared artist. This model elucidates which type\nof social and contextual features are most predictive, although peak\nperformance is achieved when a diverse set of features are included. These\nfindings provide new insights into the multifaceted mechanisms underpinning the\ninterplay between music discovery and social processes.", "field": "Computer Science", "categories": "cs.SI,cs.IR,cs.LG,physics.soc-ph"}, {"arxiv_id": "2401.08819", "title": "Learning from Sparse Offline Datasets via Conservative Density\n  Estimation", "abstract": "Offline reinforcement learning (RL) offers a promising direction for learning\npolicies from pre-collected datasets without requiring further interactions\nwith the environment. However, existing methods struggle to handle\nout-of-distribution (OOD) extrapolation errors, especially in sparse reward or\nscarce data settings. In this paper, we propose a novel training algorithm\ncalled Conservative Density Estimation (CDE), which addresses this challenge by\nexplicitly imposing constraints on the state-action occupancy stationary\ndistribution. CDE overcomes the limitations of existing approaches, such as the\nstationary distribution correction method, by addressing the support mismatch\nissue in marginal importance sampling. Our method achieves state-of-the-art\nperformance on the D4RL benchmark. Notably, CDE consistently outperforms\nbaselines in challenging tasks with sparse rewards or insufficient data,\ndemonstrating the advantages of our approach in addressing the extrapolation\nerror problem in offline RL.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.08822", "title": "An Empirical Study of Counterfactual Visualization to Support Visual\n  Causal Inference", "abstract": "Counterfactuals -- expressing what might have been true under different\ncircumstances -- have been widely applied in statistics and machine learning to\nhelp understand causal relationships. More recently, counterfactuals have begun\nto emerge as a technique being applied within visualization research. However,\nit remains unclear to what extent counterfactuals can aid with visual data\ncommunication. In this paper, we primarily focus on assessing the quality of\nusers' understanding of data when provided with counterfactual visualizations.\nWe propose a preliminary model of causality comprehension by connecting\ntheories from causal inference and visual data communication. Leveraging this\nmodel, we conducted an empirical study to explore how counterfactuals can\nimprove users' understanding of data in static visualizations. Our results\nindicate that visualizing counterfactuals had a positive impact on\nparticipants' interpretations of causal relations within datasets. These\nresults motivate a discussion of how to more effectively incorporate\ncounterfactuals into data visualizations.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.08825", "title": "AiGen-FoodReview: A Multimodal Dataset of Machine-Generated Restaurant\n  Reviews and Images on Social Media", "abstract": "Online reviews in the form of user-generated content (UGC) significantly\nimpact consumer decision-making. However, the pervasive issue of not only human\nfake content but also machine-generated content challenges UGC's reliability.\nRecent advances in Large Language Models (LLMs) may pave the way to fabricate\nindistinguishable fake generated content at a much lower cost. Leveraging\nOpenAI's GPT-4-Turbo and DALL-E-2 models, we craft AiGen-FoodReview, a\nmulti-modal dataset of 20,144 restaurant review-image pairs divided into\nauthentic and machine-generated. We explore unimodal and multimodal detection\nmodels, achieving 99.80% multimodal accuracy with FLAVA. We use attributes from\nreadability and photographic theories to score reviews and images,\nrespectively, demonstrating their utility as hand-crafted features in scalable\nand interpretable detection models, with comparable performance. The paper\ncontributes by open-sourcing the dataset and releasing fake review detectors,\nrecommending its use in unimodal and multimodal fake review detection tasks,\nand evaluating linguistic and visual features in synthetic versus authentic\ndata.", "field": "Computer Science", "categories": "cs.LG,cs.CL,cs.CV"}, {"arxiv_id": "2401.0883", "title": "Stochastic Subnetwork Annealing: A Regularization Technique for Fine\n  Tuning Pruned Subnetworks", "abstract": "Pruning methods have recently grown in popularity as an effective way to\nreduce the size and computational complexity of deep neural networks. Large\nnumbers of parameters can be removed from trained models with little\ndiscernible loss in accuracy after a small number of continued training epochs.\nHowever, pruning too many parameters at once often causes an initial steep drop\nin accuracy which can undermine convergence quality. Iterative pruning\napproaches mitigate this by gradually removing a small number of parameters\nover multiple epochs. However, this can still lead to subnetworks that overfit\nlocal regions of the loss landscape. We introduce a novel and effective\napproach to tuning subnetworks through a regularization technique we call\nStochastic Subnetwork Annealing. Instead of removing parameters in a discrete\nmanner, we instead represent subnetworks with stochastic masks where each\nparameter has a probabilistic chance of being included or excluded on any given\nforward pass. We anneal these probabilities over time such that subnetwork\nstructure slowly evolves as mask values become more deterministic, allowing for\na smoother and more robust optimization of subnetworks at high levels of\nsparsity.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.08832", "title": "Topic Diversity and Conspiracy Theories Shape Engagement with COVID-19\n  Misinformation on X/Twitter", "abstract": "The engagement with online health misinformation, particularly during\nCOVID-19, poses unprecedented threats to societal well-being. The\nsusceptibility to misinformation is heightened within a multi-topic context\nduring health crises. This paper addresses a critical gap in understanding\nonline engagement with multi-topic misinformation related to COVID-19. We\nconduct a comprehensive analysis of 7273 fact-checked source news claims\nrelated to COVID-19 and their corresponding social engagement on X/Twitter\nthrough the lens of topic diversity and conspiracy theories. Our analysis\nyields several key findings: (i) False news, especially when accompanied by\nconspiracy theories, exhibits higher topic diversity compared to true news.\n(ii) In terms of engagement from source claims to online posts, false news has\na longer lifetime and receives more posts on X/Twitter compared to true news.\nAdditionally, the integration of conspiracy theories is associated with a\nlonger lifetime of COVID-19 misinformation. (iii) News posts characterized by\nheightened topic diversity receive increased social engagement on X/Twitter in\nterms of reposts, likes, and replies. However, the effect of topic diversity is\nmoderated by the news veracity. High topic diversity is linked to more\nengagement with true news posts compared to false news posts. (iiii) The\nintegration of conspiracy theories is linked to more social engagement with\nmisinformation on X/Twitter. False news posts that contain conspiracy theories,\non average, receive 40.8% more reposts, 45.2% more likes, and 44.1% more\nreplies compared to false news posts without conspiracy theories. These\nfindings offer insights into understanding the engagement with multi-topic\nmisinformation during health crises and highlight the importance of considering\ntopic diversity and conspiracy theories in developing targeted interventions.", "field": "Computer Science", "categories": "cs.SI,physics.soc-ph"}, {"arxiv_id": "2401.08835", "title": "Improving ASR Contextual Biasing with Guided Attention", "abstract": "In this paper, we propose a Guided Attention (GA) auxiliary training loss,\nwhich improves the effectiveness and robustness of automatic speech recognition\n(ASR) contextual biasing without introducing additional parameters. A common\nchallenge in previous literature is that the word error rate (WER) reduction\nbrought by contextual biasing diminishes as the number of bias phrases\nincreases. To address this challenge, we employ a GA loss as an additional\ntraining objective besides the Transducer loss. The proposed GA loss aims to\nteach the cross attention how to align bias phrases with text tokens or audio\nframes. Compared to studies with similar motivations, the proposed loss\noperates directly on the cross attention weights and is easier to implement.\nThrough extensive experiments based on Conformer Transducer with Contextual\nAdapter, we demonstrate that the proposed method not only leads to a lower WER\nbut also retains its effectiveness as the number of bias phrases increases.\nSpecifically, the GA loss decreases the WER of rare vocabularies by up to 19.2%\non LibriSpeech compared to the contextual biasing baseline, and up to 49.3%\ncompared to a vanilla Transducer.", "field": "Computer Science", "categories": "cs.CL,eess.AS"}, {"arxiv_id": "2401.08837", "title": "Image Fusion in Remote Sensing: An Overview and Meta Analysis", "abstract": "Image fusion in Remote Sensing (RS) has been a consistent demand due to its\nability to turn raw images of different resolutions, sources, and modalities\ninto accurate, complete, and spatio-temporally coherent images. It greatly\nfacilitates downstream applications such as pan-sharpening, change detection,\nland-cover classification, etc. Yet, image fusion solutions are highly\ndisparate to various remote sensing problems and thus are often narrowly\ndefined in existing reviews as topical applications, such as pan-sharpening,\nand spatial-temporal image fusion. Considering that image fusion can be\ntheoretically applied to any gridded data through pixel-level operations, in\nthis paper, we expanded its scope by comprehensively surveying relevant works\nwith a simple taxonomy: 1) many-to-one image fusion; 2) many-to-many image\nfusion. This simple taxonomy defines image fusion as a mapping problem that\nturns either a single or a set of images into another single or set of images,\ndepending on the desired coherence, e.g., spectral, spatial/resolution\ncoherence, etc. We show that this simple taxonomy, despite the significant\nmodality difference it covers, can be presented by a conceptually easy\nframework. In addition, we provide a meta-analysis to review the major papers\nstudying the various types of image fusion and their applications over the\nyears (from the 1980s to date), covering 5,926 peer-reviewed papers. Finally,\nwe discuss the main benefits and emerging challenges to provide open research\ndirections and potential future works.", "field": "Computer Science", "categories": "cs.CV,eess.IV"}, {"arxiv_id": "2401.0884", "title": "Efficient Neural Representation of Volumetric Data using\n  Coordinate-Based Networks", "abstract": "In this paper, we propose an efficient approach for the compression and\nrepresentation of volumetric data utilizing coordinate-based networks and\nmulti-resolution hash encoding. Efficient compression of volumetric data is\ncrucial for various applications, such as medical imaging and scientific\nsimulations. Our approach enables effective compression by learning a mapping\nbetween spatial coordinates and intensity values. We compare different encoding\nschemes and demonstrate the superiority of multi-resolution hash encoding in\nterms of compression quality and training efficiency. Furthermore, we leverage\noptimization-based meta-learning, specifically using the Reptile algorithm, to\nlearn weight initialization for neural representations tailored to volumetric\ndata, enabling faster convergence during optimization. Additionally, we compare\nour approach with state-of-the-art methods to showcase improved image quality\nand compression ratios. These findings highlight the potential of\ncoordinate-based networks and multi-resolution hash encoding for an efficient\nand accurate representation of volumetric data, paving the way for advancements\nin large-scale data visualization and other applications.", "field": "Computer Science", "categories": "cs.CV,cs.GR"}, {"arxiv_id": "2401.08841", "title": "Exploring Content-Based and Meta-Data Analysis for Detecting Fake News\n  Infodemic: A case study on COVID-19", "abstract": "The coronavirus pandemic (COVID-19) is probably the most disruptive global\nhealth disaster in recent history. It negatively impacted the whole world and\nvirtually brought the global economy to a standstill. However, as the virus was\nspreading, infecting people and claiming thousands of lives so was the spread\nand propagation of fake news, misinformation and disinformation about the\nevent. These included the spread of unconfirmed health advice and remedies on\nsocial media. In this paper, false information about the pandemic is identified\nusing a content-based approach and metadata curated from messages posted to\nonline social networks. A content-based approach combined with metadata as well\nas an initial feature analysis is used and then several supervised learning\nmodels are tested for identifying and predicting misleading posts. Our approach\nshows up to 93% accuracy in the detection of fake news related posts about the\nCOVID-19 pandemic", "field": "Computer Science", "categories": "cs.IR,H.3.3"}, {"arxiv_id": "2401.08844", "title": "Wind tunnel actuation movement system", "abstract": "In this dissertation project, an actuation system was designed for the\nsupersonic wind tunnel at the University of Manchester. The aim of this project\nis to build a remote control actuation system which could adjust the angle of\nattack for the aerodynamic shape to save researchers' time and improve the\nexperimental efficiency. This project involves the model supporting system, a\nsix component wind tunnel balance, a control system design, a virtual angle of\nattack adjustment interface and LabVIEW programming implementation, the angle\nof attack adjustment range is from -20 to 20 degree. The three-dimensional\nmodel of the mechanical part and its engineering drawing were finished in\nSolidWorks, and the control system including the sensors and rotary encoder\ncontrol, the closed-loop control of the stepper motor and the wind tunnel\nbalance feedback. The performance of the wind tunnel balance can be known in\nadvance by finite element analysis. Finally, the virtual operating system was\nbuilt based on the LabVIEW and Arduino interactive programs", "field": "Computer Science", "categories": "eess.SY,cs.SY"}, {"arxiv_id": "2401.08846", "title": "Iterative Planning for Multi-agent Systems: An Application in\n  Energy-Aware UAV-UGV Cooperative Task Site Assignments", "abstract": "This paper presents an iterative planning framework for multi-agent systems\nwith hybrid state spaces. The framework uses transition systems to\nmathematically represent planning tasks and employs multiple solvers to\niteratively improve the plan until computation resources are exhausted. When\nintegrating different solvers for iterative planning, we establish theoretical\nguarantees on the mathematical framework to ensure recursive feasibility. The\nproposed framework enables continual improvement of solution optimality,\nefficiently using allocated computation resources. The proposed method is\nvalidated by applying it to an energy-aware UGV-UAV cooperative task site\nassignment. The results demonstrate the continual solution improvement while\npreserving real-time implementation ability compared to algorithms proposed in\nthe literature.", "field": "Computer Science", "categories": "eess.SY,cs.SY"}, {"arxiv_id": "2401.0885", "title": "REValueD: Regularised Ensemble Value-Decomposition for Factorisable\n  Markov Decision Processes", "abstract": "Discrete-action reinforcement learning algorithms often falter in tasks with\nhigh-dimensional discrete action spaces due to the vast number of possible\nactions. A recent advancement leverages value-decomposition, a concept from\nmulti-agent reinforcement learning, to tackle this challenge. This study delves\ndeep into the effects of this value-decomposition, revealing that whilst it\ncurtails the over-estimation bias inherent to Q-learning algorithms, it\namplifies target variance. To counteract this, we present an ensemble of\ncritics to mitigate target variance. Moreover, we introduce a regularisation\nloss that helps to mitigate the effects that exploratory actions in one\ndimension can have on the value of optimal actions in other dimensions. Our\nnovel algorithm, REValueD, tested on discretised versions of the DeepMind\nControl Suite tasks, showcases superior performance, especially in the\nchallenging humanoid and dog tasks. We further dissect the factors influencing\nREValueD's performance, evaluating the significance of the regularisation loss\nand the scalability of REValueD with increasing sub-actions per dimension.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.08851", "title": "Using i-vectors for subject-independent cross-session EEG transfer\n  learning", "abstract": "Cognitive load classification is the task of automatically determining an\nindividual's utilization of working memory resources during performance of a\ntask based on physiologic measures such as electroencephalography (EEG). In\nthis paper, we follow a cross-disciplinary approach, where tools and\nmethodologies from speech processing are used to tackle this problem. The\ncorpus we use was released publicly in 2021 as part of the first passive\nbrain-computer interface competition on cross-session workload estimation. We\npresent our approach which used i-vector-based neural network classifiers to\naccomplish inter-subject cross-session EEG transfer learning, achieving 18%\nrelative improvement over equivalent subject-dependent models. We also report\nexperiments showing how our subject-independent models perform competitively on\nheld-out subjects and improve with additional subject data, suggesting that\nsubject-dependent training is not required for effective cognitive load\ndetermination.", "field": "Computer Science", "categories": "cs.LG,cs.CL,cs.SD,eess.AS,q-bio.NC"}, {"arxiv_id": "2401.08858", "title": "File System Aging", "abstract": "File systems must allocate space for files without knowing what will be added\nor removed in the future. Over the life of a file system, this may cause\nsuboptimal file placement decisions that eventually lead to slower performance,\nor aging. Conventional wisdom suggests that file system aging is a solved\nproblem in the common case; heuristics to avoid aging, such as colocating\nrelated files and data blocks, are effective until a storage device fills up,\nat which point space pressure exacerbates fragmentation-based aging. However,\nthis article describes both realistic and synthetic workloads that can cause\nthese heuristics to fail, inducing large performance declines due to aging,\neven when the storage device is nearly empty.\n  We argue that these slowdowns are caused by poor layout. We demonstrate a\ncorrelation between the read performance of a directory scan and the locality\nwithin a file system's access patterns, using a dynamic layout score. We\ncomplement these results with microbenchmarks that show that space pressure can\ncause a substantial amount of inter-file and intra-file fragmentation. However,\nour results suggest that the effect of free-space fragmentation on read\nperformance is best described as accelerating the file system aging process.\nThe effect on write performance is non-existent in some cases, and, in most\ncases, an order of magnitude smaller than the read degradation from\nfragmentation caused by normal usage.\n  In short, many file systems are exquisitely prone to read aging after a\nvariety of write patterns. We show, however, that aging is not inevitable.\nBetrFS, a file system based on write-optimized dictionaries, exhibits almost no\naging in our experiments. We present a framework for understanding and\npredicting aging, and identify the key features of BetrFS that avoid aging.", "field": "Computer Science", "categories": "cs.OS,H.3.2; D.4.3; D.4.2; D.4.8; E.1; E.5; H.3.4"}, {"arxiv_id": "2401.08859", "title": "Shabari: Delayed Decision-Making for Faster and Efficient Serverless\n  Function", "abstract": "Serverless computing relieves developers from the burden of resource\nmanagement, thus providing ease-of-use to the users and the opportunity to\noptimize resource utilization for the providers. However, today's serverless\nsystems lack performance guarantees for function invocations, thus limiting\nsupport for performance-critical applications: we observed severe performance\nvariability (up to 6x). Providers lack visibility into user functions and hence\nfind it challenging to right-size them: we observed heavy resource\nunderutilization (up to 80%). To understand the causes behind the performance\nvariability and underutilization, we conducted a measurement study of commonly\ndeployed serverless functions and learned that the function performance and\nresource utilization depend crucially on function semantics and inputs. Our key\ninsight is to delay making resource allocation decisions until after the\nfunction inputs are available. We introduce Shabari, a resource management\nframework for serverless systems that makes decisions as late as possible to\nright-size each invocation to meet functions' performance objectives (SLOs) and\nimprove resource utilization. Shabari uses an online learning agent to\nright-size each function invocation based on the features of the function input\nand makes cold-start-aware scheduling decisions. For a range of serverless\nfunctions and inputs, Shabari reduces SLO violations by 11-73% while not\nwasting any vCPUs and reducing wasted memory by 64-94% in the median case,\ncompared to state-of-the-art systems, including Aquatope, Parrotfish, and\nCypress.", "field": "Computer Science", "categories": "cs.DC,cs.LG"}, {"arxiv_id": "2401.0886", "title": "Cross-Level Multi-Instance Distillation for Self-Supervised Fine-Grained\n  Visual Categorization", "abstract": "High-quality annotation of fine-grained visual categories demands great\nexpert knowledge, which is taxing and time consuming. Alternatively, learning\nfine-grained visual representation from enormous unlabeled images (e.g.,\nspecies, brands) by self-supervised learning becomes a feasible solution.\nHowever, recent researches find that existing self-supervised learning methods\nare less qualified to represent fine-grained categories. The bottleneck lies in\nthat the pre-text representation is built from every patch-wise embedding,\nwhile fine-grained categories are only determined by several key patches of an\nimage. In this paper, we propose a Cross-level Multi-instance Distillation\n(CMD) framework to tackle the challenge. Our key idea is to consider the\nimportance of each image patch in determining the fine-grained pre-text\nrepresentation by multiple instance learning. To comprehensively learn the\nrelation between informative patches and fine-grained semantics, the\nmulti-instance knowledge distillation is implemented on both the region/image\ncrop pairs from the teacher and student net, and the region-image crops inside\nthe teacher / student net, which we term as intra-level multi-instance\ndistillation and inter-level multi-instance distillation. Extensive experiments\non CUB-200-2011, Stanford Cars and FGVC Aircraft show that the proposed method\noutperforms the contemporary method by upto 10.14% and existing\nstate-of-the-art self-supervised learning approaches by upto 19.78% on both\ntop-1 accuracy and Rank-1 retrieval metric.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.08861", "title": "Semi-Supervised Learning Approach for Efficient Resource Allocation with\n  Network Slicing in O-RAN", "abstract": "The Open Radio Access Network (O-RAN) technology has emerged as a promising\nsolution for network operators, providing them with an open and favorable\nenvironment. Ensuring effective coordination of x-applications (xAPPs) is\ncrucial to enhance flexibility and optimize network performance within the\nO-RAN. In this paper, we introduce an innovative approach to the resource\nallocation problem, aiming to coordinate multiple independent xAPPs for network\nslicing and resource allocation in O-RAN. Our proposed method focuses on\nmaximizing the weighted throughput among user equipments (UE), as well as\nallocating physical resource blocks (PRBs). We prioritize two service types,\nnamely enhanced Mobile Broadband and Ultra Reliable Low Latency Communication.\nTo achieve this, we have designed two xAPPs: a power control xAPP for each UE\nand a PRB allocation xAPP. The proposed method consists of a two-part training\nphase, where the first part uses supervised learning with a Variational\nAutoencoder trained to regress the power transmission as well as the user\nassociation and PRB allocation decisions, and the second part uses unsupervised\nlearning with a contrastive loss approach to improve the generalization and\nrobustness of the model. We evaluate the performance of our proposed method by\ncomparing its results to those obtained from an exhaustive search algorithm,\ndeep Q-network algorithm, and by reporting performance metrics for the\nregression task. We also evaluate the proposed model's performance in different\nscenarios among the service types. The results show that the proposed method is\na more efficient and effective solution for network slicing problems compared\nto state-of-the-art methods.", "field": "Computer Science", "categories": "cs.NI,cs.LG,cs.MS,cs.NA,math.NA"}, {"arxiv_id": "2401.08863", "title": "Robust Localization of Key Fob Using Channel Impulse Response of Ultra\n  Wide Band Sensors for Keyless Entry Systems", "abstract": "Using neural networks for localization of key fob within and surrounding a\ncar as a security feature for keyless entry is fast emerging. In this paper we\nstudy: 1) the performance of pre-computed features of neural networks based UWB\n(ultra wide band) localization classification forming the baseline of our\nexperiments. 2) Investigate the inherent robustness of various neural networks;\ntherefore, we include the study of robustness of the adversarial examples\nwithout any adversarial training in this work. 3) Propose a multi-head\nself-supervised neural network architecture which outperforms the baseline\nneural networks without any adversarial training. The model's performance\nimproved by 67% at certain ranges of adversarial magnitude for fast gradient\nsign method and 37% each for basic iterative method and projected gradient\ndescent method.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.CR"}, {"arxiv_id": "2401.08865", "title": "The Effect of Intrinsic Dataset Properties on Generalization: Unraveling\n  Learning Differences Between Natural and Medical Images", "abstract": "This paper investigates discrepancies in how neural networks learn from\ndifferent imaging domains, which are commonly overlooked when adopting computer\nvision techniques from the domain of natural images to other specialized\ndomains such as medical images. Recent works have found that the generalization\nerror of a trained network typically increases with the intrinsic dimension\n($d_{data}$) of its training set. Yet, the steepness of this relationship\nvaries significantly between medical (radiological) and natural imaging\ndomains, with no existing theoretical explanation. We address this gap in\nknowledge by establishing and empirically validating a generalization scaling\nlaw with respect to $d_{data}$, and propose that the substantial scaling\ndiscrepancy between the two considered domains may be at least partially\nattributed to the higher intrinsic \"label sharpness\" ($K_F$) of medical imaging\ndatasets, a metric which we propose. Next, we demonstrate an additional benefit\nof measuring the label sharpness of a training set: it is negatively correlated\nwith the trained model's adversarial robustness, which notably leads to models\nfor medical images having a substantially higher vulnerability to adversarial\nattack. Finally, we extend our $d_{data}$ formalism to the related metric of\nlearned representation intrinsic dimension ($d_{repr}$), derive a\ngeneralization scaling law with respect to $d_{repr}$, and show that $d_{data}$\nserves as an upper bound for $d_{repr}$. Our theoretical results are supported\nby thorough experiments with six models and eleven natural and medical imaging\ndatasets over a range of training set sizes. Our findings offer insights into\nthe influence of intrinsic dataset properties on generalization, representation\nlearning, and robustness in deep neural networks.", "field": "Computer Science", "categories": "cs.CV,cs.LG,eess.IV,stat.ML"}, {"arxiv_id": "2401.08866", "title": "Foundation Models in Augmentative and Alternative Communication:\n  Opportunities and Challenges", "abstract": "Augmentative and Alternative Communication (AAC) are essential techniques\nthat help people with communication disabilities. AAC demonstrates its\ntransformative power by replacing spoken language with symbol sequences.\nHowever, to unlock its full potential, AAC materials must adhere to specific\ncharacteristics, placing the onus on educators to create custom-tailored\nmaterials and symbols. This paper introduces AMBRA (Pervasive and Personalized\nAugmentative and Alternative Communication based on Federated Learning and\nGenerative AI), an open platform that aims to leverage the capabilities of\nfoundation models to tackle many AAC issues, opening new opportunities (but\nalso challenges) for AI-enhanced AAC. We thus present a compelling vision--a\nroadmap towards a more inclusive society. By leveraging the capabilities of\nmodern technologies, we aspire to not only transform AAC but also guide the way\ntoward a world where communication knows no bounds.", "field": "Computer Science", "categories": "cs.CY"}, {"arxiv_id": "2401.08867", "title": "MambaTab: A Simple Yet Effective Approach for Handling Tabular Data", "abstract": "Tabular data remains ubiquitous across domains despite growing use of images\nand texts for machine learning. While deep learning models like convolutional\nneural networks and transformers achieve strong performance on tabular data,\nthey require extensive data preprocessing, tuning, and resources, limiting\naccessibility and scalability. This work develops an innovative approach based\non a structured state-space model (SSM), MambaTab, for tabular data. SSMs have\nstrong capabilities for efficiently extracting effective representations from\ndata with long-range dependencies. MambaTab leverages Mamba, an emerging SSM\nvariant, for end-to-end supervised learning on tables. Compared to\nstate-of-the-art baselines, MambaTab delivers superior performance while\nrequiring significantly fewer parameters and minimal preprocessing, as\nempirically validated on diverse benchmark datasets. MambaTab's efficiency,\nscalability, generalizability, and predictive gains signify it as a\nlightweight, \"out-of-the-box\" solution for diverse tabular data with promise\nfor enabling wider practical applications.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.08868", "title": "B-Cos Aligned Transformers Learn Human-Interpretable Features", "abstract": "Vision Transformers (ViTs) and Swin Transformers (Swin) are currently\nstate-of-the-art in computational pathology. However, domain experts are still\nreluctant to use these models due to their lack of interpretability. This is\nnot surprising, as critical decisions need to be transparent and\nunderstandable. The most common approach to understanding transformers is to\nvisualize their attention. However, attention maps of ViTs are often\nfragmented, leading to unsatisfactory explanations. Here, we introduce a novel\narchitecture called the B-cos Vision Transformer (BvT) that is designed to be\nmore interpretable. It replaces all linear transformations with the B-cos\ntransform to promote weight-input alignment. In a blinded study, medical\nexperts clearly ranked BvTs above ViTs, suggesting that our network is better\nat capturing biomedically relevant structures. This is also true for the B-cos\nSwin Transformer (Bwin). Compared to the Swin Transformer, it even improves the\nF1-score by up to 4.7% on two public datasets.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.0887", "title": "Benchmarking Particle Filter Algorithms for Efficient Velodyne-Based\n  Vehicle Localization", "abstract": "Keeping a vehicle well-localized within a prebuilt-map is at the core of any\nautonomous vehicle navigation system. In this work, we show that both standard\nSIR sampling and rejection-based optimal sampling are suitable for efficient\n(10 to 20 ms) real-time pose tracking without feature detection that is using\nraw point clouds from a 3D LiDAR. Motivated by the large amount of information\ncaptured by these sensors, we perform a systematic statistical analysis of how\nmany points are actually required to reach an optimal ratio between efficiency\nand positioning accuracy. Furthermore, initialization from adverse conditions,\ne.g., poor GPS signal in urban canyons, we also identify the optimal particle\nfilter settings required to ensure convergence. Our findings include that a\ndecimation factor between 100 and 200 on incoming point clouds provides a large\nsavings in computational cost with a negligible loss in localization accuracy\nfor a VLP-16 scanner. Furthermore, an initial density of $\\sim$2\nparticles/m$^2$ is required to achieve 100% convergence success for large-scale\n($\\sim$100,000 m$^2$), outdoor global localization without any additional hint\nfrom GPS or magnetic field sensors. All implementations have been released as\nopen-source software.", "field": "Computer Science", "categories": "cs.RO,stat.AP"}, {"arxiv_id": "2401.08875", "title": "DCRMTA: Unbiased Causal Representation for Multi-touch Attribution", "abstract": "Multi-touch attribution (MTA) currently plays a pivotal role in achieving a\nfair estimation of the contributions of each advertising touchpoint to-wards\nconversion behavior, deeply influencing budget allocation and advertising\nrecommenda-tion. Traditional multi-touch attribution methods initially build a\nconversion prediction model, an-ticipating learning the inherent relationship\nbe-tween touchpoint sequences and user purchasing behavior through historical\ndata. Based on this, counterfactual touchpoint sequences are con-structed from\nthe original sequence subset, and conversions are estimated using the\nprediction model, thus calculating advertising contributions. A covert\nassumption of these methods is the un-biased nature of conversion prediction\nmodels. However, due to confounding variables factors arising from user\npreferences and internet recom-mendation mechanisms such as homogenization of\nad recommendations resulting from past shop-ping records, bias can easily occur\nin conversion prediction models trained on observational data. This paper\nredefines the causal effect of user fea-tures on conversions and proposes a\nnovel end-to-end approach, Deep Causal Representation for MTA (DCRMTA). Our\nmodel while eliminating confounding variables, extracts features with causal\nrelations to conversions from users. Fur-thermore, Extensive experiments on\nboth synthet-ic and real-world Criteo data demonstrate DCRMTA's superior\nperformance in converting prediction across varying data distributions, while\nalso effectively attributing value across dif-ferent advertising channels", "field": "Computer Science", "categories": "cs.LG,cs.AI,stat.ME"}, {"arxiv_id": "2401.08876", "title": "Evaluating the Utility of Conformal Prediction Sets for AI-Advised Image\n  Labeling", "abstract": "As deep neural networks are more commonly deployed in high-stakes domains,\ntheir lack of interpretability makes uncertainty quantification challenging. We\ninvestigate the effects of presenting conformal prediction\nsets$\\unicode{x2013}$a method for generating valid confidence sets in\ndistribution-free uncertainty quantification$\\unicode{x2013}$to express\nuncertainty in AI-advised decision-making. Through a large pre-registered\nexperiment, we compare the utility of conformal prediction sets to displays of\nTop-1 and Top-k predictions for AI-advised image labeling. We find that the\nutility of prediction sets for accuracy varies with the difficulty of the task:\nwhile they result in accuracy on par with or less than Top-1 and Top-k displays\nfor easy images, prediction sets excel at assisting humans in labeling\nout-of-distribution (OOD) images especially when the set size is small. Our\nresults empirically pinpoint the practical challenges of conformal prediction\nsets and provide implications on how to incorporate them for real-world\ndecision-making.", "field": "Computer Science", "categories": "cs.HC,cs.CV,cs.LG"}, {"arxiv_id": "2401.08878", "title": "A Survey on Hypergraph Mining: Patterns, Tools, and Generators", "abstract": "Hypergraphs are a natural and powerful choice for modeling group interactions\nin the real world, which are often referred to as higher-order networks. For\nexample, when modeling collaboration networks, where collaborations can involve\nnot just two but three or more people, employing hypergraphs allows us to\nexplore beyond pairwise (dyadic) patterns and capture groupwise (polyadic)\npatterns. The mathematical complexity of hypergraphs offers both opportunities\nand challenges for learning and mining on hypergraphs, and hypergraph mining,\nwhich seeks to enhance our understanding of underlying systems through\nhypergraph modeling, gained increasing attention in research. Researchers have\ndiscovered various structural patterns in real-world hypergraphs, leading to\nthe development of mining tools. Moreover, they have designed generators with\nthe aim of reproducing and thereby shedding light on these patterns. In this\nsurvey, we provide a comprehensive overview of the current landscape of\nhypergraph mining, covering patterns, tools, and generators. We provide\ncomprehensive taxonomies for them, and we also provide in-depth discussions to\nprovide insights into future research on hypergraph mining.", "field": "Computer Science", "categories": "cs.SI,cs.DB,physics.soc-ph"}, {"arxiv_id": "2401.08879", "title": "Contribution Functions for Quantitative Bipolar Argumentation Graphs: A\n  Principle-based Analysis", "abstract": "We present a principle-based analysis of contribution functions for\nquantitative bipolar argumentation graphs that quantify the contribution of one\nargument to another. The introduced principles formalise the intuitions\nunderlying different contribution functions as well as expectations one would\nhave regarding the behaviour of contribution functions in general. As none of\nthe covered contribution functions satisfies all principles, our analysis can\nserve as a tool that enables the selection of the most suitable function based\non the requirements of a given use case.", "field": "Computer Science", "categories": "cs.AI"}, {"arxiv_id": "2401.08881", "title": "Whispering Pixels: Exploiting Uninitialized Register Accesses in Modern\n  GPUs", "abstract": "Graphic Processing Units (GPUs) have transcended their traditional use-case\nof rendering graphics and nowadays also serve as a powerful platform for\naccelerating ubiquitous, non-graphical rendering tasks. One prominent task is\ninference of neural networks, which process vast amounts of personal data, such\nas audio, text or images. Thus, GPUs became integral components for handling\nvast amounts of potentially confidential data, which has awakened the interest\nof security researchers. This lead to the discovery of various vulnerabilities\nin GPUs in recent years. In this paper, we uncover yet another vulnerability\nclass in GPUs: We found that some GPU implementations lack proper register\ninitialization routines before shader execution, leading to unintended register\ncontent leakage of previously executed shader kernels. We showcase the\nexistence of the aforementioned vulnerability on products of 3 major vendors -\nApple, NVIDIA and Qualcomm. The vulnerability poses unique challenges to an\nadversary due to opaque scheduling and register remapping algorithms present in\nthe GPU firmware, complicating the reconstruction of leaked data. In order to\nillustrate the real-world impact of this flaw, we showcase how these challenges\ncan be solved for attacking various workloads on the GPU. First, we showcase\nhow uninitialized registers leak arbitrary pixel data processed by fragment\nshaders. We further implement information leakage attacks on intermediate data\nof Convolutional Neural Networks (CNNs) and present the attack's capability to\nleak and reconstruct the output of Large Language Models (LLMs).", "field": "Computer Science", "categories": "cs.CR"}, {"arxiv_id": "2401.08886", "title": "RiemannONets: Interpretable Neural Operators for Riemann Problems", "abstract": "Developing the proper representations for simulating high-speed flows with\nstrong shock waves, rarefactions, and contact discontinuities has been a\nlong-standing question in numerical analysis. Herein, we employ neural\noperators to solve Riemann problems encountered in compressible flows for\nextreme pressure jumps (up to $10^{10}$ pressure ratio). In particular, we\nfirst consider the DeepONet that we train in a two-stage process, following the\nrecent work of Lee and Shin, wherein the first stage, a basis is extracted from\nthe trunk net, which is orthonormalized and subsequently is used in the second\nstage in training the branch net. This simple modification of DeepONet has a\nprofound effect on its accuracy, efficiency, and robustness and leads to very\naccurate solutions to Riemann problems compared to the vanilla version. It also\nenables us to interpret the results physically as the hierarchical data-driven\nproduced basis reflects all the flow features that would otherwise be\nintroduced using ad hoc feature expansion layers. We also compare the results\nwith another neural operator based on the U-Net for low, intermediate, and very\nhigh-pressure ratios that are very accurate for Riemann problems, especially\nfor large pressure ratios, due to their multiscale nature but computationally\nmore expensive. Overall, our study demonstrates that simple neural network\narchitectures, if properly pre-trained, can achieve very accurate solutions of\nRiemann problems for real-time forecasting.", "field": "Computer Science", "categories": "cs.LG,physics.flu-dyn"}, {"arxiv_id": "2401.08887", "title": "NOTSOFAR-1 Challenge: New Datasets, Baseline, and Tasks for Distant\n  Meeting Transcription", "abstract": "We introduce the first Natural Office Talkers in Settings of Far-field Audio\nRecordings (``NOTSOFAR-1'') Challenge alongside datasets and baseline system.\nThe challenge focuses on distant speaker diarization and automatic speech\nrecognition (DASR) in far-field meeting scenarios, with single-channel and\nknown-geometry multi-channel tracks, and serves as a launch platform for two\nnew datasets: First, a benchmarking dataset of 315 meetings, averaging 6\nminutes each, capturing a broad spectrum of real-world acoustic conditions and\nconversational dynamics. It is recorded across 30 conference rooms, featuring\n4-8 attendees and a total of 35 unique speakers. Second, a 1000-hour simulated\ntraining dataset, synthesized with enhanced authenticity for real-world\ngeneralization, incorporating 15,000 real acoustic transfer functions. The\ntasks focus on single-device DASR, where multi-channel devices always share the\nsame known geometry. This is aligned with common setups in actual conference\nrooms, and avoids technical complexities associated with multi-device tasks. It\nalso allows for the development of geometry-specific solutions. The NOTSOFAR-1\nChallenge aims to advance research in the field of distant conversational\nspeech recognition, providing key resources to unlock the potential of\ndata-driven methods, which we believe are currently constrained by the absence\nof comprehensive high-quality training and benchmarking datasets.", "field": "Computer Science", "categories": "cs.SD,cs.AI,cs.CL,eess.AS"}, {"arxiv_id": "2401.08889", "title": "On the Effect of Data-Augmentation on Local Embedding Properties in the\n  Contrastive Learning of Music Audio Representations", "abstract": "Audio embeddings are crucial tools in understanding large catalogs of music.\nTypically embeddings are evaluated on the basis of the performance they provide\nin a wide range of downstream tasks, however few studies have investigated the\nlocal properties of the embedding spaces themselves which are important in\nnearest neighbor algorithms, commonly used in music search and recommendation.\nIn this work we show that when learning audio representations on music datasets\nvia contrastive learning, musical properties that are typically homogeneous\nwithin a track (e.g., key and tempo) are reflected in the locality of\nneighborhoods in the resulting embedding space. By applying appropriate data\naugmentation strategies, localisation of such properties can not only be\nreduced but the localisation of other attributes is increased. For example,\nlocality of features such as pitch and tempo that are less relevant to\nnon-expert listeners, may be mitigated while improving the locality of more\nsalient features such as genre and mood, achieving state-of-the-art performance\nin nearest neighbor retrieval accuracy. Similarly, we show that the optimal\nselection of data augmentation strategies for contrastive learning of music\naudio embeddings is dependent on the downstream task, highlighting this as an\nimportant embedding design decision.", "field": "Computer Science", "categories": "cs.SD,cs.IR,cs.LG,cs.MM,eess.AS"}, {"arxiv_id": "2401.0889", "title": "Characterizing TCP's Performance for Low-Priority Flows Inside a Cloud", "abstract": "Many cloud systems utilize low-priority flows to achieve various performance\nobjectives (e.g., low latency, high utilization), relying on TCP as their\npreferred transport protocol. However, the suitability of TCP for such\nlow-priority flows is relatively unexplored. Specifically, how\nprioritization-induced delays in packet transmission can cause spurious\ntimeouts and low utilization. In this paper, we conduct an empirical study to\ninvestigate the performance of TCP for low-priority flows under a wide range of\nrealistic scenarios: use-cases (with accompanying workloads) where the\nperformance of low-priority flows is crucial to the functioning of the overall\nsystem as well as various network loads and other network parameters. Our\nfindings yield two key insights: 1) for several popular use-cases (e.g.,\nnetwork scheduling), TCP's performance for low-priority flows is within 2x of a\nnear-optimal scheme, 2) for emerging workloads that exhibit an on-off behavior\nin the high priority queue (e.g., distributed ML model training), TCP's\nperformance for low-priority flows is poor. Finally, we discuss and conduct\npreliminary evaluation to show that two simple strategies -- weighted fair\nqueuing (WFQ) and cross-queue congestion notification -- can substantially\nimprove TCP's performance for low-priority flows.", "field": "Computer Science", "categories": "cs.NI"}, {"arxiv_id": "2401.08891", "title": "Tempo estimation as fully self-supervised binary classification", "abstract": "This paper addresses the problem of global tempo estimation in musical audio.\nGiven that annotating tempo is time-consuming and requires certain musical\nexpertise, few publicly available data sources exist to train machine learning\nmodels for this task. Towards alleviating this issue, we propose a fully\nself-supervised approach that does not rely on any human labeled data. Our\nmethod builds on the fact that generic (music) audio embeddings already encode\na variety of properties, including information about tempo, making them easily\nadaptable for downstream tasks. While recent work in self-supervised tempo\nestimation aimed to learn a tempo specific representation that was subsequently\nused to train a supervised classifier, we reformulate the task into the binary\nclassification problem of predicting whether a target track has the same or a\ndifferent tempo compared to a reference. While the former still requires\nlabeled training data for the final classification model, our approach uses\narbitrary unlabeled music data in combination with time-stretching for model\ntraining as well as a small set of synthetically created reference samples for\npredicting the final tempo. Evaluation of our approach in comparison with the\nstate-of-the-art reveals highly competitive performance when the constraint of\nfinding the precise tempo octave is relaxed.", "field": "Computer Science", "categories": "cs.SD,cs.LG,eess.AS"}, {"arxiv_id": "2401.08893", "title": "MADA: Meta-Adaptive Optimizers through hyper-gradient Descent", "abstract": "Since Adam was introduced, several novel adaptive optimizers for deep\nlearning have been proposed. These optimizers typically excel in some tasks but\nmay not outperform Adam uniformly across all tasks. In this work, we introduce\nMeta-Adaptive Optimizers (MADA), a unified optimizer framework that can\ngeneralize several known optimizers and dynamically learn the most suitable one\nduring training. The key idea in MADA is to parameterize the space of\noptimizers and search through it using hyper-gradient descent. Numerical\nresults suggest that MADA is robust against sub-optimally tuned\nhyper-parameters, and outperforms Adam, Lion, and Adan with their default\nhyper-parameters, often even with optimized hyper-parameters. We also propose\nAVGrad, a variant of AMSGrad where the maximum operator is replaced with\naveraging, and observe that it performs better within MADA. Finally, we provide\na convergence analysis to show that interpolation of optimizers (specifically,\nAVGrad and Adam) can improve their error bounds (up to constants), hinting at\nan advantage for meta-optimizers.", "field": "Computer Science", "categories": "cs.LG,math.OC"}, {"arxiv_id": "2401.08895", "title": "cedar: Composable and Optimized Machine Learning Input Data Pipelines", "abstract": "The input data pipeline is an essential component of each machine learning\n(ML) training job. It is responsible for reading massive amounts of training\ndata, processing batches of samples using complex of transformations, and\nloading them onto training nodes at low latency and high throughput. Performant\ninput data systems are becoming increasingly critical, driven by skyrocketing\ndata volumes and training throughput demands. Unfortunately, current input data\nsystems cannot fully leverage key performance optimizations, resulting in\nhugely inefficient infrastructures that require significant resources -- or\nworse -- underutilize expensive accelerators.\n  To address these demands, we present cedar, a programming model and framework\nthat allows users to easily build, optimize, and execute input data pipelines.\ncedar presents an easy-to-use programming interface, allowing users to define\ninput data pipelines using composable operators that support arbitrary ML\nframeworks and libraries. Meanwhile, cedar transparently applies a complex and\nextensible set of optimization techniques (e.g., offloading, caching,\nprefetching, fusion, and reordering). It then orchestrates processing across a\ncustomizable set of local and distributed compute resources in order to\nmaximize processing performance and efficiency, all without user input. On\naverage across six diverse input data pipelines, cedar achieves a 2.49x, 1.87x,\n2.18x, and 2.74x higher performance compared to tf.data, tf.data service, Ray\nData, and PyTorch's DataLoader, respectively.", "field": "Computer Science", "categories": "cs.LG,cs.DC,cs.PF"}, {"arxiv_id": "2401.08896", "title": "Real-Time Control and Monitoring of Photovoltaic Arrays Using RTDS and\n  BeagleBoard Technology", "abstract": "Increasing integration of alternate electricity generation due to declining\nfossil fuels is becoming an essential option for future generations. As\nphotovoltaic technology brings forth enormous benefits to the alternate\nsolution for future power grid systems, this paper presents a comprehensive\nreal-time system designed to model, control, and monitor a PV array subjected\nto dynamic loads using the Real-Time Digital Simulator (RTDS) environment.\nIntegration with the Generic Transducer Network (GTNET)- Socket(SKT) module\nallows for the simulation of various environmental conditions, such as changes\nin insolation and temperature, and their direct impact on the PV array's\nperformance. Utilizing BeagleBoard technology, the system demonstrates the\ncapability to modify these conditions through real-time data input,\nsubsequently observing the effects on current and voltage output curves. The\nreal-time simulation results are visualized as a SCADA system within the\nReal-time Simulation for Automated Controller Design (RSCAD) runtime\nenvironment, providing insights into the effective management of solar power\nsystems.", "field": "Computer Science", "categories": "eess.SY,cs.SY,94C99"}, {"arxiv_id": "2401.08897", "title": "CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in\n  Variational AutoEncoder", "abstract": "Symmetries of input and latent vectors have provided valuable insights for\ndisentanglement learning in VAEs.However, only a few works were proposed as an\nunsupervised method, and even these works require known factor information in\ntraining data. We propose a novel method, Composite Factor-Aligned Symmetry\nLearning (CFASL), which is integrated into VAEs for learning symmetry-based\ndisentanglement in unsupervised learning without any knowledge of the dataset\nfactor information.CFASL incorporates three novel features for learning\nsymmetry-based disentanglement: 1) Injecting inductive bias to align latent\nvector dimensions to factor-aligned symmetries within an explicit learnable\nsymmetry codebook 2) Learning a composite symmetry to express unknown factors\nchange between two random samples by learning factor-aligned symmetries within\nthe codebook 3) Inducing group equivariant encoder and decoder in training VAEs\nwith the two conditions. In addition, we propose an extended evaluation metric\nfor multi-factor changes in comparison to disentanglement evaluation in VAEs.\nIn quantitative and in-depth qualitative analysis, CFASL demonstrates a\nsignificant improvement of disentanglement in single-factor change, and\nmulti-factor change conditions compared to state-of-the-art methods.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.08898", "title": "Bridging State and History Representations: Understanding\n  Self-Predictive RL", "abstract": "Representations are at the core of all deep reinforcement learning (RL)\nmethods for both Markov decision processes (MDPs) and partially observable\nMarkov decision processes (POMDPs). Many representation learning methods and\ntheoretical frameworks have been developed to understand what constitutes an\neffective representation. However, the relationships between these methods and\nthe shared properties among them remain unclear. In this paper, we show that\nmany of these seemingly distinct methods and frameworks for state and history\nabstractions are, in fact, based on a common idea of self-predictive\nabstraction. Furthermore, we provide theoretical insights into the widely\nadopted objectives and optimization, such as the stop-gradient technique, in\nlearning self-predictive representations. These findings together yield a\nminimalist algorithm to learn self-predictive representations for states and\nhistories. We validate our theories by applying our algorithm to standard MDPs,\nMDPs with distractors, and POMDPs with sparse rewards. These findings culminate\nin a set of practical guidelines for RL practitioners.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.08899", "title": "Landscape of Generative AI in Global News: Topics, Sentiments, and\n  Spatiotemporal Analysis", "abstract": "Generative AI has exhibited considerable potential to transform various\nindustries and public life. The role of news media coverage of generative AI is\npivotal in shaping public perceptions and judgments about this significant\ntechnological innovation. This paper provides in-depth analysis and rich\ninsights into the temporal and spatial distribution of topics, sentiment, and\nsubstantive themes within global news coverage focusing on the latest emerging\ntechnology --generative AI. We collected a comprehensive dataset of news\narticles (January 2018 to November 2023, N = 24,827). For topic modeling, we\nemployed the BERTopic technique and combined it with qualitative coding to\nidentify semantic themes. Subsequently, sentiment analysis was conducted using\nthe RoBERTa-base model. Analysis of temporal patterns in the data reveals\nnotable variability in coverage across key topics--business, corporate\ntechnological development, regulation and security, and education--with spikes\nin articles coinciding with major AI developments and policy discussions.\nSentiment analysis shows a predominantly neutral to positive media stance, with\nthe business-related articles exhibiting more positive sentiment, while\nregulation and security articles receive a reserved, neutral to negative\nsentiment. Our study offers a valuable framework to investigate global news\ndiscourse and evaluate news attitudes and themes related to emerging\ntechnologies.", "field": "Computer Science", "categories": "cs.CY"}, {"arxiv_id": "2401.08901", "title": "HasTEE+ : Confidential Cloud Computing and Analytics with Haskell", "abstract": "Confidential computing is a security paradigm that enables the protection of\nconfidential code and data in a co-tenanted cloud deployment using specialized\nhardware isolation units called Trusted Execution Environments (TEEs). By\nintegrating TEEs with a Remote Attestation protocol, confidential computing\nallows a third party to establish the integrity of an \\textit{enclave} hosted\nwithin an untrusted cloud. However, TEE solutions, such as Intel SGX and ARM\nTrustZone, offer low-level C/C++-based toolchains that are susceptible to\ninherent memory safety vulnerabilities and lack language constructs to monitor\nexplicit and implicit information-flow leaks. Moreover, the toolchains involve\ncomplex multi-project hierarchies and the deployment of hand-written\nattestation protocols for verifying \\textit{enclave} integrity.\n  We address the above with HasTEE+, a domain-specific language (DSL) embedded\nin Haskell that enables programming TEEs in a high-level language with strong\ntype-safety. HasTEE+ assists in multi-tier cloud application development by (1)\nintroducing a \\textit{tierless} programming model for expressing distributed\nclient-server interactions as a single program, (2) integrating a general\nremote-attestation architecture that removes the necessity to write\napplication-specific cross-cutting attestation code, and (3) employing a\ndynamic information flow control mechanism to prevent explicit as well as\nimplicit data leaks. We demonstrate the practicality of HasTEE+ through a case\nstudy on confidential data analytics, presenting a data-sharing pattern\napplicable to mutually distrustful participants and providing overall\nperformance metrics.", "field": "Computer Science", "categories": "cs.CR,cs.PL"}, {"arxiv_id": "2401.08902", "title": "Similar but Faster: Manipulation of Tempo in Music Audio Embeddings for\n  Tempo Prediction and Search", "abstract": "Audio embeddings enable large scale comparisons of the similarity of audio\nfiles for applications such as search and recommendation. Due to the\nsubjectivity of audio similarity, it can be desirable to design systems that\nanswer not only whether audio is similar, but similar in what way (e.g., wrt.\ntempo, mood or genre). Previous works have proposed disentangled embedding\nspaces where subspaces representing specific, yet possibly correlated,\nattributes can be weighted to emphasize those attributes in downstream tasks.\nHowever, no research has been conducted into the independence of these\nsubspaces, nor their manipulation, in order to retrieve tracks that are similar\nbut different in a specific way. Here, we explore the manipulation of tempo in\nembedding spaces as a case-study towards this goal. We propose tempo\ntranslation functions that allow for efficient manipulation of tempo within a\npre-existing embedding space whilst maintaining other properties such as genre.\nAs this translation is specific to tempo it enables retrieval of tracks that\nare similar but have specifically different tempi. We show that such a function\ncan be used as an efficient data augmentation strategy for both training of\ndownstream tempo predictors, and improved nearest neighbor retrieval of\nproperties largely independent of tempo.", "field": "Computer Science", "categories": "cs.SD,cs.DL,cs.IR,cs.LG,eess.AS"}, {"arxiv_id": "2401.08903", "title": "PPR: Enhancing Dodging Attacks while Maintaining Impersonation Attacks\n  on Face Recognition Systems", "abstract": "Adversarial Attacks on Face Recognition (FR) encompass two types:\nimpersonation attacks and evasion attacks. We observe that achieving a\nsuccessful impersonation attack on FR does not necessarily ensure a successful\ndodging attack on FR in the black-box setting. Introducing a novel attack\nmethod named Pre-training Pruning Restoration Attack (PPR), we aim to enhance\nthe performance of dodging attacks whilst avoiding the degradation of\nimpersonation attacks. Our method employs adversarial example pruning, enabling\na portion of adversarial perturbations to be set to zero, while tending to\nmaintain the attack performance. By utilizing adversarial example pruning, we\ncan prune the pre-trained adversarial examples and selectively free up certain\nadversarial perturbations. Thereafter, we embed adversarial perturbations in\nthe pruned area, which enhances the dodging performance of the adversarial face\nexamples. The effectiveness of our proposed attack method is demonstrated\nthrough our experimental results, showcasing its superior performance.", "field": "Computer Science", "categories": "cs.CV,cs.LG"}, {"arxiv_id": "2401.08908", "title": "Herding LLaMaS: Using LLMs as an OS Module", "abstract": "Computer systems are becoming increasingly heterogeneous with the emergence\nof new memory technologies and compute devices. GPUs alongside CPUs have become\ncommonplace and CXL is poised to be a mainstay of cloud systems. The operating\nsystem is responsible for managing these hardware resources, requiring\nmodification every time a new device is released. Years of research and\ndevelopment are sunk into tuning the OS for high performance with each new\nheterogeneous device. With the recent explosion in memory technologies and\ndomain-specific accelerators, it would be beneficial to have an OS that could\nprovide high performance for new devices without significant effort.\n  We propose LLaMaS which can adapt to new devices easily. LLaMaS uses Large\nLanguage Models (LLMs) to extract the useful features of new devices from their\ntextual description and uses these features to make operating system decisions\nat runtime. Adding support to LLaMaS for a new device is as simple as\ndescribing the system and new device properties in plaintext.\n  LLaMaS reduces the burden on system administrators to enable easy integration\nof new devices into production systems.\n  Preliminary evaluation using ChatGPT shows that LLMs are capable of\nextracting device features from text and make correct OS decisions based on\nthose features.", "field": "Computer Science", "categories": "cs.OS,cs.LG"}, {"arxiv_id": "2401.08909", "title": "Characterising Gradients for Unsupervised Accuracy Estimation under\n  Distribution Shift", "abstract": "Estimating test accuracy without access to the ground-truth test labels under\nvarying test environments is a challenging, yet extremely important problem in\nthe safe deployment of machine learning algorithms. Existing works rely on the\ninformation from either the outputs or the extracted features of neural\nnetworks to formulate an estimation score correlating with the ground-truth\ntest accuracy. In this paper, we investigate--both empirically and\ntheoretically--how the information provided by the gradients can be predictive\nof the ground-truth test accuracy even under a distribution shift.\nSpecifically, we use the norm of classification-layer gradients, backpropagated\nfrom the cross-entropy loss after only one gradient step over test data. Our\nkey idea is that the model should be adjusted with a higher magnitude of\ngradients when it does not generalize to the test dataset with a distribution\nshift. We provide theoretical insights highlighting the main ingredients of\nsuch an approach ensuring its empirical success. Extensive experiments\nconducted on diverse distribution shifts and model structures demonstrate that\nour method significantly outperforms state-of-the-art algorithms.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.08913", "title": "Efficient Image Super-Resolution via Symmetric Visual Attention Network", "abstract": "An important development direction in the Single-Image Super-Resolution\n(SISR) algorithms is to improve the efficiency of the algorithms. Recently,\nefficient Super-Resolution (SR) research focuses on reducing model complexity\nand improving efficiency through improved deep small kernel convolution,\nleading to a small receptive field. The large receptive field obtained by large\nkernel convolution can significantly improve image quality, but the\ncomputational cost is too high. To improve the reconstruction details of\nefficient super-resolution reconstruction, we propose a Symmetric Visual\nAttention Network (SVAN) by applying large receptive fields. The SVAN\ndecomposes a large kernel convolution into three different combinations of\nconvolution operations and combines them with an attention mechanism to form a\nSymmetric Large Kernel Attention Block (SLKAB), which forms a symmetric\nattention block with a bottleneck structure by the size of the receptive field\nin the convolution combination to extract depth features effectively as the\nbasic component of the SVAN. Our network gets a large receptive field while\nminimizing the number of parameters and improving the perceptual ability of the\nmodel. The experimental results show that the proposed SVAN can obtain\nhigh-quality super-resolution reconstruction results using only about 30% of\nthe parameters of existing SOTA methods.", "field": "Computer Science", "categories": "cs.CV,eess.IV"}, {"arxiv_id": "2401.08919", "title": "Partial Diacritization: A Context-Contrastive Inference Approach", "abstract": "Diacritization plays a pivotal role in improving readability and\ndisambiguating the meaning of Arabic texts. Efforts have so far focused on\nmarking every eligible character (Full Diacritization). Comparatively\noverlooked, Partial Diacritzation (PD) is the selection of a subset of\ncharacters to be marked to aid comprehension where needed. Research has\nindicated that excessive diacritic marks can hinder skilled readers--reducing\nreading speed and accuracy. We conduct a behavioral experiment and show that\npartially marked text is often easier to read than fully marked text, and\nsometimes easier than plain text. In this light, we introduce\nContext-Contrastive Partial Diacritization (CCPD)--a novel approach to PD which\nintegrates seamlessly with existing Arabic diacritization systems. CCPD\nprocesses each word twice, once with context and once without, and diacritizes\nonly the characters with disparities between the two inferences. Further, we\nintroduce novel indicators for measuring partial diacritization quality (SR,\nPDER, HDER, ERE), essential for establishing this as a machine learning task.\nLastly, we introduce TD2, a Transformer-variant of an established model which\noffers a markedly different per formance profile on our proposed indicators\ncompared to all other known systems.", "field": "Computer Science", "categories": "cs.CL,cs.LG"}, {"arxiv_id": "2401.08921", "title": "Electromagnetic Information Theory: Fundamentals and Applications for 6G\n  Wireless Communication Systems", "abstract": "In wireless communications, electromagnetic theory and information theory\nconstitute a pair of fundamental theories, bridged by antenna theory and\nwireless propagation channel modeling theory. Up to the fifth generation (5G)\nwireless communication networks, these four theories have been developing\nrelatively independently. However, in sixth generation (6G)\nspace-air-ground-sea wireless communication networks, seamless coverage is\nexpected in the three-dimensional (3D) space, potentially necessitating the\nacquisition of channel state information (CSI) and channel capacity calculation\nat anywhere and any time. Additionally, the key 6G technologies such as\nultra-massive multiple-input multiple-output (MIMO) and holographic MIMO\nachieves intricate interaction of the antennas and wireless propagation\nenvironments, which necessitates the joint modeling of antennas and wireless\npropagation channels. To address the challenges in 6G, the integration of the\nabove four theories becomes inevitable, leading to the concept of the so-called\nelectromagnetic information theory (EIT). In this article, a suite of 6G key\ntechnologies is highlighted. Then, the concepts and relationships of the four\ntheories are unveiled. Finally, the necessity and benefits of integrating them\ninto the EIT are revealed.", "field": "Computer Science", "categories": "cs.IT,cs.SY,eess.SP,eess.SY,math.IT"}, {"arxiv_id": "2401.08922", "title": "Post-Pandemic Hybrid Work in Software Companies: Findings from an\n  Industrial Case Study", "abstract": "Context. Software professionals learned from their experience during the\npandemic that most of their work can be done remotely, and now software\ncompanies are expected to adopt hybrid work models to avoid the resignation of\ntalented professionals who require more flexibility and work-life balance.\nHowever, hybrid work is a spectrum of flexible work arrangements, and\ncurrently, there are no well-established hybrid work configurations to be\nfollowed in the post-pandemic period. Goal. We investigated how software\nengineers are experiencing the post-pandemic hybrid work landscape, aiming to\nunderstand the factors that influence their choices between remote and\nin-office work. Method. We explored a large South American company by\ncollecting quantitative and qualitative data from 545 software professionals\nwho are currently navigating diverse hybrid work arrangements tailored to their\nindividual and team requirements. Findings. Our study revealed an array of\nfactors that significantly impact hybrid work within the software industry,\nincluding individual preferences, work-life balance, commute time, social\ninteractions, productivity, and more. Team dynamics, project demands, client\nexpectations, and organizational strategies also play an important role in\nshaping the complex landscape of hybrid work configurations in software\nengineering. Conclusions. In summary, the success of hybrid work models depends\non balancing individual preferences, team dynamics, and organizational\nstrategies. Our study demonstrated that, at present, there is no\none-size-fits-all individual approach to hybrid work in the software industry.", "field": "Computer Science", "categories": "cs.SE"}, {"arxiv_id": "2401.08925", "title": "RandOhm: Mitigating Impedance Side-channel Attacks using Randomized\n  Circuit Configurations", "abstract": "Physical side-channel attacks can compromise the security of integrated\ncircuits. Most of the physical side-channel attacks (e.g., power or\nelectromagnetic) exploit the dynamic behavior of a chip, typically manifesting\nas changes in current consumption or voltage fluctuations where algorithmic\ncountermeasures, such as masking, can effectively mitigate the attacks.\nHowever, as demonstrated recently, these mitigation techniques are not entirely\neffective against backscattered side-channel attacks such as impedance\nanalysis. In the case of an impedance attack, an adversary exploits the\ndata-dependent impedance variations of chip power delivery network (PDN) to\nextract secret information. In this work, we introduce RandOhm, which exploits\nmoving target defense (MTD) strategy based on partial reconfiguration of\nmainstream FPGAs, to defend against impedance side-channel attacks. We\ndemonstrate that the information leakage through the PDN impedance could be\nreduced via run-time reconfiguration of the secret-sensitive parts of the\ncircuitry. Hence, by constantly randomizing the placement and routing of the\ncircuit, one can decorrelate the data-dependent computation from the impedance\nvalue. To validate our claims, we present a systematic approach equipped with\ntwo different partial reconfiguration strategies on implementations of the AES\ncipher realized on 28-nm FPGAs. We investigate the overhead of our mitigation\nin terms of delay and performance and provide security analysis by performing\nnon-profiled and profiled impedance analysis attacks against these\nimplementations to demonstrate the resiliency of our approach.", "field": "Computer Science", "categories": "cs.CR"}, {"arxiv_id": "2401.08926", "title": "Uncertainty-aware No-Reference Point Cloud Quality Assessment", "abstract": "The evolution of compression and enhancement algorithms necessitates an\naccurate quality assessment for point clouds. Previous works consistently\nregard point cloud quality assessment (PCQA) as a MOS regression problem and\ndevise a deterministic mapping, ignoring the stochasticity in generating MOS\nfrom subjective tests. Besides, the viewpoint switching of 3D point clouds in\nsubjective tests reinforces the judging stochasticity of different subjects\ncompared with traditional images. This work presents the first probabilistic\narchitecture for no-reference PCQA, motivated by the labeling process of\nexisting datasets. The proposed method can model the quality judging\nstochasticity of subjects through a tailored conditional variational\nautoencoder (CVAE) and produces multiple intermediate quality ratings. These\nintermediate ratings simulate the judgments from different subjects and are\nthen integrated into an accurate quality prediction, mimicking the generation\nprocess of a ground truth MOS. Specifically, our method incorporates a Prior\nModule, a Posterior Module, and a Quality Rating Generator, where the former\ntwo modules are introduced to model the judging stochasticity in subjective\ntests, while the latter is developed to generate diverse quality ratings.\nExtensive experiments indicate that our approach outperforms previous\ncutting-edge methods by a large margin and exhibits gratifying cross-dataset\nrobustness.", "field": "Computer Science", "categories": "cs.CV,eess.IV"}, {"arxiv_id": "2401.0893", "title": "3D Human Pose Analysis via Diffusion Synthesis", "abstract": "Diffusion models have demonstrated remarkable success in generative modeling.\nIn this paper, we propose PADS (Pose Analysis by Diffusion Synthesis), a novel\nframework designed to address various challenges in 3D human pose analysis\nthrough a unified pipeline. Central to PADS are two distinctive strategies: i)\nlearning a task-agnostic pose prior using a diffusion synthesis process to\neffectively capture the kinematic constraints in human pose data, and ii)\nunifying multiple pose analysis tasks like estimation, completion, denoising,\netc, as instances of inverse problems. The learned pose prior will be treated\nas a regularization imposing on task-specific constraints, guiding the\noptimization process through a series of conditional denoising steps. PADS\nrepresents the first diffusion-based framework for tackling general 3D human\npose analysis within the inverse problem framework. Its performance has been\nvalidated on different benchmarks, signaling the adaptability and robustness of\nthis pipeline.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.08932", "title": "Learning to detect cloud and snow in remote sensing images from noisy\n  labels", "abstract": "Detecting clouds and snow in remote sensing images is an essential\npreprocessing task for remote sensing imagery. Previous works draw inspiration\nfrom semantic segmentation models in computer vision, with most research\nfocusing on improving model architectures to enhance detection performance.\nHowever, unlike natural images, the complexity of scenes and the diversity of\ncloud types in remote sensing images result in many inaccurate labels in cloud\nand snow detection datasets, introducing unnecessary noises into the training\nand testing processes. By constructing a new dataset and proposing a novel\ntraining strategy with the curriculum learning paradigm, we guide the model in\nreducing overfitting to noisy labels. Additionally, we design a more\nappropriate model performance evaluation method, that alleviates the\nperformance assessment bias caused by noisy labels. By conducting experiments\non models with UNet and Segformer, we have validated the effectiveness of our\nproposed method. This paper is the first to consider the impact of label noise\non the detection of clouds and snow in remote sensing images.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.08936", "title": "DeLF: Designing Learning Environments with Foundation Models", "abstract": "Reinforcement learning (RL) offers a capable and intuitive structure for the\nfundamental sequential decision-making problem. Despite impressive\nbreakthroughs, it can still be difficult to employ RL in practice in many\nsimple applications. In this paper, we try to address this issue by introducing\na method for designing the components of the RL environment for a given,\nuser-intended application. We provide an initial formalization for the problem\nof RL component design, that concentrates on designing a good representation\nfor observation and action space. We propose a method named DeLF: Designing\nLearning Environments with Foundation Models, that employs large language\nmodels to design and codify the user's intended learning scenario. By testing\nour method on four different learning environments, we demonstrate that DeLF\ncan obtain executable environment codes for the corresponding RL problems.", "field": "Computer Science", "categories": "cs.AI,cs.LG"}, {"arxiv_id": "2401.08937", "title": "ICON: Incremental CONfidence for Joint Pose and Radiance Field\n  Optimization", "abstract": "Neural Radiance Fields (NeRF) exhibit remarkable performance for Novel View\nSynthesis (NVS) given a set of 2D images. However, NeRF training requires\naccurate camera pose for each input view, typically obtained by\nStructure-from-Motion (SfM) pipelines. Recent works have attempted to relax\nthis constraint, but they still often rely on decent initial poses which they\ncan refine. Here we aim at removing the requirement for pose initialization. We\npresent Incremental CONfidence (ICON), an optimization procedure for training\nNeRFs from 2D video frames. ICON only assumes smooth camera motion to estimate\ninitial guess for poses. Further, ICON introduces ``confidence\": an adaptive\nmeasure of model quality used to dynamically reweight gradients. ICON relies on\nhigh-confidence poses to learn NeRF, and high-confidence 3D structure (as\nencoded by NeRF) to learn poses. We show that ICON, without prior pose\ninitialization, achieves superior performance in both CO3D and HO3D versus\nmethods which use SfM pose.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.08939", "title": "Enhancing Campus Mobility: Achievements and Challenges of Autonomous\n  Shuttle \"Snow Lion''", "abstract": "The rapid evolution of autonomous vehicles (AVs) has significantly influenced\nglobal transportation systems. In this context, we present ``Snow Lion'', an\nautonomous shuttle meticulously designed to revolutionize on-campus\ntransportation, offering a safer and more efficient mobility solution for\nstudents, faculty, and visitors. The primary objective of this research is to\nenhance campus mobility by providing a reliable, efficient, and eco-friendly\ntransportation solution that seamlessly integrates with existing infrastructure\nand meets the diverse needs of a university setting. To achieve this goal, we\ndelve into the intricacies of the system design, encompassing sensing,\nperception, localization, planning, and control aspects. We evaluate the\nautonomous shuttle's performance in real-world scenarios, involving a\n1146-kilometer road haul and the transportation of 442 passengers over a\ntwo-month period. These experiments demonstrate the effectiveness of our system\nand offer valuable insights into the intricate process of integrating an\nautonomous vehicle within campus shuttle operations. Furthermore, a thorough\nanalysis of the lessons derived from this experience furnishes a valuable\nreal-world case study, accompanied by recommendations for future research and\ndevelopment in the field of autonomous driving.", "field": "Computer Science", "categories": "cs.RO"}, {"arxiv_id": "2401.0894", "title": "CEL: A Continual Learning Model for Disease Outbreak Prediction by\n  Leveraging Domain Adaptation via Elastic Weight Consolidation", "abstract": "Continual learning, the ability of a model to learn over time without\nforgetting previous knowledge and, therefore, be adaptive to new data, is\nparamount in dynamic fields such as disease outbreak prediction. Deep neural\nnetworks, i.e., LSTM, are prone to error due to catastrophic forgetting. This\nstudy introduces a novel CEL model for continual learning by leveraging domain\nadaptation via Elastic Weight Consolidation (EWC). This model aims to mitigate\nthe catastrophic forgetting phenomenon in a domain incremental setting. The\nFisher Information Matrix (FIM) is constructed with EWC to develop a\nregularization term that penalizes changes to important parameters, namely, the\nimportant previous knowledge. CEL's performance is evaluated on three distinct\ndiseases, Influenza, Mpox, and Measles, with different metrics. The high\nR-squared values during evaluation and reevaluation outperform the other\nstate-of-the-art models in several contexts, indicating that CEL adapts to\nincremental data well. CEL's robustness and reliability are underscored by its\nminimal 65% forgetting rate and 18% higher memory stability compared to\nexisting benchmark studies. This study highlights CEL's versatility in disease\noutbreak prediction, addressing evolving data with temporal patterns. It offers\na valuable model for proactive disease control with accurate, timely\npredictions.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.08943", "title": "Fluid Dynamic DNNs for Reliable and Adaptive Distributed Inference on\n  Edge Devices", "abstract": "Distributed inference is a popular approach for efficient DNN inference at\nthe edge. However, traditional Static and Dynamic DNNs are not\ndistribution-friendly, causing system reliability and adaptability issues. In\nthis paper, we introduce Fluid Dynamic DNNs (Fluid DyDNNs), tailored for\ndistributed inference. Distinct from Static and Dynamic DNNs, Fluid DyDNNs\nutilize a novel nested incremental training algorithm to enable independent and\ncombined operation of its sub-networks, enhancing system reliability and\nadaptability. Evaluation on embedded Arm CPUs with a DNN model and the MNIST\ndataset, shows that in scenarios of single device failure, Fluid DyDNNs ensure\ncontinued inference, whereas Static and Dynamic DNNs fail. When devices are\nfully operational, Fluid DyDNNs can operate in either a High-Accuracy mode and\nachieve comparable accuracy with Static DNNs, or in a High-Throughput mode and\nachieve 2.5x and 2x throughput compared with Static and Dynamic DNNs,\nrespectively.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.08947", "title": "AntiPhishStack: LSTM-based Stacked Generalization Model for Optimized\n  Phishing URLs Detection", "abstract": "The escalating reliance on revolutionary online web services has introduced\nheightened security risks, with persistent challenges posed by phishing despite\nextensive security measures. Traditional phishing systems, reliant on machine\nlearning and manual features, struggle with evolving tactics. Recent advances\nin deep learning offer promising avenues for tackling novel phishing challenges\nand malicious URLs. This paper introduces a two-phase stack generalized model\nnamed AntiPhishStack, designed to detect phishing sites. The model leverages\nthe learning of URLs and character-level TF-IDF features symmetrically,\nenhancing its ability to combat emerging phishing threats. In Phase I, features\nare trained on a base machine learning classifier, employing K-fold\ncross-validation for robust mean prediction. Phase II employs a two-layered\nstacked-based LSTM network with five adaptive optimizers for dynamic\ncompilation, ensuring premier prediction on these features. Additionally, the\nsymmetrical predictions from both phases are optimized and integrated to train\na meta-XGBoost classifier, contributing to a final robust prediction. The\nsignificance of this work lies in advancing phishing detection with\nAntiPhishStack, operating without prior phishing-specific feature knowledge.\nExperimental validation on two benchmark datasets, comprising benign and\nphishing or malicious URLs, demonstrates the model's exceptional performance,\nachieving a notable 96.04% accuracy compared to existing studies. This research\nadds value to the ongoing discourse on symmetry and asymmetry in information\nsecurity and provides a forward-thinking solution for enhancing network\nsecurity in the face of evolving cyber threats.", "field": "Computer Science", "categories": "cs.CR,cs.LG"}, {"arxiv_id": "2401.08948", "title": "PINSAT: Parallelized Interleaving of Graph Search and Trajectory\n  Optimization for Kinodynamic Motion Planning", "abstract": "Trajectory optimization is a widely used technique in robot motion planning\nfor letting the dynamics and constraints on the system shape and synthesize\ncomplex behaviors. Several previous works have shown its benefits in\nhigh-dimensional continuous state spaces and under differential constraints.\nHowever, long time horizons and planning around obstacles in non-convex spaces\npose challenges in guaranteeing convergence or finding optimal solutions. As a\nresult, discrete graph search planners and sampling-based planers are preferred\nwhen facing obstacle-cluttered environments. A recently developed algorithm\ncalled INSAT effectively combines graph search in the low-dimensional subspace\nand trajectory optimization in the full-dimensional space for global\nkinodynamic planning over long horizons. Although INSAT successfully reasoned\nabout and solved complex planning problems, the numerous expensive calls to an\noptimizer resulted in large planning times, thereby limiting its practical use.\nInspired by the recent work on edge-based parallel graph search, we present\nPINSAT, which introduces systematic parallelization in INSAT to achieve lower\nplanning times and higher success rates, while maintaining significantly lower\ncosts over relevant baselines. We demonstrate PINSAT by evaluating it on 6 DoF\nkinodynamic manipulation planning with obstacles.", "field": "Computer Science", "categories": "cs.RO"}, {"arxiv_id": "2401.08953", "title": "An Efficient and Scalable Auditing Scheme for Cloud Data Storage using\n  an Enhanced B-tree", "abstract": "An efficient, scalable, and provably secure dynamic auditing scheme is highly\ndesirable in the cloud storage environment for verifying the integrity of the\noutsourced data. Most of the existing work on remote integrity checking focuses\non static archival data and therefore cannot be applied to cases where dynamic\ndata updates are more common. Additionally, existing auditing schemes suffer\nfrom performance bottlenecks and scalability issues. To address these issues,\nin this paper, we present a novel dynamic auditing scheme for centralized cloud\nenvironments leveraging an enhanced version of the B-tree. Our proposed scheme\nachieves the immutable characteristic of a decentralized system (i.e.,\nblockchain technology) while effectively addressing the synchronization and\nperformance challenges of such systems. Unlike other static auditing schemes,\nour scheme supports dynamic insert, update, and delete operations. Also, by\nleveraging an enhanced B-tree, our scheme maintains a balanced tree after any\nalteration to a certain file, improving performance significantly. Experimental\nresults show that our scheme outperforms both traditional Merkle Hash\nTree-based centralized auditing and decentralized blockchain-based auditing\nschemes in terms of block modifications (e.g., insert, delete, update), block\nretrieval, and data verification time.", "field": "Computer Science", "categories": "cs.CR,cs.DS"}, {"arxiv_id": "2401.08956", "title": "A Unified NOMA Framework in Beam-Hopping Satellite Communication Systems", "abstract": "This paper investigates the application of a unified non-orthogonal multiple\naccess framework in beam hopping (U-NOMA-BH) based satellite communication\nsystems. More specifically, the proposed U-NOMA-BH framework can be applied to\ncode-domain NOMA based BH (CD-NOMA-BH) and power-domain NOMA based BH\n(PD-NOMA-BH) systems. To satisfy dynamic-uneven traffic demands, we formulate\nthe optimization problem to minimize the square of discrete difference by\njointly optimizing power allocation, carrier assignment and beam scheduling.\nThe non-convexity of the objective function and the constraint condition is\nsolved through Dinkelbach's transform and variable relaxation. As a further\ndevelopment, the closed-from and asymptotic expressions of outage probability\nare derived for CD/PD-NOMA-BH systems. Based on approximated results, the\ndiversity orders of a pair of users are obtained in detail. In addition, the\nsystem throughput of U-NOMA-BH is discussed in delay-limited transmission mode.\nNumerical results verify that: i) The gap between traffic requests of\nCD/PD-NOMA-BH systems appears to be more closely compared with orthogonal\nmultiple access based BH (OMA-BH); ii) The CD-NOMA-BH system is capable of\nproviding the enhanced traffic request and capacity provision; and iii) The\noutage behaviors of CD/PD-NOMA-BH are better than that of OMA-BH.", "field": "Computer Science", "categories": "cs.IT,eess.SP,math.IT"}, {"arxiv_id": "2401.08957", "title": "SWBT: Similarity Weighted Behavior Transformer with the Imperfect\n  Demonstration for Robotic Manipulation", "abstract": "Imitation learning (IL), aiming to learn optimal control policies from expert\ndemonstrations, has been an effective method for robot manipulation tasks.\nHowever, previous IL methods either only use expensive expert demonstrations\nand omit imperfect demonstrations or rely on interacting with the environment\nand learning from online experiences. In the context of robotic manipulation,\nwe aim to conquer the above two challenges and propose a novel framework named\nSimilarity Weighted Behavior Transformer (SWBT). SWBT effectively learn from\nboth expert and imperfect demonstrations without interaction with environments.\nWe reveal that the easy-to-get imperfect demonstrations, such as forward and\ninverse dynamics, significantly enhance the network by learning fruitful\ninformation. To the best of our knowledge, we are the first to attempt to\nintegrate imperfect demonstrations into the offline imitation learning setting\nfor robot manipulation tasks. Extensive experiments on the ManiSkill2 benchmark\nbuilt on the high-fidelity Sapien simulator and real-world robotic manipulation\ntasks demonstrated that the proposed method can extract better features and\nimprove the success rates for all tasks. Our code will be released upon\nacceptance of the paper.", "field": "Computer Science", "categories": "cs.RO,cs.AI,I.2.9"}, {"arxiv_id": "2401.08959", "title": "Towards Off-Policy Reinforcement Learning for Ranking Policies with\n  Human Feedback", "abstract": "Probabilistic learning to rank (LTR) has been the dominating approach for\noptimizing the ranking metric, but cannot maximize long-term rewards.\nReinforcement learning models have been proposed to maximize user long-term\nrewards by formulating the recommendation as a sequential decision-making\nproblem, but could only achieve inferior accuracy compared to LTR counterparts,\nprimarily due to the lack of online interactions and the characteristics of\nranking. In this paper, we propose a new off-policy value ranking (VR)\nalgorithm that can simultaneously maximize user long-term rewards and optimize\nthe ranking metric offline for improved sample efficiency in a unified\nExpectation-Maximization (EM) framework. We theoretically and empirically show\nthat the EM process guides the leaned policy to enjoy the benefit of\nintegration of the future reward and ranking metric, and learn without any\nonline interactions. Extensive offline and online experiments demonstrate the\neffectiveness of our methods.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.0896", "title": "From User Surveys to Telemetry-Driven Agents: Exploring the Potential of\n  Personalized Productivity Solutions", "abstract": "We present a comprehensive, user-centric approach to understand preferences\nin AI-based productivity agents and develop personalized solutions tailored to\nusers' needs. Utilizing a two-phase method, we first conducted a survey with\n363 participants, exploring various aspects of productivity, communication\nstyle, agent approach, personality traits, personalization, and privacy.\nDrawing on the survey insights, we developed a GPT-4 powered personalized\nproductivity agent that utilizes telemetry data gathered via Viva Insights from\ninformation workers to provide tailored assistance. We compared its performance\nwith alternative productivity-assistive tools, such as dashboard and narrative,\nin a study involving 40 participants. Our findings highlight the importance of\nuser-centric design, adaptability, and the balance between personalization and\nprivacy in AI-assisted productivity tools. By building on the insights\ndistilled from our study, we believe that our work can enable and guide future\nresearch to further enhance productivity solutions, ultimately leading to\noptimized efficiency and user experiences for information workers.", "field": "Computer Science", "categories": "cs.HC,cs.AI,cs.CY,H.5.0; H.5.3; H.5.m; J.0"}, {"arxiv_id": "2401.08961", "title": "Cascading Reinforcement Learning", "abstract": "Cascading bandits have gained popularity in recent years due to their\napplicability to recommendation systems and online advertising. In the\ncascading bandit model, at each timestep, an agent recommends an ordered subset\nof items (called an item list) from a pool of items, each associated with an\nunknown attraction probability. Then, the user examines the list, and clicks\nthe first attractive item (if any), and after that, the agent receives a\nreward. The goal of the agent is to maximize the expected cumulative reward.\nHowever, the prior literature on cascading bandits ignores the influences of\nuser states (e.g., historical behaviors) on recommendations and the change of\nstates as the session proceeds. Motivated by this fact, we propose a\ngeneralized cascading RL framework, which considers the impact of user states\nand state transition into decisions. In cascading RL, we need to select items\nnot only with large attraction probabilities but also leading to good successor\nstates. This imposes a huge computational challenge due to the combinatorial\naction space. To tackle this challenge, we delve into the properties of value\nfunctions, and design an oracle BestPerm to efficiently find the optimal item\nlist. Equipped with BestPerm, we develop two algorithms CascadingVI and\nCascadingBPI, which are both computationally-efficient and sample-efficient,\nand provide near-optimal regret and sample complexity guarantees. Furthermore,\nwe present experiments to show the improved computational and sample\nefficiencies of our algorithms compared to straightforward adaptations of\nexisting RL algorithms in practice.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.08962", "title": "DOO-RE: A dataset of ambient sensors in a meeting room for activity\n  recognition", "abstract": "With the advancement of IoT technology, recognizing user activities with\nmachine learning methods is a promising way to provide various smart services\nto users. High-quality data with privacy protection is essential for deploying\nsuch services in the real world. Data streams from surrounding ambient sensors\nare well suited to the requirement. Existing ambient sensor datasets only\nsupport constrained private spaces and those for public spaces have yet to be\nexplored despite growing interest in research on them. To meet this need, we\nbuild a dataset collected from a meeting room equipped with ambient sensors.\nThe dataset, DOO-RE, includes data streams from various ambient sensor types\nsuch as Sound and Projector. Each sensor data stream is segmented into activity\nunits and multiple annotators provide activity labels through a\ncross-validation annotation process to improve annotation quality. We finally\nobtain 9 types of activities. To our best knowledge, DOO-RE is the first\ndataset to support the recognition of both single and group activities in a\nreal meeting room with reliable annotations.", "field": "Computer Science", "categories": "cs.HC,cs.LG,cs.SD,eess.AS"}, {"arxiv_id": "2401.08964", "title": "Evidence-centered Assessment for Writing with Generative AI", "abstract": "We propose a learning analytics-based methodology for assessing the\ncollaborative writing of humans and generative artificial intelligence. Framed\nby the evidence-centered design, we used elements of knowledge-telling,\nknowledge transformation, and cognitive presence to identify assessment claims;\nwe used data collected from the CoAuthor writing tool as potential evidence for\nthese claims; and we used epistemic network analysis to make inferences from\nthe data about the claims. Our findings revealed significant differences in the\nwriting processes of different groups of CoAuthor users, suggesting that our\nmethod is a plausible approach to assessing human-AI collaborative writing.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.08965", "title": "Dynamic DNNs and Runtime Management for Efficient Inference on\n  Mobile/Embedded Devices", "abstract": "Deep neural network (DNN) inference is increasingly being executed on mobile\nand embedded platforms due to several key advantages in latency, privacy and\nalways-on availability. However, due to limited computing resources, efficient\nDNN deployment on mobile and embedded platforms is challenging. Although many\nhardware accelerators and static model compression methods were proposed by\nprevious works, at system runtime, multiple applications are typically executed\nconcurrently and compete for hardware resources. This raises two main\nchallenges: Runtime Hardware Availability and Runtime Application Variability.\nPrevious works have addressed these challenges through either dynamic neural\nnetworks that contain sub-networks with different performance trade-offs or\nruntime hardware resource management. In this thesis, we proposed a combined\nmethod, a system was developed for DNN performance trade-off management,\ncombining the runtime trade-off opportunities in both algorithms and hardware\nto meet dynamically changing application performance targets and hardware\nconstraints in real time. We co-designed novel Dynamic Super-Networks to\nmaximise runtime system-level performance and energy efficiency on\nheterogeneous hardware platforms. Compared with SOTA, our experimental results\nusing ImageNet on the GPU of Jetson Xavier NX show our model is 2.4x faster for\nsimilar ImageNet Top-1 accuracy, or 5.1% higher accuracy at similar latency. We\nalso designed a hierarchical runtime resource manager that tunes both dynamic\nneural networks and DVFS at runtime. Compared with the Linux DVFS governor\nschedutil, our runtime approach achieves up to a 19% energy reduction and a 9%\nlatency reduction in single model deployment scenario, and an 89% energy\nreduction and a 23% latency reduction in a two concurrent model deployment\nscenario.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.08967", "title": "ReFT: Reasoning with Reinforced Fine-Tuning", "abstract": "One way to enhance the reasoning capability of Large Language Models (LLMs)\nis to conduct Supervised Fine-Tuning (SFT) using Chain-of-Thought (CoT)\nannotations. This approach does not show sufficiently strong generalization\nability, however, because the training only relies on the given CoT data. In\nmath problem-solving, for example, there is usually only one annotated\nreasoning path for each question in the training data. Intuitively, it would be\nbetter for the algorithm to learn from multiple annotated reasoning paths given\na question. To address this issue, we propose a simple yet effective approach\ncalled Reinforced Fine-Tuning (ReFT) to enhance the generalizability of\nlearning LLMs for reasoning, with math problem-solving as an example. ReFT\nfirst warmups the model with SFT, and then employs on-line reinforcement\nlearning, specifically the PPO algorithm in this paper, to further fine-tune\nthe model, where an abundance of reasoning paths are automatically sampled\ngiven the question and the rewards are naturally derived from the ground-truth\nanswers. Extensive experiments on GSM8K, MathQA, and SVAMP datasets show that\nReFT significantly outperforms SFT, and the performance can be potentially\nfurther boosted by combining inference-time strategies such as majority voting\nand re-ranking. Note that ReFT obtains the improvement by learning from the\nsame training questions as SFT, without relying on extra or augmented training\nquestions. This indicates a superior generalization ability for ReFT.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.08968", "title": "COCO is \"ALL'' You Need for Visual Instruction Fine-tuning", "abstract": "Multi-modal Large Language Models (MLLMs) are increasingly prominent in the\nfield of artificial intelligence. Visual instruction fine-tuning (IFT) is a\nvital process for aligning MLLMs' output with user's intentions. High-quality\nand diversified instruction following data is the key to this fine-tuning\nprocess. Recent studies propose to construct visual IFT datasets through a\nmultifaceted approach: transforming existing datasets with rule-based\ntemplates, employing GPT-4 for rewriting annotations, and utilizing GPT-4V for\nvisual dataset pseudo-labeling. LLaVA-1.5 adopted similar approach and\nconstruct LLaVA-mix-665k, which is one of the simplest, most widely used, yet\nmost effective IFT datasets today. Notably, when properly fine-tuned with this\ndataset, MLLMs can achieve state-of-the-art performance on several benchmarks.\nHowever, we noticed that models trained with this dataset often struggle to\nfollow user instructions properly in multi-round dialog. In addition, tradition\ncaption and VQA evaluation benchmarks, with their closed-form evaluation\nstructure, are not fully equipped to assess the capabilities of modern\nopen-ended generative MLLMs. This problem is not unique to the LLaVA-mix-665k\ndataset, but may be a potential issue in all IFT datasets constructed from\nimage captioning or VQA sources, though the extent of this issue may vary. We\nargue that datasets with diverse and high-quality detailed instruction\nfollowing annotations are essential and adequate for MLLMs IFT. In this work,\nwe establish a new IFT dataset, with images sourced from the COCO dataset along\nwith more diverse instructions. Our experiments show that when fine-tuned with\nout proposed dataset, MLLMs achieve better performance on open-ended evaluation\nbenchmarks in both single-round and multi-round dialog setting.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.08972", "title": "Hearing Loss Detection from Facial Expressions in One-on-one\n  Conversations", "abstract": "Individuals with impaired hearing experience difficulty in conversations,\nespecially in noisy environments. This difficulty often manifests as a change\nin behavior and may be captured via facial expressions, such as the expression\nof discomfort or fatigue. In this work, we build on this idea and introduce the\nproblem of detecting hearing loss from an individual's facial expressions\nduring a conversation. Building machine learning models that can represent\nhearing-related facial expression changes is a challenge. In addition, models\nneed to disentangle spurious age-related correlations from hearing-driven\nexpressions. To this end, we propose a self-supervised pre-training strategy\ntailored for the modeling of expression variations. We also use adversarial\nrepresentation learning to mitigate the age bias. We evaluate our approach on a\nlarge-scale egocentric dataset with real-world conversational scenarios\ninvolving subjects with hearing loss and show that our method for hearing loss\ndetection achieves superior performance over baselines.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.08973", "title": "OCTO+: A Suite for Automatic Open-Vocabulary Object Placement in Mixed\n  Reality", "abstract": "One key challenge in Augmented Reality is the placement of virtual content in\nnatural locations. Most existing automated techniques can only work with a\nclosed-vocabulary, fixed set of objects. In this paper, we introduce and\nevaluate several methods for automatic object placement using recent advances\nin open-vocabulary vision-language models. Through a multifaceted evaluation,\nwe identify a new state-of-the-art method, OCTO+. We also introduce a benchmark\nfor automatically evaluating the placement of virtual objects in augmented\nreality, alleviating the need for costly user studies. Through this, in\naddition to human evaluations, we find that OCTO+ places objects in a valid\nregion over 70% of the time, outperforming other methods on a range of metrics.", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.CL"}, {"arxiv_id": "2401.08974", "title": "Performance Analysis and Optimization for Movable Antenna Aided Wideband\n  Communications", "abstract": "Movable antenna (MA) has emerged as a promising technology to enhance\nwireless communication performance by enabling the local movement of antennas\nat the transmitter (Tx) and/or receiver (Rx) for achieving more favorable\nchannel conditions. As the existing studies on MA-aided wireless communications\nhave mainly considered narrow-band transmission in flat fading channels, we\ninvestigate in this paper the MA-aided wideband communications employing\northogonal frequency division multiplexing (OFDM) in frequency-selective fading\nchannels. Under the general multi-tap field-response channel model, the\nwireless channel variations in both space and frequency are characterized with\ndifferent positions of the MAs. Unlike the narrow-band transmission where the\noptimal MA position at the Tx/Rx simply maximizes the single-tap channel\namplitude, the MA position in the wideband case needs to balance the amplitudes\nand phases over multiple channel taps in order to maximize the OFDM\ntransmission rate over multiple frequency subcarriers. First, we derive an\nupper bound on the OFDM achievable rate in closed form when the size of the\nTx/Rx region for antenna movement is arbitrarily large. Next, we develop a\nparallel greedy ascent (PGA) algorithm to obtain locally optimal solutions to\nthe MAs' positions for OFDM rate maximization subject to finite-size Tx/Rx\nregions. To reduce computational complexity, a simplified PGA algorithm is also\nprovided to optimize the MAs' positions more efficiently. Simulation results\ndemonstrate that the proposed PGA algorithms can approach the OFDM rate upper\nbound closely with the increase of Tx/Rx region sizes and outperform\nconventional systems with fixed-position antennas (FPAs) under the wideband\nchannel setup.", "field": "Computer Science", "categories": "cs.IT,eess.SP,math.IT"}, {"arxiv_id": "2401.08976", "title": "ACT-GAN: Radio map construction based on generative adversarial networks\n  with ACT blocks", "abstract": "The radio map, serving as a visual representation of electromagnetic spatial\ncharacteristics, plays a pivotal role in assessment of wireless communication\nnetworks and radio monitoring coverage. Addressing the issue of low accuracy\nexisting in the current radio map construction, this paper presents a novel\nradio map construction method based on generative adversarial network (GAN) in\nwhich the Aggregated Contextual-Transformation (AOT) block, Convolutional Block\nAttention Module (CBAM), and Transposed Convolution (T-Conv) block are applied\nto the generator, and we name it as ACT-GAN. It significantly improves the\nreconstruction accuracy and local texture of the radio maps. The performance of\nACT-GAN across three different scenarios is demonstrated. Experiment results\nreveal that in the scenario without sparse discrete observations, the proposed\nmethod reduces the root mean square error (RMSE) by 14.6% in comparison to the\nstate-of-the-art models. In the scenario with sparse discrete observations, the\nRMSE is diminished by 13.2%. Furthermore, the predictive results of the\nproposed model show a more lucid representation of electromagnetic spatial\nfield distribution. To verify the universality of this model in radio map\nconstruction tasks, the scenario of unknown radio emission source is\ninvestigated. The results indicate that the proposed model is robust radio map\nconstruction and accurate in predicting the location of the emission source.", "field": "Computer Science", "categories": "cs.LG,eess.SP"}, {"arxiv_id": "2401.08977", "title": "FedLoGe: Joint Local and Generic Federated Learning under Long-tailed\n  Data", "abstract": "Federated Long-Tailed Learning (Fed-LT), a paradigm wherein data collected\nfrom decentralized local clients manifests a globally prevalent long-tailed\ndistribution, has garnered considerable attention in recent times. In the\ncontext of Fed-LT, existing works have predominantly centered on addressing the\ndata imbalance issue to enhance the efficacy of the generic global model while\nneglecting the performance at the local level. In contrast, conventional\nPersonalized Federated Learning (pFL) techniques are primarily devised to\noptimize personalized local models under the presumption of a balanced global\ndata distribution. This paper introduces an approach termed Federated Local and\nGeneric Model Training in Fed-LT (FedLoGe), which enhances both local and\ngeneric model performance through the integration of representation learning\nand classifier alignment within a neural collapse framework. Our investigation\nreveals the feasibility of employing a shared backbone as a foundational\nframework for capturing overarching global trends, while concurrently employing\nindividualized classifiers to encapsulate distinct refinements stemming from\neach client's local features. Building upon this discovery, we establish the\nStatic Sparse Equiangular Tight Frame Classifier (SSE-C), inspired by neural\ncollapse principles that naturally prune extraneous noisy features and foster\nthe acquisition of potent data representations. Furthermore, leveraging\ninsights from imbalance neural collapse's classifier norm patterns, we develop\nGlobal and Local Adaptive Feature Realignment (GLA-FR) via an auxiliary global\nclassifier and personalized Euclidean norm transfer to align global features\nwith client preferences. Extensive experimental results on CIFAR-10/100-LT,\nImageNet, and iNaturalist demonstrate the advantage of our method over\nstate-of-the-art pFL and Fed-LT approaches.", "field": "Computer Science", "categories": "cs.LG,cs.AI,I.2.0"}, {"arxiv_id": "2401.08981", "title": "Real-time generative design of diverse, \"truly\" optimized structures\n  with controllable structural complexities", "abstract": "Compared with traditional design methods, generative design significantly\nattracts engineers in various disciplines. In thiswork, howto achieve the\nreal-time generative design of optimized structures with various diversities\nand controllable structural complexities is investigated. To this end, a\nmodified Moving Morphable Component (MMC) method together with novel strategies\nare adopted to generate high-quality dataset. The complexity level of optimized\nstructures is categorized by the topological invariant. By improving the cost\nfunction, the WGAN is trained to produce optimized designs with the input of\nloading position and complexity level in real time. It is found that, diverse\ndesigns with a clear load transmission path and crisp boundary, even not\nrequiring further optimization and different from any reference in the dataset,\ncan be generated by the proposed model. This method holds great potential for\nfuture applications of machine learning enhanced intelligent design.", "field": "Computer Science", "categories": "cs.CE"}, {"arxiv_id": "2401.08982", "title": "Robot Tape Manipulation for 3D Printing", "abstract": "3D printing has enabled various applications using different forms of\nmaterials, such as filaments, sheets, and inks. Typically, during 3D printing,\nfeedstocks are transformed into discrete building blocks and placed or\ndeposited in a designated location similar to the manipulation and assembly of\ndiscrete objects. However, 3D printing of continuous and flexible tape (with\nthe geometry between filaments and sheets) without breaking or transformation\nremains underexplored and challenging. Here, we report the design and\nimplementation of a customized end-effector, i.e., tape print module (TPM), to\nrealize robot tape manipulation for 3D printing by leveraging the tension\nformed on the tape between two endpoints. We showcase the feasibility of\nmanufacturing representative 2D and 3D structures while utilizing conductive\ncopper tape for various electronic applications, such as circuits and sensors.\nWe believe this manipulation strategy could unlock the potential of other tape\nmaterials for manufacturing, including packaging tape and carbon fiber prepreg\ntape, and inspire new mechanisms for robot manipulation, 3D printing, and\npackaging.", "field": "Computer Science", "categories": "cs.RO,cs.SY,eess.SY"}, {"arxiv_id": "2401.08984", "title": "A GAN-based data poisoning framework against anomaly detection in\n  vertical federated learning", "abstract": "In vertical federated learning (VFL), commercial entities collaboratively\ntrain a model while preserving data privacy. However, a malicious participant's\npoisoning attack may degrade the performance of this collaborative model. The\nmain challenge in achieving the poisoning attack is the absence of access to\nthe server-side top model, leaving the malicious participant without a clear\ntarget model. To address this challenge, we introduce an innovative end-to-end\npoisoning framework P-GAN. Specifically, the malicious participant initially\nemploys semi-supervised learning to train a surrogate target model.\nSubsequently, this participant employs a GAN-based method to produce\nadversarial perturbations to degrade the surrogate target model's performance.\nFinally, the generator is obtained and tailored for VFL poisoning. Besides, we\ndevelop an anomaly detection algorithm based on a deep auto-encoder (DAE),\noffering a robust defense mechanism to VFL scenarios. Through extensive\nexperiments, we evaluate the efficacy of P-GAN and DAE, and further analyze the\nfactors that influence their performance.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.CR"}, {"arxiv_id": "2401.08986", "title": "Rigid Protein-Protein Docking via Equivariant Elliptic-Paraboloid\n  Interface Prediction", "abstract": "The study of rigid protein-protein docking plays an essential role in a\nvariety of tasks such as drug design and protein engineering. Recently, several\nlearning-based methods have been proposed for the task, exhibiting much faster\ndocking speed than those computational methods. In this paper, we propose a\nnovel learning-based method called ElliDock, which predicts an elliptic\nparaboloid to represent the protein-protein docking interface. To be specific,\nour model estimates elliptic paraboloid interfaces for the two input proteins\nrespectively, and obtains the roto-translation transformation for docking by\nmaking two interfaces coincide. By its design, ElliDock is independently\nequivariant with respect to arbitrary rotations/translations of the proteins,\nwhich is an indispensable property to ensure the generalization of the docking\nprocess. Experimental evaluations show that ElliDock achieves the fastest\ninference time among all compared methods and is strongly competitive with\ncurrent state-of-the-art learning-based models such as DiffDock-PP and Multimer\nparticularly for antibody-antigen docking.", "field": "Computer Science", "categories": "cs.LG,q-bio.BM"}, {"arxiv_id": "2401.08988", "title": "DECENT-BRM: Decentralization through Block Reward Mechanisms", "abstract": "Proof-of-Work is a consensus algorithm where miners solve cryptographic\npuzzles to mine blocks and obtain a reward through some Block Reward Mechanism\n(BRM). PoW blockchain faces the problem of centralization due to the formation\nof mining pools, where miners mine blocks as a group and distribute rewards.\nThe rationale is to reduce the risk (variance) in reward while obtaining the\nsame expected block reward. In this work, we address the problem of\ncentralization due to mining pools in PoW blockchain. We propose a two-player\ngame between the new miner joining the system and the PoW blockchain system.\n  We model the utility for the incoming miner as a combination of (i) expected\nblock reward, (ii) risk, and (iii) cost of switching between different mining\npools. With this utility structure, we analyze the equilibrium strategy of the\nincoming miner for different BRMs: (a) memoryless -- block reward is history\nindependent (e.g., Bitcoin) (b) retentive: block reward is history-dependent\n(e.g., Fruitchains). For memoryless BRMs, we show that depending on the\ncoefficient of switching cost $c$, the protocol is decentralized when $c = 0$\nand centralized when $c > \\underline{c}$. In addition, we show the\nimpossibility of constructing a memoryless BRM where solo mining gives a higher\npayoff than forming/joining mining pools. While retentive BRM in Fruitchains\nreduces risk in solo mining, the equilibrium strategy for incoming miners is\nstill to join mining pools, leading to centralization. We then propose our\nnovel retentive BRM -- \\textsf{Decent-BRM}. We show that under\n\\textsf{Decent-BRM}, incoming miners obtain higher utility in solo mining than\njoining mining pools. Therefore, no mining pools are formed, and the Pow\nblockchain using \\textsf{Decent-BRM} is decentralized.", "field": "Computer Science", "categories": "cs.GT"}, {"arxiv_id": "2401.08991", "title": "Knight Watch: Ubiquitous Computing Enhancements To Sleep Quality With\n  Acoustic Analysis", "abstract": "This project introduces a wearable, non-intrusive device for snoring\ndetection and remediation, designed to be placed under or alongside a pillow.\nThe device uses sensors and machine learning algorithms to detect snoring and\nemploys gentle vibrations to prompt positional changes, thereby reducing\nsnoring episodes. The device is capable of connecting via an API to a\ncloud-based platform for the analysis of snoring sleep patterns and\nenvironmental context. The paper details the development from concept to\nprototype, emphasizing the technical challenges, solutions, and alignment with\nubiquitous computing in sleep quality improvement.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.08992", "title": "Efficient Adapter Finetuning for Tail Languages in Streaming\n  Multilingual ASR", "abstract": "The end-to-end ASR model is often desired in the streaming multilingual\nscenario since it is easier to deploy and can benefit from pre-trained speech\nmodels such as powerful foundation models. Meanwhile, the heterogeneous nature\nand imbalanced data abundance of different languages may cause performance\ndegradation, leading to asynchronous peak performance for different languages\nduring training, especially on tail ones. Sometimes even the data itself may\nbecome unavailable as a result of the enhanced privacy protection. Existing\nwork tend to significantly increase the model size or learn language-specific\ndecoders to accommodate each language separately. In this study, we explore\nsimple yet effective Language-Dependent Adapter (LDA) finetuning under a\ncascaded Conformer transducer framework enhanced by teacher pseudo-labeling for\ntail languages in the streaming multilingual ASR. The adapter only accounts for\n0.4% of the full model per language. It is plugged into the frozen foundation\nmodel and is the only trainable module during the finetuning process with noisy\nstudent training. The final model merges the adapter parameters from different\ncheckpoints for different languages. The model performance is validated on a\nchallenging multilingual dictation dataset, which includes 39 tail languages\nacross Latin, Greek, Arabic, etc. Our proposed method brings 12.2% word error\nrate reduction on average and up to 37.5% on a single locale. Furthermore, we\nshow that our parameter-efficient LDA can match the quality of the full model\nfinetuning, thus greatly alleviating the asynchronous peak performance issue.", "field": "Computer Science", "categories": "cs.CL,cs.LG,cs.SD,eess.AS"}, {"arxiv_id": "2401.08993", "title": "Estimating Gender Completeness in Wikipedia", "abstract": "Gender imbalance in Wikipedia content is a known challenge which the editor\ncommunity is actively addressing. The aim of this paper is to provide the\nWikipedia community with instruments to estimate the magnitude of the problem\nfor different entity types (also known as classes) in Wikipedia. To this end,\nwe apply class completeness estimation methods based on the gender attribute.\nOur results show not only which gender for different sub-classes of Person is\nmore prevalent in Wikipedia, but also an idea of how complete the coverage is\nfor difference genders and sub-classes of Person.", "field": "Computer Science", "categories": "cs.CY,cs.IR"}, {"arxiv_id": "2401.08994", "title": "Understanding and Facilitating Mental Health Help-Seeking of Young\n  Adults: A Socio-technical Ecosystem Framework", "abstract": "Prior research on young adults' mental health help-seeking mostly focuses on\none particular resource such as a mobile app or digital platform, paying less\nattention to their lived experiences interacting with the ecosystem of\nresources. We conducted in-depth interviews with 18 participants about their\nhelp-seeking and non-help-seeking experiences. Guided by Social Ecological\nTheory, we proposed a Socio-technical Ecosystem Framework for mental health\ncare, consisting of four levels of resources, including technological-,\ninterpersonal-, community-, and societal level resources. Using this framework,\nwe identified two types of support systems for help-seeking, single-resource\nsupport system and multi-resource support system. These resources support young\nadults' help-seeking via three mechanisms, \\textit{care-giving},\n\\textit{care-mediating}, and \\textit{care-outreaching}, forming various\npathways to care. We then pointed out the barriers to resource use at each\nlevel and the general challenges in finding a support system. Our findings\ncontributed to a conceptual framework to categorize mental health care. It also\nserves as a practical framework to identify challenges in the pathways to care\nand discover design implications.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.08996", "title": "MicroNAS: Zero-Shot Neural Architecture Search for MCUs", "abstract": "Neural Architecture Search (NAS) effectively discovers new Convolutional\nNeural Network (CNN) architectures, particularly for accuracy optimization.\nHowever, prior approaches often require resource-intensive training on super\nnetworks or extensive architecture evaluations, limiting practical\napplications. To address these challenges, we propose MicroNAS, a\nhardware-aware zero-shot NAS framework designed for microcontroller units\n(MCUs) in edge computing. MicroNAS considers target hardware optimality during\nthe search, utilizing specialized performance indicators to identify optimal\nneural architectures without high computational costs. Compared to previous\nworks, MicroNAS achieves up to 1104x improvement in search efficiency and\ndiscovers models with over 3.23x faster MCU inference while maintaining similar\naccuracy", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.08998", "title": "Attack and Reset for Unlearning: Exploiting Adversarial Noise toward\n  Machine Unlearning through Parameter Re-initialization", "abstract": "With growing concerns surrounding privacy and regulatory compliance, the\nconcept of machine unlearning has gained prominence, aiming to selectively\nforget or erase specific learned information from a trained model. In response\nto this critical need, we introduce a novel approach called Attack-and-Reset\nfor Unlearning (ARU). This algorithm leverages meticulously crafted adversarial\nnoise to generate a parameter mask, effectively resetting certain parameters\nand rendering them unlearnable. ARU outperforms current state-of-the-art\nresults on two facial machine-unlearning benchmark datasets, MUFAC and MUCAC.\nIn particular, we present the steps involved in attacking and masking that\nstrategically filter and re-initialize network parameters biased towards the\nforget set. Our work represents a significant advancement in rendering data\nunexploitable to deep learning models through parameter re-initialization,\nachieved by harnessing adversarial noise to craft a mask.", "field": "Computer Science", "categories": "cs.LG,cs.CR,cs.CV"}, {"arxiv_id": "2401.08999", "title": "Continuous Time Continuous Space Homeostatic Reinforcement Learning\n  (CTCS-HRRL) : Towards Biological Self-Autonomous Agent", "abstract": "Homeostasis is a biological process by which living beings maintain their\ninternal balance. Previous research suggests that homeostasis is a learned\nbehaviour. Recently introduced Homeostatic Regulated Reinforcement Learning\n(HRRL) framework attempts to explain this learned homeostatic behavior by\nlinking Drive Reduction Theory and Reinforcement Learning. This linkage has\nbeen proven in the discrete time-space, but not in the continuous time-space.\nIn this work, we advance the HRRL framework to a continuous time-space\nenvironment and validate the CTCS-HRRL (Continuous Time Continuous Space HRRL)\nframework. We achieve this by designing a model that mimics the homeostatic\nmechanisms in a real-world biological agent. This model uses the\nHamilton-Jacobian Bellman Equation, and function approximation based on neural\nnetworks and Reinforcement Learning. Through a simulation-based experiment we\ndemonstrate the efficacy of this model and uncover the evidence linked to the\nagent's ability to dynamically choose policies that favor homeostasis in a\ncontinuously changing internal-state milieu. Results of our experiments\ndemonstrate that agent learns homeostatic behaviour in a CTCS environment,\nmaking CTCS-HRRL a promising framework for modellng animal dynamics and\ndecision-making.", "field": "Computer Science", "categories": "cs.AI,cs.LG"}, {"arxiv_id": "2401.09001", "title": "Enablers and Barriers of Empathy in Software Developer and User\n  Interaction: A Mixed Methods Case Study", "abstract": "Software engineering (SE) requires developers to collaborate with\nstakeholders, and understanding their emotions and perspectives is often vital.\nEmpathy is a concept characterising a person's ability to understand and share\nthe feelings of another. However, empathy continues to be an under-researched\nhuman aspect in SE. We studied how empathy is practised between developers and\nend users using a mixed methods case study. We used an empathy test,\nobservations and interviews to collect data, and socio technical grounded\ntheory and descriptive statistics to analyse data. We identified the nature of\nawareness required to trigger empathy and enablers of empathy. We discovered\nbarriers to empathy and a set of potential strategies to overcome these\nbarriers. We report insights on emerging relationships and present a set of\nrecommendations and potential future works on empathy and SE for software\npractitioners and SE researchers.", "field": "Computer Science", "categories": "cs.SE"}, {"arxiv_id": "2401.09002", "title": "AttackEval: How to Evaluate the Effectiveness of Jailbreak Attacking on\n  Large Language Models", "abstract": "In our research, we pioneer a novel approach to evaluate the effectiveness of\njailbreak attacks on Large Language Models (LLMs), such as GPT-4 and LLaMa2,\ndiverging from traditional robustness-focused binary evaluations. Our study\nintroduces two distinct evaluation frameworks: a coarse-grained evaluation and\na fine-grained evaluation. Each framework, using a scoring range from 0 to 1,\noffers a unique perspective, enabling a more comprehensive and nuanced\nevaluation of attack effectiveness and empowering attackers to refine their\nattack prompts with greater understanding. Furthermore, we have developed a\ncomprehensive ground truth dataset specifically tailored for jailbreak tasks.\nThis dataset not only serves as a crucial benchmark for our current study but\nalso establishes a foundational resource for future research, enabling\nconsistent and comparative analyses in this evolving field. Upon meticulous\ncomparison with traditional evaluation methods, we discovered that our\nevaluation aligns with the baseline's trend while offering a more profound and\ndetailed assessment. We believe that by accurately evaluating the effectiveness\nof attack prompts in the Jailbreak task, our work lays a solid foundation for\nassessing a wider array of similar or even more complex tasks in the realm of\nprompt injection, potentially revolutionizing this field.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.09003", "title": "Augmenting Math Word Problems via Iterative Question Composing", "abstract": "Despite recent progress in improving the mathematical reasoning ability of\nlarge language models(LLMs), solving competition-level math problems without\nthe use of external tools remains challenging for open-source LLMs. In this\nwork, we introduce the MMIQC dataset, a mixture of processed web data and\nsynthetic question-response pairs, to equip base models with better\nmathematical reasoning skills. Mistral-7B-MMIQC, the model obtained by\nfine-tuning Mistral-7B(arXiv:2310.06825) on MMIQC, achieves 36.0\\% accuracy on\nMATH(arXiv:2103.03874), 5.8\\% higher than the previous (model size $\\sim$7B)\nSOTA. Our experiments also show that a large part of the improvement attributes\nto our novel augmentation method IQC(Iterative Question Composing), where we\niteratively ask an LLM to compose new questions from the given seed problems\nand do rejection sampling from another LLM. MMIQC has now been released on\nhttps://huggingface.co/datasets/Vivacem/MMIQC.", "field": "Computer Science", "categories": "cs.CL,cs.AI,cs.LG"}, {"arxiv_id": "2401.09006", "title": "Generalized Face Liveness Detection via De-spoofing Face Generator", "abstract": "Previous Face Anti-spoofing (FAS) works face the challenge of generalizing in\nunseen domains. One of the major problems is that most existing FAS datasets\nare relatively small and lack data diversity. However, we find that there are\nnumerous real faces that can be easily achieved under various conditions, which\nare neglected by previous FAS works. In this paper, we conduct an Anomalous cue\nGuided FAS (AG-FAS) method, which leverages real faces for improving model\ngeneralization via a De-spoofing Face Generator (DFG). Specifically, the DFG\ntrained only on the real faces gains the knowledge of what a real face should\nbe like and can generate a \"real\" version of the face corresponding to any\ngiven input face. The difference between the generated \"real\" face and the\ninput face can provide an anomalous cue for the downstream FAS task. We then\npropose an Anomalous cue Guided FAS feature extraction Network (AG-Net) to\nfurther improve the FAS feature generalization via a cross-attention\ntransformer. Extensive experiments on a total of nine public datasets show our\nmethod achieves state-of-the-art results under cross-domain evaluations with\nunseen scenarios and unknown presentation attacks.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.09008", "title": "Hybrid of DiffStride and Spectral Pooling in Convolutional Neural\n  Networks", "abstract": "Stride determines the distance between adjacent filter positions as the\nfilter moves across the input. A fixed stride causes important information\ncontained in the image can not be captured, so that important information is\nnot classified. Therefore, in previous research, the DiffStride Method was\napplied, namely the Strided Convolution Method with which it can learn its own\nstride value. Severe Quantization and a constraining lower bound on preserved\ninformation are arises with Max Pooling Downsampling Method. Spectral Pooling\nreduce the constraint lower bound on preserved information by cutting off the\nrepresentation in the frequency domain. In this research a CNN Model is\nproposed with the Downsampling Learnable Stride Technique performed by\nBackpropagation combined with the Spectral Pooling Technique. Diffstride and\nSpectral Pooling techniques are expected to maintain most of the information\ncontained in the image. In this study, we compare the Hybrid Method, which is a\ncombined implementation of Spectral Pooling and DiffStride against the Baseline\nMethod, which is the DiffStride implementation on ResNet 18. The accuracy\nresult of the DiffStride combination with Spectral Pooling improves over\nDiffStride which is baseline method by 0.0094. This shows that the Hybrid\nMethod can maintain most of the information by cutting of the representation in\nthe frequency domain and determine the stride of the learning result through\nBackpropagation.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.09011", "title": "Inductive Models for Artificial Intelligence Systems are Insufficient\n  without Good Explanations", "abstract": "This paper discusses the limitations of machine learning (ML), particularly\ndeep artificial neural networks (ANNs), which are effective at approximating\ncomplex functions but often lack transparency and explanatory power. It\nhighlights the `problem of induction' : the philosophical issue that past\nobservations may not necessarily predict future events, a challenge that ML\nmodels face when encountering new, unseen data. The paper argues for the\nimportance of not just making predictions but also providing good explanations,\na feature that current models often fail to deliver. It suggests that for AI to\nprogress, we must seek models that offer insights and explanations, not just\npredictions.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.09013", "title": "An Improved Virtual Force Approach for UAV Deployment and Resource\n  Allocation in Emergency Communications", "abstract": "In this paper, we consider an unmanned aerial vehicle (UAV)-enabled emergency\ncommunication system, which establishes temporary communication link with users\nequipment (UEs) in a typical disaster environment with mountainous forest and\nobstacles. Towards this end, a joint deployment, power allocation, and user\nassociation optimization problem is formulated to maximize the total\ntransmission rate, while considering the demand of each UE and the disaster\nenvironment characteristics. Then, an alternating optimization algorithm is\nproposed by integrating coalition game and virtual force approach which\ncaptures the impact of the demand priority of UEs and the obstacles to the\nflight path and consumed power. Simulation results demonstrate that the\ncomputation time consumed by our proposed algorithm is only $5.6\\%$ of the\ntraditional heuristic algorithms, which validates its effectiveness in disaster\nscenarios.", "field": "Computer Science", "categories": "cs.NI,eess.SP"}, {"arxiv_id": "2401.09014", "title": "Data assimilation approach for addressing imperfections in people flow\n  measurement techniques using particle filter", "abstract": "Understanding and predicting people flow in urban areas is useful for\ndecision-making in urban planning and marketing strategies. Traditional methods\nfor understanding people flow can be divided into measurement-based approaches\nand simulation-based approaches. Measurement-based approaches have the\nadvantage of directly capturing actual people flow, but they face the challenge\nof data imperfection. On the other hand, simulations can obtain complete data\non a computer, but they only consider some of the factors determining human\nbehavior, leading to a divergence from actual people flow. Both measurement and\nsimulation methods have unresolved issues, and combining the two can\ncomplementarily overcome them. This paper proposes a method that applies data\nassimilation, a fusion technique of measurement and simulation, to agent-based\nsimulation. Data assimilation combines the advantages of both measurement and\nsimulation, contributing to the creation of an environment that can reflect\nreal people flow while acquiring richer data. The paper verifies the\neffectiveness of the proposed method in a virtual environment and demonstrates\nthe potential of data assimilation to compensate for the three types of\nimperfection in people flow measurement techniques. These findings can serve as\nguidelines for supplementing sparse measurement data in physical environments.", "field": "Computer Science", "categories": "cs.HC,cs.MA"}, {"arxiv_id": "2401.09016", "title": "Fast parallel sampling under isoperimetry", "abstract": "We show how to sample in parallel from a distribution $\\pi$ over $\\mathbb\nR^d$ that satisfies a log-Sobolev inequality and has a smooth log-density, by\nparallelizing the Langevin (resp. underdamped Langevin) algorithms. We show\nthat our algorithm outputs samples from a distribution $\\hat\\pi$ that is close\nto $\\pi$ in Kullback--Leibler (KL) divergence (resp. total variation (TV)\ndistance), while using only $\\log(d)^{O(1)}$ parallel rounds and\n$\\widetilde{O}(d)$ (resp. $\\widetilde O(\\sqrt d)$) gradient evaluations in\ntotal. This constitutes the first parallel sampling algorithms with TV distance\nguarantees.\n  For our main application, we show how to combine the TV distance guarantees\nof our algorithms with prior works and obtain RNC sampling-to-counting\nreductions for families of discrete distribution on the hypercube $\\{\\pm 1\\}^n$\nthat are closed under exponential tilts and have bounded covariance.\nConsequently, we obtain an RNC sampler for directed Eulerian tours and\nasymmetric determinantal point processes, resolving open questions raised in\nprior works.", "field": "Computer Science", "categories": "cs.DS,math.ST,stat.ML,stat.TH"}, {"arxiv_id": "2401.09018", "title": "Residual Alignment: Uncovering the Mechanisms of Residual Networks", "abstract": "The ResNet architecture has been widely adopted in deep learning due to its\nsignificant boost to performance through the use of simple skip connections,\nyet the underlying mechanisms leading to its success remain largely unknown. In\nthis paper, we conduct a thorough empirical study of the ResNet architecture in\nclassification tasks by linearizing its constituent residual blocks using\nResidual Jacobians and measuring their singular value decompositions. Our\nmeasurements reveal a process called Residual Alignment (RA) characterized by\nfour properties:\n  (RA1) intermediate representations of a given input are equispaced on a line,\nembedded in high dimensional space, as observed by Gai and Zhang [2021];\n  (RA2) top left and right singular vectors of Residual Jacobians align with\neach other and across different depths;\n  (RA3) Residual Jacobians are at most rank C for fully-connected ResNets,\nwhere C is the number of classes; and\n  (RA4) top singular values of Residual Jacobians scale inversely with depth.\n  RA consistently occurs in models that generalize well, in both\nfully-connected and convolutional architectures, across various depths and\nwidths, for varying numbers of classes, on all tested benchmark datasets, but\nceases to occur once the skip connections are removed. It also provably occurs\nin a novel mathematical model we propose. This phenomenon reveals a strong\nalignment between residual branches of a ResNet (RA2+4), imparting a highly\nrigid geometric structure to the intermediate representations as they progress\nlinearly through the network (RA1) up to the final layer, where they undergo\nNeural Collapse.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.09023", "title": "Explain Thyself Bully: Sentiment Aided Cyberbullying Detection with\n  Explanation", "abstract": "Cyberbullying has become a big issue with the popularity of different social\nmedia networks and online communication apps. While plenty of research is going\non to develop better models for cyberbullying detection in monolingual\nlanguage, there is very little research on the code-mixed languages and\nexplainability aspect of cyberbullying. Recent laws like \"right to\nexplanations\" of General Data Protection Regulation, have spurred research in\ndeveloping interpretable models rather than focusing on performance. Motivated\nby this we develop the first interpretable multi-task model called {\\em mExCB}\nfor automatic cyberbullying detection from code-mixed languages which can\nsimultaneously solve several tasks, cyberbullying detection,\nexplanation/rationale identification, target group detection and sentiment\nanalysis. We have introduced {\\em BullyExplain}, the first benchmark dataset\nfor explainable cyberbullying detection in code-mixed language. Each post in\n{\\em BullyExplain} dataset is annotated with four labels, i.e., {\\em bully\nlabel, sentiment label, target and rationales (explainability)}, i.e., which\nphrases are being responsible for annotating the post as a bully. The proposed\nmultitask framework (mExCB) based on CNN and GRU with word and sub-sentence\n(SS) level attention is able to outperform several baselines and state of the\nart models when applied on {\\em BullyExplain} dataset.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.09025", "title": "Exploring the Diversity of Music Experiences for Deaf and Hard of\n  Hearing People", "abstract": "Sensory substitution or enhancement techniques have been proposed to enable\ndeaf or hard of hearing (DHH) people to listen to and even compose music.\nHowever, little is known about how such techniques enhance DHH people's music\nexperience. Since deafness is a spectrum -- as are DHH people's preferences and\nperceptions of music -- a more situated understanding of their interaction with\nmusic is needed. To understand the music experience of this population, we\nconducted social media analyses, both qualitatively and quantitatively, in the\ndeaf and hard of hearing Reddit communities. Our content analysis revealed that\nDHH people leveraged sign language and visual/haptic cues to feel the music and\npreferred familiar, non-lyrical, instrument-heavy, and loud music. In addition,\nhearing aids were not customized for music, and the visual/haptic techniques\ndeveloped were not widely adopted by DHH people, leading to their suboptimal\nmusic experiences. The DHH community embodied mutual support among music\nlovers, evidenced by active information sharing and Q&A around music and\nhearing loss. We reflect on design justice for DHH people's music experience\nand propose practical design implications to create a more accessible music\nexperience for them.", "field": "Computer Science", "categories": "cs.HC,cs.CY"}, {"arxiv_id": "2401.09029", "title": "Cross-modality Guidance-aided Multi-modal Learning with Dual Attention\n  for MRI Brain Tumor Grading", "abstract": "Brain tumor represents one of the most fatal cancers around the world, and is\nvery common in children and the elderly. Accurate identification of the type\nand grade of tumor in the early stages plays an important role in choosing a\nprecise treatment plan. The Magnetic Resonance Imaging (MRI) protocols of\ndifferent sequences provide clinicians with important contradictory information\nto identify tumor regions. However, manual assessment is time-consuming and\nerror-prone due to big amount of data and the diversity of brain tumor types.\nHence, there is an unmet need for MRI automated brain tumor diagnosis. We\nobserve that the predictive capability of uni-modality models is limited and\ntheir performance varies widely across modalities, and the commonly used\nmodality fusion methods would introduce potential noise, which results in\nsignificant performance degradation. To overcome these challenges, we propose a\nnovel cross-modality guidance-aided multi-modal learning with dual attention\nfor addressing the task of MRI brain tumor grading. To balance the tradeoff\nbetween model efficiency and efficacy, we employ ResNet Mix Convolution as the\nbackbone network for feature extraction. Besides, dual attention is applied to\ncapture the semantic interdependencies in spatial and slice dimensions\nrespectively. To facilitate information interaction among modalities, we design\na cross-modality guidance-aided module where the primary modality guides the\nother secondary modalities during the process of training, which can\neffectively leverage the complementary information of different MRI modalities\nand meanwhile alleviate the impact of the possible noise.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.09031", "title": "Data Attribution for Diffusion Models: Timestep-induced Bias in\n  Influence Estimation", "abstract": "Data attribution methods trace model behavior back to its training dataset,\noffering an effective approach to better understand ``black-box'' neural\nnetworks. While prior research has established quantifiable links between model\noutput and training data in diverse settings, interpreting diffusion model\noutputs in relation to training samples remains underexplored. In particular,\ndiffusion models operate over a sequence of timesteps instead of instantaneous\ninput-output relationships in previous contexts, posing a significant challenge\nto extend existing frameworks to diffusion models directly. Notably, we present\nDiffusion-TracIn that incorporates this temporal dynamics and observe that\nsamples' loss gradient norms are highly dependent on timestep. This trend leads\nto a prominent bias in influence estimation, and is particularly noticeable for\nsamples trained on large-norm-inducing timesteps, causing them to be generally\ninfluential. To mitigate this effect, we introduce Diffusion-ReTrac as a\nre-normalized adaptation that enables the retrieval of training samples more\ntargeted to the test sample of interest, facilitating a localized measurement\nof influence and considerably more intuitive visualization. We demonstrate the\nefficacy of our approach through various evaluation metrics and auxiliary\ntasks, reducing the amount of generally influential samples to $\\frac{1}{3}$ of\nits original quantity.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.09032", "title": "Improved Consensus ADMM for Cooperative Motion Planning of Large-Scale\n  Connected Autonomous Vehicles with Limited Communication", "abstract": "This paper investigates a cooperative motion planning problem for large-scale\nconnected autonomous vehicles (CAVs) under limited communications, which\naddresses the challenges of high communication and computing resource\nrequirements. Our proposed methodology incorporates a parallel optimization\nalgorithm with improved consensus ADMM considering a more realistic locally\nconnected topology network, and time complexity of O(N) is achieved by\nexploiting the sparsity in the dual update process. To further enhance the\ncomputational efficiency, we employ a lightweight evolution strategy for the\ndynamic connectivity graph of CAVs, and each sub-problem split from the\nconsensus ADMM only requires managing a small group of CAVs. The proposed\nmethod implemented with the receding horizon scheme is validated thoroughly,\nand comparisons with existing numerical solvers and approaches demonstrate the\nefficiency of our proposed algorithm. Also, simulations on large-scale\ncooperative driving tasks involving 80 vehicles are performed in the\nhigh-fidelity CARLA simulator, which highlights the remarkable computational\nefficiency, scalability, and effectiveness of our proposed development.\nDemonstration videos are available at\nhttps://henryhcliu.github.io/icadmm_cmp_carla.", "field": "Computer Science", "categories": "cs.RO,cs.MA,cs.SY,eess.SY"}, {"arxiv_id": "2401.09034", "title": "UOEP: User-Oriented Exploration Policy for Enhancing Long-Term User\n  Experiences in Recommender Systems", "abstract": "Reinforcement learning (RL) has gained traction for enhancing user long-term\nexperiences in recommender systems by effectively exploring users' interests.\nHowever, modern recommender systems exhibit distinct user behavioral patterns\namong tens of millions of items, which increases the difficulty of exploration.\nFor example, user behaviors with different activity levels require varying\nintensity of exploration, while previous studies often overlook this aspect and\napply a uniform exploration strategy to all users, which ultimately hurts user\nexperiences in the long run. To address these challenges, we propose\nUser-Oriented Exploration Policy (UOEP), a novel approach facilitating\nfine-grained exploration among user groups. We first construct a distributional\ncritic which allows policy optimization under varying quantile levels of\ncumulative reward feedbacks from users, representing user groups with varying\nactivity levels. Guided by this critic, we devise a population of distinct\nactors aimed at effective and fine-grained exploration within its respective\nuser group. To simultaneously enhance diversity and stability during the\nexploration process, we further introduce a population-level diversity\nregularization term and a supervision module. Experimental results on public\nrecommendation datasets demonstrate that our approach outperforms all other\nbaselines in terms of long-term performance, validating its user-oriented\nexploration effectiveness. Meanwhile, further analyses reveal our approach's\nbenefits of improved performance for low-activity users as well as increased\nfairness among users.", "field": "Computer Science", "categories": "cs.IR,cs.AI"}, {"arxiv_id": "2401.09036", "title": "IRS-Enhanced Anti-Jamming Precoding Against DISCO Physical Layer Jamming\n  Attacks", "abstract": "Illegitimate intelligent reflective surfaces (IRSs) can pose significant\nphysical layer security risks on multi-user multiple-input single-output\n(MU-MISO) systems. Recently, a DISCO approach has been proposed an illegitimate\nIRS with random and time-varying reflection coefficients, referred to as a\n\"disco\" IRS (DIRS). Such DIRS can attack MU-MISO systems without relying on\neither jamming power or channel state information (CSI), and classical\nanti-jamming techniques are ineffective for the DIRS-based fully-passive\njammers (DIRS-based FPJs). In this paper, we propose an IRS-enhanced\nanti-jamming precoder against DIRS-based FPJs that requires only statistical\nrather than instantaneous CSI of the DIRS-jammed channels. Specifically, a\nlegitimate IRS is introduced to reduce the strength of the DIRS-based jamming\nrelative to the transmit signals at a legitimate user (LU). In addition, the\nactive beamforming at the legitimate access point (AP) is designed to maximize\nthe signal-to-jamming-plus-noise ratios (SJNRs). Numerical results are\npresented to evaluate the effectiveness of the proposed IRS-enhanced\nanti-jamming precoder against DIRS-based FPJs.", "field": "Computer Science", "categories": "cs.IT,eess.SP,math.IT"}, {"arxiv_id": "2401.09038", "title": "Visual Robotic Manipulation with Depth-Aware Pretraining", "abstract": "Recent work on visual representation learning has shown to be efficient for\nrobotic manipulation tasks. However, most existing works pretrained the visual\nbackbone solely on 2D images or egocentric videos, ignoring the fact that\nrobots learn to act in 3D space, which is hard to learn from 2D observation. In\nthis paper, we examine the effectiveness of pretraining for vision backbone\nwith public-available large-scale 3D data to improve manipulation policy\nlearning. Our method, namely Depth-aware Pretraining for Robotics (DPR),\nenables an RGB-only backbone to learn 3D scene representations from\nself-supervised contrastive learning, where depth information serves as\nauxiliary knowledge. No 3D information is necessary during manipulation policy\nlearning and inference, making our model enjoy both efficiency and\neffectiveness in 3D space manipulation. Furthermore, we introduce a new way to\ninject robots' proprioception into the policy networks that makes the\nmanipulation model robust and generalizable. We demonstrate in experiments that\nour proposed framework improves performance on unseen objects and visual\nenvironments for various robotics tasks on both simulated and real robots.", "field": "Computer Science", "categories": "cs.RO"}, {"arxiv_id": "2401.09041", "title": "Textual Summarisation of Large Sets: Towards a General Approach", "abstract": "We are developing techniques to generate summary descriptions of sets of\nobjects. In this paper, we present and evaluate a rule-based NLG technique for\nsummarising sets of bibliographical references in academic papers. This extends\nour previous work on summarising sets of consumer products and shows how our\nmodel generalises across these two very different domains.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.09042", "title": "LLMs for Relational Reasoning: How Far are We?", "abstract": "Large language models (LLMs) have revolutionized many areas (e.g. natural\nlanguage processing, software engineering, etc.) by achieving state-of-the-art\nperformance on extensive downstream tasks. Aiming to achieve robust and general\nartificial intelligence, there has been a surge of interest in investigating\nthe reasoning ability of the LLMs. Whereas the textual and numerical reasoning\nbenchmarks adopted by previous works are rather shallow and simple, it is hard\nto conclude that the LLMs possess strong reasoning ability by merely achieving\npositive results on these benchmarks. Recent efforts have demonstrated that the\nLLMs are poor at solving sequential decision-making problems that require\ncommon-sense planning by evaluating their performance on the reinforcement\nlearning benchmarks. In this work, we conduct an in-depth assessment of several\nstate-of-the-art LLMs' reasoning ability based on the inductive logic\nprogramming (ILP) benchmark, which is broadly recognized as a representative\nand challenging measurement for evaluating logic program induction/synthesis\nsystems as it requires inducing strict cause-effect logic to achieve robust\ndeduction on independent and identically distributed (IID) and\nout-of-distribution (OOD) test samples. Our evaluations illustrate that\ncompared with the neural program induction systems which are much smaller in\nmodel size, the state-of-the-art LLMs are much poorer in terms of reasoning\nability by achieving much lower performance and generalization using either\nnatural language prompting or truth-value matrix prompting.", "field": "Computer Science", "categories": "cs.AI,cs.CL"}, {"arxiv_id": "2401.09044", "title": "Algorithmic amplification of biases on Google Search", "abstract": "The evolution of information-seeking processes, driven by search engines like\nGoogle, has transformed the access to information people have. This paper\ninvestigates how individuals' preexisting attitudes influence the modern\ninformation-seeking process, specifically the results presented by Google\nSearch. Through a comprehensive study involving surveys and information-seeking\ntasks focusing on the topic of abortion, the paper provides four crucial\ninsights: 1) Individuals with opposing attitudes on abortion receive different\nsearch results. 2) Individuals express their beliefs in their choice of\nvocabulary used in formulating the search queries, shaping the outcome of the\nsearch. 3) Additionally, the user's search history contributes to divergent\nresults among those with opposing attitudes. 4) Google Search engine reinforces\npreexisting beliefs in search results. Overall, this study provides insights\ninto the interplay between human biases and algorithmic processes, highlighting\nthe potential for information polarization in modern information-seeking\nprocesses.", "field": "Computer Science", "categories": "cs.CY,cs.HC,cs.IR"}, {"arxiv_id": "2401.09047", "title": "VideoCrafter2: Overcoming Data Limitations for High-Quality Video\n  Diffusion Models", "abstract": "Text-to-video generation aims to produce a video based on a given prompt.\nRecently, several commercial video models have been able to generate plausible\nvideos with minimal noise, excellent details, and high aesthetic scores.\nHowever, these models rely on large-scale, well-filtered, high-quality videos\nthat are not accessible to the community. Many existing research works, which\ntrain models using the low-quality WebVid-10M dataset, struggle to generate\nhigh-quality videos because the models are optimized to fit WebVid-10M. In this\nwork, we explore the training scheme of video models extended from Stable\nDiffusion and investigate the feasibility of leveraging low-quality videos and\nsynthesized high-quality images to obtain a high-quality video model. We first\nanalyze the connection between the spatial and temporal modules of video models\nand the distribution shift to low-quality videos. We observe that full training\nof all modules results in a stronger coupling between spatial and temporal\nmodules than only training temporal modules. Based on this stronger coupling,\nwe shift the distribution to higher quality without motion degradation by\nfinetuning spatial modules with high-quality images, resulting in a generic\nhigh-quality video model. Evaluations are conducted to demonstrate the\nsuperiority of the proposed method, particularly in picture quality, motion,\nand concept composition.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.09048", "title": "Compose and Conquer: Diffusion-Based 3D Depth Aware Composable Image\n  Synthesis", "abstract": "Addressing the limitations of text as a source of accurate layout\nrepresentation in text-conditional diffusion models, many works incorporate\nadditional signals to condition certain attributes within a generated image.\nAlthough successful, previous works do not account for the specific\nlocalization of said attributes extended into the three dimensional plane. In\nthis context, we present a conditional diffusion model that integrates control\nover three-dimensional object placement with disentangled representations of\nglobal stylistic semantics from multiple exemplar images. Specifically, we\nfirst introduce \\textit{depth disentanglement training} to leverage the\nrelative depth of objects as an estimator, allowing the model to identify the\nabsolute positions of unseen objects through the use of synthetic image\ntriplets. We also introduce \\textit{soft guidance}, a method for imposing\nglobal semantics onto targeted regions without the use of any additional\nlocalization cues. Our integrated framework, \\textsc{Compose and Conquer\n(CnC)}, unifies these techniques to localize multiple conditions in a\ndisentangled manner. We demonstrate that our approach allows perception of\nobjects at varying depths while offering a versatile framework for composing\nlocalized objects with different global semantics. Code:\nhttps://github.com/tomtom1103/compose-and-conquer/", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.09049", "title": "Enhancing Lidar-based Object Detection in Adverse Weather using Offset\n  Sequences in Time", "abstract": "Automated vehicles require an accurate perception of their surroundings for\nsafe and efficient driving. Lidar-based object detection is a widely used\nmethod for environment perception, but its performance is significantly\naffected by adverse weather conditions such as rain and fog. In this work, we\ninvestigate various strategies for enhancing the robustness of lidar-based\nobject detection by processing sequential data samples generated by lidar\nsensors. Our approaches leverage temporal information to improve a lidar object\ndetection model, without the need for additional filtering or pre-processing\nsteps. We compare $10$ different neural network architectures that process\npoint cloud sequences including a novel augmentation strategy introducing a\ntemporal offset between frames of a sequence during training and evaluate the\neffectiveness of all strategies on lidar point clouds under adverse weather\nconditions through experiments. Our research provides a comprehensive study of\neffective methods for mitigating the effects of adverse weather on the\nreliability of lidar-based object detection using sequential data that are\nevaluated using public datasets such as nuScenes, Dense, and the Canadian\nAdverse Driving Conditions Dataset. Our findings demonstrate that our novel\nmethod, involving temporal offset augmentation through randomized frame\nskipping in sequences, enhances object detection accuracy compared to both the\nbaseline model (Pillar-based Object Detection) and no augmentation.", "field": "Computer Science", "categories": "cs.CV,cs.RO"}, {"arxiv_id": "2401.0905", "title": "Consistent3D: Towards Consistent High-Fidelity Text-to-3D Generation\n  with Deterministic Sampling Prior", "abstract": "Score distillation sampling (SDS) and its variants have greatly boosted the\ndevelopment of text-to-3D generation, but are vulnerable to geometry collapse\nand poor textures yet. To solve this issue, we first deeply analyze the SDS and\nfind that its distillation sampling process indeed corresponds to the\ntrajectory sampling of a stochastic differential equation (SDE): SDS samples\nalong an SDE trajectory to yield a less noisy sample which then serves as a\nguidance to optimize a 3D model. However, the randomness in SDE sampling often\nleads to a diverse and unpredictable sample which is not always less noisy, and\nthus is not a consistently correct guidance, explaining the vulnerability of\nSDS. Since for any SDE, there always exists an ordinary differential equation\n(ODE) whose trajectory sampling can deterministically and consistently converge\nto the desired target point as the SDE, we propose a novel and effective\n\"Consistent3D\" method that explores the ODE deterministic sampling prior for\ntext-to-3D generation. Specifically, at each training iteration, given a\nrendered image by a 3D model, we first estimate its desired 3D score function\nby a pre-trained 2D diffusion model, and build an ODE for trajectory sampling.\nNext, we design a consistency distillation sampling loss which samples along\nthe ODE trajectory to generate two adjacent samples and uses the less noisy\nsample to guide another more noisy one for distilling the deterministic prior\ninto the 3D model. Experimental results show the efficacy of our Consistent3D\nin generating high-fidelity and diverse 3D objects and large-scale scenes, as\nshown in Fig. 1. The codes are available at\nhttps://github.com/sail-sg/Consistent3D.", "field": "Computer Science", "categories": "cs.CV,cs.LG"}, {"arxiv_id": "2401.09051", "title": "Canvil: Designerly Adaptation for LLM-Powered User Experiences", "abstract": "Advancements in large language models (LLMs) are poised to spark a\nproliferation of LLM-powered user experiences. In product teams, designers are\noften tasked with crafting user experiences that align with user needs. To\ninvolve designers and leverage their user-centered perspectives to create\neffective and responsible LLM-powered products, we introduce the practice of\ndesignerly adaptation for engaging with LLMs as an adaptable design material.\nWe first identify key characteristics of designerly adaptation through a\nformative study with designers experienced in designing for LLM-powered\nproducts (N=12). These characteristics are 1) have a low technical barrier to\nentry, 2) leverage designers' unique perspectives bridging users and\ntechnology, and 3) encourage model tinkering. Based on this characterization,\nwe build Canvil, a Figma widget that operationalizes designerly adaptation.\nCanvil supports structured authoring of system prompts to adapt LLM behavior,\ntesting of adapted models on diverse user inputs, and integration of model\noutputs into interface designs. We use Canvil as a technology probe in a\ngroup-based design study (6 groups, N=17) to investigate the implications of\nintegrating designerly adaptation into design workflows. We find that designers\nare able to iteratively tinker with different adaptation approaches and reason\nabout interface affordances to enhance end-user interaction with LLMs.\nFurthermore, designers identified promising collaborative workflows for\ndesignerly adaptation. Our work opens new avenues for collaborative processes\nand tools that foreground designers' user-centered expertise in the crafting\nand deployment of LLM-powered user experiences.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.09052", "title": "Flow Divergence: Comparing Maps of Flows with Relative Entropy", "abstract": "Networks represent how the entities of a system are connected and can be\npartitioned differently, prompting ways to compare partitions. Common\napproaches for comparing network partitions include information-theoretic\nmeasures based on mutual information and set-theoretic measures such as the\nJaccard index. These measures are often based on computing the agreement in\nterms of overlap between different partitions of the same set. However, they\nignore link patterns which are essential for the organisation of networks. We\npropose flow divergence, an information-theoretic divergence measure for\ncomparing network partitions, inspired by the ideas behind the Kullback-Leibler\ndivergence and the map equation for community detection. Similar to the\nKullback-Leibler divergence, flow divergence adopts a coding perspective and\ncompares two network partitions $\\mathsf{M}_a$ and $\\mathsf{M}_b$ by\nconsidering the expected extra number of bits required to describe a random\nwalk on a network using $\\mathsf{M}_b$ relative to reference partition\n$\\mathsf{M}_a$. Because flow divergence is based on random walks, it can be\nused to compare partitions with arbitrary and different depths. We show that\nflow divergence distinguishes between partitions that traditional measures\nconsider to be equally good when compared to a reference partition. Applied to\nreal networks, we use flow divergence to estimate the cost of overfitting in\nincomplete networks and to visualise the solution landscape of network\npartitions.", "field": "Computer Science", "categories": "cs.SI,physics.soc-ph"}, {"arxiv_id": "2401.09057", "title": "CrossVideo: Self-supervised Cross-modal Contrastive Learning for Point\n  Cloud Video Understanding", "abstract": "This paper introduces a novel approach named CrossVideo, which aims to\nenhance self-supervised cross-modal contrastive learning in the field of point\ncloud video understanding. Traditional supervised learning methods encounter\nlimitations due to data scarcity and challenges in label acquisition. To\naddress these issues, we propose a self-supervised learning method that\nleverages the cross-modal relationship between point cloud videos and image\nvideos to acquire meaningful feature representations. Intra-modal and\ncross-modal contrastive learning techniques are employed to facilitate\neffective comprehension of point cloud video. We also propose a multi-level\ncontrastive approach for both modalities. Through extensive experiments, we\ndemonstrate that our method significantly surpasses previous state-of-the-art\napproaches, and we conduct comprehensive ablation studies to validate the\neffectiveness of our proposed designs.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.09059", "title": "Autonomous Catheterization with Open-source Simulator and Expert\n  Trajectory", "abstract": "Endovascular robots have been actively developed in both academia and\nindustry. However, progress toward autonomous catheterization is often hampered\nby the widespread use of closed-source simulators and physical phantoms.\nAdditionally, the acquisition of large-scale datasets for training machine\nlearning algorithms with endovascular robots is usually infeasible due to\nexpensive medical procedures. In this chapter, we introduce CathSim, the first\nopen-source simulator for endovascular intervention to address these\nlimitations. CathSim emphasizes real-time performance to enable rapid\ndevelopment and testing of learning algorithms. We validate CathSim against the\nreal robot and show that our simulator can successfully mimic the behavior of\nthe real robot. Based on CathSim, we develop a multimodal expert navigation\nnetwork and demonstrate its effectiveness in downstream endovascular navigation\ntasks. The intensive experimental results suggest that CathSim has the\npotential to significantly accelerate research in the autonomous\ncatheterization field. Our project is publicly available at\nhttps://github.com/airvlab/cathsim.", "field": "Computer Science", "categories": "cs.RO,cs.CV"}, {"arxiv_id": "2401.0906", "title": "Joint Route Selection and Power Allocation in Multi-hop Cache-enabled\n  Networks", "abstract": "The caching paradigm has been introduced to alleviate backhaul traffic load\nand to reduce latencies due to massive never ending increase in data traffic.\nTo fully exploit the benefits offered by caching, unmanned aerial vehicles\n(UAVs) and device-to-device (D2D) communication can be further utilized. In\ncontrast to prior works, that strictly limits the content delivery routes up to\ntwo hops, we explore a multi-hop communications scenario, where the UAVs, the\nUEs, or both can relay the content to individual users. In this context, we\nformulate the problem for joint route selection and power allocation to\nminimize the overall system content delivery duration. First, motivated by the\nlimitations of existing works, we consider the case where the nodes may\ntransmit content simultaneously rather than sequentially and propose simple yet\neffective approach to allocate the transmission power. Second, we design a\nlow-complexity greedy algorithm jointly handling route selection and power\nallocation. The simulation results demonstrate that the proposed greedy\nalgorithm outperforms the benchmark algorithm by up to 56.98% in terms of\ncontent delivery duration while it achieves close-to-optimal performance.", "field": "Computer Science", "categories": "cs.IT,math.IT"}, {"arxiv_id": "2401.09062", "title": "On Optimization of Next-Generation Microservice-Based Core Networks", "abstract": "Next-generation mobile core networks are required to be scalable and capable\nof efficiently utilizing heterogeneous bare metal resources that may include\nedge servers. To this end, microservice-based solutions where control plane\nprocedures are deconstructed in their fundamental building blocks are gaining\nmomentum. This letter proposes an optimization framework delivering the\npartitioning and mapping of large-scale microservice graphs onto heterogeneous\nbare metal deployments while minimizing the total network traffic among\nservers. An efficient heuristic strategy for solving the optimization problem\nis also provided. Simulation results show that, with the proposed framework, a\nmicroservice-based core can consistently support the requested load in\nheterogeneous bare metal deployments even when alternative architecture fails.\nBesides, our framework ensures an overall reduction in the control\nplane-related network traffic if compared to current core architectures.", "field": "Computer Science", "categories": "cs.NI"}, {"arxiv_id": "2401.09064", "title": "Performance Bounds and Optimization for CSI-Ratio based Bi-static\n  Doppler Sensing in ISAC Systems", "abstract": "Bi-static sensing is crucial for exploring the potential of networked sensing\ncapabilities in integrated sensing and communications (ISAC). However, it\nsuffers from the challenging clock asynchronism issue. CSI ratio-based sensing\nis an effective means to address the issue. Its performance bounds, particular\nfor Doppler sensing, have not been fully understood yet. This work endeavors to\nfill the research gap. Focusing on a single dynamic path in high-SNR scenarios,\nwe derive the closed-form CRB. Then, through analyzing the mutual interference\nbetween dynamic and static paths, we simplify the CRB results by deriving close\napproximations, further unveiling new insights of the impact of numerous\nphysical parameters on Doppler sensing. Moreover, utilizing the new CRB and\nanalyses, we propose novel waveform optimization strategies for noise- and\ninterference-limited sensing scenarios, which are also empowered by closed-form\nand efficient solutions. Extensive simulation results are provided to validate\nthe preciseness of the derived CRB results and analyses, with the aid of the\nmaximum-likelihood estimator. The results also demonstrate the substantial\nenhanced Doppler sensing accuracy and the sensing capabilities for low-speed\ntarget achieved by the proposed waveform design.", "field": "Computer Science", "categories": "cs.IT,eess.SP,math.IT"}, {"arxiv_id": "2401.09067", "title": "Towards Continual Learning Desiderata via HSIC-Bottleneck\n  Orthogonalization and Equiangular Embedding", "abstract": "Deep neural networks are susceptible to catastrophic forgetting when trained\non sequential tasks. Various continual learning (CL) methods often rely on\nexemplar buffers or/and network expansion for balancing model stability and\nplasticity, which, however, compromises their practical value due to privacy\nand memory concerns. Instead, this paper considers a strict yet realistic\nsetting, where the training data from previous tasks is unavailable and the\nmodel size remains relatively constant during sequential training. To achieve\nsuch desiderata, we propose a conceptually simple yet effective method that\nattributes forgetting to layer-wise parameter overwriting and the resulting\ndecision boundary distortion. This is achieved by the synergy between two key\ncomponents: HSIC-Bottleneck Orthogonalization (HBO) implements non-overwritten\nparameter updates mediated by Hilbert-Schmidt independence criterion in an\northogonal space and EquiAngular Embedding (EAE) enhances decision boundary\nadaptation between old and new tasks with predefined basis vectors. Extensive\nexperiments demonstrate that our method achieves competitive accuracy\nperformance, even with absolute superiority of zero exemplar buffer and 1.02x\nthe base model.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.CV"}, {"arxiv_id": "2401.09068", "title": "DTMM: Deploying TinyML Models on Extremely Weak IoT Devices with Pruning", "abstract": "DTMM is a library designed for efficient deployment and execution of machine\nlearning models on weak IoT devices such as microcontroller units (MCUs). The\nmotivation for designing DTMM comes from the emerging field of tiny machine\nlearning (TinyML), which explores extending the reach of machine learning to\nmany low-end IoT devices to achieve ubiquitous intelligence. Due to the weak\ncapability of embedded devices, it is necessary to compress models by pruning\nenough weights before deploying. Although pruning has been studied extensively\non many computing platforms, two key issues with pruning methods are\nexacerbated on MCUs: models need to be deeply compressed without significantly\ncompromising accuracy, and they should perform efficiently after pruning.\nCurrent solutions only achieve one of these objectives, but not both. In this\npaper, we find that pruned models have great potential for efficient deployment\nand execution on MCUs. Therefore, we propose DTMM with pruning unit selection,\npre-execution pruning optimizations, runtime acceleration, and post-execution\nlow-cost storage to fill the gap for efficient deployment and execution of\npruned models. It can be integrated into commercial ML frameworks for practical\ndeployment, and a prototype system has been developed. Extensive experiments on\nvarious models show promising gains compared to state-of-the-art methods.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.0907", "title": "Knowledge Pyramid: A Novel Hierarchical Reasoning Structure for\n  Generalized Knowledge Augmentation and Inference", "abstract": "Knowledge graph (KG) based reasoning has been regarded as an effective means\nfor the analysis of semantic networks and is of great usefulness in areas of\ninformation retrieval, recommendation, decision-making, and man-machine\ninteraction. It is widely used in recommendation, decision-making,\nquestion-answering, search, and other fields. However, previous studies mainly\nused low-level knowledge in the KG for reasoning, which may result in\ninsufficient generalization and poor robustness of reasoning. To this end, this\npaper proposes a new inference approach using a novel knowledge augmentation\nstrategy to improve the generalization capability of KG. This framework\nextracts high-level pyramidal knowledge from low-level knowledge and applies it\nto reasoning in a multi-level hierarchical KG, called knowledge pyramid in this\npaper. We tested some medical data sets using the proposed approach, and the\nexperimental results show that the proposed knowledge pyramid has improved the\nknowledge inference performance with better generalization. Especially, when\nthere are fewer training samples, the inference accuracy can be significantly\nimproved.", "field": "Computer Science", "categories": "cs.AI,cs.IR"}, {"arxiv_id": "2401.09071", "title": "Rethinking Spectral Graph Neural Networks with Spatially Adaptive\n  Filtering", "abstract": "Whilst spectral Graph Neural Networks (GNNs) are theoretically well-founded\nin the spectral domain, their practical reliance on polynomial approximation\nimplies a profound linkage to the spatial domain. As previous studies rarely\nexamine spectral GNNs from the spatial perspective, their spatial-domain\ninterpretability remains elusive, e.g., what information is essentially encoded\nby spectral GNNs in the spatial domain? In this paper, to answer this question,\nwe establish a theoretical connection between spectral filtering and spatial\naggregation, unveiling an intrinsic interaction that spectral filtering\nimplicitly leads the original graph to an adapted new graph, explicitly\ncomputed for spatial aggregation. Both theoretical and empirical investigations\nreveal that the adapted new graph not only exhibits non-locality but also\naccommodates signed edge weights to reflect label consistency between nodes.\nThese findings thus highlight the interpretable role of spectral GNNs in the\nspatial domain and inspire us to rethink graph spectral filters beyond the\nfixed-order polynomials, which neglect global information. Built upon the\ntheoretical findings, we revisit the state-of-the-art spectral GNNs and propose\na novel Spatially Adaptive Filtering (SAF) framework, which leverages the\nadapted new graph by spectral filtering for an auxiliary non-local aggregation.\nNotably, our proposed SAF comprehensively models both node similarity and\ndissimilarity from a global perspective, therefore alleviating persistent\ndeficiencies of GNNs related to long-range dependencies and graph heterophily.\nExtensive experiments over 13 node classification benchmarks demonstrate the\nsuperiority of our proposed framework to the state-of-the-art models.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.09072", "title": "A five field formulation for flow simulations in porous media with\n  fractures and barriers via an optimization based domain decomposition method", "abstract": "The present work deals with the numerical resolution of coupled 3D-2D\nproblems arising from the simulation of fluid flow in fractured porous media\nmodeled via the Discrete Fracture and Matrix (DFM) model. According to the DFM\nmodel, fractures are represented as planar interfaces immersed in a 3D porous\nmatrix and can behave as preferential flow paths, in the case of conductive\nfractures, or can actually be a barrier for the flow, when, instead, the\npermeability in the normal-to-fracture direction is small compared to the\npermeability of the matrix. Consequently, the pressure solution in a DFM can be\ndiscontinuous across a barrier, as a result of the geometrical dimensional\nreduction operated on the fracture.\n  The present work is aimed at developing a numerical scheme suitable for the\nsimulation of the flow in a DFM with fractures and barriers, using a mesh for\nthe 3D matrix non conforming to the fractures and that is ready for domain\ndecomposition. This is achieved starting from a PDE-constrained optimization\nmethod, currently available in literature only for conductive fractures in a\nDFM. First, a novel formulation of the optimization problem is defined to\naccount for non permeable fractures. These are described by a filtration-like\ncoupling at the interface with the surrounding porous matrix. Also the extended\nfinite element method with discontinuous enrichment functions is used to\nreproduce the pressure solution in the matrix around a barrier.\n  The method is presented here in its simplest form, for clarity of exposition,\ni.e. considering the case of a single fracture in a 3D domain, also providing a\nproof of the well posedness of the resulting discrete problem. Four validation\nexamples are proposed to show the viability and the effectiveness of the\nmethod.", "field": "Computer Science", "categories": "math.NA,cs.NA,65N30, 65N50, 68U20"}, {"arxiv_id": "2401.09073", "title": "Fixed-Budget Differentially Private Best Arm Identification", "abstract": "We study best arm identification (BAI) in linear bandits in the fixed-budget\nregime under differential privacy constraints, when the arm rewards are\nsupported on the unit interval. Given a finite budget $T$ and a privacy\nparameter $\\varepsilon>0$, the goal is to minimise the error probability in\nfinding the arm with the largest mean after $T$ sampling rounds, subject to the\nconstraint that the policy of the decision maker satisfies a certain {\\em\n$\\varepsilon$-differential privacy} ($\\varepsilon$-DP) constraint. We construct\na policy satisfying the $\\varepsilon$-DP constraint (called {\\sc DP-BAI}) by\nproposing the principle of {\\em maximum absolute determinants}, and derive an\nupper bound on its error probability. Furthermore, we derive a minimax lower\nbound on the error probability, and demonstrate that the lower and the upper\nbounds decay exponentially in $T$, with exponents in the two bounds matching\norder-wise in (a) the sub-optimality gaps of the arms, (b) $\\varepsilon$, and\n(c) the problem complexity that is expressible as the sum of two terms, one\ncharacterising the complexity of standard fixed-budget BAI (without privacy\nconstraints), and the other accounting for the $\\varepsilon$-DP constraint.\nAdditionally, we present some auxiliary results that contribute to the\nderivation of the lower bound on the error probability. These results, we\nposit, may be of independent interest and could prove instrumental in proving\nlower bounds on error probabilities in several other bandit problems. Whereas\nprior works provide results for BAI in the fixed-budget regime without privacy\nconstraints or in the fixed-confidence regime with privacy constraints, our\nwork fills the gap in the literature by providing the results for BAI in the\nfixed-budget regime under the $\\varepsilon$-DP constraint.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.IT,math.IT,math.ST,stat.ML,stat.TH"}, {"arxiv_id": "2401.09074", "title": "Code Simulation Challenges for Large Language Models", "abstract": "We investigate the extent to which Large Language Models (LLMs) can simulate\nthe execution of computer code and algorithms. We begin by looking straight\nline programs, and show that current LLMs demonstrate poor performance even\nwith such simple programs -- performance rapidly degrades with the length of\ncode. We then investigate the ability of LLMs to simulate programs that contain\ncritical paths and redundant instructions. We also go beyond straight line\nprogram simulation with sorting algorithms and nested loops, and we show the\ncomputational complexity of a routine directly affects the ability of an LLM to\nsimulate its execution. We observe that LLMs execute instructions sequentially\nand with a low error margin only for short programs or standard procedures.\nLLMs' code simulation is in tension with their pattern recognition and\nmemorisation capabilities: on tasks where memorisation is detrimental, we\npropose a novel prompting method to simulate code execution line by line.\nEmpirically, our new Chain of Simulation (CoSm) method improves on the standard\nChain of Thought prompting approach by avoiding the pitfalls of memorisation.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.CL,cs.PL"}, {"arxiv_id": "2401.09075", "title": "GPT in Sheep's Clothing: The Risk of Customized GPTs", "abstract": "In November 2023, OpenAI introduced a new service allowing users to create\ncustom versions of ChatGPT (GPTs) by using specific instructions and knowledge\nto guide the model's behavior. We aim to raise awareness of the fact that GPTs\ncan be used maliciously, posing privacy and security risks to their users.", "field": "Computer Science", "categories": "cs.CR,cs.AI"}, {"arxiv_id": "2401.09077", "title": "Hands-On Robotics: Enabling Communication Through Direct Gesture Control", "abstract": "Effective Human-Robot Interaction (HRI) is fundamental to seamlessly\nintegrating robotic systems into our daily lives. However, current\ncommunication modes require additional technological interfaces, which can be\ncumbersome and indirect. This paper presents a novel approach, using direct\nmotion-based communication by moving a robot's end effector. Our strategy\nenables users to communicate with a robot by using four distinct gestures --\ntwo handshakes ('formal' and 'informal') and two letters ('W' and 'S'). As a\nproof-of-concept, we conducted a user study with 16 participants, capturing\nsubjective experience ratings and objective data for training machine learning\nclassifiers. Our findings show that the four different gestures performed by\nmoving the robot's end effector can be distinguished with close to 100%\naccuracy. Our research offers implications for the design of future HRI\ninterfaces, suggesting that motion-based interaction can empower human\noperators to communicate directly with robots, removing the necessity for\nadditional hardware.", "field": "Computer Science", "categories": "cs.HC,cs.RO"}, {"arxiv_id": "2401.0908", "title": "Mixed Finite Elements of Higher-Order in Elastoplasticity", "abstract": "In this paper a higher-order mixed finite element method for elastoplasticity\nwith linear kinematic hardening is analyzed. Thereby, the non-differentiability\nof the involved plasticity functional is resolved by a Lagrange multiplier\nleading to a three field formulation. The finite element discretization is\nconforming in the displacement field and the plastic strain but potentially\nnon-conforming in the Lagrange multiplier as its Frobenius norm is only\nconstrained in a certain set of Gauss quadrature points. A discrete inf-sup\ncondition with constant 1 and the well posedness of the discrete mixed problem\nare shown. Moreover, convergence and guaranteed convergence rates are proved\nwith respect to the mesh size and the polynomial degree, which are optimal for\nthe lowest order case. Numerical experiments underline the theoretical results.", "field": "Computer Science", "categories": "math.NA,cs.NA,65N30, 65N50,G.1.8"}, {"arxiv_id": "2401.09082", "title": "What makes for a 'good' social actor? Using respect as a lens to\n  evaluate interactions with language agents", "abstract": "With the growing popularity of dialogue agents based on large language models\n(LLMs), urgent attention has been drawn to finding ways to ensure their\nbehaviour is ethical and appropriate. These are largely interpreted in terms of\nthe 'HHH' criteria: making outputs more helpful and honest, and avoiding\nharmful (biased, toxic, or inaccurate) statements. Whilst this semantic focus\nis useful from the perspective of viewing LLM agents as mere mediums for\ninformation, it fails to account for pragmatic factors that can make the same\nutterance seem more or less offensive or tactless in different social\nsituations. We propose an approach to ethics that is more centred on relational\nand situational factors, exploring what it means for a system, as a social\nactor, to treat an individual respectfully in a (series of) interaction(s). Our\nwork anticipates a set of largely unexplored risks at the level of situated\ninteraction, and offers practical suggestions to help LLM technologies behave\nas 'good' social actors and treat people respectfully.", "field": "Computer Science", "categories": "cs.CL,cs.AI,cs.HC,68T42,H.5.2; I.2; J.4; J.5"}, {"arxiv_id": "2401.09083", "title": "Remote Sensing ChatGPT: Solving Remote Sensing Tasks with ChatGPT and\n  Visual Models", "abstract": "Recently, the flourishing large language models(LLM), especially ChatGPT,\nhave shown exceptional performance in language understanding, reasoning, and\ninteraction, attracting users and researchers from multiple fields and domains.\nAlthough LLMs have shown great capacity to perform human-like task\naccomplishment in natural language and natural image, their potential in\nhandling remote sensing interpretation tasks has not yet been fully explored.\nMoreover, the lack of automation in remote sensing task planning hinders the\naccessibility of remote sensing interpretation techniques, especially to\nnon-remote sensing experts from multiple research fields. To this end, we\npresent Remote Sensing ChatGPT, an LLM-powered agent that utilizes ChatGPT to\nconnect various AI-based remote sensing models to solve complicated\ninterpretation tasks. More specifically, given a user request and a remote\nsensing image, we utilized ChatGPT to understand user requests, perform task\nplanning according to the tasks' functions, execute each subtask iteratively,\nand generate the final response according to the output of each subtask.\nConsidering that LLM is trained with natural language and is not capable of\ndirectly perceiving visual concepts as contained in remote sensing images, we\ndesigned visual cues that inject visual information into ChatGPT. With Remote\nSensing ChatGPT, users can simply send a remote sensing image with the\ncorresponding request, and get the interpretation results as well as language\nfeedback from Remote Sensing ChatGPT. Experiments and examples show that Remote\nSensing ChatGPT can tackle a wide range of remote sensing tasks and can be\nextended to more tasks with more sophisticated models such as the remote\nsensing foundation model. The code and demo of Remote Sensing ChatGPT is\npublicly available at https://github.com/HaonanGuo/Remote-Sensing-ChatGPT .", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.09084", "title": "UniVG: Towards UNIfied-modal Video Generation", "abstract": "Diffusion based video generation has received extensive attention and\nachieved considerable success within both the academic and industrial\ncommunities. However, current efforts are mainly concentrated on\nsingle-objective or single-task video generation, such as generation driven by\ntext, by image, or by a combination of text and image. This cannot fully meet\nthe needs of real-world application scenarios, as users are likely to input\nimages and text conditions in a flexible manner, either individually or in\ncombination. To address this, we propose a Unified-modal Video Genearation\nsystem that is capable of handling multiple video generation tasks across text\nand image modalities. To this end, we revisit the various video generation\ntasks within our system from the perspective of generative freedom, and\nclassify them into high-freedom and low-freedom video generation categories.\nFor high-freedom video generation, we employ Multi-condition Cross Attention to\ngenerate videos that align with the semantics of the input images or text. For\nlow-freedom video generation, we introduce Biased Gaussian Noise to replace the\npure random Gaussian Noise, which helps to better preserve the content of the\ninput conditions. Our method achieves the lowest Fr\\'echet Video Distance (FVD)\non the public academic benchmark MSR-VTT, surpasses the current open-source\nmethods in human evaluations, and is on par with the current close-source\nmethod Gen2. For more samples, visit https://univg-baidu.github.io.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.09089", "title": "Is Synchronization a Bottleneck for Pilot-Assisted URLLC Links?", "abstract": "We propose a framework to evaluate the random-coding union bound with\nparameter $s$ on the achievable error probability in the finite-blocklength\nregime for a pilot-assisted transmission scheme operating over an imperfectly\nsynchronized and memoryless block-fading waveform channel. Unlike previous\nresults, which disregard the effects of imperfect synchronization, our\nframework utilizes pilots for both synchronization and channel estimation.\nSpecifically, we provide an algorithm to perform joint synchronization and\nchannel estimation and verify its accuracy by observing its tightness in\ncomparison with the Cramer-Rao bound. Then, we develop an RCUs bound on the\nerror probability, which applies for a receiver that treats the estimates\nprovided by the algorithm as accurate. Additionally, we utilize the saddlepoint\napproximation to provide a numerically efficient method for evaluating the RCUs\nbound in this scenario. Our numerical experiments verify the accuracy of the\nproposed approximation. Moreover, when transmission blocks are received\nsynchronously, numerical results indicate that the number of pilot symbols\nneeded to estimate the fading channel gains to the level of accuracy required\nin ultra-reliable low-latency communication is also sufficient to acquire\nsufficiently good synchronization. However, when the blocks are received\nasynchronously, synchronization becomes the bottleneck for the system\nperformance.", "field": "Computer Science", "categories": "cs.IT,math.IT"}, {"arxiv_id": "2401.0909", "title": "Understanding the concerns and choices of public when using large\n  language models for healthcare", "abstract": "Large language models (LLMs) have shown their potential in biomedical fields.\nHowever, how the public uses them for healthcare purposes such as medical Q\\&A,\nself-diagnosis, and daily healthcare information seeking is under-investigated.\nIn this paper, we adopt a mixed-methods approach, including surveys (N=167) and\ninterviews (N=17) to investigate how and why the public uses LLMs for\nhealthcare. LLMs as a healthcare tool have gained popularity, and are often\nused in combination with other information channels such as search engines and\nonline health communities to optimize information quality. LLMs provide more\naccurate information and a more convenient interaction/service model compared\nto traditional channels. LLMs also do a better job of reducing misinformation,\nespecially in daily healthcare questions. Doctors using LLMs for diagnosis is\nless acceptable than for auxiliary work such as writing medical records. Based\non the findings, we reflect on the ethical and effective use of LLMs for\nhealthcare and propose future research directions.", "field": "Computer Science", "categories": "cs.CY,J.4; K.4.2"}, {"arxiv_id": "2401.09092", "title": "BibSonomy Meets ChatLLMs for Publication Management: From Chat to\n  Publication Management: Organizing your related work using BibSonomy & LLMs", "abstract": "The ever-growing corpus of scientific literature presents significant\nchallenges for researchers with respect to discovery, management, and\nannotation of relevant publications. Traditional platforms like Semantic\nScholar, BibSonomy, and Zotero offer tools for literature management, but\nlargely require manual laborious and error-prone input of tags and metadata.\nHere, we introduce a novel retrieval augmented generation system that leverages\nchat-based large language models (LLMs) to streamline and enhance the process\nof publication management. It provides a unified chat-based interface, enabling\nintuitive interactions with various backends, including Semantic Scholar,\nBibSonomy, and the Zotero Webscraper. It supports two main use-cases: (1)\nExplorative Search & Retrieval - leveraging LLMs to search for and retrieve\nboth specific and general scientific publications, while addressing the\nchallenges of content hallucination and data obsolescence; and (2) Cataloguing\n& Management - aiding in the organization of personal publication libraries, in\nthis case BibSonomy, by automating the addition of metadata and tags, while\nfacilitating manual edits and updates. We compare our system to different LLM\nmodels in three different settings, including a user study, and we can show its\nadvantages in different metrics.", "field": "Computer Science", "categories": "cs.IR,cs.HC"}, {"arxiv_id": "2401.09093", "title": "RWKV-TS: Beyond Traditional Recurrent Neural Network for Time Series\n  Tasks", "abstract": "Traditional Recurrent Neural Network (RNN) architectures, such as LSTM and\nGRU, have historically held prominence in time series tasks. However, they have\nrecently seen a decline in their dominant position across various time series\ntasks. As a result, recent advancements in time series forecasting have seen a\nnotable shift away from RNNs towards alternative architectures such as\nTransformers, MLPs, and CNNs. To go beyond the limitations of traditional RNNs,\nwe design an efficient RNN-based model for time series tasks, named RWKV-TS,\nwith three distinctive features: (i) A novel RNN architecture characterized by\n$O(L)$ time complexity and memory usage. (ii) An enhanced ability to capture\nlong-term sequence information compared to traditional RNNs. (iii) High\ncomputational efficiency coupled with the capacity to scale up effectively.\nThrough extensive experimentation, our proposed RWKV-TS model demonstrates\ncompetitive performance when compared to state-of-the-art Transformer-based or\nCNN-based models. Notably, RWKV-TS exhibits not only comparable performance but\nalso demonstrates reduced latency and memory utilization. The success of\nRWKV-TS encourages further exploration and innovation in leveraging RNN-based\napproaches within the domain of Time Series. The combination of competitive\nperformance, low latency, and efficient memory usage positions RWKV-TS as a\npromising avenue for future research in time series tasks. Code is available\nat:\\href{https://github.com/howard-hou/RWKV-TS}{\nhttps://github.com/howard-hou/RWKV-TS}", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.09101", "title": "PIN-SLAM: LiDAR SLAM Using a Point-Based Implicit Neural Representation\n  for Achieving Global Map Consistency", "abstract": "Accurate and robust localization and mapping are essential components for\nmost autonomous robots. In this paper, we propose a SLAM system for building\nglobally consistent maps, called PIN-SLAM, that is based on an elastic and\ncompact point-based implicit neural map representation. Taking range\nmeasurements as input, our approach alternates between incremental learning of\nthe local implicit signed distance field and the pose estimation given the\ncurrent local map using a correspondence-free, point-to-implicit model\nregistration. Our implicit map is based on sparse optimizable neural points,\nwhich are inherently elastic and deformable with the global pose adjustment\nwhen closing a loop. Loops are also detected using the neural point features.\nExtensive experiments validate that PIN-SLAM is robust to various environments\nand versatile to different range sensors such as LiDAR and RGB-D cameras.\nPIN-SLAM achieves pose estimation accuracy better or on par with the\nstate-of-the-art LiDAR odometry or SLAM systems and outperforms the recent\nneural implicit SLAM approaches while maintaining a more consistent, and highly\ncompact implicit map that can be reconstructed as accurate and complete meshes.\nFinally, thanks to the voxel hashing for efficient neural points indexing and\nthe fast implicit map-based registration without closest point association,\nPIN-SLAM can run at the sensor frame rate on a moderate GPU. Codes will be\navailable at: https://github.com/PRBonn/PIN_SLAM.", "field": "Computer Science", "categories": "cs.RO,cs.CV"}, {"arxiv_id": "2401.09102", "title": "SendingNetwork: Advancing the Future of Decentralized Messaging Networks", "abstract": "In the evolving landscape of Internet technologies, where decentralized\nsystems, especially blockchain-based computation and storage like Ethereum\nVirtual Machine (EVM), Arweave, and IPFS, are gaining prominence, there remains\na stark absence of a holistic decentralized communication framework. This gap\nunderlines the pressing necessity for a protocol that not only enables seamless\ncross-platform messaging but also allows direct messaging to wallet addresses,\nfostering interoperability and privacy across diverse platforms. SendingNetwork\naddresses this need by creating a reliable and secure decentralized\ncommunication network, targeting essential challenges like privacy protection,\nscalability, efficiency, and composability. Central to our approach is the\nincorporation of edge computing to form an adaptive relay network with the\nmodular libp2p library. We introduce a dynamic group chat encryption mechanism\nbased on the Double Ratchet algorithm for secure communication and propose a\nDelegation scheme for efficient message processing in large group chats,\nenhancing both resilience and scalability. Our theoretical analyses affirm the\nDelegation scheme's superior performance. To bolster system stability and\nencourage node participation, we integrate two innovative consensus mechanisms:\n\"Proof of Relay\" for validating message relay workload based on the novel KZG\ncommitment, and \"Proof of Availability\" for ensuring network consistency and\nmanaging incentives through Verkle trees. Our whitepaper details the network's\nkey components and architecture, concluding with a roadmap and a preview of\nfuture enhancements to SendingNetwork.", "field": "Computer Science", "categories": "cs.SI"}, {"arxiv_id": "2401.09105", "title": "A Posteriori Error Estimates for $hp$-FE Discretizations in\n  Elastoplasticity", "abstract": "In this paper, a reliable a posteriori error estimator for a model problem of\nelastoplasticity with linear kinematic hardening is derived, which satisfies\nsome (local) efficiency estimates. It is applicable to any discretization that\nis conforming with respect to the displacement field and the plastic strain.\nFurthermore, the paper presents $hp$-finite element discretizations relying on\na variational inequality as well as on a mixed variational formulation and\ndiscusses their equivalence by using biorthogonal basis functions. Numerical\nexperiments demonstrate the applicability of the theoretical findings and\nunderline the potential of $h$- and $hp$-adaptive finite element\ndiscretizations for problems of elastoplasticity.", "field": "Computer Science", "categories": "math.NA,cs.NA,65N30, 65N50,G.1.8"}, {"arxiv_id": "2401.09109", "title": "Trapped in texture bias? A large scale comparison of deep instance\n  segmentation", "abstract": "Do deep learning models for instance segmentation generalize to novel objects\nin a systematic way? For classification, such behavior has been questioned. In\nthis study, we aim to understand if certain design decisions such as framework,\narchitecture or pre-training contribute to the semantic understanding of\ninstance segmentation. To answer this question, we consider a special case of\nrobustness and compare pre-trained models on a challenging benchmark for\nobject-centric, out-of-distribution texture. We do not introduce another method\nin this work. Instead, we take a step back and evaluate a broad range of\nexisting literature. This includes Cascade and Mask R-CNN, Swin Transformer,\nBMask, YOLACT(++), DETR, BCNet, SOTR and SOLOv2. We find that YOLACT++, SOTR\nand SOLOv2 are significantly more robust to out-of-distribution texture than\nother frameworks. In addition, we show that deeper and dynamic architectures\nimprove robustness whereas training schedules, data augmentation and\npre-training have only a minor impact. In summary we evaluate 68 models on 61\nversions of MS COCO for a total of 4148 evaluations.", "field": "Computer Science", "categories": "cs.CV,I.2; I.2.10; I.4; I.4.6; I.4.7; I.5"}, {"arxiv_id": "2401.0911", "title": "Global and Local Error-Tolerant Decentralized State Estimation under\n  Partially Ordered Observations", "abstract": "We investigate decentralized state estimation for a discrete event system in\na setting where the information received at a coordinator may be corrupted or\ntampered by a malicious attacker. Specifically, a system is observed by a set\nof (local) observation sites (OSs) which occasionally send their recorded\nsequences of observations to the coordinator that is in charge of estimating\nthe system state. The malfunctions and attacks, referred to as errors in this\npaper, include symbol deletions, insertions and replacements, each of which\nbears a positive cost. Two types of errors, global errors and local errors, are\nproposed to describe the impact of errors on decentralized information\nprocessing. Global errors occur when all OSs record the same error, while local\nerrors occur when different OSs record different errors. Distinguishing these\ntypes of errors is important for a proper design of decentralized information\nprocessing (so as to be more resilient and better equipped to handle errors and\nfailures). For each type of error, we propose two methods to efficiently\nperform state estimation: one based on appropriately modifying the original\nsystem and the other based on inferring the matching behavior of the original\nsystem. For each method, we adopt an estimation-by-release methodology to\ndesign an algorithm for constructing a corresponding synchronizer for state\nestimation.", "field": "Computer Science", "categories": "eess.SY,cs.SY"}, {"arxiv_id": "2401.09112", "title": "Stream Query Denoising for Vectorized HD Map Construction", "abstract": "To enhance perception performance in complex and extensive scenarios within\nthe realm of autonomous driving, there has been a noteworthy focus on temporal\nmodeling, with a particular emphasis on streaming methods. The prevailing trend\nin streaming models involves the utilization of stream queries for the\npropagation of temporal information. Despite the prevalence of this approach,\nthe direct application of the streaming paradigm to the construction of\nvectorized high-definition maps (HD-maps) fails to fully harness the inherent\npotential of temporal information. This paper introduces the Stream Query\nDenoising (SQD) strategy as a novel approach for temporal modeling in\nhigh-definition map (HD-map) construction. SQD is designed to facilitate the\nlearning of temporal consistency among map elements within the streaming model.\nThe methodology involves denoising the queries that have been perturbed by the\naddition of noise to the ground-truth information from the preceding frame.\nThis denoising process aims to reconstruct the ground-truth information for the\ncurrent frame, thereby simulating the prediction process inherent in stream\nqueries. The SQD strategy can be applied to those streaming methods (e.g.,\nStreamMapNet) to enhance the temporal modeling. The proposed SQD-MapNet is the\nStreamMapNet equipped with SQD. Extensive experiments on nuScenes and\nArgoverse2 show that our method is remarkably superior to other existing\nmethods across all settings of close range and long range. The code will be\navailable soon.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.09115", "title": "A Type II Singularity Avoidance Algorithm for Parallel Manipulators\n  using Output Twist Screws", "abstract": "Parallel robots (PRs) are closed-chain manipulators with diverse applications\ndue to their accuracy and high payload. However, there are configurations\nwithin the workspace named Type II singularities where the PRs lose control of\nthe end-effector movements. Type II singularities are a problem for\napplications where complete control of the end-effector is essential.\nTrajectory planning produces accurate movements of a PR by avoiding Type II\nsingularities. Generally, singularity avoidance is achieved by optimising a\ngeometrical path with a velocity profile considering singular configurations as\nobstacles. This research presents an algorithm that avoids Type II\nsingularities by modifying the trajectory of a subset of the actuators. The\nsubset of actuators represents the limbs responsible for a Type II singularity,\nand they are identified by the angle between two Output Twist Screws. The\nproposed avoidance algorithm does not require optimisation procedures, which\nreduces the computational cost for offline trajectory planning and makes it\nsuitable for online trajectory planning. The avoidance algorithm is implemented\nin offline trajectory planning for a pick and place planar PR and a spatial\nknee rehabilitation PR", "field": "Computer Science", "categories": "cs.RO,cs.SY,eess.SY"}, {"arxiv_id": "2401.09118", "title": "Learning based numerical methods for Helmholtz equation with high\n  frequency", "abstract": "High-frequency issues have been remarkably challenges in numerical methods\nfor partial differential equations. In this paper, a learning based numerical\nmethod (LbNM) is proposed for Helmholtz equation with high frequency. The main\nnovelty is using Tikhonov regularization method to stably learn the solution\noperator by utilizing relevant information especially the fundamental\nsolutions. Then applying the solution operator to a new boundary input could\nquickly update the solution. Based on the method of fundamental solutions and\nthe quantitative Runge approximation, we give the error estimate. This\nindicates interpretability and generalizability of the present method.\nNumerical results validates the error analysis and demonstrates the\nhigh-precision and high-efficiency features.", "field": "Computer Science", "categories": "math.NA,cs.NA"}, {"arxiv_id": "2401.09124", "title": "Machine Learning for Healthcare-IoT Security: A Review and Risk\n  Mitigation", "abstract": "The Healthcare Internet-of-Things (H-IoT), commonly known as Digital\nHealthcare, is a data-driven infrastructure that highly relies on smart sensing\ndevices (i.e., blood pressure monitors, temperature sensors, etc.) for faster\nresponse time, treatments, and diagnosis. However, with the evolving cyber\nthreat landscape, IoT devices have become more vulnerable to the broader risk\nsurface (e.g., risks associated with generative AI, 5G-IoT, etc.), which, if\nexploited, may lead to data breaches, unauthorized access, and lack of command\nand control and potential harm. This paper reviews the fundamentals of\nhealthcare IoT, its privacy, and data security challenges associated with\nmachine learning and H-IoT devices. The paper further emphasizes the importance\nof monitoring healthcare IoT layers such as perception, network, cloud, and\napplication. Detecting and responding to anomalies involves various\ncyber-attacks and protocols such as Wi-Fi 6, Narrowband Internet of Things\n(NB-IoT), Bluetooth, ZigBee, LoRa, and 5G New Radio (5G NR). A robust\nauthentication mechanism based on machine learning and deep learning techniques\nis required to protect and mitigate H-IoT devices from increasing cybersecurity\nvulnerabilities. Hence, in this review paper, security and privacy challenges\nand risk mitigation strategies for building resilience in H-IoT are explored\nand reported.", "field": "Computer Science", "categories": "cs.CR"}, {"arxiv_id": "2401.09125", "title": "Understanding Heterophily for Graph Neural Networks", "abstract": "Graphs with heterophily have been regarded as challenging scenarios for Graph\nNeural Networks (GNNs), where nodes are connected with dissimilar neighbors\nthrough various patterns. In this paper, we present theoretical understandings\nof the impacts of different heterophily patterns for GNNs by incorporating the\ngraph convolution (GC) operations into fully connected networks via the\nproposed Heterophilous Stochastic Block Models (HSBM), a general random graph\nmodel that can accommodate diverse heterophily patterns. Firstly, we show that\nby applying a GC operation, the separability gains are determined by two\nfactors, i.e., the Euclidean distance of the neighborhood distributions and\n$\\sqrt{\\mathbb{E}\\left[\\operatorname{deg}\\right]}$, where\n$\\mathbb{E}\\left[\\operatorname{deg}\\right]$ is the averaged node degree. It\nreveals that the impact of heterophily on classification needs to be evaluated\nalongside the averaged node degree. Secondly, we show that the topological\nnoise has a detrimental impact on separability, which is equivalent to\ndegrading $\\mathbb{E}\\left[\\operatorname{deg}\\right]$. Finally, when applying\nmultiple GC operations, we show that the separability gains are determined by\nthe normalized distance of the $l$-powered neighborhood distributions. It\nindicates that the nodes still possess separability as $l$ goes to infinity in\na wide range of regimes. Extensive experiments on both synthetic and real-world\ndata verify the effectiveness of our theory.", "field": "Computer Science", "categories": "cs.LG,stat.ML"}, {"arxiv_id": "2401.09126", "title": "Objects With Lighting: A Real-World Dataset for Evaluating\n  Reconstruction and Rendering for Object Relighting", "abstract": "Reconstructing an object from photos and placing it virtually in a new\nenvironment goes beyond the standard novel view synthesis task as the\nappearance of the object has to not only adapt to the novel viewpoint but also\nto the new lighting conditions and yet evaluations of inverse rendering methods\nrely on novel view synthesis data or simplistic synthetic datasets for\nquantitative analysis. This work presents a real-world dataset for measuring\nthe reconstruction and rendering of objects for relighting. To this end, we\ncapture the environment lighting and ground truth images of the same objects in\nmultiple environments allowing to reconstruct the objects from images taken in\none environment and quantify the quality of the rendered views for the unseen\nlighting environments. Further, we introduce a simple baseline composed of\noff-the-shelf methods and test several state-of-the-art methods on the\nrelighting task and show that novel view synthesis is not a reliable proxy to\nmeasure performance. Code and dataset are available at\nhttps://github.com/isl-org/objects-with-lighting .", "field": "Computer Science", "categories": "cs.CV,cs.GR"}, {"arxiv_id": "2401.09127", "title": "AI Empowered Channel Semantic Acquisition for 6G Integrated Sensing and\n  Communication Networks", "abstract": "Motivated by the need for increased spectral efficiency and the proliferation\nof intelligent applications, the sixth-generation (6G) mobile network is\nanticipated to integrate the dual-functions of communication and sensing (C&S).\nAlthough the millimeter wave (mmWave) communication and mmWave radar share\nsimilar multiple-input multiple-output (MIMO) architecture for integration, the\nfull potential of dual-function synergy remains to be exploited. In this paper,\nwe commence by overviewing state-of-the-art schemes from the aspects of\nwaveform design and signal processing. Nevertheless, these approaches face the\ndilemma of mutual compromise between C&S performance. To this end, we reveal\nand exploit the synergy between C&S. In the proposed framework, we introduce a\ntwo-stage frame structure and resort artificial intelligence (AI) to achieve\nthe synergistic gain by designing a joint C&S channel semantic extraction and\nreconstruction network (JCASCasterNet). With just a cost-effective and\nenergy-efficient single sensing antenna, the proposed scheme achieves enhanced\noverall performance while requiring only limited pilot and feedback signaling\noverhead. In the end, we outline the challenges that lie ahead in the future\ndevelopment of integrated sensing and communication networks, along with\npromising directions for further research.", "field": "Computer Science", "categories": "cs.IT,eess.SP,math.IT"}, {"arxiv_id": "2401.09129", "title": "Optimal one-sided approximants of circular arc", "abstract": "The optimal one-sided parametric polynomial approximants of a circular arc\nare considered. More precisely, the approximant must be entirely in or out of\nthe underlying circle of an arc. The natural restriction to an arc's\napproximants interpolating boundary points is assumed. However, the study of\napproximants, which additionally interpolate corresponding tangent directions\nand curvatures at the boundary of an arc, is also considered. Several\nlow-degree polynomial approximants are studied in detail. When several\nsolutions fulfilling the interpolation conditions exist, the optimal one is\ncharacterized, and a numerical algorithm for its construction is suggested.\nTheoretical results are demonstrated with several numerical examples and a\ncomparison with general (i.e. non-one-sided) approximants are provided.", "field": "Computer Science", "categories": "math.NA,cs.NA,65D05, 65D07, 65D17"}, {"arxiv_id": "2401.09132", "title": "Admittance Controller Complemented with Real-time Singularity Avoidance\n  for Rehabilitation Parallel Robots", "abstract": "Rehabilitation tasks demand robust and accurate trajectory-tracking\nperformance, mainly achieved with parallel robots. In this field, limiting the\nvalue of the force exerted on the patient is crucial, especially when an\ninjured limb is involved. In human-robot interaction studies, the admittance\ncontroller modifies the location of the robot according to the user efforts\ndriving the end-effector to an arbitrary location within the workspace.\nHowever, a parallel robot has singularities within the workspace, making\nimplementing a conventional admittance controller unsafe. Thus, this study\nproposes an admittance controller that overcomes the limitations of singular\nconfigurations by using a real-time singularity avoidance algorithm. The\nsingularity avoidance algorithm modifies the original trajectory based on the\nactual location of the parallel robot. The complemented admittance controller\nis applied to a 4 degrees of freedom parallel robot for knee rehabilitation. In\nthis case, the actual location is measured by a 3D tracking system because the\nlocation calculated by the forward kinematics is inaccurate in the vicinity of\na singularity. The experimental results verify the effectiveness of the\nproposed admittance controller for safe knee rehabilitation exercises", "field": "Computer Science", "categories": "cs.RO,cs.SY,eess.SY"}, {"arxiv_id": "2401.09133", "title": "SM$^3$: Self-Supervised Multi-task Modeling with Multi-view 2D Images\n  for Articulated Objects", "abstract": "Reconstructing real-world objects and estimating their movable joint\nstructures are pivotal technologies within the field of robotics. Previous\nresearch has predominantly focused on supervised approaches, relying on\nextensively annotated datasets to model articulated objects within limited\ncategories. However, this approach falls short of effectively addressing the\ndiversity present in the real world. To tackle this issue, we propose a\nself-supervised interaction perception method, referred to as SM$^3$, which\nleverages multi-view RGB images captured before and after interaction to model\narticulated objects, identify the movable parts, and infer the parameters of\ntheir rotating joints. By constructing 3D geometries and textures from the\ncaptured 2D images, SM$^3$ achieves integrated optimization of movable part and\njoint parameters during the reconstruction process, obviating the need for\nannotations. Furthermore, we introduce the MMArt dataset, an extension of\nPartNet-Mobility, encompassing multi-view and multi-modal data of articulated\nobjects spanning diverse categories. Evaluations demonstrate that SM$^3$\nsurpasses existing benchmarks across various categories and objects, while its\nadaptability in real-world scenarios has been thoroughly validated.", "field": "Computer Science", "categories": "cs.CV,cs.RO"}, {"arxiv_id": "2401.09135", "title": "Asynchronous Local-SGD Training for Language Modeling", "abstract": "Local stochastic gradient descent (Local-SGD), also referred to as federated\naveraging, is an approach to distributed optimization where each device\nperforms more than one SGD update per communication. This work presents an\nempirical study of {\\it asynchronous} Local-SGD for training language models;\nthat is, each worker updates the global parameters as soon as it has finished\nits SGD steps. We conduct a comprehensive investigation by examining how worker\nhardware heterogeneity, model size, number of workers, and optimizer could\nimpact the learning performance. We find that with naive implementations,\nasynchronous Local-SGD takes more iterations to converge than its synchronous\ncounterpart despite updating the (global) model parameters more frequently. We\nidentify momentum acceleration on the global parameters when worker gradients\nare stale as a key challenge. We propose a novel method that utilizes a delayed\nNesterov momentum update and adjusts the workers' local training steps based on\ntheir computation speed. This approach, evaluated with models up to 150M\nparameters on the C4 dataset, matches the performance of synchronous Local-SGD\nin terms of perplexity per update step, and significantly surpasses it in terms\nof wall clock time.", "field": "Computer Science", "categories": "cs.LG,cs.CL"}, {"arxiv_id": "2401.0914", "title": "Relative Pose for Nonrigid Multi-Perspective Cameras: The Static Case", "abstract": "Multi-perspective cameras with potentially non-overlapping fields of view\nhave become an important exteroceptive sensing modality in a number of\napplications such as intelligent vehicles, drones, and mixed reality headsets.\nIn this work, we challenge one of the basic assumptions made in these\nscenarios, which is that the multi-camera rig is rigid. More specifically, we\nare considering the problem of estimating the relative pose between a static\nnon-rigid rig in different spatial orientations while taking into account the\neffect of gravity onto the system. The deformable physical connections between\neach camera and the body center are approximated by a simple cantilever model,\nand inserted into the generalized epipolar constraint. Our results lead us to\nthe important insight that the latent parameters of the deformation model,\nmeaning the gravity vector in both views, become observable. We present a\nconcise analysis of the observability of all variables based on noise,\noutliers, and rig rigidity for two different algorithms. The first one is a\nvision-only alternative, while the second one makes use of additional gravity\nmeasurements. To conclude, we demonstrate the ability to sense gravity in a\nreal-world example, and discuss practical implications.", "field": "Computer Science", "categories": "cs.RO,cs.CV"}, {"arxiv_id": "2401.09145", "title": "Your blush gives you away: detecting hidden mental states with remote\n  photoplethysmography and thermal imaging", "abstract": "Multimodal emotion recognition techniques are increasingly essential for\nassessing mental states. Image-based methods, however, tend to focus\npredominantly on overt visual cues and often overlook subtler mental state\nchanges. Psychophysiological research has demonstrated that HR and skin\ntemperature are effective in detecting ANS activities, thereby revealing these\nsubtle changes. However, traditional HR tools are generally more costly and\nless portable, while skin temperature analysis usually necessitates extensive\nmanual processing. Advances in remote-PPG and automatic thermal ROI detection\nalgorithms have been developed to address these issues, yet their accuracy in\npractical applications remains limited. This study aims to bridge this gap by\nintegrating r-PPG with thermal imaging to enhance prediction performance.\nNinety participants completed a 20-minute questionnaire to induce cognitive\nstress, followed by watching a film aimed at eliciting moral elevation. The\nresults demonstrate that the combination of r-PPG and thermal imaging\neffectively detects emotional shifts. Using r-PPG alone, the prediction\naccuracy was 77% for cognitive stress and 61% for moral elevation, as\ndetermined by SVM. Thermal imaging alone achieved 79% accuracy for cognitive\nstress and 78% for moral elevation, utilizing a RF algorithm. An early fusion\nstrategy of these modalities significantly improved accuracies, achieving 87%\nfor cognitive stress and 83% for moral elevation using RF. Further analysis,\nwhich utilized statistical metrics and explainable machine learning methods\nincluding SHAP, highlighted key features and clarified the relationship between\ncardiac responses and facial temperature variations. Notably, it was observed\nthat cardiovascular features derived from r-PPG models had a more pronounced\ninfluence in data fusion, despite thermal imaging's higher predictive accuracy\nin unimodal analysis.", "field": "Computer Science", "categories": "cs.CY"}, {"arxiv_id": "2401.09146", "title": "Continuous Piecewise-Affine Based Motion Model for Image Animation", "abstract": "Image animation aims to bring static images to life according to driving\nvideos and create engaging visual content that can be used for various purposes\nsuch as animation, entertainment, and education. Recent unsupervised methods\nutilize affine and thin-plate spline transformations based on keypoints to\ntransfer the motion in driving frames to the source image. However, limited by\nthe expressive power of the transformations used, these methods always produce\npoor results when the gap between the motion in the driving frame and the\nsource image is large. To address this issue, we propose to model motion from\nthe source image to the driving frame in highly-expressive diffeomorphism\nspaces. Firstly, we introduce Continuous Piecewise-Affine based (CPAB)\ntransformation to model the motion and present a well-designed inference\nalgorithm to generate CPAB transformation from control keypoints. Secondly, we\npropose a SAM-guided keypoint semantic loss to further constrain the keypoint\nextraction process and improve the semantic consistency between the\ncorresponding keypoints on the source and driving images. Finally, we design a\nstructure alignment loss to align the structure-related features extracted from\ndriving and generated images, thus helping the generator generate results that\nare more consistent with the driving action. Extensive experiments on four\ndatasets demonstrate the effectiveness of our method against state-of-the-art\ncompetitors quantitatively and qualitatively. Code will be publicly available\nat: https://github.com/DevilPG/AAAI2024-CPABMM.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.09149", "title": "InternEvo: Efficient Long-sequence Large Language Model Training via\n  Hybrid Parallelism and Redundant Sharding", "abstract": "Large language models (LLMs) with long sequences begin to power more and more\nfundamentally new applications we use every day. Existing methods for\nlong-sequence LLM training are neither efficient nor compatible with\ncommonly-used training algorithms such as FlashAttention. We design Buff to\naddress these issues. Buff decouples all of the sharding dimensions into a new\nhierarchical space, and systematically analyzes the memory and communication\ncost of LLM training. Then, it generates an effective hybrid parallelism\nstrategy. We design a new selective overlap mechanism to mitigate the\ncommunication overhead introduced by the hybrid parallelism. We also implement\nmemory management techniques to reduce GPU memory fragmentation. Evaluation\nresults show that Buff generates parallelization strategies that match or\noutperform existing methods in model FLOPs utilization.", "field": "Computer Science", "categories": "cs.DC"}, {"arxiv_id": "2401.0915", "title": "Bridging Research and Readers: A Multi-Modal Automated Academic Papers\n  Interpretation System", "abstract": "In the contemporary information era, significantly accelerated by the advent\nof Large-scale Language Models, the proliferation of scientific literature is\nreaching unprecedented levels. Researchers urgently require efficient tools for\nreading and summarizing academic papers, uncovering significant scientific\nliterature, and employing diverse interpretative methodologies. To address this\nburgeoning demand, the role of automated scientific literature interpretation\nsystems has become paramount. However, prevailing models, both commercial and\nopen-source, confront notable challenges: they often overlook multimodal data,\ngrapple with summarizing over-length texts, and lack diverse user interfaces.\nIn response, we introduce an open-source multi-modal automated academic paper\ninterpretation system (MMAPIS) with three-step process stages, incorporating\nLLMs to augment its functionality. Our system first employs the hybrid modality\npreprocessing and alignment module to extract plain text, and tables or figures\nfrom documents separately. It then aligns this information based on the section\nnames they belong to, ensuring that data with identical section names are\ncategorized under the same section. Following this, we introduce a hierarchical\ndiscourse-aware summarization method. It utilizes the extracted section names\nto divide the article into shorter text segments, facilitating specific\nsummarizations both within and between sections via LLMs with specific prompts.\nFinally, we have designed four types of diversified user interfaces, including\npaper recommendation, multimodal Q\\&A, audio broadcasting, and interpretation\nblog, which can be widely applied across various scenarios. Our qualitative and\nquantitative evaluations underscore the system's superiority, especially in\nscientific summarization, where it outperforms solutions relying solely on\nGPT-4.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.0916", "title": "DK-SLAM: Monocular Visual SLAM with Deep Keypoints Adaptive Learning,\n  Tracking and Loop-Closing", "abstract": "Unreliable feature extraction and matching in handcrafted features undermine\nthe performance of visual SLAM in complex real-world scenarios. While learned\nlocal features, leveraging CNNs, demonstrate proficiency in capturing\nhigh-level information and excel in matching benchmarks, they encounter\nchallenges in continuous motion scenes, resulting in poor generalization and\nimpacting loop detection accuracy. To address these issues, we present DK-SLAM,\na monocular visual SLAM system with adaptive deep local features. MAML\noptimizes the training of these features, and we introduce a coarse-to-fine\nfeature tracking approach. Initially, a direct method approximates the relative\npose between consecutive frames, followed by a feature matching method for\nrefined pose estimation. To counter cumulative positioning errors, a novel\nonline learning binary feature-based online loop closure module identifies loop\nnodes within a sequence. Experimental results underscore DK-SLAM's efficacy,\noutperforms representative SLAM solutions, such as ORB-SLAM3 on publicly\navailable datasets.", "field": "Computer Science", "categories": "cs.RO,cs.CV"}, {"arxiv_id": "2401.09162", "title": "Named Service Networking as a primer for the Metaverse", "abstract": "Ubiquitous extended reality environments such as the Metaverse will have a\nsignificant impact on the Internet, which will evolve to interconnect a large\nnumber of mixed reality spaces. Currently, Metaverse development is related to\nthe creation of mixed reality environments, not tackling the required\nnetworking functionalities. This article analyzes suitable networking design\nchoices to support the Metaverse, proposing a new service-centric networking\napproach capable of incorporating low-latency data fetching, distributed\ncomputing, and fusion of heterogeneous data types over the Cloud-to-Thing\ncontinuum.", "field": "Computer Science", "categories": "cs.NI"}, {"arxiv_id": "2401.09168", "title": "Fine-tuning Strategies for Domain Specific Question Answering under Low\n  Annotation Budget Constraints", "abstract": "The progress introduced by pre-trained language models and their fine-tuning\nhas resulted in significant improvements in most downstream NLP tasks. The\nunsupervised training of a language model combined with further target task\nfine-tuning has become the standard QA fine-tuning procedure. In this work, we\ndemonstrate that this strategy is sub-optimal for fine-tuning QA models,\nespecially under a low QA annotation budget, which is a usual setting in\npractice due to the extractive QA labeling cost. We draw our conclusions by\nconducting an exhaustive analysis of the performance of the alternatives of the\nsequential fine-tuning strategy on different QA datasets. Based on the\nexperiments performed, we observed that the best strategy to fine-tune the QA\nmodel in low-budget settings is taking a pre-trained language model (PLM) and\nthen fine-tuning PLM with a dataset composed of the target dataset and SQuAD\ndataset. With zero extra annotation effort, the best strategy outperforms the\nstandard strategy by 2.28% to 6.48%. Our experiments provide one of the first\ninvestigations on how to best fine-tune a QA system under a low budget and are\ntherefore of the utmost practical interest to the QA practitioners.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.09175", "title": "QAnswer: Towards Question Answering Search over Websites", "abstract": "Question Answering (QA) is increasingly used by search engines to provide\nresults to their end-users, yet very few websites currently use QA technologies\nfor their search functionality. To illustrate the potential of QA technologies\nfor the website search practitioner, we demonstrate web searches that combine\nQA over knowledge graphs and QA over free text -- each being usually tackled\nseparately. We also discuss the different benefits and drawbacks of both\napproaches for web site searches. We use the case studies made of websites\nhosted by the Wikimedia Foundation (namely Wikipedia and Wikidata). Differently\nfrom a search engine (e.g. Google, Bing, etc), the data are indexed integrally,\ni.e. we do not index only a subset, and they are indexed exclusively, i.e. we\nindex only data available on the corresponding website.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.09176", "title": "ADCNet: a unified framework for predicting the activity of antibody-drug\n  conjugates", "abstract": "Antibody-drug conjugate (ADC) has revolutionized the field of cancer\ntreatment in the era of precision medicine due to their ability to precisely\ntarget cancer cells and release highly effective drug. Nevertheless, the\nrealization of rational design of ADC is very difficult because the\nrelationship between their structures and activities is difficult to\nunderstand. In the present study, we introduce a unified deep learning\nframework called ADCNet to help design potential ADCs. The ADCNet highly\nintegrates the protein representation learning language model ESM-2 and\nsmall-molecule representation learning language model FG-BERT models to achieve\nactivity prediction through learning meaningful features from antigen and\nantibody protein sequences of ADC, SMILES strings of linker and payload, and\ndrug-antibody ratio (DAR) value. Based on a carefully designed and manually\ntailored ADC data set, extensive evaluation results reveal that ADCNet performs\nbest on the test set compared to baseline machine learning models across all\nevaluation metrics. For example, it achieves an average prediction accuracy of\n87.12%, a balanced accuracy of 0.8689, and an area under receiver operating\ncharacteristic curve of 0.9293 on the test set. In addition, cross-validation,\nablation experiments, and external independent testing results further prove\nthe stability, advancement, and robustness of the ADCNet architecture. For the\nconvenience of the community, we develop the first online platform\n(https://ADCNet.idruglab.cn) for the prediction of ADCs activity based on the\noptimal ADCNet model, and the source code is publicly available at\nhttps://github.com/idrugLab/ADCNet.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.0918", "title": "Unsupervised Multiple Domain Translation through Controlled\n  Disentanglement in Variational Autoencoder", "abstract": "Unsupervised Multiple Domain Translation is the task of transforming data\nfrom one domain to other domains without having paired data to train the\nsystems. Typically, methods based on Generative Adversarial Networks (GANs) are\nused to address this task. However, our proposal exclusively relies on a\nmodified version of a Variational Autoencoder. This modification consists of\nthe use of two latent variables disentangled in a controlled way by design. One\nof this latent variables is imposed to depend exclusively on the domain, while\nthe other one must depend on the rest of the variability factors of the data.\nAdditionally, the conditions imposed over the domain latent variable allow for\nbetter control and understanding of the latent space. We empirically\ndemonstrate that our approach works on different vision datasets improving the\nperformance of other well known methods. Finally, we prove that, indeed, one of\nthe latent variables stores all the information related to the domain and the\nother one hardly contains any domain information.", "field": "Computer Science", "categories": "cs.LG,cs.CV"}, {"arxiv_id": "2401.09181", "title": "Beyond Anti-Forgetting: Multimodal Continual Instruction Tuning with\n  Positive Forward Transfer", "abstract": "Multimodal Continual Instruction Tuning (MCIT) enables Multimodal Large\nLanguage Models (MLLMs) to meet continuously emerging requirements without\nexpensive retraining. MCIT faces two major obstacles: catastrophic forgetting\n(where old knowledge is forgotten) and negative forward transfer (where the\nperformance of future tasks is degraded). Although existing methods have\ngreatly alleviated catastrophic forgetting, they still suffer from negative\nforward transfer. By performing singular value decomposition (SVD) on input\nembeddings, we discover a large discrepancy in different input embeddings. The\ndiscrepancy results in the model learning irrelevant information for old and\npre-trained tasks, which leads to catastrophic forgetting and negative forward\ntransfer. To address these issues, we propose Fwd-Prompt, a prompt-based method\nprojecting prompt gradient to the residual space to minimize the interference\nbetween tasks and to the pre-trained subspace for reusing pre-trained\nknowledge. Our experiments demonstrate that Fwd-Prompt achieves\nstate-of-the-art performance while updating fewer parameters and requiring no\nold samples. Our research sheds light on the potential of continuously adapting\nMLLMs to new tasks under the instruction tuning paradigm and encourages future\nstudies to explore MCIT. The code will soon be publicly available.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.09185", "title": "Behavior Trees with Dataflow: Coordinating Reactive Tasks in Lingua\n  Franca", "abstract": "Behavior Trees (BTs) provide a lean set of control flow elements that are\neasily composable in a modular tree structure. They are well established for\nmodeling the high-level behavior of non-player characters in computer games and\nrecently gained popularity in other areas such as industrial automation. While\nBTs nicely express control, data handling aspects so far must be provided\nseparately, e. g. in the form of blackboards. This may hamper reusability and\ncan be a source of nondeterminism. We here present a dataflow extension to BTs\nthat explicitly models data relations and communication. We provide a combined\ntextual/graphical approach in line with modern, productivity-enhancing\npragmatics-aware modeling techniques. We realized and validated that approach\nin the recently introduced polyglot coordination language Lingua Franca (LF).", "field": "Computer Science", "categories": "cs.PL"}, {"arxiv_id": "2401.09186", "title": "The Mikado Filesystem: An experimental RPC filesystem running over gRPC", "abstract": "Computer applications seeking to persist files remotely across the Internet\nare faced with a bewildering choice of mechanisms which tend to boil down to\nmonolithic proprietary closed-source Vendor solutions. We introduce The Mikado\nFilesystem (mikfs), which provides an open simple lightweight interoperable\nportable extensible remote filesystem that is open source. mikfs consists of\nclient applications accessing remote servers via RPC running over TCP/IP\nconnections. mikfs is defined as a concrete set of API method calls over gRPC\nexpressed in Google's Protocol Buffers' IDL. gRPC supports a wide variety of\nprogramming languages & platforms. For a given language + platform, the gRPC\ntoolset can generate client- & server-side stubs from the IDL callable from\nclient & server code in the selected languages, e.g., a client written in C# or\njava running on a Windows PC can access a server written in C++ running on\nLinux. mikfs consists of a virtual hierarchical tree of files & directories.\nThis logical filesystem is not constrained to the limits and file naming\nconventions of the host's own physical native filesystem. API methods are\nprovided for authentication; for atomic file-level operations on files &\ndirectories; for clients to register to receive notifications of file &\ndirectory changes on a server. The public API allows developers to write their\nown new servers and clients; allowing migration of hosted files between\ndifferent implementations; extension with new methods & features; is Open\nSource code available for inspection and adaptation. gRPC provides secure\nauthenticated connection & communication over HTTP/2; End-to-End Privacy &\nSecurity against eavesdropping of data in transit; support for multiple\nalternate user login mechanisms. mikfs is provided as source code, 'The\nBootstrap Distribution', consisting of an ecosystem of clients, servers, tools\nand utilities.", "field": "Computer Science", "categories": "cs.NI,cs.SI,H.3.2; H.3.3; H.3.5; D.4.3"}, {"arxiv_id": "2401.0919", "title": "Exploring the Role of Convolutional Neural Networks (CNN) in Dental\n  Radiography Segmentation: A Comprehensive Systematic Literature Review", "abstract": "In the field of dentistry, there is a growing demand for increased precision\nin diagnostic tools, with a specific focus on advanced imaging techniques such\nas computed tomography, cone beam computed tomography, magnetic resonance\nimaging, ultrasound, and traditional intra-oral periapical X-rays. Deep\nlearning has emerged as a pivotal tool in this context, enabling the\nimplementation of automated segmentation techniques crucial for extracting\nessential diagnostic data. This integration of cutting-edge technology\naddresses the urgent need for effective management of dental conditions, which,\nif left undetected, can have a significant impact on human health. The\nimpressive track record of deep learning across various domains, including\ndentistry, underscores its potential to revolutionize early detection and\ntreatment of oral health issues. Objective: Having demonstrated significant\nresults in diagnosis and prediction, deep convolutional neural networks (CNNs)\nrepresent an emerging field of multidisciplinary research. The goals of this\nstudy were to provide a concise overview of the state of the art, standardize\nthe current debate, and establish baselines for future research. Method: In\nthis study, a systematic literature review is employed as a methodology to\nidentify and select relevant studies that specifically investigate the deep\nlearning technique for dental imaging analysis. This study elucidates the\nmethodological approach, including the systematic collection of data,\nstatistical analysis, and subsequent dissemination of outcomes. Conclusion:\nThis work demonstrates how Convolutional Neural Networks (CNNs) can be employed\nto analyze images, serving as effective tools for detecting dental pathologies.\nAlthough this research acknowledged some limitations, CNNs utilized for\nsegmenting and categorizing teeth exhibited their highest level of performance\noverall.", "field": "Computer Science", "categories": "cs.CV,cs.LG"}, {"arxiv_id": "2401.09191", "title": "An Optimal Transport Approach for Computing Adversarial Training Lower\n  Bounds in Multiclass Classification", "abstract": "Despite the success of deep learning-based algorithms, it is widely known\nthat neural networks may fail to be robust. A popular paradigm to enforce\nrobustness is adversarial training (AT), however, this introduces many\ncomputational and theoretical difficulties. Recent works have developed a\nconnection between AT in the multiclass classification setting and\nmultimarginal optimal transport (MOT), unlocking a new set of tools to study\nthis problem. In this paper, we leverage the MOT connection to propose\ncomputationally tractable numerical algorithms for computing universal lower\nbounds on the optimal adversarial risk and identifying optimal classifiers. We\npropose two main algorithms based on linear programming (LP) and entropic\nregularization (Sinkhorn). Our key insight is that one can harmlessly truncate\nthe higher order interactions between classes, preventing the combinatorial run\ntimes typically encountered in MOT problems. We validate these results with\nexperiments on MNIST and CIFAR-$10$, which demonstrate the tractability of our\napproach.", "field": "Computer Science", "categories": "cs.LG,math.OC,stat.ML"}, {"arxiv_id": "2401.09192", "title": "Preparing Lessons for Progressive Training on Language Models", "abstract": "The rapid progress of Transformers in artificial intelligence has come at the\ncost of increased resource consumption and greenhouse gas emissions due to\ngrowing model sizes. Prior work suggests using pretrained small models to\nimprove training efficiency, but this approach may not be suitable for new\nmodel structures. On the other hand, training from scratch can be slow, and\nprogressively stacking layers often fails to achieve significant acceleration.\nTo address these challenges, we propose a novel method called Apollo, which\nprep\\textbf{a}res lessons for ex\\textbf{p}anding \\textbf{o}perations by\n\\textbf{l}earning high-\\textbf{l}ayer functi\\textbf{o}nality during training of\nlow layers. Our approach involves low-value-prioritized sampling (LVPS) to\ntrain different depths and weight sharing to facilitate efficient expansion. We\nalso introduce an interpolation method for stable model depth extension.\nExperiments demonstrate that Apollo achieves state-of-the-art acceleration\nratios, even rivaling methods using pretrained models, making it a universal\nand efficient solution for training deep models while reducing time, financial,\nand environmental costs.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.09193", "title": "GNN-LoFI: a Novel Graph Neural Network through Localized Feature-based\n  Histogram Intersection", "abstract": "Graph neural networks are increasingly becoming the framework of choice for\ngraph-based machine learning. In this paper, we propose a new graph neural\nnetwork architecture that substitutes classical message passing with an\nanalysis of the local distribution of node features. To this end, we extract\nthe distribution of features in the egonet for each local neighbourhood and\ncompare them against a set of learned label distributions by taking the\nhistogram intersection kernel. The similarity information is then propagated to\nother nodes in the network, effectively creating a message passing-like\nmechanism where the message is determined by the ensemble of the features. We\nperform an ablation study to evaluate the network's performance under different\nchoices of its hyper-parameters. Finally, we test our model on standard graph\nclassification and regression benchmarks, and we find that it outperforms\nwidely used alternative approaches, including both graph kernels and graph\nneural networks.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.09195", "title": "Training-Free Semantic Video Composition via Pre-trained Diffusion Model", "abstract": "The video composition task aims to integrate specified foregrounds and\nbackgrounds from different videos into a harmonious composite. Current\napproaches, predominantly trained on videos with adjusted foreground color and\nlighting, struggle to address deep semantic disparities beyond superficial\nadjustments, such as domain gaps. Therefore, we propose a training-free\npipeline employing a pre-trained diffusion model imbued with semantic prior\nknowledge, which can process composite videos with broader semantic\ndisparities. Specifically, we process the video frames in a cascading manner\nand handle each frame in two processes with the diffusion model. In the\ninversion process, we propose Balanced Partial Inversion to obtain generation\ninitial points that balance reversibility and modifiability. Then, in the\ngeneration process, we further propose Inter-Frame Augmented attention to\naugment foreground continuity across frames. Experimental results reveal that\nour pipeline successfully ensures the visual harmony and inter-frame coherence\nof the outputs, demonstrating efficacy in managing broader semantic\ndisparities.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.09198", "title": "Space and Time Continuous Physics Simulation From Partial Observations", "abstract": "Modern techniques for physical simulations rely on numerical schemes and\nmesh-refinement methods to address trade-offs between precision and complexity,\nbut these handcrafted solutions are tedious and require high computational\npower. Data-driven methods based on large-scale machine learning promise high\nadaptivity by integrating long-range dependencies more directly and\nefficiently. In this work, we focus on fluid dynamics and address the\nshortcomings of a large part of the literature, which are based on fixed\nsupport for computations and predictions in the form of regular or irregular\ngrids. We propose a novel setup to perform predictions in a continuous spatial\nand temporal domain while being trained on sparse observations. We formulate\nthe task as a double observation problem and propose a solution with two\ninterlinked dynamical systems defined on, respectively, the sparse positions\nand the continuous domain, which allows to forecast and interpolate a solution\nfrom the initial condition. Our practical implementation involves recurrent\nGNNs and a spatio-temporal attention observer capable of interpolating the\nsolution at arbitrary locations. Our model not only generalizes to new initial\nconditions (as standard auto-regressive models do) but also performs evaluation\nat arbitrary space and time locations. We evaluate on three standard datasets\nin fluid dynamics and compare to strong baselines, which are outperformed both\nin classical settings and in the extended new task requiring continuous\npredictions.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.09199", "title": "Data Trading and Monetization: Challenges and Open Research Directions", "abstract": "Traditional data monetization approaches face challenges related to data\nprotection and logistics. In response, digital data marketplaces have emerged\nas intermediaries simplifying data transactions. Despite the growing\nestablishment and acceptance of digital data marketplaces, significant\nchallenges hinder efficient data trading. As a result, few companies can derive\ntangible value from their data, leading to missed opportunities in\nunderstanding customers, pricing decisions, and fraud prevention. In this\npaper, we explore both technical and organizational challenges affecting data\nmonetization. Moreover, we identify areas in need of further research, aiming\nto expand the boundaries of current knowledge by emphasizing where research is\ncurrently limited or lacking.", "field": "Computer Science", "categories": "cs.DC,cs.DB"}, {"arxiv_id": "2401.092", "title": "A Real-Time Lyrics Alignment System Using Chroma And Phonetic Features\n  For Classical Vocal Performance", "abstract": "The goal of real-time lyrics alignment is to take live singing audio as input\nand to pinpoint the exact position within given lyrics on the fly. The task can\nbenefit real-world applications such as the automatic subtitling of live\nconcerts or operas. However, designing a real-time model poses a great\nchallenge due to the constraints of only using past input and operating within\na minimal latency. Furthermore, due to the lack of datasets for real-time\nmodels for lyrics alignment, previous studies have mostly evaluated with\nprivate in-house datasets, resulting in a lack of standard evaluation methods.\nThis paper presents a real-time lyrics alignment system for classical vocal\nperformances with two contributions. First, we improve the lyrics alignment\nalgorithm by finding an optimal combination of chromagram and phonetic\nposteriorgram (PPG) that capture melodic and phonetics features of the singing\nvoice, respectively. Second, we recast the Schubert Winterreise Dataset (SWD)\nwhich contains multiple performance renditions of the same pieces as an\nevaluation set for the real-time lyrics alignment.", "field": "Computer Science", "categories": "cs.SD,cs.LG,eess.AS"}, {"arxiv_id": "2401.09204", "title": "Cross-Domain AI for Early Attack Detection and Defense Against Malicious\n  Flows in O-RAN", "abstract": "Only the chairs can edit In the fight against cyber attacks, Network\nSoftwarization (NS) is a flexible and adaptable shield, using advanced software\nto spot malicious activity in regular network traffic. However, the\navailability of comprehensive datasets for mobile networks, which are\nfundamental for the development of Machine Learning (ML) solutions for attack\ndetection near their source, is still limited. Cross-Domain Artificial\nIntelligence (AI) can be the key to address this, although its application in\nOpen Radio Access Network (O-RAN) is still at its infancy. To address these\nchallenges, we deployed an end-to-end O-RAN network, that was used to collect\ndata from the RAN and the transport network. These datasets allow us to combine\nthe knowledge from an in-network ML traffic classifier for attack detection to\nbolster the training of an ML-based traffic classifier specifically tailored\nfor the RAN. Our results demonstrate the potential of the proposed approach,\nachieving an accuracy rate of 93%. This approach not only bridges critical gaps\nin mobile network security but also showcases the potential of cross-domain AI\nin enhancing the efficacy of network security measures.", "field": "Computer Science", "categories": "cs.CR,cs.NI"}, {"arxiv_id": "2401.09207", "title": "An Energy-efficient Capacitive-Memristive Content Addressable Memory", "abstract": "Content addressable memory is popular in the field of intelligent computing\nsystems with its searching nature. Emerging CAMs show a promising increase in\npixel density and a decrease in power consumption than pure CMOS solutions.\nThis article introduced an energy-efficient 3T1R1C TCAM cooperating with\ncapacitor dividers and RRAM devices. The RRAM as a storage element also acts as\na switch to the capacitor divider while searching for content. CAM cells\nbenefit from working parallel in an array structure. We implemented a 64 x 64\narray and digital controllers to perform with an internal built-in clock\nfrequency of 875MHz. Both data searches and reads take 3x clock cycles. Its\nworst average energy for data match is reported to be 1.71 fJ/bit-search and\nthe worst average energy for data miss is found with 4.69 fJ/bit-search. The\nprototype is simulated and fabricated in 0.18 um technology with in-lab RRAM\npost-processing. Such memory explores the charge domain searching mechanism and\ncan be applied to data centers that are power-hungry.", "field": "Computer Science", "categories": "eess.SY,cs.SY,eess.IV"}, {"arxiv_id": "2401.09209", "title": "Username Squatting on Online Social Networks: A Study on X", "abstract": "Adversaries have been targeting unique identifiers to launch typo-squatting,\nmobile app squatting and even voice squatting attacks. Anecdotal evidence\nsuggest that online social networks (OSNs) are also plagued with accounts that\nuse similar usernames. This can be confusing to users but can also be exploited\nby adversaries. However, to date no study characterizes this problem on OSNs.\nIn this work, we define the username squatting problem and design the first\nmulti-faceted measurement study to characterize it on X. We develop a username\ngeneration tool (UsernameCrazy) to help us analyze hundreds of thousands of\nusername variants derived from celebrity accounts. Our study reveals that\nthousands of squatted usernames have been suspended by X, while tens of\nthousands that still exist on the network are likely bots. Out of these, a\nlarge number share similar profile pictures and profile names to the original\naccount signalling impersonation attempts. We found that squatted accounts are\nbeing mentioned by mistake in tweets hundreds of thousands of times and are\neven being prioritized in searches by the network's search recommendation\nalgorithm exacerbating the negative impact squatted accounts can have in OSNs.\nWe use our insights and take the first step to address this issue by designing\na framework (SQUAD) that combines UsernameCrazy with a new classifier to\nefficiently detect suspicious squatted accounts. Our evaluation of SQUAD's\nprototype implementation shows that it can achieve 94% F1-score when trained on\na small dataset.", "field": "Computer Science", "categories": "cs.CR,cs.SI"}, {"arxiv_id": "2401.0921", "title": "Narratives of Collective Action in YouTube's Discourse on Veganism", "abstract": "Narratives can be powerful tools for inspiring action on pressing societal\nissues such as climate change. While social science theories offer frameworks\nfor understanding the narratives that arise within collective movements, these\nare rarely applied to the vast data available from social media platforms,\nwhich play a significant role in shaping public opinion and mobilizing\ncollective action. This gap in the empirical evaluation of online narratives\nlimits our understanding of their relationship with public response. In this\nstudy, we focus on plant-based diets as a form of pro-environmental action and\nemploy natural language processing to operationalize a theoretical framework of\nmoral narratives specific to the vegan movement. We apply this framework to\nnarratives found in YouTube videos promoting environmental initiatives such as\nVeganuary, Meatless March, and No Meat May. Our analysis reveals that several\nnarrative types, as defined by the theory, are empirically present in the data.\nTo identify narratives with the potential to elicit positive public engagement,\nwe used text processing to estimate the proportion of comments supporting\ncollective action across narrative types. Video narratives advocating social\nfight, whether through protest or through efforts to convert others to the\ncause, are associated with a stronger sense of collective action in the\nrespective comments. These narrative types also demonstrate increased semantic\ncoherence and alignment between the message and public response, markers\ntypically associated with successful collective action. Our work offers new\ninsights into the complex factors that influence the emergence of collective\naction, thereby informing the development of effective communication strategies\nwithin social movements.", "field": "Computer Science", "categories": "cs.CY,physics.soc-ph"}, {"arxiv_id": "2401.09217", "title": "Neural Network Equalizers and Successive Interference Cancellation for\n  Bandlimited Channels with a Nonlinearity", "abstract": "Neural networks (NNs) inspired by the forward-backward algorithm (FBA) are\nused as equalizers for bandlimited channels with a memoryless nonlinearity. The\nNN-equalizers are combined with successive interference cancellation (SIC) to\napproach the information rates of joint detection and decoding (JDD) with\nconsiderably less complexity than JDD and other existing equalizers.\nSimulations for short-haul optical fiber links with square-law detection\nillustrate the gains of NNs as compared to the complexity-limited FBA and Gibbs\nsampling.", "field": "Computer Science", "categories": "cs.IT,eess.SP,math.IT"}, {"arxiv_id": "2401.0922", "title": "UniVIE: A Unified Label Space Approach to Visual Information Extraction\n  from Form-like Documents", "abstract": "Existing methods for Visual Information Extraction (VIE) from form-like\ndocuments typically fragment the process into separate subtasks, such as key\ninformation extraction, key-value pair extraction, and choice group extraction.\nHowever, these approaches often overlook the hierarchical structure of form\ndocuments, including hierarchical key-value pairs and hierarchical choice\ngroups. To address these limitations, we present a new perspective, reframing\nVIE as a relation prediction problem and unifying labels of different tasks\ninto a single label space. This unified approach allows for the definition of\nvarious relation types and effectively tackles hierarchical relationships in\nform-like documents. In line with this perspective, we present UniVIE, a\nunified model that addresses the VIE problem comprehensively. UniVIE functions\nusing a coarse-to-fine strategy. It initially generates tree proposals through\na tree proposal network, which are subsequently refined into hierarchical trees\nby a relation decoder module. To enhance the relation prediction capabilities\nof UniVIE, we incorporate two novel tree constraints into the relation decoder:\na tree attention mask and a tree level embedding. Extensive experimental\nevaluations on both our in-house dataset HierForms and a publicly available\ndataset SIBR, substantiate that our method achieves state-of-the-art results,\nunderscoring the effectiveness and potential of our unified approach in\nadvancing the field of VIE.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.09221", "title": "Multiple Subset Problem as an encryption scheme for communication", "abstract": "Using well-known mathematical problems for encryption is a widely used\ntechnique because they are computationally hard and provide security against\npotential attacks on the encryption method. The subset sum problem (SSP) can be\ndefined as finding a subset of integers from a given set, whose sum is equal to\na specified integer. The classic SSP has various variants, one of which is the\nmultiple-subset problem (MSSP). In the MSSP, the goal is to select items from a\ngiven set and distribute them among multiple bins, en-suring that the capacity\nof each bin is not exceeded while maximizing the total weight of the selected\nitems. This approach addresses a related problem with a different perspective.\nHere a related different kind of problem is approached: given a set of sets\nA={A1, A2..., An}, find an integer s for which every subset of the given sets\nis summed up to, if such an integer exists. The problem is NP-complete when\nconsidering it as a variant of SSP. However, there exists an algorithm that is\nrelatively efficient for known pri-vate keys. This algorithm is based on\ndispensing non-relevant values of the potential sums. In this paper we present\nthe encryption scheme based on MSSP and present its novel usage and\nimplementation in communication.", "field": "Computer Science", "categories": "cs.CR"}, {"arxiv_id": "2401.09229", "title": "Information flow and Laplacian dynamics on local optima networks", "abstract": "We propose a new way of looking at local optima networks (LONs). LONs\nrepresent fitness landscapes; the nodes are local optima, and the edges are\nsearch transitions between them. Many metrics computed on LONs have been\nproposed and shown to be linked to metaheuristic search difficulty. These have\ntypically considered LONs as describing static structures. In contrast to this,\nLaplacian dynamics (LD) is an approach to consider the information flow across\na network as a dynamical process. We adapt and apply LD to the context of LONs.\nAs a testbed, we consider instances from the quadratic assignment problem (QAP)\nlibrary. Metrics related to LD are proposed and these are compared with\nexisting LON metrics. The results show that certain LD metrics are strong\npredictors of metaheuristic performance for iterated local search and tabu\nsearch.", "field": "Computer Science", "categories": "cs.NE"}, {"arxiv_id": "2401.09231", "title": "Scalable Resource Provisioning for Multi-user Communications in Next\n  Generation Networks", "abstract": "The great demand for real-time multimedia sessions encompassing groups of\nusers (multi-user), associated with the limitations of the current Internet in\nproviding quality assurance, has raised challenges for defining the best\nmechanisms to deploy the Next Generation of Networks (NGN). There is a\nconsensus that an efficient and scalable provisioning of network resources is\ncrucial for the success of the NGN, mainly in what concerns access networks.\nPrevious solutions for the control of multi-user sessions rely mostly on\nuncoordinated actions to allocate per-flow bandwidth and multicast trees. This\npaper introduces a Multiuser Aggregated Resource Allocation mechanism (MARA)\nthat coordinates the control of class-based bandwidth and multicast resources\nin a scalable manner. In comparison with previous work, MARA significantly\nreduces signaling, state and processing overhead. The performance benefits of\nMARA are analyzed though simulations, which successfully demonstrated the\nsignificant optimization in the network performance.", "field": "Computer Science", "categories": "cs.NI"}, {"arxiv_id": "2401.09232", "title": "Dynamic Relation Transformer for Contextual Text Block Detection", "abstract": "Contextual Text Block Detection (CTBD) is the task of identifying coherent\ntext blocks within the complexity of natural scenes. Previous methodologies\nhave treated CTBD as either a visual relation extraction challenge within\ncomputer vision or as a sequence modeling problem from the perspective of\nnatural language processing. We introduce a new framework that frames CTBD as a\ngraph generation problem. This methodology consists of two essential\nprocedures: identifying individual text units as graph nodes and discerning the\nsequential reading order relationships among these units as graph edges.\nLeveraging the cutting-edge capabilities of DQ-DETR for node detection, our\nframework innovates further by integrating a novel mechanism, a Dynamic\nRelation Transformer (DRFormer), dedicated to edge generation. DRFormer\nincorporates a dual interactive transformer decoder that deftly manages a\ndynamic graph structure refinement process. Through this iterative process, the\nmodel systematically enhances the graph's fidelity, ultimately resulting in\nimproved precision in detecting contextual text blocks. Comprehensive\nexperimental evaluations conducted on both SCUT-CTW-Context and ReCTS-Context\ndatasets substantiate that our method achieves state-of-the-art results,\nunderscoring the effectiveness and potential of our graph generation framework\nin advancing the field of CTBD.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.09234", "title": "SARRIGUREN: a polynomial-time complete algorithm for random $k$-SAT with\n  relatively dense clauses", "abstract": "SARRIGUREN, a new complete algorithm for SAT based on counting clauses (which\nis valid also for Unique-SAT and #SAT) is described, analyzed and tested.\nAlthough existing complete algorithms for SAT perform slower with clauses with\nmany literals, that is an advantage for SARRIGUREN, because the more literals\nare in the clauses the bigger is the probability of overlapping among clauses,\na property that makes the clause counting process more efficient. Actually, it\nprovides a $O(m^2 \\times n/k)$ time complexity for random $k$-SAT instances of\n$n$ variables and $m$ relatively dense clauses, where that density level is\nrelative to the number of variables $n$, that is, clauses are relatively dense\nwhen $k\\geq7\\sqrt{n}$. Although theoretically there could be worst-cases with\nexponential complexity, the probability of those cases to happen in random\n$k$-SAT with relatively dense clauses is practically zero. The algorithm has\nbeen empirically tested and that polynomial time complexity maintains also for\n$k$-SAT instances with less dense clauses ($k\\geq5\\sqrt{n}$). That density\ncould, for example, be of only 0.049 working with $n=20000$ variables and\n$k=989$ literals. In addition, they are presented two more complementary\nalgorithms that provide the solutions to $k$-SAT instances and valuable\ninformation about number of solutions for each literal. Although this algorithm\ndoes not solve the NP=P problem (it is not a polynomial algorithm for 3-SAT),\nit broads the knowledge about that subject, because $k$-SAT with $k>3$ and\ndense clauses is not harder than 3-SAT. Moreover, the Python implementation of\nthe algorithms, and all the input datasets and obtained results in the\nexperiments are made available.", "field": "Computer Science", "categories": "cs.DS,cs.CC,F.2.2"}, {"arxiv_id": "2401.09235", "title": "A Characterization Theorem for Equivariant Networks with Point-wise\n  Activations", "abstract": "Equivariant neural networks have shown improved performance, expressiveness\nand sample complexity on symmetrical domains. But for some specific symmetries,\nrepresentations, and choice of coordinates, the most common point-wise\nactivations, such as ReLU, are not equivariant, hence they cannot be employed\nin the design of equivariant neural networks. The theorem we present in this\npaper describes all possible combinations of finite-dimensional\nrepresentations, choice of coordinates and point-wise activations to obtain an\nexactly equivariant layer, generalizing and strengthening existing\ncharacterizations. Notable cases of practical relevance are discussed as\ncorollaries. Indeed, we prove that rotation-equivariant networks can only be\ninvariant, as it happens for any network which is equivariant with respect to\nconnected compact groups. Then, we discuss implications of our findings when\napplied to important instances of exactly equivariant networks. First, we\ncompletely characterize permutation equivariant networks such as Invariant\nGraph Networks with point-wise nonlinearities and their geometric counterparts,\nhighlighting a plethora of models whose expressive power and performance are\nstill unknown. Second, we show that feature spaces of disentangled steerable\nconvolutional neural networks are trivial representations.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.09237", "title": "Classification and Reconstruction Processes in Deep Predictive Coding\n  Networks: Antagonists or Allies?", "abstract": "Predictive coding-inspired deep networks for visual computing integrate\nclassification and reconstruction processes in shared intermediate layers.\nAlthough synergy between these processes is commonly assumed, it has yet to be\nconvincingly demonstrated. In this study, we take a critical look at how\nclassifying and reconstructing interact in deep learning architectures. Our\napproach utilizes a purposefully designed family of model architectures\nreminiscent of autoencoders, each equipped with an encoder, a decoder, and a\nclassification head featuring varying modules and complexities. We meticulously\nanalyze the extent to which classification- and reconstruction-driven\ninformation can seamlessly coexist within the shared latent layer of the model\narchitectures. Our findings underscore a significant challenge:\nClassification-driven information diminishes reconstruction-driven information\nin intermediate layers' shared representations and vice versa. While expanding\nthe shared representation's dimensions or increasing the network's complexity\ncan alleviate this trade-off effect, our results challenge prevailing\nassumptions in predictive coding and offer guidance for future iterations of\npredictive coding concepts in deep networks.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.09239", "title": "DaFoEs: Mixing Datasets towards the generalization of vision-state\n  deep-learning Force Estimation in Minimally Invasive Robotic Surgery", "abstract": "Precisely determining the contact force during safe interaction in Minimally\nInvasive Robotic Surgery (MIRS) is still an open research challenge. Inspired\nby post-operative qualitative analysis from surgical videos, the use of\ncross-modality data driven deep neural network models has been one of the\nnewest approaches to predict sensorless force trends. However, these methods\nrequired for large and variable datasets which are not currently available. In\nthis paper, we present a new vision-haptic dataset (DaFoEs) with variable soft\nenvironments for the training of deep neural models. In order to reduce the\nbias from a single dataset, we present a pipeline to generalize different\nvision and state data inputs for mixed dataset training, using a previously\nvalidated dataset with different setup. Finally, we present a variable\nencoder-decoder architecture to predict the forces done by the laparoscopic\ntool using single input or sequence of inputs. For input sequence, we use a\nrecurrent decoder, named with the prefix R, and a new temporal sampling to\nrepresent the acceleration of the tool. During our training, we demonstrate\nthat single dataset training tends to overfit to the training data domain, but\nhas difficulties on translating the results across new domains. However,\ndataset mixing presents a good translation with a mean relative estimated force\nerror of 5% and 12% for the recurrent and non-recurrent models respectively.\nOur method, also marginally increase the effectiveness of transformers for\nforce estimation up to a maximum of ~15%, as the volume of available data is\nincrease by 150%. In conclusion, we demonstrate that mixing experimental set\nups for vision-state force estimation in MIRS is a possible approach towards\nthe general solution of the problem.", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.RO"}, {"arxiv_id": "2401.0924", "title": "A Blockchain-based Model for Securing Data Pipeline in a Heterogeneous\n  Information System", "abstract": "In our digital world, access to personal and public data has become an item\nof concern, with challenging security and privacy aspects. Modern information\nsystems are heterogeneous in nature and have an inherent security\nvulnerability, which is susceptible to data interception and data modification\ndue to unsecured communication data pipelines between connected endpoints. This\nre-search article presents a blockchain-based model for securing data pipelines\nin a heterogeneous information system using an integrated multi-hazard early\nwarning system (MHEWS) as a case study. The proposed model utilizes the\ninherent security features of blockchain technology to address the security and\nprivacy concerns that arise in data pipelines. The model is designed to ensure\ndata integrity, confidentiality, and authenticity in a decentralized manner.\nThe model is evaluated in a hybrid environment using a prototype implementation\nand simulation experiments with outcomes that demonstrate advantages over\ntraditional approaches for a tamper-proof and immutable data pipeline for data\nauthenticity and integrity using a confidential ledger.", "field": "Computer Science", "categories": "cs.CR,cs.AI,cs.DC,cs.NI"}, {"arxiv_id": "2401.09241", "title": "Biased-MPPI: Informing Sampling-Based Model Predictive Control by Fusing\n  Ancillary Controllers", "abstract": "Motion planning for autonomous robots in human-populated environments poses\nnumerous challenges due to uncertainties in the robot's dynamics, environment,\nand interaction with other agents. Sampling-based MPC approaches, such as Model\nPredictive Path Integral (MPPI) control, have shown promise in addressing these\ncomplex motion planning problems. However, the performance of MPPI heavily\nrelies on the choice of the sampling distribution. Existing literature often\nuses the previously computed input sequence as the mean of a Gaussian\ndistribution for sampling, leading to potential failures and local minima. In\nthis paper, we propose novel derivations of the MPPI method to enhance its\nefficiency, robustness, and convergence. Our approach includes a mathematical\nformulation allowing for arbitrary sampling distributions, addressing numerical\nissues, and alleviating the problem of local minima. We present an efficient\nimportance sampling scheme that combines classical and learning-based ancillary\ncontrollers simultaneously, resulting in more informative sampling and control\nfusion. We demonstrate our proposed scheme's superior efficiency and robustness\nthrough experiments by handling model uncertainties, rapid environmental\nchanges and reducing susceptibility to local minima.", "field": "Computer Science", "categories": "cs.RO"}, {"arxiv_id": "2401.09242", "title": "Offloading platooning applications from 5.9\\,GHz V2X to Radar\n  Communications: effects on safety and efficiency", "abstract": "V2X communications are nowadays performed at 5.9\\,GHz spectrum, either using\nWiFi-based or Cellular technology. The channel capacity is limited, and\ncongestion control regulates the number of messages that can enter the medium.\nWith user rate growing, overloading becomes a factor that might affect road\nsafety and traffic efficiency. The present paper evaluates the potential of\nusing Radar-Based Communication (RadCom) for offloading the V2X spectrum. We\nconsider a heavy-duty vehicle (HDV) platooning scenario as a case of maneuver\ncoordination where local messages are transmitted by means of RadCom at\ndifferent penetration rates. Simulations show significant improvements in\nchannel occupation and network reliability. As a result, RadCom allows for\nshorter safe and energy efficient inter-vehicle distances.", "field": "Computer Science", "categories": "cs.NI"}, {"arxiv_id": "2401.09243", "title": "DiffClone: Enhanced Behaviour Cloning in Robotics with Diffusion-Driven\n  Policy Learning", "abstract": "Robot learning tasks are extremely compute-intensive and hardware-specific.\nThus the avenues of tackling these challenges, using a diverse dataset of\noffline demonstrations that can be used to train robot manipulation agents, is\nvery appealing. The Train-Offline-Test-Online (TOTO) Benchmark provides a\nwell-curated open-source dataset for offline training comprised mostly of\nexpert data and also benchmark scores of the common offline-RL and behaviour\ncloning agents. In this paper, we introduce DiffClone, an offline algorithm of\nenhanced behaviour cloning agent with diffusion-based policy learning, and\nmeasured the efficacy of our method on real online physical robots at test\ntime. This is also our official submission to the Train-Offline-Test-Online\n(TOTO) Benchmark Challenge organized at NeurIPS 2023. We experimented with both\npre-trained visual representation and agent policies. In our experiments, we\nfind that MOCO finetuned ResNet50 performs the best in comparison to other\nfinetuned representations. Goal state conditioning and mapping to transitions\nresulted in a minute increase in the success rate and mean-reward. As for the\nagent policy, we developed DiffClone, a behaviour cloning agent improved using\nconditional diffusion.", "field": "Computer Science", "categories": "cs.RO,cs.AI,cs.LG"}, {"arxiv_id": "2401.09244", "title": "Cross-lingual Offensive Language Detection: A Systematic Review of\n  Datasets, Transfer Approaches and Challenges", "abstract": "The growing prevalence and rapid evolution of offensive language in social\nmedia amplify the complexities of detection, particularly highlighting the\nchallenges in identifying such content across diverse languages. This survey\npresents a systematic and comprehensive exploration of Cross-Lingual Transfer\nLearning (CLTL) techniques in offensive language detection in social media. Our\nstudy stands as the first holistic overview to focus exclusively on the\ncross-lingual scenario in this domain. We analyse 67 relevant papers and\ncategorise these studies across various dimensions, including the\ncharacteristics of multilingual datasets used, the cross-lingual resources\nemployed, and the specific CLTL strategies implemented. According to \"what to\ntransfer\", we also summarise three main CLTL transfer approaches: instance,\nfeature, and parameter transfer. Additionally, we shed light on the current\nchallenges and future research opportunities in this field. Furthermore, we\nhave made our survey resources available online, including two comprehensive\ntables that provide accessible references to the multilingual datasets and CLTL\nmethods used in the reviewed literature.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.09245", "title": "Uncertainty estimates for semantic segmentation: providing enhanced\n  reliability for automated motor claims handling", "abstract": "Deep neural network models for image segmentation can be a powerful tool for\nthe automation of motor claims handling processes in the insurance industry. A\ncrucial aspect is the reliability of the model outputs when facing adverse\nconditions, such as low quality photos taken by claimants to document damages.\nWe explore the use of a meta-classification model to assess the precision of\nsegments predicted by a model trained for the semantic segmentation of car body\nparts. Different sets of features correlated with the quality of a segment are\ncompared, and an AUROC score of 0.915 is achieved for distinguishing between\nhigh- and low-quality segments. By removing low-quality segments, the average\nmIoU of the segmentation output is improved by 16 percentage points and the\nnumber of wrongly predicted segments is reduced by 77%.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.09248", "title": "Learning from Emotions, Demographic Information and Implicit User\n  Feedback in Task-Oriented Document-Grounded Dialogues", "abstract": "The success of task-oriented and document-grounded dialogue systems depends\non users accepting and enjoying using them. To achieve this, recently published\nwork in the field of Human-Computer Interaction suggests that the combination\nof considering demographic information, user emotions and learning from the\nimplicit feedback in their utterances, is particularly important. However,\nthese findings have not yet been transferred to the field of Natural Language\nProcessing, where these data are primarily studied separately. Accordingly, no\nsufficiently annotated dataset is available. To address this gap, we introduce\nFEDI, the first English dialogue dataset for task-oriented document-grounded\ndialogues annotated with demographic information, user emotions and implicit\nfeedback. Our experiments with FLAN-T5, GPT-2 and LLaMA-2 show that these data\nhave the potential to improve task completion and the factual consistency of\nthe generated responses and user acceptance.", "field": "Computer Science", "categories": "cs.CL,cs.HC"}, {"arxiv_id": "2401.09251", "title": "Bridging the Gap Between General and Down-Closed Convex Sets in\n  Submodular Maximization", "abstract": "Optimization of DR-submodular functions has experienced a notable surge in\nsignificance in recent times, marking a pivotal development within the domain\nof non-convex optimization. Motivated by real-world scenarios, some recent\nworks have delved into the maximization of non-monotone DR-submodular functions\nover general (not necessarily down-closed) convex set constraints. Up to this\npoint, these works have all used the minimum $\\ell_\\infty$ norm of any feasible\nsolution as a parameter. Unfortunately, a recent hardness result due to Mualem\n\\& Feldman~\\cite{mualem2023resolving} shows that this approach cannot yield a\nsmooth interpolation between down-closed and non-down-closed constraints. In\nthis work, we suggest novel offline and online algorithms that provably provide\nsuch an interpolation based on a natural decomposition of the convex body\nconstraint into two distinct convex bodies: a down-closed convex body and a\ngeneral convex body. We also empirically demonstrate the superiority of our\nproposed algorithms across three offline and two online applications.", "field": "Computer Science", "categories": "cs.LG,math.OC"}, {"arxiv_id": "2401.09252", "title": "3D Scene Geometry Estimation from 360$^\\circ$ Imagery: A Survey", "abstract": "This paper provides a comprehensive survey on pioneer and state-of-the-art 3D\nscene geometry estimation methodologies based on single, two, or multiple\nimages captured under the omnidirectional optics. We first revisit the basic\nconcepts of the spherical camera model, and review the most common acquisition\ntechnologies and representation formats suitable for omnidirectional (also\ncalled 360$^\\circ$, spherical or panoramic) images and videos. We then survey\nmonocular layout and depth inference approaches, highlighting the recent\nadvances in learning-based solutions suited for spherical data. The classical\nstereo matching is then revised on the spherical domain, where methodologies\nfor detecting and describing sparse and dense features become crucial. The\nstereo matching concepts are then extrapolated for multiple view camera setups,\ncategorizing them among light fields, multi-view stereo, and structure from\nmotion (or visual simultaneous localization and mapping). We also compile and\ndiscuss commonly adopted datasets and figures of merit indicated for each\npurpose and list recent results for completeness. We conclude this paper by\npointing out current and future trends.", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.GR,cs.LG"}, {"arxiv_id": "2401.09256", "title": "Relay Channels with Unreliable Helpers", "abstract": "The relay channel with unreliable helper is introduced and studied. The model\nis that of a classical relay channel where the input from the relay to the\nchannel has an extra primitive link whose presence is not assured a priori. The\nextra link represents a helper who may decide not to cooperate in transmission.\nThe goal is to devise robust coding schemes that exploit all the relay links\nwhen they are present, but can also operate, possibly at reduced rates, when\nthe extra primitive link (helper) is absent. The capacity region of this class\nof problems is defined, and fully characterized for degraded relay channels.\nThe degraded Gaussian relay channel with unreliable relay link is solved.", "field": "Computer Science", "categories": "cs.IT,math.IT"}, {"arxiv_id": "2401.09257", "title": "A First-Order Multi-Gradient Algorithm for Multi-Objective Bi-Level\n  Optimization", "abstract": "In this paper, we study the Multi-Objective Bi-Level Optimization (MOBLO)\nproblem, where the upper-level subproblem is a multi-objective optimization\nproblem and the lower-level subproblem is for scalar optimization. Existing\ngradient-based MOBLO algorithms need to compute the Hessian matrix, causing the\ncomputational inefficient problem. To address this, we propose an efficient\nfirst-order multi-gradient method for MOBLO, called FORUM. Specifically, we\nreformulate MOBLO problems as a constrained multi-objective optimization (MOO)\nproblem via the value-function approach. Then we propose a novel multi-gradient\naggregation method to solve the challenging constrained MOO problem.\nTheoretically, we provide the complexity analysis to show the efficiency of the\nproposed method and a non-asymptotic convergence result. Empirically, extensive\nexperiments demonstrate the effectiveness and efficiency of the proposed FORUM\nmethod in different learning problems. In particular, it achieves\nstate-of-the-art performance on three multi-task learning benchmark datasets.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.09258", "title": "An Efficient Generalizable Framework for Visuomotor Policies via\n  Control-aware Augmentation and Privilege-guided Distillation", "abstract": "Visuomotor policies, which learn control mechanisms directly from\nhigh-dimensional visual observations, confront challenges in adapting to new\nenvironments with intricate visual variations. Data augmentation emerges as a\npromising method for bridging these generalization gaps by enriching data\nvariety. However, straightforwardly augmenting the entire observation shall\nimpose excessive burdens on policy learning and may even result in performance\ndegradation. In this paper, we propose to improve the generalization ability of\nvisuomotor policies as well as preserve training stability from two aspects: 1)\nWe learn a control-aware mask through a self-supervised reconstruction task\nwith three auxiliary losses and then apply strong augmentation only to those\ncontrol-irrelevant regions based on the mask to reduce the generalization gaps.\n2) To address training instability issues prevalent in visual reinforcement\nlearning (RL), we distill the knowledge from a pretrained RL expert processing\nlow-level environment states, to the student visuomotor policy. The policy is\nsubsequently deployed to unseen environments without any further finetuning. We\nconducted comparison and ablation studies across various benchmarks: the\nDMControl Generalization Benchmark (DMC-GB), the enhanced Robot Manipulation\nDistraction Benchmark (RMDB), and a specialized long-horizontal drawer-opening\nrobotic task. The extensive experimental results well demonstrate the\neffectiveness of our method, e.g., showing a 17\\% improvement over previous\nmethods in the video-hard setting of DMC-GB.", "field": "Computer Science", "categories": "cs.RO,cs.CV"}, {"arxiv_id": "2401.09259", "title": "Mitigating distribution shift in machine learning-augmented hybrid\n  simulation", "abstract": "We study the problem of distribution shift generally arising in\nmachine-learning augmented hybrid simulation, where parts of simulation\nalgorithms are replaced by data-driven surrogates. We first establish a\nmathematical framework to understand the structure of machine-learning\naugmented hybrid simulation problems, and the cause and effect of the\nassociated distribution shift. We show correlations between distribution shift\nand simulation error both numerically and theoretically. Then, we propose a\nsimple methodology based on tangent-space regularized estimator to control the\ndistribution shift, thereby improving the long-term accuracy of the simulation\nresults. In the linear dynamics case, we provide a thorough theoretical\nanalysis to quantify the effectiveness of the proposed method. Moreover, we\nconduct several numerical experiments, including simulating a partially known\nreaction-diffusion equation and solving Navier-Stokes equations using the\nprojection method with a data-driven pressure solver. In all cases, we observe\nmarked improvements in simulation accuracy under the proposed method,\nespecially for systems with high degrees of distribution shift, such as those\nwith relatively strong non-linear reaction mechanisms, or flows at large\nReynolds numbers.", "field": "Computer Science", "categories": "math.NA,cs.NA,math.DS,stat.ML,68T99, 65M15, 37M05"}, {"arxiv_id": "2401.09261", "title": "MSHyper: Multi-Scale Hypergraph Transformer for Long-Range Time Series\n  Forecasting", "abstract": "Demystifying interactions between temporal patterns of different scales is\nfundamental to precise long-range time series forecasting. However, previous\nworks lack the ability to model high-order interactions. To promote more\ncomprehensive pattern interaction modeling for long-range time series\nforecasting, we propose a Multi-Scale Hypergraph Transformer (MSHyper)\nframework. Specifically, a multi-scale hypergraph is introduced to provide\nfoundations for modeling high-order pattern interactions. Then by treating\nhyperedges as nodes, we also build a hyperedge graph to enhance hypergraph\nmodeling. In addition, a tri-stage message passing mechanism is introduced to\naggregate pattern information and learn the interaction strength between\ntemporal patterns of different scales. Extensive experiments on five real-world\ndatasets demonstrate that MSHyper achieves state-of-the-art performance,\nreducing prediction errors by an average of 8.73% and 7.15% over the best\nbaseline in MSE and MAE, respectively.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.09266", "title": "P$^2$OT: Progressive Partial Optimal Transport for Deep Imbalanced\n  Clustering", "abstract": "Deep clustering, which learns representation and semantic clustering without\nlabels information, poses a great challenge for deep learning-based approaches.\nDespite significant progress in recent years, most existing methods focus on\nuniformly distributed datasets, significantly limiting the practical\napplicability of their methods. In this paper, we first introduce a more\npractical problem setting named deep imbalanced clustering, where the\nunderlying classes exhibit an imbalance distribution. To tackle this problem,\nwe propose a novel pseudo-labeling-based learning framework. Our framework\nformulates pseudo-label generation as a progressive partial optimal transport\nproblem, which progressively transports each sample to imbalanced clusters\nunder prior distribution constraints, thus generating imbalance-aware\npseudo-labels and learning from high-confident samples. In addition, we\ntransform the initial formulation into an unbalanced optimal transport problem\nwith augmented constraints, which can be solved efficiently by a fast matrix\nscaling algorithm. Experiments on various datasets, including a human-curated\nlong-tailed CIFAR100, challenging ImageNet-R, and large-scale subsets of\nfine-grained iNaturalist2018 datasets, demonstrate the superiority of our\nmethod.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.09267", "title": "Risk-Aware Accelerated Wireless Federated Learning with Heterogeneous\n  Clients", "abstract": "Wireless Federated Learning (FL) is an emerging distributed machine learning\nparadigm, particularly gaining momentum in domains with confidential and\nprivate data on mobile clients. However, the location-dependent performance, in\nterms of transmission rates and susceptibility to transmission errors, poses\nmajor challenges for wireless FL's convergence speed and accuracy. The\nchallenge is more acute for hostile environments without a metric that\nauthenticates the data quality and security profile of the clients. In this\ncontext, this paper proposes a novel risk-aware accelerated FL framework that\naccounts for the clients heterogeneity in the amount of possessed data,\ntransmission rates, transmission errors, and trustworthiness. Classifying\nclients according to their location-dependent performance and trustworthiness\nprofiles, we propose a dynamic risk-aware global model aggregation scheme that\nallows clients to participate in descending order of their transmission rates\nand an ascending trustworthiness constraint. In particular, the transmission\nrate is the dominant participation criterion for initial rounds to accelerate\nthe convergence speed. Our model then progressively relaxes the transmission\nrate restriction to explore more training data at cell-edge clients. The\naggregation rounds incorporate a debiasing factor that accounts for\ntransmission errors. Risk-awareness is enabled by a validation set, where the\nbase station eliminates non-trustworthy clients at the fine-tuning stage. The\nproposed scheme is benchmarked against a conservative scheme (i.e., only\nallowing trustworthy devices) and an aggressive scheme (i.e., oblivious to the\ntrust metric). The numerical results highlight the superiority of the proposed\nscheme in terms of accuracy and convergence speed when compared to both\nbenchmarks.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.0927", "title": "Exact Real Search: Formalised Optimisation and Regression in\n  Constructive Univalent Mathematics", "abstract": "The real numbers are important in both mathematics and computation theory.\nComputationally, real numbers can be represented in several ways; most commonly\nusing inexact floating-point data-types, but also using exact\narbitrary-precision data-types which satisfy the expected mathematical\nproperties of the reals. This thesis is concerned with formalising properties\nof certain types for exact real arithmetic, as well as utilising them\ncomputationally for the purposes of search, optimisation and regression.\n  We develop, in a constructive and univalent type-theoretic foundation of\nmathematics, a formalised framework for performing search, optimisation and\nregression on a wide class of types. This framework utilises Mart\\'in\nEscard\\'o's prior work on searchable types, along with a convenient version of\nultrametric spaces -- which we call closeness spaces -- in order to\nconsistently search certain infinite types using the functional programming\nlanguage and proof assistant Agda.\n  We formally define and prove the convergence properties of type-theoretic\nvariants of global optimisation and parametric regression, problems related to\nsearch from the literature of analysis. As we work in a constructive setting,\nthese convergence theorems yield computational algorithms for correct\noptimisation and regression on the types of our framework.\n  Importantly, we can instantiate our framework on data-types from the\nliterature of exact real arithmetic, allowing us to perform our variants of\nsearch, optimisation and regression on ternary signed-digit encodings of the\nreal numbers, as well as a simplified version of Hans-J. Boehm's functional\nencodings of real numbers. Furthermore, we contribute to the extensive work on\nternary signed-digits by formally verifying the definition of certain exact\nreal arithmetic operations using the Escard\\'o-Simpson interval object\nspecification of compact intervals.", "field": "Computer Science", "categories": "cs.LO"}, {"arxiv_id": "2401.09271", "title": "PixelDINO: Semi-Supervised Semantic Segmentation for Detecting\n  Permafrost Disturbances", "abstract": "Arctic Permafrost is facing significant changes due to global climate change.\nAs these regions are largely inaccessible, remote sensing plays a crucial rule\nin better understanding the underlying processes not just on a local scale, but\nacross the Arctic. In this study, we focus on the remote detection of\nretrogressive thaw slumps (RTS), a permafrost disturbance comparable to\nlandslides induced by thawing. For such analyses from space, deep learning has\nbecome an indispensable tool, but limited labelled training data remains a\nchallenge for training accurate models. To improve model generalization across\nthe Arctic without the need for additional labelled data, we present a\nsemi-supervised learning approach to train semantic segmentation models to\ndetect RTS. Our framework called PixelDINO is trained in parallel on labelled\ndata as well as unlabelled data. For the unlabelled data, the model segments\nthe imagery into self-taught pseudo-classes and the training procedure ensures\nconsistency of these pseudo-classes across strong augmentations of the input\ndata. Our experimental results demonstrate that PixelDINO can improve model\nperformance both over supervised baseline methods as well as existing\nsemi-supervised semantic segmentation approaches, highlighting its potential\nfor training robust models that generalize well to regions that were not\nincluded in the training data. The project page containing code and other\nmaterials for this study can be found at\n\\url{https://khdlr.github.io/PixelDINO/}.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.09273", "title": "A classification of bisimilarities for general Markov decision processes", "abstract": "We provide a fine classification of bisimilarities between states of possibly\ndifferent labelled Markov processes (LMP). We show that a bisimilarity relation\nproposed by Panangaden that uses direct sums coincides with \"event\nbisimilarity\" from his joint work with Danos, Desharnais, and Laviolette. We\nalso extend Giorgio Bacci's notions of bisimilarity between two different\nprocesses to the case of nondeterministic LMP and generalize the game\ncharacterization of state bisimilarity by Clerc et al. for the latter.", "field": "Computer Science", "categories": "cs.LO,math.LO,68Q85 (Primary), 60Jxx, 03E15, 28A05 (Secondary),F.4.1"}, {"arxiv_id": "2401.09275", "title": "Hot Fixing Software: A Comprehensive Review of Terminology, Techniques,\n  and Applications", "abstract": "A hot fix is an improvement to a specific time-critical issue deployed to a\nsoftware system in production. While hot fixing is an essential and common\nactivity in software maintenance, it has never been surveyed as a research\nactivity. Thus, such a review is long overdue. In this paper, we conduct a\ncomprehensive literature review of work on hot fixing. We highlight the fields\nwhere this topic has been addressed, inconsistencies we identified in the\nterminology, gaps in the literature, and directions for future work. Our search\nconcluded with 91 papers on the topic between the year 2000 and 2022. The\npapers found encompass many different research areas such as log analysis,\nruntime patching (also known as hot patching), and automated repair, as well as\nvarious application domains such as security, mobile, and video games. We find\nthat there are many directions that can take hot fix research forward such as\nunifying existing terminology, establishing a benchmark set of hot fixes,\nresearching costs and frequency of hot fixes, and researching the possibility\nof end-to-end automation of detection, mitigation, and propagation. We discuss\nthese avenues in detail to inspire the community to systematize hot fixing as a\nsoftware engineering activity. We hope that this paper streamlines the existing\nbody of work and drives research in the area forward.", "field": "Computer Science", "categories": "cs.SE"}, {"arxiv_id": "2401.09278", "title": "Adaptive Regret for Bandits Made Possible: Two Queries Suffice", "abstract": "Fast changing states or volatile environments pose a significant challenge to\nonline optimization, which needs to perform rapid adaptation under limited\nobservation. In this paper, we give query and regret optimal bandit algorithms\nunder the strict notion of strongly adaptive regret, which measures the maximum\nregret over any contiguous interval $I$. Due to its worst-case nature, there is\nan almost-linear $\\Omega(|I|^{1-\\epsilon})$ regret lower bound, when only one\nquery per round is allowed [Daniely el al, ICML 2015]. Surprisingly, with just\ntwo queries per round, we give Strongly Adaptive Bandit Learner (StABL) that\nachieves $\\tilde{O}(\\sqrt{n|I|})$ adaptive regret for multi-armed bandits with\n$n$ arms. The bound is tight and cannot be improved in general. Our algorithm\nleverages a multiplicative update scheme of varying stepsizes and a carefully\nchosen observation distribution to control the variance. Furthermore, we extend\nour results and provide optimal algorithms in the bandit convex optimization\nsetting. Finally, we empirically demonstrate the superior performance of our\nalgorithms under volatile environments and for downstream tasks, such as\nalgorithm selection for hyperparameter optimization.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.09281", "title": "PIM-STM: Software Transactional Memory for Processing-In-Memory Systems", "abstract": "Processing-In-Memory (PIM) is a novel approach that augments existing DRAM\nmemory chips with lightweight logic. By allowing to offload computations to the\nPIM system, this architecture allows for circumventing the data-bottleneck\nproblem that affects many modern workloads. This work tackles the problem of\nhow to build efficient software implementations of the Transactional Memory\n(TM) abstraction by introducing PIM-STM, a library that provides a range of\ndiverse TM implementations for UPMEM, the first commercial PIM system. Via an\nextensive study we assess the efficiency of alternative choices in the design\nspace of TM algorithms on this emerging architecture. We further quantify the\nimpact of using different memory tiers of the UPMEM system (having different\ntrade-offs for what concerns latency vs capacity) to store the metadata used by\ndifferent TM implementations. Finally, we assess the gains achievable in terms\nof performance and memory efficiency when using PIM-STM to accelerate TM\napplications originally conceived for conventional CPU-based systems.", "field": "Computer Science", "categories": "cs.DC,B.3.3; B.8.2; C.4; D.1.3"}, {"arxiv_id": "2401.09284", "title": "A Fast Control Plane for a Large-Scale and High-Speed Optical Circuit\n  Switch System", "abstract": "We experimentally verify a fast control plane with 100 microseconds of\nconfiguration time that can support more than 1000 racks, leveraged by a\nsoftware-defined network controller and an industrial real-time Ethernet\nstandard EtherCAT.", "field": "Computer Science", "categories": "cs.NI"}, {"arxiv_id": "2401.09285", "title": "Enhancing Rural Agricultural Value Chains through Electric Mobility\n  Services in Ethiopia", "abstract": "Transportation is a constitutional part of most supply and value chains in\nmodern economies. Smallholder farmers in rural Ethiopia face severe challenges\nalong their supply and value chains. In particular, suitable, affordable, and\navailable transport services are in high demand. To develop context-specific\ntechnical solutions, a problem-to-solution methodology based on the interaction\nwith technology is developed. With this approach, we fill the gap between\nproven transportation assessment frameworks and general user-centered\ntechniques. Central to our approach is an electric test vehicle that is\nimplemented in rural supply and value chains for research, development, and\ntesting. Based on our objective and the derived methodological requirements, a\nset of existing methods is selected. Local partners are integrated in an\norganizational framework that executes major parts of this research endeavour\nin Arsi Zone, Oromia Region, Ethiopia.", "field": "Computer Science", "categories": "cs.SE"}, {"arxiv_id": "2401.09286", "title": "Deployable Reinforcement Learning with Variable Control Rate", "abstract": "Deploying controllers trained with Reinforcement Learning (RL) on real robots\ncan be challenging: RL relies on agents' policies being modeled as Markov\nDecision Processes (MDPs), which assume an inherently discrete passage of time.\nThe use of MDPs results in that nearly all RL-based control systems employ a\nfixed-rate control strategy with a period (or time step) typically chosen based\non the developer's experience or specific characteristics of the application\nenvironment. Unfortunately, the system should be controlled at the highest,\nworst-case frequency to ensure stability, which can demand significant\ncomputational and energy resources and hinder the deployability of the\ncontroller on onboard hardware. Adhering to the principles of reactive\nprogramming, we surmise that applying control actions only when necessary\nenables the use of simpler hardware and helps reduce energy consumption. We\nchallenge the fixed frequency assumption by proposing a variant of RL with\nvariable control rate. In this approach, the policy decides the action the\nagent should take as well as the duration of the time step associated with that\naction. In our new setting, we expand Soft Actor-Critic (SAC) to compute the\noptimal policy with a variable control rate, introducing the Soft Elastic\nActor-Critic (SEAC) algorithm. We show the efficacy of SEAC through a\nproof-of-concept simulation driving an agent with Newtonian kinematics. Our\nexperiments show higher average returns, shorter task completion times, and\nreduced computational resources when compared to fixed rate policies.", "field": "Computer Science", "categories": "cs.RO,cs.AI"}, {"arxiv_id": "2401.09289", "title": "Same Data, Diverging Perspectives: The Power of Visualizations to Elicit\n  Competing Interpretations", "abstract": "People routinely rely on data to make decisions, but the process can be\nriddled with biases. We show that patterns in data might be noticed first or\nmore strongly, depending on how the data is visually represented or what the\nviewer finds salient. We also demonstrate that viewer interpretation of data is\nsimilar to that of 'ambiguous figures' such that two people looking at the same\ndata can come to different decisions. In our studies, participants read\nvisualizations depicting competitions between two entities, where one has a\nhistorical lead (A) but the other has been gaining momentum (B) and predicted a\nwinner, across two chart types and three annotation approaches. They either saw\nthe historical lead as salient and predicted that A would win, or saw the\nincreasing momentum as salient and predicted B to win. These results suggest\nthat decisions can be influenced by both how data are presented and what\npatterns people find visually salient.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.0929", "title": "G-Safe: Safe GPU Sharing in Multi-Tenant Environments", "abstract": "Modern GPU applications, such as machine learning (ML) frameworks, can only\npartially utilize beefy GPUs, leading to GPU underutilization in cloud\nenvironments. Sharing GPUs across multiple applications from different users\ncan improve resource utilization and consequently cost, energy, and power\nefficiency. However, GPU sharing creates memory safety concerns because kernels\nmust share a single GPU address space (GPU context). Previous GPU memory\nprotection approaches have limited deployability because they require\nspecialized hardware extensions or access to source code. This is often\nunavailable in GPU-accelerated libraries heavily utilized by ML frameworks. In\nthis paper, we present G-Safe, a PTX-level bounds checking approach for GPUs\nthat limits GPU kernels of each application to stay within the memory partition\nallocated to them. G-Safe relies on three mechanisms: (1) It divides the common\nGPU address space into separate partitions for different applications. (2) It\nintercepts and checks data transfers, fencing erroneous operations. (3) It\ninstruments all GPU kernels at the PTX level (available in closed GPU\nlibraries) fencing all kernel memory accesses outside application memory\nbounds. We implement G-Safe as an external, dynamically linked library that can\nbe pre-loaded at application startup time. G-Safe's approach is transparent to\napplications and can support real-life, complex frameworks, such as Caffe and\nPyTorch, that issue billions of GPU kernels. Our evaluation shows that the\noverhead of G-Safe compared to native (unprotected) for such frameworks is\nbetween 4\\% - 12\\% and on average 9\\%.", "field": "Computer Science", "categories": "cs.DC"}, {"arxiv_id": "2401.09292", "title": "Hierarchical Analyses Applied to Computer System Performance: Review and\n  Call for Further Studies", "abstract": "We review studies based on analytic and simulation methods for hierarchical\nperformance analysis of Queueing Network - QN models, which result in an order\nof magnitude reduction in performance evaluation cost with respect to\nsimulation. The computational cost at the lower level is reduced when the\ncomputer system is modeled as a product-form QN. A Continuous Time Markov Chain\n- CTMC or discrete-event simulation can then be used at the higher level. We\nfirst consider a multiprogrammed transaction - txn processing system with\nPoisson arrivals and predeclared locks requests. Txn throughputs obtained by\nthe analysis of multiprogrammed computer systems serve as the transition rates\nin a higher level CTMC to determine txn response times. We next analyze a task\nsystem where task precedence relationships are specified by a directed acyclic\ngraph to determine its makespan. Task service demands are specified on the\ndevices of a computer system. The composition of tasks in execution determines\ntxn throughputs, which serve as transition rates among the states of the higher\nlevel CTMC model. As a third example we consider the hierarchical simulation of\na timesharing system with two user classes. Txn throughputs in processing\nvarious combinations of requests are obtained by analyzing a closed\nproduct-form QN model. A discrete event simulator is provided. More detailed QN\nmodeling parameters, such as the distribution of the number of cycles in\ncentral server model - CSM affects the performance of a fork/join queueing\nsystem. This detail can be taken into account in Schwetman's hybrid simulation\nmethod, which counts remaining cycles in CSM. We propose an extension to hybrid\nsimulation to adjust job service demands according to elapsed time, rather than\ncounting cycles. An example where Equilibrium Point Analysis to reduce\ncomputaional cost is privided.", "field": "Computer Science", "categories": "cs.PF"}, {"arxiv_id": "2401.09294", "title": "T-FOLEY: A Controllable Waveform-Domain Diffusion Model for\n  Temporal-Event-Guided Foley Sound Synthesis", "abstract": "Foley sound, audio content inserted synchronously with videos, plays a\ncritical role in the user experience of multimedia content. Recently, there has\nbeen active research in Foley sound synthesis, leveraging the advancements in\ndeep generative models. However, such works mainly focus on replicating a\nsingle sound class or a textual sound description, neglecting temporal\ninformation, which is crucial in the practical applications of Foley sound. We\npresent T-Foley, a Temporal-event-guided waveform generation model for Foley\nsound synthesis. T-Foley generates high-quality audio using two conditions: the\nsound class and temporal event feature. For temporal conditioning, we devise a\ntemporal event feature and a novel conditioning technique named Block-FiLM.\nT-Foley achieves superior performance in both objective and subjective\nevaluation metrics and generates Foley sound well-synchronized with the\ntemporal events. Additionally, we showcase T-Foley's practical applications,\nparticularly in scenarios involving vocal mimicry for temporal event control.\nWe show the demo on our companion website.", "field": "Computer Science", "categories": "cs.SD,cs.AI,cs.LG,eess.AS,eess.SP"}, {"arxiv_id": "2401.09296", "title": "Tight Fusion of Events and Inertial Measurements for Direct Velocity\n  Estimation", "abstract": "Traditional visual-inertial state estimation targets absolute camera poses\nand spatial landmark locations while first-order kinematics are typically\nresolved as an implicitly estimated sub-state. However, this poses a risk in\nvelocity-based control scenarios, as the quality of the estimation of\nkinematics depends on the stability of absolute camera and landmark coordinates\nestimation. To address this issue, we propose a novel solution to tight\nvisual-inertial fusion directly at the level of first-order kinematics by\nemploying a dynamic vision sensor instead of a normal camera. More\nspecifically, we leverage trifocal tensor geometry to establish an incidence\nrelation that directly depends on events and camera velocity, and demonstrate\nhow velocity estimates in highly dynamic situations can be obtained over short\ntime intervals. Noise and outliers are dealt with using a nested two-layer\nRANSAC scheme. Additionally, smooth velocity signals are obtained from a tight\nfusion with pre-integrated inertial signals using a sliding window optimizer.\nExperiments on both simulated and real data demonstrate that the proposed tight\nevent-inertial fusion leads to continuous and reliable velocity estimation in\nhighly dynamic scenarios independently of absolute coordinates. Furthermore, in\nextreme cases, it achieves more stable and more accurate estimation of\nkinematics than traditional, point-position-based visual-inertial odometry.", "field": "Computer Science", "categories": "cs.CV,cs.RO"}, {"arxiv_id": "2401.09321", "title": "The landscape of Collective Awareness in multi-robot systems", "abstract": "The development of collective-aware multi-robot systems is crucial for\nenhancing the efficiency and robustness of robotic applications in multiple\nfields. These systems enable collaboration, coordination, and resource sharing\namong robots, leading to improved scalability, adaptability to dynamic\nenvironments, and increased overall system robustness. In this work, we want to\nprovide a brief overview of this research topic and identify open challenges.", "field": "Computer Science", "categories": "cs.RO"}, {"arxiv_id": "2401.09322", "title": "FIT-SLAM -- Fisher Information and Traversability estimation-based\n  Active SLAM for exploration in 3D environments", "abstract": "Active visual SLAM finds a wide array of applications in GNSS-Denied\nsub-terrain environments and outdoor environments for ground robots. To achieve\nrobust localization and mapping accuracy, it is imperative to incorporate the\nperception considerations in the goal selection and path planning towards the\ngoal during an exploration mission. Through this work, we propose FIT-SLAM\n(Fisher Information and Traversability estimation-based Active SLAM), a new\nexploration method tailored for unmanned ground vehicles (UGVs) to explore 3D\nenvironments. This approach is devised with the dual objectives of sustaining\nan efficient exploration rate while optimizing SLAM accuracy. Initially, an\nestimation of a global traversability map is conducted, which accounts for the\nenvironmental constraints pertaining to traversability. Subsequently, we\npropose a goal candidate selection approach along with a path planning method\ntowards this goal that takes into account the information provided by the\nlandmarks used by the SLAM backend to achieve robust localization and\nsuccessful path execution . The entire algorithm is tested and evaluated first\nin a simulated 3D world, followed by a real-world environment and is compared\nto pre-existing exploration methods. The results obtained during this\nevaluation demonstrate a significant increase in the exploration rate while\neffectively minimizing the localization covariance.", "field": "Computer Science", "categories": "cs.RO,cs.AI"}, {"arxiv_id": "2401.09323", "title": "BENO: Boundary-embedded Neural Operators for Elliptic PDEs", "abstract": "Elliptic partial differential equations (PDEs) are a major class of\ntime-independent PDEs that play a key role in many scientific and engineering\ndomains such as fluid dynamics, plasma physics, and solid mechanics. Recently,\nneural operators have emerged as a promising technique to solve elliptic PDEs\nmore efficiently by directly mapping the input to solutions. However, existing\nnetworks typically cannot handle complex geometries and inhomogeneous boundary\nvalues present in the real world. Here we introduce Boundary-Embedded Neural\nOperators (BENO), a novel neural operator architecture that embeds the complex\ngeometries and inhomogeneous boundary values into the solving of elliptic PDEs.\nInspired by classical Green's function, BENO consists of two branches of Graph\nNeural Networks (GNNs) for interior source term and boundary values,\nrespectively. Furthermore, a Transformer encoder maps the global boundary\ngeometry into a latent vector which influences each message passing layer of\nthe GNNs. We test our model extensively in elliptic PDEs with various boundary\nconditions. We show that all existing baseline methods fail to learn the\nsolution operator. In contrast, our model, endowed with boundary-embedded\narchitecture, outperforms state-of-the-art neural operators and strong\nbaselines by an average of 60.96\\%. Our source code can be found\nhttps://github.com/AI4Science-WestlakeU/beno.git.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.09324", "title": "Establishing Awareness through Pointing Gestures during Collaborative\n  Decision-Making in a Wall-Display Environment", "abstract": "Sharing a physical environment, such as that of a wall-display, facilitates\ngaining awareness of others' actions and intentions, thereby bringing benefits\nfor collaboration. Previous studies have provided first insights on awareness\nin the context of tabletops or smaller vertical displays. This paper seeks to\nadvance the current understanding on how users share awareness information in\nwall-display environments and focusses on mid-air pointing gestures as a\nfoundational part of communication. We present a scenario dealing with the\norganization of medical supply chains in crisis situations, and report on the\nresults of a user study with 24 users, split into 6 groups of 4, performing\nseveral tasks. We investigate pointing gestures and identify three subtypes\nused as awareness cues during face-to-face collaboration: narrative pointing,\nloose pointing, and sharp pointing. Our observations show that reliance on\ngesture subtypes varies across participants and groups, and that sometimes\nvague pointing is sufficient to support verbal negotiations.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.09325", "title": "Siamese Meets Diffusion Network: SMDNet for Enhanced Change Detection in\n  High-Resolution RS Imagery", "abstract": "Recently, the application of deep learning to change detection (CD) has\nsignificantly progressed in remote sensing images. In recent years, CD tasks\nhave mostly used architectures such as CNN and Transformer to identify these\nchanges. However, these architectures have shortcomings in representing\nboundary details and are prone to false alarms and missed detections under\ncomplex lighting and weather conditions. For that, we propose a new network,\nSiamese Meets Diffusion Network (SMDNet). This network combines the Siam-U2Net\nFeature Differential Encoder (SU-FDE) and the denoising diffusion implicit\nmodel to improve the accuracy of image edge change detection and enhance the\nmodel's robustness under environmental changes. First, we propose an innovative\nSU-FDE module that utilizes shared weight features to capture differences\nbetween time series images and identify similarities between features to\nenhance edge detail detection. Furthermore, we add an attention mechanism to\nidentify key coarse features to improve the model's sensitivity and accuracy.\nFinally, the diffusion model of progressive sampling is used to fuse key coarse\nfeatures, and the noise reduction ability of the diffusion model and the\nadvantages of capturing the probability distribution of image data are used to\nenhance the adaptability of the model in different environments. Our method's\ncombination of feature extraction and diffusion models demonstrates\neffectiveness in change detection in remote sensing images. The performance\nevaluation of SMDNet on LEVIR-CD, DSIFN-CD, and CDD datasets yields validated\nF1 scores of 90.99%, 88.40%, and 88.47%, respectively. This substantiates the\nadvanced capabilities of our model in accurately identifying variations and\nintricate details.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.09328", "title": "Online Stability Improvement of Groebner Basis Solvers using Deep\n  Learning", "abstract": "Over the past decade, the Gr\\\"obner basis theory and automatic solver\ngeneration have lead to a large number of solutions to geometric vision\nproblems. In practically all cases, the derived solvers apply a fixed\nelimination template to calculate the Gr\\\"obner basis and thereby identify the\nzero-dimensional variety of the original polynomial constraints. However, it is\nclear that different variable or monomial orderings lead to different\nelimination templates, and we show that they may present a large variability in\naccuracy for a certain instance of a problem. The present paper has two\ncontributions. We first show that for a common class of problems in geometric\nvision, variable reordering simply translates into a permutation of the columns\nof the initial coefficient matrix, and that -- as a result -- one and the same\nelimination template can be reused in different ways, each one leading to\npotentially different accuracy. We then prove that the original set of\ncoefficients may contain sufficient information to train a classifier for\nonline selection of a good solver, most notably at the cost of only a small\ncomputational overhead. We demonstrate wide applicability at the hand of\ngeneric dense polynomial problem solvers, as well as a concrete solver from\ngeometric vision.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.09329", "title": "Calibrate-Extrapolate: Rethinking Prevalence Estimation with Black Box\n  Classifiers", "abstract": "In computational social science, researchers often use a pre-trained, black\nbox classifier to estimate the frequency of each class in unlabeled datasets. A\nvariety of prevalence estimation techniques have been developed in the\nliterature, each yielding an unbiased estimate if certain stability assumption\nholds. This work introduces a framework to rethink the prevalence estimation\nprocess as calibrating the classifier outputs against ground truth labels to\nobtain the joint distribution of a base dataset and then extrapolating to the\njoint distribution of a target dataset. We call this framework\n\"Calibrate-Extrapolate\". Visualizing the joint distribution makes the stability\nassumption needed for a prevalence estimation technique clear and easy to\nunderstand. In the calibration phase, the techniques assume only a stable\ncalibration curve between a calibration dataset and the full base dataset. This\nallows for the classifier outputs to be used for purposive sampling, thus\nimproving the efficiency of calibration. In the extrapolation phase, some\ntechniques assume a stable calibration curve while some assume stable\nclass-conditional densities. We discuss the stability assumptions from a causal\nperspective. By specifying base and target joint distributions, we can generate\nsimulated datasets, as a way to build intuitions about the impacts of\nassumption violations. This also leads to a better understanding of how the\nclassifier predictive power affects the accuracy of prevalence estimates: the\ngreater the predictive power, the lower the sensitivity to violations of\nstability assumptions in the extrapolation phase. We illustrate the framework\nwith an application that estimates the prevalence of toxic news comments over\ntime on Reddit, Twitter, and YouTube, using Jigsaw's Perspective API as a black\nbox classifier.", "field": "Computer Science", "categories": "cs.SI"}, {"arxiv_id": "2401.09331", "title": "Event-Based Visual Odometry on Non-Holonomic Ground Vehicles", "abstract": "Despite the promise of superior performance under challenging conditions,\nevent-based motion estimation remains a hard problem owing to the difficulty of\nextracting and tracking stable features from event streams. In order to\nrobustify the estimation, it is generally believed that fusion with other\nsensors is a requirement. In this work, we demonstrate reliable, purely\nevent-based visual odometry on planar ground vehicles by employing the\nconstrained non-holonomic motion model of Ackermann steering platforms. We\nextend single feature n-linearities for regular frame-based cameras to the case\nof quasi time-continuous event-tracks, and achieve a polynomial form via\nvariable degree Taylor expansions. Robust averaging over multiple event tracks\nis simply achieved via histogram voting. As demonstrated on both simulated and\nreal data, our algorithm achieves accurate and robust estimates of the\nvehicle's instantaneous rotational velocity, and thus results that are\ncomparable to the delta rotations obtained by frame-based sensors under normal\nconditions. We furthermore significantly outperform the more traditional\nalternatives in challenging illumination scenarios. The code is available at\n\\url{https://github.com/gowanting/NHEVO}.", "field": "Computer Science", "categories": "cs.CV,cs.RO"}, {"arxiv_id": "2401.09332", "title": "Vision-driven Autonomous Flight of UAV Along River Using Deep\n  Reinforcement Learning with Dynamic Expert Guidance", "abstract": "Vision-driven autonomous flight and obstacle avoidance of Unmanned Aerial\nVehicles (UAVs) along complex riverine environments for tasks like rescue and\nsurveillance requires a robust control policy, which is yet difficult to obtain\ndue to the shortage of trainable river environment simulators and reward\nsparsity in such environments. To easily verify the navigation controller\nperformance for the river following task before real-world deployment, we\ndeveloped a trainable photo-realistic dynamics-free riverine simulation\nenvironment using Unity. Successful river following trajectories in the\nenvironment are manually collected and Behavior Clone (BC) is used to train an\nImitation Learning (IL) agent to mimic expert behavior and generate expert\nguidance. Finally, a framework is proposed to train a Deep Reinforcement\nLearning (DRL) agent using BC expert guidance and improve the expert policy\nonline by sampling good demonstrations produced by the DRL to increase\nconvergence rate and policy performance. This framework is able to solve the\nalong-river autonomous navigation task and outperform baseline RL and IL\nmethods. The code and trainable environments are available.", "field": "Computer Science", "categories": "cs.RO"}, {"arxiv_id": "2401.09333", "title": "Machines Do See Color: A Guideline to Classify Different Forms of Racist\n  Discourse in Large Corpora", "abstract": "Current methods to identify and classify racist language in text rely on\nsmall-n qualitative approaches or large-n approaches focusing exclusively on\novert forms of racist discourse. This article provides a step-by-step\ngeneralizable guideline to identify and classify different forms of racist\ndiscourse in large corpora. In our approach, we start by conceptualizing racism\nand its different manifestations. We then contextualize these racist\nmanifestations to the time and place of interest, which allows researchers to\nidentify their discursive form. Finally, we apply XLM-RoBERTa (XLM-R), a\ncross-lingual model for supervised text classification with a cutting-edge\ncontextual understanding of text. We show that XLM-R and XLM-R-Racismo, our\npretrained model, outperform other state-of-the-art approaches in classifying\nracism in large corpora. We illustrate our approach using a corpus of tweets\nrelating to the Ecuadorian ind\\'igena community between 2018 and 2021.", "field": "Computer Science", "categories": "cs.CL,cs.LG"}, {"arxiv_id": "2401.09334", "title": "Large Language Models Are Neurosymbolic Reasoners", "abstract": "A wide range of real-world applications is characterized by their symbolic\nnature, necessitating a strong capability for symbolic reasoning. This paper\ninvestigates the potential application of Large Language Models (LLMs) as\nsymbolic reasoners. We focus on text-based games, significant benchmarks for\nagents with natural language capabilities, particularly in symbolic tasks like\nmath, map reading, sorting, and applying common sense in text-based worlds. To\nfacilitate these agents, we propose an LLM agent designed to tackle symbolic\nchallenges and achieve in-game objectives. We begin by initializing the LLM\nagent and informing it of its role. The agent then receives observations and a\nset of valid actions from the text-based games, along with a specific symbolic\nmodule. With these inputs, the LLM agent chooses an action and interacts with\nthe game environments. Our experimental results demonstrate that our method\nsignificantly enhances the capability of LLMs as automated agents for symbolic\nreasoning, and our LLM agent is effective in text-based games involving\nsymbolic tasks, achieving an average performance of 88% across all tasks.", "field": "Computer Science", "categories": "cs.CL,cs.AI"}, {"arxiv_id": "2401.0934", "title": "SceneVerse: Scaling 3D Vision-Language Learning for Grounded Scene\n  Understanding", "abstract": "3D vision-language grounding, which focuses on aligning language with the 3D\nphysical environment, stands as a cornerstone in the development of embodied\nagents. In comparison to recent advancements in the 2D domain, grounding\nlanguage in 3D scenes faces several significant challenges: (i) the inherent\ncomplexity of 3D scenes due to the diverse object configurations, their rich\nattributes, and intricate relationships; (ii) the scarcity of paired 3D\nvision-language data to support grounded learning; and (iii) the absence of a\nunified learning framework to distill knowledge from grounded 3D data. In this\nwork, we aim to address these three major challenges in 3D vision-language by\nexamining the potential of systematically upscaling 3D vision-language learning\nin indoor environments. We introduce the first million-scale 3D vision-language\ndataset, SceneVerse, encompassing about 68K 3D indoor scenes and comprising\n2.5M vision-language pairs derived from both human annotations and our scalable\nscene-graph-based generation approach. We demonstrate that this scaling allows\nfor a unified pre-training framework, Grounded Pre-training for Scenes (GPS),\nfor 3D vision-language learning. Through extensive experiments, we showcase the\neffectiveness of GPS by achieving state-of-the-art performance on all existing\n3D visual grounding benchmarks. The vast potential of SceneVerse and GPS is\nunveiled through zero-shot transfer experiments in the challenging 3D\nvision-language tasks. Project website: https://scene-verse.github.io .", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.CL,cs.LG,cs.RO"}, {"arxiv_id": "2401.09343", "title": "Efficient slot labelling", "abstract": "Slot labelling is an essential component of any dialogue system, aiming to\nfind important arguments in every user turn. Common approaches involve large\npre-trained language models (PLMs) like BERT or RoBERTa, but they face\nchallenges such as high computational requirements and dependence on\npre-training data. In this work, we propose a lightweight method which performs\non par or better than the state-of-the-art PLM-based methods, while having\nalmost 10x less trainable parameters. This makes it especially applicable for\nreal-life industry scenarios.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.09348", "title": "On the discrete equivalence of Lagrangian, Hamiltonian and mixed finite\n  element formulations for linear wave phenomena", "abstract": "It is well known that the Lagrangian and Hamiltonian descriptions of field\ntheories are equivalent at the discrete time level when variational integrators\nare used. Besides the symplectic Hamiltonian structure, many physical systems\nexhibit a Hamiltonian structure when written in mixed form. In this\ncontribution, the discrete equivalence of Lagrangian, symplectic Hamiltonian\nand mixed formulations is investigated for linear wave propagation phenomena.\nUnder compatibility conditions between the finite elements, the Lagrangian and\nmixed formulations are indeed equivalent. For the time discretization the\nleapfrog scheme and the implicit midpoint rule are considered. In mixed methods\napplied to wave problems the primal variable (e.g. the displacement in\nmechanics or the magnetic potential in electromagnetism) is not an unknown of\nthe problem and is reconstructed a posteriori from its time derivative. When\nthis reconstruction is performed via the trapezoidal rule, then these\ntime-discretization methods lead to equivalent formulations.", "field": "Computer Science", "categories": "math.NA,cs.NA"}, {"arxiv_id": "2401.0935", "title": "Foundations of Vector Retrieval", "abstract": "Vectors are universal mathematical objects that can represent text, images,\nspeech, or a mix of these data modalities. That happens regardless of whether\ndata is represented by hand-crafted features or learnt embeddings. Collect a\nlarge enough quantity of such vectors and the question of retrieval becomes\nurgently relevant: Finding vectors that are more similar to a query vector.\nThis monograph is concerned with the question above and covers fundamental\nconcepts along with advanced data structures and algorithms for vector\nretrieval. In doing so, it recaps this fascinating topic and lowers barriers of\nentry into this rich area of research.", "field": "Computer Science", "categories": "cs.DS,cs.IR"}, {"arxiv_id": "2401.09352", "title": "Neural Contractive Dynamical Systems", "abstract": "Stability guarantees are crucial when ensuring a fully autonomous robot does\nnot take undesirable or potentially harmful actions. Unfortunately, global\nstability guarantees are hard to provide in dynamical systems learned from\ndata, especially when the learned dynamics are governed by neural networks. We\npropose a novel methodology to learn neural contractive dynamical systems,\nwhere our neural architecture ensures contraction, and hence, global stability.\nTo efficiently scale the method to high-dimensional dynamical systems, we\ndevelop a variant of the variational autoencoder that learns dynamics in a\nlow-dimensional latent representation space while retaining contractive\nstability after decoding. We further extend our approach to learning\ncontractive systems on the Lie group of rotations to account for full-pose\nend-effector dynamic motions. The result is the first highly flexible learning\narchitecture that provides contractive stability guarantees with capability to\nperform obstacle avoidance. Empirically, we demonstrate that our approach\nencodes the desired dynamics more accurately than the current state-of-the-art,\nwhich provides less strong stability guarantees.", "field": "Computer Science", "categories": "cs.RO,cs.AI,cs.LG"}, {"arxiv_id": "2401.09356", "title": "Swing: Short-cutting Rings for Higher Bandwidth Allreduce", "abstract": "The allreduce collective operation accounts for a significant fraction of the\nruntime of workloads running on distributed systems. One factor determining its\nperformance is the distance between communicating nodes, especially on networks\nlike torus, where a higher distance implies multiple messages being forwarded\non the same link, thus reducing the allreduce bandwidth. Torus networks are\nwidely used on systems optimized for machine learning workloads (e.g., Google\nTPUs and Amazon Trainium devices), as well as on some of the Top500\nsupercomputers. To improve allreduce performance on torus networks we introduce\nSwing, a new algorithm that keeps a low distance between communicating nodes by\nswinging between torus directions. Our analysis and experimental evaluation\nshow that Swing outperforms by up to 3x existing allreduce algorithms for\nvectors ranging from 32B to 128MiB, on different types of torus and torus-like\ntopologies, regardless of their shape and size.", "field": "Computer Science", "categories": "cs.DC,cs.LG,cs.NI,cs.PF,C.2.4; C.2.2"}, {"arxiv_id": "2401.09358", "title": "Detection of Distributed Denial of Service Attacks Carried Out by\n  Botnets in Software-Defined Networks", "abstract": "Recent years witnessed a surge in network traffic due to the emergence of new\nonline services, causing periodic saturation and complexity problems.\nAdditionally, the growing number of IoT devices further compounds the problem.\nSoftware Defined Network (SDN) is a new architecture which offers innovative\nadvantages that help to reduce saturation problems. Despite its benefits, SDNs\nnot only can be affected by traditional attacks but also introduce new security\nchallenges. In this context, Distributed Denial of Service (DDoS) is one of the\nmost important attacks that can damage an SDN network's normal operation.\nFurthermore, if these attacks are executed using botnets, they can use\nthousands of compromised devices to disrupt critical online services. This\npaper proposes a framework for detecting DDoS attacks generated by a group of\nbotnets in an SDN network. The framework is implemented using open-source tools\nsuch as Mininet and OpenDaylight and tested in a centralized network topology\nusing BYOB and SNORT. The results demonstrate real-time attack identification\nby implementing an intrusion detection mechanism in the victim client. Our\nproposed solution offers quick and effective detection of DDoS attacks in SDN\nnetworks. The framework can successfully differentiate the type of attack with\nhigh accuracy in a short time", "field": "Computer Science", "categories": "cs.NI"}, {"arxiv_id": "2401.09359", "title": "LRSCwait: Enabling Scalable and Efficient Synchronization in Manycore\n  Systems through Polling-Free and Retry-Free Operation", "abstract": "Extensive polling in shared-memory manycore systems can lead to contention,\ndecreased throughput, and poor energy efficiency. Both lock implementations and\nthe general-purpose atomic operation, load-reserved/store-conditional (LRSC),\ncause polling due to serialization and retries. To alleviate this overhead, we\npropose LRwait and SCwait, a synchronization pair that eliminates polling by\nallowing contending cores to sleep while waiting for previous cores to finish\ntheir atomic access. As a scalable implementation of LRwait, we present\nColibri, a distributed and scalable approach to managing LRwait reservations.\nThrough extensive benchmarking on an open-source RISC-V platform with 256\ncores, we demonstrate that Colibri outperforms current synchronization\napproaches for various concurrent algorithms with high and low contention\nregarding throughput, fairness, and energy efficiency. With an area overhead of\nonly 6%, Colibri outperforms LRSC-based implementations by a factor of 6.5x in\nterms of throughput and 7.1x in terms of energy efficiency.", "field": "Computer Science", "categories": "cs.AR"}, {"arxiv_id": "2401.09366", "title": "An Introduction to Different Approaches to Initial Semantics", "abstract": "Characterizing programming languages with variable binding as initial\nobjects, was first achieved by Fiore, Plotkin, and Turi in their seminal paper\npublished at LICS'99. To do so, in particular to prove initiality theorems,\nthey developed a framework based on monoidal categories, functors with\nstrengths, and $\\Sigma$-monoids. An alternative approach using modules over\nmonads was later introduced by Hirschowitz and Maggesi, for endofunctor\ncategories, that is, for particular monoidal categories. This approach has the\nadvantage of providing a more general and abstract definition of signatures and\nmodels; however, no general initiality result is known for this notion of\nsignature. Furthermore, Matthes and Uustalu provided a categorical formalism\nfor constructing (initial) monads via Mendler-style recursion, that can also be\nused for initial semantics. The different approaches have been developed\nfurther in several articles. However, in practice, the literature is difficult\nto access, and links between the different strands of work remain\nunderexplored.\n  In the present work, we give an introduction to initial semantics that\nencompasses the three different strands. We develop a suitable \"pushout\" of\nHirschowitz and Maggesi's framework with Fiore's, and rely on Matthes and\nUustalu's formalism to provide modular proofs. For this purpose, we generalize\nboth Hirschowitz and Maggesi's framework, and Matthes and Uustalu's formalism\nto the general setting of monoidal categories studied by Fiore and\ncollaborators. Moreover, we provide fully worked out presentation of some basic\ninstances of the literature, and an extensive discussion of related work\nexplaining the links between the different approaches.", "field": "Computer Science", "categories": "cs.LO,cs.PL"}, {"arxiv_id": "2401.09372", "title": "Numerical analysis of an evolving bulk--surface model of tumour growth", "abstract": "This paper studies an evolving bulk--surface finite element method for a\nmodel of tissue growth, which is a modification of the model of Eyles, King and\nStyles (2019). The model couples a Poisson equation on the domain with a forced\nmean curvature flow of the free boundary, with nontrivial bulk--surface\ncoupling in both the velocity law of the evolving surface and the boundary\ncondition of the Poisson equation. The numerical method discretizes evolution\nequations for the mean curvature and the outer normal and it uses a harmonic\nextension of the surface velocity into the bulk. The discretization admits a\nconvergence analysis in the case of continuous finite elements of polynomial\ndegree at least two. The stability of the discretized bulk--surface coupling is\na major concern. The error analysis combines stability estimates and\nconsistency estimates to yield optimal-order $H^1$-norm error bounds for the\ncomputed tissue pressure and for the surface position, velocity, normal vector\nand mean curvature. Numerical experiments illustrate and complement the\ntheoretical results.", "field": "Computer Science", "categories": "math.NA,cs.NA"}, {"arxiv_id": "2401.09375", "title": "Self-navigation in crowds: An invariant set-based approach", "abstract": "Self-navigation in non-coordinating crowded environments is formidably\nchallenging within multi-agent systems consisting of non-holonomic robots\noperating through local sensing. Our primary objective is the development of a\nnovel, rapid, sensor-driven, self-navigation controller that directly computes\ncontrol commands to enable safe maneuvering while coexisting with other agents.\nWe propose an input-constrained feedback controller meticulously crafted for\nnon-holonomic mobile robots and the characterization of associated invariant\nsets. The invariant sets are the key to maintaining stability and safety amidst\nthe non-cooperating agents. We then propose a planning strategy that\nstrategically guides the generation of invariant sets toward the agent's\nintended target. This enables the agents to directly compute theoretically safe\ncontrol inputs without explicitly requiring pre-planned paths/trajectories to\nreliably navigate through crowded multi-agent environments. The practicality of\nour technique is demonstrated through hardware experiments, and the ability to\nparallelize computations to shorten computational durations for synthesizing\nsafe control commands. The proposed approach finds potential applications in\ncrowded multi-agent scenarios that require rapid control computations based on\nperceived safety bounds during run-time.", "field": "Computer Science", "categories": "cs.RO"}, {"arxiv_id": "2401.09376", "title": "Unlocking Unlabeled Data: Ensemble Learning with the Hui- Walter\n  Paradigm for Performance Estimation in Online and Static Settings", "abstract": "In the realm of machine learning and statistical modeling, practitioners\noften work under the assumption of accessible, static, labeled data for\nevaluation and training. However, this assumption often deviates from reality\nwhere data may be private, encrypted, difficult- to-measure, or unlabeled. In\nthis paper, we bridge this gap by adapting the Hui-Walter paradigm, a method\ntraditionally applied in epidemiology and medicine, to the field of machine\nlearning. This approach enables us to estimate key performance metrics such as\nfalse positive rate, false negative rate, and priors in scenarios where no\nground truth is available. We further extend this paradigm for handling online\ndata, opening up new possibilities for dynamic data environments. Our\nmethodology involves partitioning data into latent classes to simulate multiple\ndata populations (if natural populations are unavailable) and independently\ntraining models to replicate multiple tests. By cross-tabulating binary\noutcomes across ensemble categorizers and multiple populations, we are able to\nestimate unknown parameters through Gibbs sampling, eliminating the need for\nground-truth or labeled data. This paper showcases the potential of our\nmethodology to transform machine learning practices by allowing for accurate\nmodel assessment under dynamic and uncertain data conditions.", "field": "Computer Science", "categories": "cs.LG,math.ST,stat.ML,stat.TH"}, {"arxiv_id": "2401.09382", "title": "POE: Acoustic Soft Robotic Proprioception for Omnidirectional\n  End-effectors", "abstract": "Soft robotic shape estimation and proprioception are challenging because of\nsoft robot's complex deformation behaviors and infinite degrees of freedom. A\nsoft robot's continuously deforming body makes it difficult to integrate rigid\nsensors and to reliably estimate its shape. In this work, we present\nProprioceptive Omnidirectional End-effector (POE), which has six embedded\nmicrophones across the tendon-driven soft robot's surface. We first introduce\nnovel applications of previously proposed 3D reconstruction methods to acoustic\nsignals from the microphones for soft robot shape proprioception. To improve\nthe proprioception pipeline's training efficiency and model prediction\nconsistency, we present POE-M. POE-M first predicts key point positions from\nthe acoustic signal observations with the embedded microphone array. Then we\nutilize an energy-minimization method to reconstruct a physically admissible\nhigh-resolution mesh of POE given the estimated key points. We evaluate the\nmesh reconstruction module with simulated data and the full POE-M pipeline with\nreal-world experiments. We demonstrate that POE-M's explicit guidance of the\nkey points during the mesh reconstruction process provides robustness and\nstability to the pipeline with ablation studies. POE-M reduced the maximum\nChamfer distance error by 23.10 % compared to the state-of-the-art end-to-end\nsoft robot proprioception models and achieved 4.91 mm average Chamfer distance\nerror during evaluation.", "field": "Computer Science", "categories": "cs.RO"}, {"arxiv_id": "2401.09383", "title": "Synthesizing Hardware-Software Leakage Contracts for RISC-V Open-Source\n  Processors", "abstract": "Microarchitectural attacks compromise security by exploiting software-visible\nartifacts of microarchitectural optimizations such as caches and speculative\nexecution. Defending against such attacks at the software level requires an\nappropriate abstraction at the instruction set architecture (ISA) level that\ncaptures microarchitectural leakage. Hardware-software leakage contracts have\nrecently been proposed as such an abstraction. In this paper, we propose a\nsemi-automatic methodology for synthesizing hardware-software leakage contracts\nfor open-source microarchitectures. For a given ISA, our approach relies on\nhuman experts to (a) capture the space of possible contracts in the form of\ncontract templates and (b) devise a test-case generation strategy to explore a\nmicroarchitecture's potential leakage. For a given implementation of an ISA,\nthese two ingredients are then used to automatically synthesize the most\nprecise leakage contract that is satisfied by the microarchitecture. We have\ninstantiated this methodology for the RISC-V ISA and applied it to the Ibex and\nCVA6 open-source processors. Our experiments demonstrate the practical\napplicability of the methodology and uncover subtle and unexpected leaks.", "field": "Computer Science", "categories": "cs.CR"}, {"arxiv_id": "2401.09384", "title": "Diverse Part Synthesis for 3D Shape Creation", "abstract": "Methods that use neural networks for synthesizing 3D shapes in the form of a\npart-based representation have been introduced over the last few years. These\nmethods represent shapes as a graph or hierarchy of parts and enable a variety\nof applications such as shape sampling and reconstruction. However, current\nmethods do not allow easily regenerating individual shape parts according to\nuser preferences. In this paper, we investigate techniques that allow the user\nto generate multiple, diverse suggestions for individual parts. Specifically,\nwe experiment with multimodal deep generative models that allow sampling\ndiverse suggestions for shape parts and focus on models which have not been\nconsidered in previous work on shape synthesis. To provide a comparative study\nof these techniques, we introduce a method for synthesizing 3D shapes in a\npart-based representation and evaluate all the part suggestion techniques\nwithin this synthesis method. In our method, which is inspired by previous\nwork, shapes are represented as a set of parts in the form of implicit\nfunctions which are then positioned in space to form the final shape. Synthesis\nin this representation is enabled by a neural network architecture based on an\nimplicit decoder and a spatial transformer. We compare the various multimodal\ngenerative models by evaluating their performance in generating part\nsuggestions. Our contribution is to show with qualitative and quantitative\nevaluations which of the new techniques for multimodal part generation perform\nthe best and that a synthesis method based on the top-performing techniques\nallows the user to more finely control the parts that are generated in the 3D\nshapes while maintaining high shape fidelity when reconstructing shapes.", "field": "Computer Science", "categories": "cs.GR,cs.CV,cs.LG"}, {"arxiv_id": "2401.09386", "title": "Tri$^{2}$-plane: Volumetric Avatar Reconstruction with Feature Pyramid", "abstract": "Recent years have witnessed considerable achievements in facial avatar\nreconstruction with neural volume rendering. Despite notable advancements, the\nreconstruction of complex and dynamic head movements from monocular videos\nstill suffers from capturing and restoring fine-grained details. In this work,\nwe propose a novel approach, named Tri$^2$-plane, for monocular photo-realistic\nvolumetric head avatar reconstructions. Distinct from the existing works that\nrely on a single tri-plane deformation field for dynamic facial modeling, the\nproposed Tri$^2$-plane leverages the principle of feature pyramids and three\ntop-to-down lateral connections tri-planes for details improvement. It samples\nand renders facial details at multiple scales, transitioning from the entire\nface to specific local regions and then to even more refined sub-regions.\nMoreover, we incorporate a camera-based geometry-aware sliding window method as\nan augmentation in training, which improves the robustness beyond the canonical\nspace, with a particular improvement in cross-identity generation capabilities.\nExperimental outcomes indicate that the Tri$^2$-plane not only surpasses\nexisting methodologies but also achieves superior performance across both\nquantitative metrics and qualitative assessments through experiments.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.09387", "title": "A Multi-Agent Security Testbed for the Analysis of Attacks and Defenses\n  in Collaborative Sensor Fusion", "abstract": "The performance and safety of autonomous vehicles (AVs) deteriorates under\nadverse environments and adversarial actors. The investment in multi-sensor,\nmulti-agent (MSMA) AVs is meant to promote improved efficiency of travel and\nmitigate safety risks. Unfortunately, minimal investment has been made to\ndevelop security-aware MSMA sensor fusion pipelines leaving them vulnerable to\nadversaries. To advance security analysis of AVs, we develop the Multi-Agent\nSecurity Testbed, MAST, in the Robot Operating System (ROS2). Our framework is\nscalable for general AV scenarios and is integrated with recent multi-agent\ndatasets. We construct the first bridge between AVstack and ROS and develop\nautomated AV pipeline builds to enable rapid AV prototyping. We tackle the\nchallenge of deploying variable numbers of agent/adversary nodes at launch-time\nwith dynamic topic remapping. Using this testbed, we motivate the need for\nsecurity-aware AV architectures by exposing the vulnerability of centralized\nmulti-agent fusion pipelines to (un)coordinated adversary models in case\nstudies and Monte Carlo analysis.", "field": "Computer Science", "categories": "cs.RO,cs.SY,eess.SY"}, {"arxiv_id": "2401.09388", "title": "CognitiveDog: Large Multimodal Model Based System to Translate Vision\n  and Language into Action of Quadruped Robot", "abstract": "This paper introduces CognitiveDog, a pioneering development of quadruped\nrobot with Large Multi-modal Model (LMM) that is capable of not only\ncommunicating with humans verbally but also physically interacting with the\nenvironment through object manipulation. The system was realized on Unitree Go1\nrobot-dog equipped with a custom gripper and demonstrated autonomous\ndecision-making capabilities, independently determining the most appropriate\nactions and interactions with various objects to fulfill user-defined tasks.\nThese tasks do not necessarily include direct instructions, challenging the\nrobot to comprehend and execute them based on natural language input and\nenvironmental cues. The paper delves into the intricacies of this system,\ndataset characteristics, and the software architecture. Key to this development\nis the robot's proficiency in navigating space using Visual-SLAM, effectively\nmanipulating and transporting objects, and providing insightful natural\nlanguage commentary during task execution. Experimental results highlight the\nrobot's advanced task comprehension and adaptability, underscoring its\npotential in real-world applications. The dataset used to fine-tune the\nrobot-dog behavior generation model is provided at the following link:\nhuggingface.co/datasets/ArtemLykov/CognitiveDog_dataset", "field": "Computer Science", "categories": "cs.RO"}, {"arxiv_id": "2401.09395", "title": "Stuck in the Quicksand of Numeracy, Far from AGI Summit: Evaluating\n  LLMs' Mathematical Competency through Ontology-guided Perturbations", "abstract": "Recent advancements in Large Language Models (LLMs) have showcased striking\nresults on existing logical reasoning benchmarks, with some models even\nsurpassing human performance. However, the true depth of their competencies and\nrobustness, in mathematical reasoning tasks, remains an open question. In\nresponse, we develop (i) an ontology of perturbations of maths questions, (ii)\na semi-automatic method of perturbation, and (iii) a dataset of perturbed maths\nquestions to probe the limits of LLM capabilities in mathematical reasoning\ntasks. These controlled perturbations span across multiple fine dimensions of\nthe structural and representational aspects of maths questions. Using GPT-4, we\ngenerated the MORE dataset by perturbing randomly selected five seed questions\nfrom GSM8K. This process was guided by our ontology and involved a thorough\nautomatic and manual filtering process, yielding a set of 216 maths problems.\nWe conducted comprehensive evaluation of both closed-source and open-source\nLLMs on MORE. The results show a significant performance drop across all the\nmodels against the perturbed questions. This strongly suggests that current\nLLMs lack robust mathematical skills and deep reasoning abilities. This\nresearch not only identifies multiple gaps in the capabilities of current\nmodels, but also highlights multiple potential directions for future\ndevelopment. Our dataset will be made publicly available at\nhttps://huggingface.co/datasets/declare-lab/GSM8k_MORE.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.09407", "title": "Deciphering Textual Authenticity: A Generalized Strategy through the\n  Lens of Large Language Semantics for Detecting Human vs. Machine-Generated\n  Text", "abstract": "With the recent proliferation of Large Language Models (LLMs), there has been\nan increasing demand for tools to detect machine-generated text. The effective\ndetection of machine-generated text face two pertinent problems: First, they\nare severely limited in generalizing against real-world scenarios, where\nmachine-generated text is produced by a variety of generators, including but\nnot limited to GPT-4 and Dolly, and spans diverse domains, ranging from\nacademic manuscripts to social media posts. Second, existing detection\nmethodologies treat texts produced by LLMs through a restrictive binary\nclassification lens, neglecting the nuanced diversity of artifacts generated by\ndifferent LLMs. In this work, we undertake a systematic study on the detection\nof machine-generated text in real-world scenarios. We first study the\neffectiveness of state-of-the-art approaches and find that they are severely\nlimited against text produced by diverse generators and domains in the real\nworld. Furthermore, t-SNE visualizations of the embeddings from a pretrained\nLLM's encoder show that they cannot reliably distinguish between human and\nmachine-generated text. Based on our findings, we introduce a novel system,\nT5LLMCipher, for detecting machine-generated text using a pretrained T5 encoder\ncombined with LLM embedding sub-clustering to address the text produced by\ndiverse generators and domains in the real world. We evaluate our approach\nacross 9 machine-generated text systems and 9 domains and find that our\napproach provides state-of-the-art generalization ability, with an average\nincrease in F1 score on machine-generated text of 19.6\\% on unseen generators\nand domains compared to the top performing existing approaches and correctly\nattributes the generator of text with an accuracy of 93.6\\%.", "field": "Computer Science", "categories": "cs.CL,cs.LG"}, {"arxiv_id": "2401.0941", "title": "Through the Looking-Glass: Transparency Implications and Challenges in\n  Enterprise AI Knowledge Systems", "abstract": "Knowledge can't be disentangled from people. As AI knowledge systems mine\nvast volumes of work-related data, the knowledge that's being extracted and\nsurfaced is intrinsically linked to the people who create and use it. When\nthese systems get embedded in organizational settings, the information that is\nbrought to the foreground and the information that's pushed to the periphery\ncan influence how individuals see each other and how they see themselves at\nwork. In this paper, we present the looking-glass metaphor and use it to\nconceptualize AI knowledge systems as systems that reflect and distort,\nexpanding our view on transparency requirements, implications and challenges.\nWe formulate transparency as a key mediator in shaping different ways of\nseeing, including seeing into the system, which unveils its capabilities,\nlimitations and behavior, and seeing through the system, which shapes workers'\nperceptions of their own contributions and others within the organization.\nRecognizing the sociotechnical nature of these systems, we identify three\ntransparency dimensions necessary to realize the value of AI knowledge systems,\nnamely system transparency, procedural transparency and transparency of\noutcomes. We discuss key challenges hindering the implementation of these forms\nof transparency, bringing to light the wider sociotechnical gap and\nhighlighting directions for future Computer-supported Cooperative Work (CSCW)\nresearch.", "field": "Computer Science", "categories": "cs.CY,cs.AI,cs.HC"}, {"arxiv_id": "2401.09412", "title": "Weakly-Private Information Retrieval From MDS-Coded Distributed Storage", "abstract": "We consider the problem of weakly-private information retrieval (WPIR) when\ndata is encoded by a maximum distance separable code and stored across multiple\nservers. In WPIR, a user wishes to retrieve a piece of data from a set of\nservers without leaking too much information about which piece of data she is\ninterested in. We study and provide the first WPIR protocols for this scenario\nand present results on their optimal trade-off between download rate and\ninformation leakage using the maximal leakage privacy metric.", "field": "Computer Science", "categories": "cs.IT,cs.CR,math.IT"}, {"arxiv_id": "2401.09413", "title": "POP-3D: Open-Vocabulary 3D Occupancy Prediction from Images", "abstract": "We describe an approach to predict open-vocabulary 3D semantic voxel\noccupancy map from input 2D images with the objective of enabling 3D grounding,\nsegmentation and retrieval of free-form language queries. This is a challenging\nproblem because of the 2D-3D ambiguity and the open-vocabulary nature of the\ntarget tasks, where obtaining annotated training data in 3D is difficult. The\ncontributions of this work are three-fold. First, we design a new model\narchitecture for open-vocabulary 3D semantic occupancy prediction. The\narchitecture consists of a 2D-3D encoder together with occupancy prediction and\n3D-language heads. The output is a dense voxel map of 3D grounded language\nembeddings enabling a range of open-vocabulary tasks. Second, we develop a\ntri-modal self-supervised learning algorithm that leverages three modalities:\n(i) images, (ii) language and (iii) LiDAR point clouds, and enables training\nthe proposed architecture using a strong pre-trained vision-language model\nwithout the need for any 3D manual language annotations. Finally, we\ndemonstrate quantitatively the strengths of the proposed model on several\nopen-vocabulary tasks: Zero-shot 3D semantic segmentation using existing\ndatasets; 3D grounding and retrieval of free-form language queries, using a\nsmall dataset that we propose as an extension of nuScenes. You can find the\nproject page here https://vobecant.github.io/POP3D.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.09414", "title": "Vlogger: Make Your Dream A Vlog", "abstract": "In this work, we present Vlogger, a generic AI system for generating a\nminute-level video blog (i.e., vlog) of user descriptions. Different from short\nvideos with a few seconds, vlog often contains a complex storyline with\ndiversified scenes, which is challenging for most existing video generation\napproaches. To break through this bottleneck, our Vlogger smartly leverages\nLarge Language Model (LLM) as Director and decomposes a long video generation\ntask of vlog into four key stages, where we invoke various foundation models to\nplay the critical roles of vlog professionals, including (1) Script, (2) Actor,\n(3) ShowMaker, and (4) Voicer. With such a design of mimicking human beings,\nour Vlogger can generate vlogs through explainable cooperation of top-down\nplanning and bottom-up shooting. Moreover, we introduce a novel video diffusion\nmodel, ShowMaker, which serves as a videographer in our Vlogger for generating\nthe video snippet of each shooting scene. By incorporating Script and Actor\nattentively as textual and visual prompts, it can effectively enhance\nspatial-temporal coherence in the snippet. Besides, we design a concise mixed\ntraining paradigm for ShowMaker, boosting its capacity for both T2V generation\nand prediction. Finally, the extensive experiments show that our method\nachieves state-of-the-art performance on zero-shot T2V generation and\nprediction tasks. More importantly, Vlogger can generate over 5-minute vlogs\nfrom open-world descriptions, without loss of video coherence on script and\nactor. The code and model is all available at\nhttps://github.com/zhuangshaobin/Vlogger.", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.LG,cs.MM"}, {"arxiv_id": "2401.09415", "title": "Randomized Kaczmarz with geometrically smoothed momentum", "abstract": "This paper studies the effect of adding geometrically smoothed momentum to\nthe randomized Kaczmarz algorithm, which is an instance of stochastic gradient\ndescent on a linear least squares loss function. We prove a result about the\nexpected error in the direction of singular vectors of the matrix defining the\nleast squares loss. We present several numerical examples illustrating the\nutility of our result and pose several questions.", "field": "Computer Science", "categories": "math.NA,cs.NA,math.PR,stat.ML"}, {"arxiv_id": "2401.09416", "title": "TextureDreamer: Image-guided Texture Synthesis through Geometry-aware\n  Diffusion", "abstract": "We present TextureDreamer, a novel image-guided texture synthesis method to\ntransfer relightable textures from a small number of input images (3 to 5) to\ntarget 3D shapes across arbitrary categories. Texture creation is a pivotal\nchallenge in vision and graphics. Industrial companies hire experienced artists\nto manually craft textures for 3D assets. Classical methods require densely\nsampled views and accurately aligned geometry, while learning-based methods are\nconfined to category-specific shapes within the dataset. In contrast,\nTextureDreamer can transfer highly detailed, intricate textures from real-world\nenvironments to arbitrary objects with only a few casually captured images,\npotentially significantly democratizing texture creation. Our core idea,\npersonalized geometry-aware score distillation (PGSD), draws inspiration from\nrecent advancements in diffuse models, including personalized modeling for\ntexture information extraction, variational score distillation for detailed\nappearance synthesis, and explicit geometry guidance with ControlNet. Our\nintegration and several essential modifications substantially improve the\ntexture quality. Experiments on real images spanning different categories show\nthat TextureDreamer can successfully transfer highly realistic, semantic\nmeaningful texture to arbitrary objects, surpassing the visual quality of\nprevious state-of-the-art.", "field": "Computer Science", "categories": "cs.CV,cs.GR"}, {"arxiv_id": "2401.09417", "title": "Vision Mamba: Efficient Visual Representation Learning with\n  Bidirectional State Space Model", "abstract": "Recently the state space models (SSMs) with efficient hardware-aware designs,\ni.e., Mamba, have shown great potential for long sequence modeling. Building\nefficient and generic vision backbones purely upon SSMs is an appealing\ndirection. However, representing visual data is challenging for SSMs due to the\nposition-sensitivity of visual data and the requirement of global context for\nvisual understanding. In this paper, we show that the reliance of visual\nrepresentation learning on self-attention is not necessary and propose a new\ngeneric vision backbone with bidirectional Mamba blocks (Vim), which marks the\nimage sequences with position embeddings and compresses the visual\nrepresentation with bidirectional state space models. On ImageNet\nclassification, COCO object detection, and ADE20k semantic segmentation tasks,\nVim achieves higher performance compared to well-established vision\ntransformers like DeiT, while also demonstrating significantly improved\ncomputation & memory efficiency. For example, Vim is 2.8$\\times$ faster than\nDeiT and saves 86.8% GPU memory when performing batch inference to extract\nfeatures on images with a resolution of 1248$\\times$1248. The results\ndemonstrate that Vim is capable of overcoming the computation & memory\nconstraints on performing Transformer-style understanding for high-resolution\nimages and it has great potential to become the next-generation backbone for\nvision foundation models. Code is available at https://github.com/hustvl/Vim.", "field": "Computer Science", "categories": "cs.CV,cs.LG"}, {"arxiv_id": "2401.09419", "title": "GARField: Group Anything with Radiance Fields", "abstract": "Grouping is inherently ambiguous due to the multiple levels of granularity in\nwhich one can decompose a scene -- should the wheels of an excavator be\nconsidered separate or part of the whole? We present Group Anything with\nRadiance Fields (GARField), an approach for decomposing 3D scenes into a\nhierarchy of semantically meaningful groups from posed image inputs. To do this\nwe embrace group ambiguity through physical scale: by optimizing a\nscale-conditioned 3D affinity feature field, a point in the world can belong to\ndifferent groups of different sizes. We optimize this field from a set of 2D\nmasks provided by Segment Anything (SAM) in a way that respects coarse-to-fine\nhierarchy, using scale to consistently fuse conflicting masks from different\nviewpoints. From this field we can derive a hierarchy of possible groupings via\nautomatic tree construction or user interaction. We evaluate GARField on a\nvariety of in-the-wild scenes and find it effectively extracts groups at many\nlevels: clusters of objects, objects, and various subparts. GARField inherently\nrepresents multi-view consistent groupings and produces higher fidelity groups\nthan the input SAM masks. GARField's hierarchical grouping could have exciting\ndownstream applications such as 3D asset extraction or dynamic scene\nunderstanding. See the project website at https://www.garfield.studio/", "field": "Computer Science", "categories": "cs.CV,cs.GR"}, {"arxiv_id": "2401.0942", "title": "LionHeart: A Layer-based Mapping Framework for Heterogeneous Systems\n  with Analog In-Memory Computing Tiles", "abstract": "When arranged in a crossbar configuration, resistive memory devices can be\nused to execute MVM, the most dominant operation of many ML algorithms, in\nconstant time complexity. Nonetheless, when performing computations in the\nanalog domain, novel challenges are introduced in terms of arithmetic precision\nand stochasticity, due to non-ideal circuit and device behaviour. Moreover,\nthese non-idealities have a temporal dimension, resulting in a degrading\napplication accuracy over time. Facing these challenges, we propose a novel\nframework, named LionHeart, to obtain hybrid analog-digital mappings to execute\nDL inference workloads using heterogeneous accelerators. The\naccuracy-constrained mappings derived by LionHeart showcase, across different\nDNNs and datasets, high accuracy and potential for speedup. The results of the\nfull system simulations highlight run-time reductions and energy efficiency\ngains that exceed 6X, with a user-defined accuracy threshold with respect to a\nfully digital floating point implementation.", "field": "Computer Science", "categories": "cs.ET"}]}