{"embeddings": [[10.212106704711914, 8.929044723510742], [10.944053649902344, 9.749626159667969], [9.283466339111328, 4.977939605712891], [11.540168762207031, 8.865538597106934], [12.464797019958496, 9.31583309173584], [12.400116920471191, 6.810340404510498], [9.274858474731445, 9.066431045532227], [10.416228294372559, 5.620526313781738], [10.84200382232666, 9.595069885253906], [7.925628662109375, 5.3379058837890625], [9.461457252502441, 8.928337097167969], [8.617899894714355, 6.154304504394531], [10.562901496887207, 7.889139652252197], [10.440216064453125, 5.806211948394775], [12.094622611999512, 9.418749809265137], [8.323166847229004, 5.492657661437988], [9.521296501159668, 6.641132354736328], [9.07846450805664, 8.590160369873047], [9.245100021362305, 8.26550006866455], [9.868428230285645, 6.576175689697266], [11.136015892028809, 7.397506237030029], [12.088113784790039, 6.493606090545654], [9.270513534545898, 8.757288932800293], [9.514578819274902, 7.088838577270508], [11.981851577758789, 7.204007625579834], [8.532941818237305, 8.096274375915527], [9.66290283203125, 7.2619452476501465], [10.828146934509277, 9.135016441345215], [8.472138404846191, 8.409524917602539], [9.52712631225586, 7.968070983886719], [9.466808319091797, 6.783838272094727], [9.612289428710938, 5.335298538208008], [9.651734352111816, 7.3021135330200195], [11.749297142028809, 7.5071306228637695], [12.69360637664795, 7.924206733703613], [8.310418128967285, 5.676413059234619], [10.582587242126465, 6.633009910583496], [10.853530883789062, 7.320437908172607], [10.051509857177734, 6.581035614013672], [8.69374942779541, 7.173422336578369], [11.306815147399902, 8.933418273925781], [12.23181438446045, 7.028266906738281], [10.32103157043457, 5.607945919036865], [10.768632888793945, 6.8472900390625], [11.275232315063477, 7.276240825653076], [8.360929489135742, 8.089958190917969], [9.490253448486328, 4.870638847351074], [8.271899223327637, 6.848188400268555], [9.624488830566406, 9.753921508789062], [10.293593406677246, 9.603768348693848], [9.319662094116211, 6.194253444671631], [10.143796920776367, 9.376742362976074], [9.43758773803711, 8.073162078857422], [10.387643814086914, 7.943085670471191], [8.396258354187012, 7.909042835235596], [10.645101547241211, 7.079495429992676], [8.231894493103027, 6.82951545715332], [9.755733489990234, 6.6839447021484375], [8.781766891479492, 8.670761108398438], [11.689691543579102, 7.965564727783203], [10.115983963012695, 5.281444072723389], [11.980243682861328, 8.725922584533691], [10.702401161193848, 7.6845502853393555], [9.170957565307617, 8.131630897521973], [11.709537506103516, 6.346804618835449], [12.343168258666992, 7.54803466796875], [9.027392387390137, 8.302794456481934], [10.292734146118164, 9.719758987426758], [8.31234073638916, 6.011314868927002], [9.769747734069824, 8.471236228942871], [9.682031631469727, 7.258771896362305], [8.50741958618164, 6.544968128204346], [10.481489181518555, 7.479193210601807], [9.62934684753418, 5.4103522300720215], [9.7561674118042, 9.277156829833984], [8.60595703125, 5.361551761627197], [9.711325645446777, 6.798496246337891], [10.428868293762207, 9.86945629119873], [9.14111042022705, 8.965871810913086], [9.934591293334961, 6.886205196380615], [8.526955604553223, 8.551222801208496], [8.054930686950684, 5.9876708984375], [11.67920970916748, 6.150121212005615], [8.788227081298828, 5.088348865509033], [10.689032554626465, 8.9148588180542], [11.383296012878418, 8.346173286437988], [11.73945426940918, 7.958221435546875], [8.46813678741455, 5.1621527671813965], [12.584752082824707, 6.912566661834717], [8.972419738769531, 5.3357768058776855], [8.538753509521484, 5.400816917419434], [9.057998657226562, 6.289502143859863], [10.609814643859863, 7.264510154724121], [11.618626594543457, 6.584813117980957], [9.20881462097168, 7.433647632598877], [8.483872413635254, 5.305342197418213], [8.997954368591309, 8.992460250854492], [10.365012168884277, 9.099237442016602], [8.2370023727417, 6.870610237121582], [10.25222396850586, 6.028558254241943], [9.133772850036621, 4.966905117034912], [8.950969696044922, 5.865758895874023], [13.003708839416504, 8.227559089660645], [8.0524320602417, 5.395406723022461], [12.043131828308105, 9.483085632324219], [10.336082458496094, 5.132284164428711], [11.944918632507324, 8.24754810333252], [12.759580612182617, 6.815324783325195], [12.426986694335938, 6.724520683288574], [8.97542667388916, 8.011223793029785], [12.109095573425293, 8.822937965393066], [9.589483261108398, 8.902694702148438], [9.275334358215332, 6.148945331573486], [13.011828422546387, 8.64023494720459], [8.83984375, 6.028576374053955], [12.549973487854004, 6.68289041519165], [10.247713088989258, 7.914971828460693], [12.129658699035645, 8.911727905273438], [10.271611213684082, 5.009759426116943], [10.158345222473145, 8.55591106414795], [9.1878080368042, 6.436183452606201], [11.29724407196045, 8.410722732543945], [9.970510482788086, 6.8524932861328125], [8.788860321044922, 7.281083106994629], [10.097865104675293, 7.322216987609863], [8.115615844726562, 5.276432991027832], [9.611936569213867, 9.864862442016602], [11.670856475830078, 9.265490531921387], [10.375840187072754, 9.556417465209961], [12.057727813720703, 9.195024490356445], [8.329073905944824, 6.96220588684082], [9.539444923400879, 7.691237449645996], [8.837096214294434, 7.314467906951904], [9.614338874816895, 5.312344074249268], [9.307222366333008, 5.657417297363281], [12.786460876464844, 7.897826194763184], [11.624566078186035, 9.296459197998047], [9.88359260559082, 9.710654258728027], [10.701742172241211, 9.401537895202637], [10.238121032714844, 10.016827583312988], [12.809158325195312, 8.443692207336426], [10.203779220581055, 7.219550132751465], [9.760652542114258, 8.233121871948242], [10.696332931518555, 7.415408134460449], [12.215141296386719, 8.65742015838623], [10.890392303466797, 6.9231791496276855], [10.606497764587402, 8.44257640838623], [9.860950469970703, 9.053418159484863], [8.59699821472168, 5.539730548858643], [8.802712440490723, 6.678725719451904], [8.919225692749023, 5.102489948272705], [10.291448593139648, 9.213000297546387], [9.052009582519531, 5.0228962898254395], [11.559539794921875, 7.64277982711792], [8.635623931884766, 8.478365898132324], [13.091007232666016, 8.250913619995117], [12.878087043762207, 7.982142925262451], [12.110302925109863, 6.3686604499816895], [10.380620956420898, 5.081676006317139], [12.611519813537598, 6.758749485015869], [9.313358306884766, 7.987297534942627], [9.560810089111328, 9.719083786010742], [9.444473266601562, 6.541365146636963], [9.927742958068848, 7.6417670249938965], [8.909463882446289, 5.482051849365234], [7.8404717445373535, 6.0273919105529785], [7.889652252197266, 5.5824480056762695], [8.341106414794922, 6.911797046661377], [10.132654190063477, 6.490156173706055], [8.985159873962402, 7.532666206359863], [11.822773933410645, 9.526959419250488], [10.491243362426758, 9.427263259887695], [12.62210750579834, 9.182467460632324], [13.149253845214844, 8.441130638122559], [9.231525421142578, 6.149056911468506], [8.983711242675781, 6.242760181427002], [8.998927116394043, 4.894681930541992], [11.103143692016602, 6.8898749351501465], [11.19669246673584, 7.815671920776367], [12.947019577026367, 8.857275009155273], [9.534762382507324, 8.245946884155273], [8.03311824798584, 5.808043956756592], [10.600947380065918, 8.932778358459473], [12.800463676452637, 7.903607368469238], [12.040857315063477, 6.419220924377441], [10.905467987060547, 9.403460502624512], [12.317705154418945, 7.915001392364502], [9.389213562011719, 8.063421249389648], [8.961618423461914, 5.9289093017578125], [10.335619926452637, 6.643238067626953], [9.814724922180176, 7.928287029266357], [10.247401237487793, 5.446047306060791], [12.052791595458984, 8.336207389831543], [12.672475814819336, 7.597104549407959], [10.260068893432617, 5.144075870513916], [8.686029434204102, 8.620513916015625], [12.284708976745605, 6.370731830596924], [10.068120956420898, 7.439465522766113], [12.519769668579102, 7.67879581451416], [8.953683853149414, 7.042788505554199], [9.475306510925293, 5.250818729400635], [8.7166166305542, 7.447585105895996], [10.170000076293945, 7.270240783691406], [8.817889213562012, 7.311457633972168], [8.32129192352295, 6.960611820220947], [9.512320518493652, 8.39918327331543], [12.27319622039795, 8.89831829071045], [10.080198287963867, 9.215827941894531], [10.593378067016602, 8.666035652160645], [10.399736404418945, 9.422453880310059], [10.069620132446289, 9.606156349182129], [9.394627571105957, 7.397778511047363], [10.444482803344727, 5.541451454162598], [8.82129192352295, 5.536895751953125], [10.562480926513672, 9.790766716003418], [12.175159454345703, 8.912687301635742], [8.190170288085938, 6.194819927215576], [9.421241760253906, 5.162966251373291], [11.178430557250977, 6.8038201332092285], [8.51992130279541, 5.367040634155273], [12.780896186828613, 8.788630485534668], [9.605679512023926, 9.820477485656738], [12.049548149108887, 9.648655891418457], [10.038573265075684, 6.12842321395874], [8.454861640930176, 7.6494903564453125], [12.06270694732666, 8.351058006286621], [10.442365646362305, 6.995247840881348], [11.414560317993164, 9.173873901367188], [10.430445671081543, 9.467377662658691], [12.799339294433594, 8.843024253845215], [9.724404335021973, 9.090124130249023], [10.492478370666504, 9.564568519592285], [10.536349296569824, 6.447269439697266], [9.190725326538086, 9.191360473632812], [10.40953254699707, 9.051152229309082], [9.710236549377441, 9.217665672302246], [12.105278968811035, 6.513967514038086], [12.683589935302734, 9.139066696166992], [9.981201171875, 9.648090362548828], [12.433564186096191, 9.09290885925293], [10.002217292785645, 6.105717658996582], [12.35399055480957, 7.397775173187256], [9.68812370300293, 9.930901527404785], [12.392081260681152, 7.89732551574707], [9.405393600463867, 4.8725152015686035], [12.040007591247559, 9.127947807312012], [9.976617813110352, 9.41213321685791], [10.509166717529297, 6.2524590492248535], [10.94907283782959, 8.80987548828125], [9.693126678466797, 6.612619876861572], [10.601774215698242, 5.080724716186523], [11.539628028869629, 6.218836784362793], [10.173225402832031, 5.203235626220703], [8.872400283813477, 6.698637008666992], [11.66458511352539, 7.867384433746338], [10.272563934326172, 9.162498474121094], [9.23476791381836, 7.845639228820801], [8.226305961608887, 7.343942165374756], [12.630609512329102, 9.215795516967773], [10.486977577209473, 8.332738876342773], [11.753766059875488, 8.853252410888672], [8.227926254272461, 7.795985698699951], [9.004951477050781, 7.402780532836914], [8.124387741088867, 6.957998752593994], [7.890000820159912, 5.493263244628906], [8.702571868896484, 6.210043430328369], [10.445929527282715, 5.237960338592529], [9.165964126586914, 8.237699508666992], [11.085147857666016, 7.2827043533325195], [10.398791313171387, 5.032119274139404], [12.219016075134277, 7.726942539215088], [8.826228141784668, 5.469050884246826], [12.490087509155273, 8.70541000366211], [13.074264526367188, 7.780189037322998], [8.616676330566406, 6.102134704589844], [8.476421356201172, 5.110581398010254], [7.784952640533447, 5.800937652587891], [12.28317928314209, 7.480151653289795], [12.7048978805542, 7.081166744232178], [8.637616157531738, 4.972774982452393], [10.356657981872559, 7.6612091064453125], [11.957033157348633, 7.305310249328613], [11.41991138458252, 9.732137680053711], [11.536798477172852, 6.83161735534668], [10.282135009765625, 9.593605041503906], [10.230100631713867, 6.055092811584473], [9.776556968688965, 9.869977951049805], [10.545674324035645, 7.490894794464111], [8.6145601272583, 5.097768783569336], [7.975672245025635, 5.9232025146484375], [9.027819633483887, 9.066837310791016], [9.777722358703613, 7.8117451667785645], [12.214205741882324, 9.283318519592285], [9.350584030151367, 4.917864799499512], [10.150092124938965, 8.519000053405762], [11.980921745300293, 6.9457197189331055], [7.959458827972412, 5.963535785675049], [12.73535442352295, 6.955301284790039], [10.58966064453125, 5.820451259613037], [12.061792373657227, 7.494815826416016], [12.432782173156738, 8.478410720825195], [11.163372993469238, 8.043606758117676], [12.48235034942627, 9.165541648864746], [11.1553955078125, 9.62255573272705], [10.532922744750977, 9.97250747680664], [12.261185646057129, 9.10330867767334], [12.635754585266113, 8.275372505187988], [13.05225944519043, 8.215219497680664], [13.073800086975098, 8.411591529846191], [12.181507110595703, 6.222444534301758], [12.311190605163574, 6.415769577026367]], "keys": ["2401.09426", "2401.09432", "2401.09434", "2401.09441", "2401.09442", "2401.09443", "2401.09444", "2401.09445", "2401.09446", "2401.09447", "2401.09448", "2401.09449", "2401.0945", "2401.09452", "2401.09454", "2401.09455", "2401.09456", "2401.09457", "2401.09459", "2401.09464", "2401.09467", "2401.09472", "2401.09473", "2401.09474", "2401.09475", "2401.09476", "2401.09479", "2401.09486", "2401.09488", "2401.09489", "2401.09491", "2401.09492", "2401.09494", "2401.09495", "2401.09496", "2401.09498", "2401.09499", "2401.09507", "2401.09509", "2401.0951", "2401.09512", "2401.09515", "2401.09516", "2401.09517", "2401.09518", "2401.09519", "2401.0952", "2401.09543", "2401.09553", "2401.09555", "2401.09561", "2401.09566", "2401.09572", "2401.09574", "2401.09575", "2401.09582", "2401.09585", "2401.09587", "2401.09591", "2401.09596", "2401.09601", "2401.09603", "2401.09604", "2401.09605", "2401.09606", "2401.09607", "2401.09608", "2401.09615", "2401.0962", "2401.09621", "2401.09622", "2401.09628", "2401.09629", "2401.09631", "2401.09637", "2401.0964", "2401.09641", "2401.09646", "2401.09647", "2401.09651", "2401.09654", "2401.09656", "2401.09658", "2401.09666", "2401.0967", "2401.09671", "2401.09673", "2401.09674", "2401.09677", "2401.09678", "2401.0968", "2401.09681", "2401.09682", "2401.09691", "2401.09693", "2401.09694", "2401.09695", "2401.09699", "2401.097", "2401.09703", "2401.09705", "2401.09706", "2401.09709", "2401.09711", "2401.09712", "2401.09714", "2401.09716", "2401.0972", "2401.09721", "2401.09724", "2401.09725", "2401.09727", "2401.09728", "2401.09732", "2401.09733", "2401.09736", "2401.0974", "2401.09742", "2401.09747", "2401.09748", "2401.0975", "2401.09752", "2401.09753", "2401.09754", "2401.09756", "2401.09757", "2401.09758", "2401.09759", "2401.0976", "2401.09763", "2401.09764", "2401.09767", "2401.09769", "2401.0977", "2401.09772", "2401.09773", "2401.09774", "2401.09775", "2401.09783", "2401.09785", "2401.09786", "2401.09787", "2401.09789", "2401.09793", "2401.09794", "2401.09795", "2401.09796", "2401.09798", "2401.098", "2401.09804", "2401.09808", "2401.09815", "2401.09819", "2401.09823", "2401.09824", "2401.09826", "2401.09828", "2401.09831", "2401.09834", "2401.09836", "2401.09838", "2401.09839", "2401.09851", "2401.09852", "2401.09853", "2401.09854", "2401.09856", "2401.09858", "2401.09859", "2401.0986", "2401.09861", "2401.09862", "2401.09865", "2401.09866", "2401.0987", "2401.09877", "2401.09878", "2401.0988", "2401.09881", "2401.09883", "2401.09885", "2401.09886", "2401.0989", "2401.09895", "2401.09896", "2401.09899", "2401.099", "2401.09906", "2401.0991", "2401.09916", "2401.09918", "2401.09919", "2401.09921", "2401.09923", "2401.09926", "2401.09937", "2401.09939", "2401.0994", "2401.09942", "2401.09943", "2401.09944", "2401.09945", "2401.09949", "2401.09953", "2401.09957", "2401.0996", "2401.09962", "2401.09964", "2401.09966", "2401.09967", "2401.09972", "2401.09973", "2401.09977", "2401.09983", "2401.09984", "2401.09985", "2401.09986", "2401.09987", "2401.09988", "2401.09989", "2401.09997", "2401.10002", "2401.10005", "2401.10007", "2401.10008", "2401.10011", "2401.10014", "2401.10015", "2401.10016", "2401.10017", "2401.10019", "2401.1002", "2401.10029", "2401.1003", "2401.10034", "2401.10036", "2401.10037", "2401.10039", "2401.1004", "2401.10041", "2401.10042", "2401.10044", "2401.10045", "2401.1005", "2401.10052", "2401.10061", "2401.10065", "2401.10068", "2401.1007", "2401.10082", "2401.10083", "2401.10085", "2401.10088", "2401.10089", "2401.1009", "2401.10091", "2401.10101", "2401.10109", "2401.1011", "2401.10111", "2401.10113", "2401.10118", "2401.10119", "2401.10122", "2401.10133", "2401.10134", "2401.10135", "2401.10136", "2401.10139", "2401.10141", "2401.10148", "2401.10149", "2401.1015", "2401.10153", "2401.10155", "2401.10156", "2401.10158", "2401.10166", "2401.10171", "2401.10175", "2401.10176", "2401.10178", "2401.10184", "2401.10185", "2401.10186", "2401.10187", "2401.10189", "2401.10191", "2401.10194", "2401.10204", "2401.10205", "2401.10207", "2401.10208", "2401.10209", "2401.1021", "2401.10213", "2401.10214", "2401.10215", "2401.10216", "2401.10217", "2401.10219", "2401.1022", "2401.10222", "2401.10224", "2401.10225", "2401.10226", "2401.10227", "2401.10228", "2401.10229", "2401.1023", "2401.10232"], "additional_info": [{"arxiv_id": "2401.09426", "title": "Transduce: learning transduction grammars for string transformation", "abstract": "The synthesis of string transformation programs from input-output examples\nutilizes various techniques, all based on an inductive bias that comprises a\nrestricted set of basic operators to be combined. A new algorithm, Transduce,\nis proposed, which is founded on the construction of abstract transduction\ngrammars and their generalization. We experimentally demonstrate that Transduce\ncan learn positional transformations efficiently from one or two positive\nexamples without inductive bias, achieving a success rate higher than the\ncurrent state of the art.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.09432", "title": "RoleCraft-GLM: Advancing Personalized Role-Playing in Large Language\n  Models", "abstract": "This study presents RoleCraft-GLM, an innovative framework aimed at enhancing\npersonalized role-playing with Large Language Models (LLMs). RoleCraft-GLM\naddresses the key issue of lacking personalized interactions in conversational\nAI, and offers a solution with detailed and emotionally nuanced character\nportrayals. We contribute a unique conversational dataset that shifts from\nconventional celebrity-centric characters to diverse, non-celebrity personas,\nthus enhancing the realism and complexity of language modeling interactions.\nAdditionally, our approach includes meticulous character development, ensuring\ndialogues are both realistic and emotionally resonant. The effectiveness of\nRoleCraft-GLM is validated through various case studies, highlighting its\nversatility and skill in different scenarios. Our framework excels in\ngenerating dialogues that accurately reflect characters' personality traits and\nemotions, thereby boosting user engagement. In conclusion, RoleCraft-GLM marks\na significant leap in personalized AI interactions, and paves the way for more\nauthentic and immersive AI-assisted role-playing experiences by enabling more\nnuanced and emotionally rich dialogues", "field": "Computer Science", "categories": "cs.CL,cs.AI,cs.LG"}, {"arxiv_id": "2401.09434", "title": "Modeling, Simulation, and Maneuvering Control of a Generic Submarine", "abstract": "This work introduces two multi-level control strategies to address the\nproblem of guidance and control of underwater vehicles. An outer-loop\npath-following algorithm and an outer-loop trajectory tracking algorithm are\npresented. Both outer-loop algorithms provide reference commands that enable\nthe generic submarine to adhere to a three-dimensional path, and both use an\ninner-loop adaptive controller to determine the required actuation commands.\nFurther, a reduced order model of a generic submarine is presented.\nComputational fluid dynamics (CFD) results are used to create and validate a\nmodel that includes depth dependence and the effect of waves on the craft. %The\nmodel and the procedure to obtain its coefficients are discussed, and examples\nof the data used to obtain the model coefficients are presented. An example of\noperation following a complex path is presented and Results from the reduced\norder model for each control strategy are compared.", "field": "Computer Science", "categories": "eess.SY,cs.SY"}, {"arxiv_id": "2401.09441", "title": "Voxceleb-ESP: preliminary experiments detecting Spanish celebrities from\n  their voices", "abstract": "This paper presents VoxCeleb-ESP, a collection of pointers and timestamps to\nYouTube videos facilitating the creation of a novel speaker recognition\ndataset. VoxCeleb-ESP captures real-world scenarios, incorporating diverse\nspeaking styles, noises, and channel distortions. It includes 160 Spanish\ncelebrities spanning various categories, ensuring a representative distribution\nacross age groups and geographic regions in Spain. We provide two speaker trial\nlists for speaker identification tasks, each of them with same-video or\ndifferent-video target trials respectively, accompanied by a cross-lingual\nevaluation of ResNet pretrained models. Preliminary speaker identification\nresults suggest that the complexity of the detection task in VoxCeleb-ESP is\nequivalent to that of the original and much larger VoxCeleb in English.\nVoxCeleb-ESP contributes to the expansion of speaker recognition benchmarks\nwith a comprehensive and diverse dataset for the Spanish language.", "field": "Computer Science", "categories": "cs.SD,cs.LG,eess.AS"}, {"arxiv_id": "2401.09442", "title": "Object Attribute Matters in Visual Question Answering", "abstract": "Visual question answering is a multimodal task that requires the joint\ncomprehension of visual and textual information. However, integrating visual\nand textual semantics solely through attention layers is insufficient to\ncomprehensively understand and align information from both modalities.\nIntuitively, object attributes can naturally serve as a bridge to unify them,\nwhich has been overlooked in previous research. In this paper, we propose a\nnovel VQA approach from the perspective of utilizing object attribute, aiming\nto achieve better object-level visual-language alignment and multimodal scene\nunderstanding. Specifically, we design an attribute fusion module and a\ncontrastive knowledge distillation module. The attribute fusion module\nconstructs a multimodal graph neural network to fuse attributes and visual\nfeatures through message passing. The enhanced object-level visual features\ncontribute to solving fine-grained problem like counting-question. The better\nobject-level visual-language alignment aids in understanding multimodal scenes,\nthereby improving the model's robustness. Furthermore, to augment scene\nunderstanding and the out-of-distribution performance, the contrastive\nknowledge distillation module introduces a series of implicit knowledge. We\ndistill knowledge into attributes through contrastive loss, which further\nstrengthens the representation learning of attribute features and facilitates\nvisual-linguistic alignment. Intensive experiments on six datasets, COCO-QA,\nVQAv2, VQA-CPv2, VQA-CPv1, VQAvs and TDIUC, show the superiority of the\nproposed method.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.09443", "title": "CRD: Collaborative Representation Distance for Practical Anomaly\n  Detection", "abstract": "Visual defect detection plays an important role in intelligent industry.\nPatch based methods consider visual images as a collection of image patches\naccording to positions, which have stronger discriminative ability for small\ndefects in products, e.g. scratches on pills. However, the nearest neighbor\nsearch for the query image and the stored patches will occupy $O(n)$ complexity\nin terms of time and space requirements, posing strict challenges for\ndeployment in edge environments. In this paper, we propose an alternative\napproach to the distance calculation of image patches via collaborative\nrepresentation models. Starting from the nearest neighbor distance with $L_0$\nconstraint, we relax the constraint to $L_2$ constraint and solve the distance\nquickly in close-formed without actually accessing the original stored\ncollection of image patches. Furthermore, we point out that the main\ncomputational burden of this close-formed solution can be pre-computed by\nhigh-performance server before deployment. Consequently, the distance\ncalculation on edge devices only requires a simple matrix multiplication, which\nis extremely lightweight and GPU-friendly. Performance on real industrial\nscenarios demonstrates that compared to the existing state-of-the-art methods,\nthis distance achieves several hundred times improvement in computational\nefficiency with slight performance drop, while greatly reducing memory\noverhead.", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.LG"}, {"arxiv_id": "2401.09444", "title": "Online Handbook of Argumentation for AI: Volume 4", "abstract": "This volume contains revised versions of the papers selected for the fourth\nvolume of the Online Handbook of Argumentation for AI (OHAAI). Previously,\nformal theories of argument and argument interaction have been proposed and\nstudied, and this has led to the more recent study of computational models of\nargument. Argumentation, as a field within artificial intelligence (AI), is\nhighly relevant for researchers interested in symbolic representations of\nknowledge and defeasible reasoning. The purpose of this handbook is to provide\nan open access and curated anthology for the argumentation research community.\nOHAAI is designed to serve as a research hub to keep track of the latest and\nupcoming PhD-driven research on the theory and application of argumentation in\nall areas related to AI.", "field": "Computer Science", "categories": "cs.AI"}, {"arxiv_id": "2401.09445", "title": "Quadratic neural networks for solving inverse problems", "abstract": "In this paper we investigate the solution of inverse problems with neural\nnetwork ansatz functions with generalized decision functions. The relevant\nobservation for this work is that such functions can approximate typical test\ncases, such as the Shepp-Logan phantom, better, than standard neural networks.\nMoreover, we show that the convergence analysis of numerical methods for\nsolving inverse problems with shallow generalized neural network functions\nleads to more intuitive convergence conditions, than for deep affine linear\nneural networks.", "field": "Computer Science", "categories": "math.NA,cs.NA,65J22, 45Q05, 42C40, 65F20"}, {"arxiv_id": "2401.09446", "title": "Explainable Multimodal Sentiment Analysis on Bengali Memes", "abstract": "Memes have become a distinctive and effective form of communication in the\ndigital era, attracting online communities and cutting across cultural\nbarriers. Even though memes are frequently linked with humor, they have an\namazing capacity to convey a wide range of emotions, including happiness,\nsarcasm, frustration, and more. Understanding and interpreting the sentiment\nunderlying memes has become crucial in the age of information. Previous\nresearch has explored text-based, image-based, and multimodal approaches,\nleading to the development of models like CAPSAN and PromptHate for detecting\nvarious meme categories. However, the study of low-resource languages like\nBengali memes remains scarce, with limited availability of publicly accessible\ndatasets. A recent contribution includes the introduction of the MemoSen\ndataset. However, the achieved accuracy is notably low, and the dataset suffers\nfrom imbalanced distribution. In this study, we employed a multimodal approach\nusing ResNet50 and BanglishBERT and achieved a satisfactory result of 0.71\nweighted F1-score, performed comparison with unimodal approaches, and\ninterpreted behaviors of the models using explainable artificial intelligence\n(XAI) techniques.", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.CL,cs.LG"}, {"arxiv_id": "2401.09447", "title": "Experimental Investigation of 5G Base Station functionalities in\n  Reverberation Chamber at Millimeter-Wave", "abstract": "The performance and functionalities of a commercial fifth generation base\nstation are evaluated inside the reverberation chamber at the mmWave frequency\nrange. The base station capability to operates in different propagation\nenvironment conditions reproduced by the reverberation chamber is investigated.\nThroughput, modulation code scheme and beamforming are analyzed for different\nreal life scenarios both in uplink and downlink. Experimental results inform\nnetwork operators in their evaluation of the base station operation: i) in many\nscenarios within a laboratory; ii) in the assessment of whether expected\nbenefit justifies the additional costs in an operating actual network.", "field": "Computer Science", "categories": "cs.NI"}, {"arxiv_id": "2401.09448", "title": "Tumbug: A pictorial, universal knowledge representation method", "abstract": "Since the key to artificial general intelligence (AGI) is commonly believed\nto be commonsense reasoning (CSR) or, roughly equivalently, discovery of a\nknowledge representation method (KRM) that is particularly suitable for CSR,\nthe author developed a custom KRM for CSR. This novel KRM called Tumbug was\ndesigned to be pictorial in nature because there exists increasing evidence\nthat the human brain uses some pictorial type of KRM, and no well-known prior\nresearch in AGI has researched this KRM possibility. Tumbug is somewhat similar\nto Roger Schank's Conceptual Dependency (CD) theory, but Tumbug is pictorial\nand uses about 30 components based on fundamental concepts from the sciences\nand human life, in contrast to CD theory, which is textual and uses about 17\ncomponents (= 6 Primitive Conceptual Categories + 11 Primitive Acts) based\nmainly on human-oriented activities. All the Building Blocks of Tumbug were\nfound to generalize to only five Basic Building Blocks that exactly correspond\nto the three components {O, A, V} of traditional Object-Attribute-Value\nrepresentation plus two new components {C, S}, which are Change and System.\nCollectively this set of five components, called \"SCOVA,\" seems to be a\nuniversal foundation for all knowledge representation.", "field": "Computer Science", "categories": "cs.AI"}, {"arxiv_id": "2401.09449", "title": "Optimal games in Room 25 solo and coop modes", "abstract": "We study the problem of optimal games for the solo and coop modes of the\nboard game Room 25 (season 1). We show that the game cannot be won in a single\nturn for any starting configuration, but that it can be done in two for some\nconfigurations. We introduce an opening that wins in two turns with enough\nluck, while having a low probability of losing immediately. We then show that\nthe game can be won in a single turn if the game's rules are slightly modified,\nalthough the probability of winning then becomes substantially lower than in\nthe two-turn strategy. At last, we show that if the players are maximally\nunlucky, they will lose regardless of their strategy.", "field": "Computer Science", "categories": "cs.GT"}, {"arxiv_id": "2401.0945", "title": "Joining Forces for Pathology Diagnostics with AI Assistance: The EMPAIA\n  Initiative", "abstract": "Over the past decade, artificial intelligence (AI) methods in pathology have\nadvanced substantially. However, integration into routine clinical practice has\nbeen slow due to numerous challenges, including technical and regulatory\nhurdles in translating research results into clinical diagnostic products and\nthe lack of standardized interfaces. The open and vendor-neutral EMPAIA\ninitiative addresses these challenges. Here, we provide an overview of EMPAIA's\nachievements and lessons learned. EMPAIA integrates various stakeholders of the\npathology AI ecosystem, i.e., pathologists, computer scientists, and industry.\nIn close collaboration, we developed technical interoperability standards,\nrecommendations for AI testing and product development, and explainability\nmethods. We implemented the modular and open-source EMPAIA platform and\nsuccessfully integrated 11 AI-based image analysis apps from 6 different\nvendors, demonstrating how different apps can use a single standardized\ninterface. We prioritized requirements and evaluated the use of AI in real\nclinical settings with 14 different pathology laboratories in Europe and Asia.\nIn addition to technical developments, we created a forum for all stakeholders\nto share information and experiences on digital pathology and AI. Commercial,\nclinical, and academic stakeholders can now adopt EMPAIA's common open-source\ninterfaces, providing a unique opportunity for large-scale standardization and\nstreamlining of processes. Further efforts are needed to effectively and\nbroadly establish AI assistance in routine laboratory use. To this end, a\nsustainable infrastructure, the non-profit association EMPAIA International,\nhas been established to continue standardization and support broad\nimplementation and advocacy for an AI-assisted digital pathology future.", "field": "Computer Science", "categories": "cs.CY,cs.AI,cs.CV,cs.HC"}, {"arxiv_id": "2401.09452", "title": "Incorporating Riemannian Geometric Features for Learning Coefficient of\n  Pressure Distributions on Airplane Wings", "abstract": "The aerodynamic coefficients of aircrafts are significantly impacted by its\ngeometry, especially when the angle of attack (AoA) is large. In the field of\naerodynamics, traditional polynomial-based parameterization uses as few\nparameters as possible to describe the geometry of an airfoil. However, because\nthe 3D geometry of a wing is more complicated than the 2D airfoil,\npolynomial-based parameterizations have difficulty in accurately representing\nthe entire shape of a wing in 3D space. Existing deep learning-based methods\ncan extract massive latent neural representations for the shape of 2D airfoils\nor 2D slices of wings. Recent studies highlight that directly taking geometric\nfeatures as inputs to the neural networks can improve the accuracy of predicted\naerodynamic coefficients. Motivated by geometry theory, we propose to\nincorporate Riemannian geometric features for learning Coefficient of Pressure\n(CP) distributions on wing surfaces. Our method calculates geometric features\n(Riemannian metric, connection, and curvature) and further inputs the geometric\nfeatures, coordinates and flight conditions into a deep learning model to\npredict the CP distribution. Experimental results show that our method,\ncompared to state-of-the-art Deep Attention Network (DAN), reduces the\npredicted mean square error (MSE) of CP by an average of 8.41% for the DLR-F11\naircraft test set.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.09454", "title": "Voila-A: Aligning Vision-Language Models with User's Gaze Attention", "abstract": "In recent years, the integration of vision and language understanding has led\nto significant advancements in artificial intelligence, particularly through\nVision-Language Models (VLMs). However, existing VLMs face challenges in\nhandling real-world applications with complex scenes and multiple objects, as\nwell as aligning their focus with the diverse attention patterns of human\nusers. In this paper, we introduce gaze information, feasibly collected by AR\nor VR devices, as a proxy for human attention to guide VLMs and propose a novel\napproach, Voila-A, for gaze alignment to enhance the interpretability and\neffectiveness of these models in real-world applications. First, we collect\nhundreds of minutes of gaze data to demonstrate that we can mimic human gaze\nmodalities using localized narratives. We then design an automatic data\nannotation pipeline utilizing GPT-4 to generate the VOILA-COCO dataset.\nAdditionally, we innovate the Voila Perceiver modules to integrate gaze\ninformation into VLMs while preserving their pretrained knowledge. We evaluate\nVoila-A using a hold-out validation set and a newly collected VOILA-GAZE\nTestset, which features real-life scenarios captured with a gaze-tracking\ndevice. Our experimental results demonstrate that Voila-A significantly\noutperforms several baseline models. By aligning model attention with human\ngaze patterns, Voila-A paves the way for more intuitive, user-centric VLMs and\nfosters engaging human-AI interaction across a wide range of applications.", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.CL,cs.LG"}, {"arxiv_id": "2401.09455", "title": "Dynamic Routing for Integrated Satellite-Terrestrial Networks: A\n  Constrained Multi-Agent Reinforcement Learning Approach", "abstract": "The integrated satellite-terrestrial network (ISTN) system has experienced\nsignificant growth, offering seamless communication services in remote areas\nwith limited terrestrial infrastructure. However, designing a routing scheme\nfor ISTN is exceedingly difficult, primarily due to the heightened complexity\nresulting from the inclusion of additional ground stations, along with the\nrequirement to satisfy various constraints related to satellite service\nquality. To address these challenges, we study packet routing with ground\nstations and satellites working jointly to transmit packets, while prioritizing\nfast communication and meeting energy efficiency and packet loss requirements.\nSpecifically, we formulate the problem of packet routing with constraints as a\nmax-min problem using the Lagrange method. Then we propose a novel constrained\nMulti-Agent reinforcement learning (MARL) dynamic routing algorithm named\nCMADR, which efficiently balances objective improvement and constraint\nsatisfaction during the updating of policy and Lagrange multipliers. Finally,\nwe conduct extensive experiments and an ablation study using the OneWeb and\nTelesat mega-constellations. Results demonstrate that CMADR reduces the packet\ndelay by a minimum of 21% and 15%, while meeting stringent energy consumption\nand packet loss rate constraints, outperforming several baseline algorithms.", "field": "Computer Science", "categories": "cs.NI,cs.AI,cs.LG,cs.SY,eess.SY"}, {"arxiv_id": "2401.09456", "title": "Parametric Constraints for Bayesian Knowledge Tracing from First\n  Principles", "abstract": "Bayesian Knowledge Tracing (BKT) is a probabilistic model of a learner's\nstate of mastery corresponding to a knowledge component. It considers the\nlearner's state of mastery as a \"hidden\" or latent binary variable and updates\nthis state based on the observed correctness of the learner's response using\nparameters that represent transition probabilities between states. BKT is often\nrepresented as a Hidden Markov Model and the Expectation-Maximization (EM)\nalgorithm is used to infer these parameters. However, this algorithm can suffer\nfrom several issues including producing multiple viable sets of parameters,\nsettling into a local minima, producing degenerate parameter values, and a high\ncomputational cost during fitting. This paper takes a \"from first principles\"\napproach to deriving constraints that can be imposed on the BKT parameter\nspace. Starting from the basic mathematical truths of probability and building\nup to the behaviors expected of the BKT parameters in real systems, this paper\npresents a mathematical derivation that results in succinct constraints that\ncan be imposed on the BKT parameter space. Since these constraints are\nnecessary conditions, they can be applied prior to fitting in order to reduce\ncomputational cost and the likelihood of issues that can emerge from the EM\nprocedure. In order to see that promise through, the paper further introduces a\nnovel algorithm for estimating BKT parameters subject to the newly defined\nconstraints. While the issue of degenerate parameter values has been reported\npreviously, this paper is the first, to our best knowledge, to derive the\nconstrains from first principles while also presenting an algorithm that\nrespects those constraints.", "field": "Computer Science", "categories": "cs.CY,cs.LG,stat.ML,62F15 (Primary) 62M05, 60J20, 68T30, 91E40 (Secondary)"}, {"arxiv_id": "2401.09457", "title": "Empowering Africa: An In-depth Exploration of the Adoption of Artificial\n  Intelligence Across the Continent", "abstract": "This paper explores the dynamic landscape of Artificial Intelligence (AI)\nadoption in Africa, analysing its varied applications in addressing\nsocio-economic challenges and fostering development. Examining the African AI\necosystem, the study considers regional nuances, cultural factors, and\ninfrastructural constraints shaping the deployment of AI solutions. Case\nstudies in healthcare, agriculture, finance, and education highlight AI's\ntransformative potential for efficiency, accessibility, and inclusivity. The\npaper emphasizes indigenous AI innovations and international collaborations\ncontributing to a distinct African AI ecosystem. Ethical considerations,\nincluding data privacy and algorithmic bias, are addressed alongside policy\nframeworks supporting responsible AI implementation. The role of governmental\nbodies, regulations, and private sector partnerships is explored in creating a\nconducive AI development environment. Challenges such as digital literacy gaps\nand job displacement are discussed, with proposed strategies for mitigation. In\nconclusion, the paper provides a nuanced understanding of AI in Africa,\ncontributing to sustainable development discussions and advocating for an\ninclusive and ethical AI ecosystem on the continent.", "field": "Computer Science", "categories": "cs.CY"}, {"arxiv_id": "2401.09459", "title": "What's my role? Modelling responsibility for AI-based safety-critical\n  systems", "abstract": "AI-Based Safety-Critical Systems (AI-SCS) are being increasingly deployed in\nthe real world. These can pose a risk of harm to people and the environment.\nReducing that risk is an overarching priority during development and operation.\nAs more AI-SCS become autonomous, a layer of risk management via human\nintervention has been removed. Following an accident it will be important to\nidentify causal contributions and the different responsible actors behind those\nto learn from mistakes and prevent similar future events. Many authors have\ncommented on the \"responsibility gap\" where it is difficult for developers and\nmanufacturers to be held responsible for harmful behaviour of an AI-SCS. This\nis due to the complex development cycle for AI, uncertainty in AI performance,\nand dynamic operating environment. A human operator can become a \"liability\nsink\" absorbing blame for the consequences of AI-SCS outputs they weren't\nresponsible for creating, and may not have understanding of.\n  This cross-disciplinary paper considers different senses of responsibility\n(role, moral, legal and causal), and how they apply in the context of AI-SCS\nsafety. We use a core concept (Actor(A) is responsible for Occurrence(O)) to\ncreate role responsibility models, producing a practical method to capture\nresponsibility relationships and provide clarity on the previously identified\nresponsibility issues. Our paper demonstrates the approach with two examples: a\nretrospective analysis of the Tempe Arizona fatal collision involving an\nautonomous vehicle, and a safety focused predictive role-responsibility\nanalysis for an AI-based diabetes co-morbidity predictor. In both examples our\nprimary focus is on safety, aiming to reduce unfair or disproportionate blame\nbeing placed on operators or developers. We present a discussion and avenues\nfor future research.", "field": "Computer Science", "categories": "cs.CY,cs.AI,I.2.0; K.4.0"}, {"arxiv_id": "2401.09464", "title": "Floating Point HUB Adder for RISC-V Sargantana Processor", "abstract": "HUB format is an emerging technique to improve the hardware and time\nrequirement when round to nearest is needed. On the other hand, RISC-V is an\nopen-source ISA that many companies currently use in their designs. This paper\npresents a tailored floating point HUB adder implemented in the Sargantana\nRISC-V processor.", "field": "Computer Science", "categories": "cs.AR"}, {"arxiv_id": "2401.09467", "title": "Offline Handwriting Signature Verification: A Transfer Learning and\n  Feature Selection Approach", "abstract": "Handwritten signature verification poses a formidable challenge in biometrics\nand document authenticity. The objective is to ascertain the authenticity of a\nprovided handwritten signature, distinguishing between genuine and forged ones.\nThis issue has many applications in sectors such as finance, legal\ndocumentation, and security. Currently, the field of computer vision and\nmachine learning has made significant progress in the domain of handwritten\nsignature verification. The outcomes, however, may be enhanced depending on the\nacquired findings, the structure of the datasets, and the used models. Four\nstages make up our suggested strategy. First, we collected a large dataset of\n12600 images from 420 distinct individuals, and each individual has 30\nsignatures of a certain kind (All authors signatures are genuine). In the\nsubsequent stage, the best features from each image were extracted using a deep\nlearning model named MobileNetV2. During the feature selection step, three\nselectors neighborhood component analysis (NCA), Chi2, and mutual info (MI)\nwere used to pull out 200, 300, 400, and 500 features, giving a total of 12\nfeature vectors. Finally, 12 results have been obtained by applying machine\nlearning techniques such as SVM with kernels (rbf, poly, and linear), KNN, DT,\nLinear Discriminant Analysis, and Naive Bayes. Without employing feature\nselection techniques, our suggested offline signature verification achieved a\nclassification accuracy of 91.3%, whereas using the NCA feature selection\napproach with just 300 features it achieved a classification accuracy of 97.7%.\nHigh classification accuracy was achieved using the designed and suggested\nmodel, which also has the benefit of being a self-organized framework.\nConsequently, using the optimum minimally chosen features, the proposed method\ncould identify the best model performance and result validation prediction\nvectors.", "field": "Computer Science", "categories": "cs.CV,cs.AI,eess.IV"}, {"arxiv_id": "2401.09472", "title": "Plug-in for visualizing 3D tool tracking from videos of Minimally\n  Invasive Surgeries", "abstract": "This paper tackles instrument tracking and 3D visualization challenges in\nminimally invasive surgery (MIS), crucial for computer-assisted interventions.\nConventional and robot-assisted MIS encounter issues with limited 2D camera\nprojections and minimal hardware integration. The objective is to track and\nvisualize the entire surgical instrument, including shaft and metallic clasper,\nenabling safe navigation within the surgical environment. The proposed method\ninvolves 2D tracking based on segmentation maps, facilitating creation of\nlabeled dataset without extensive ground-truth knowledge. Geometric changes in\n2D intervals express motion, and kinematics based algorithms process results\ninto 3D tracking information. Synthesized and experimental results in 2D and 3D\nmotion estimates demonstrate negligible errors, validating the method for\nlabeling and motion tracking of instruments in MIS videos. The conclusion\nunderscores the proposed 2D segmentation technique's simplicity and\ncomputational efficiency, emphasizing its potential as direct plug-in for 3D\nvisualization in instrument tracking and MIS practices.", "field": "Computer Science", "categories": "cs.CV,cs.SY,eess.IV,eess.SY"}, {"arxiv_id": "2401.09473", "title": "Business and ethical concerns in domestic Conversational Generative\n  AI-empowered multi-robot systems", "abstract": "Business and technology are intricately connected through logic and design.\nThey are equally sensitive to societal changes and may be devastated by\nscandal. Cooperative multi-robot systems (MRSs) are on the rise, allowing\nrobots of different types and brands to work together in diverse contexts.\nGenerative artificial intelligence has been a dominant topic in recent\nartificial intelligence (AI) discussions due to its capacity to mimic humans\nthrough the use of natural language and the production of media, including deep\nfakes. In this article, we focus specifically on the conversational aspects of\ngenerative AI, and hence use the term Conversational Generative artificial\nintelligence (CGI). Like MRSs, CGIs have enormous potential for revolutionizing\nprocesses across sectors and transforming the way humans conduct business. From\na business perspective, cooperative MRSs alone, with potential conflicts of\ninterest, privacy practices, and safety concerns, require ethical examination.\nMRSs empowered by CGIs demand multi-dimensional and sophisticated methods to\nuncover imminent ethical pitfalls. This study focuses on ethics in\nCGI-empowered MRSs while reporting the stages of developing the MORUL model.", "field": "Computer Science", "categories": "cs.CY,cs.AI"}, {"arxiv_id": "2401.09474", "title": "Weak Memory Demands Model-based Compiler Testing", "abstract": "A compiler bug arises if the behaviour of a compiled concurrent program, as\nallowed by its architecture memory model, is not a behaviour permitted by the\nsource program under its source model. One might reasonably think that most\ncompiler bugs have been found in the decade since the introduction of the C/C++\nmemory model. We observe that processor implementations are increasingly\nexploiting the behaviour of relaxed architecture models. As such, compiled\nprograms may exhibit bugs not seen on older hardware. To account for this we\nrequire model-based compiler testing.\n  While this observation is not surprising, its implications are broad.\nCompilers and their testing tools will need to be updated to follow hardware\nrelaxations, concurrent test generators will need to be improved, and\nassumptions of prior work will need revisiting. We explore these ideas using a\ncompiler toolchain bug we reported in LLVM.", "field": "Computer Science", "categories": "cs.PL,cs.AR,cs.SE,D.1.3; B.1.2; B.1.4; D.2.5"}, {"arxiv_id": "2401.09475", "title": "Triamese-ViT: A 3D-Aware Method for Robust Brain Age Estimation from\n  MRIs", "abstract": "The integration of machine learning in medicine has significantly improved\ndiagnostic precision, particularly in the interpretation of complex structures\nlike the human brain. Diagnosing challenging conditions such as Alzheimer's\ndisease has prompted the development of brain age estimation techniques. These\nmethods often leverage three-dimensional Magnetic Resonance Imaging (MRI)\nscans, with recent studies emphasizing the efficacy of 3D convolutional neural\nnetworks (CNNs) like 3D ResNet. However, the untapped potential of Vision\nTransformers (ViTs), known for their accuracy and interpretability, persists in\nthis domain due to limitations in their 3D versions. This paper introduces\nTriamese-ViT, an innovative adaptation of the ViT model for brain age\nestimation. Our model uniquely combines ViTs from three different orientations\nto capture 3D information, significantly enhancing accuracy and\ninterpretability. Tested on a dataset of 1351 MRI scans, Triamese-ViT achieves\na Mean Absolute Error (MAE) of 3.84, a 0.9 Spearman correlation coefficient\nwith chronological age, and a -0.29 Spearman correlation coefficient between\nthe brain age gap (BAG) and chronological age, significantly better than\nprevious methods for brian age estimation. A key innovation of Triamese-ViT is\nits capacity to generate a comprehensive 3D-like attention map, synthesized\nfrom 2D attention maps of each orientation-specific ViT. This feature is\nparticularly beneficial for in-depth brain age analysis and disease diagnosis,\noffering deeper insights into brain health and the mechanisms of age-related\nneural changes.", "field": "Computer Science", "categories": "cs.CV,cs.LG"}, {"arxiv_id": "2401.09476", "title": "A Framework for Agricultural Food Supply Chain using Blockchain", "abstract": "The main aim of the paper is to create a trust and transparency in the food\nsupply chain system, ensuring food safety for everyone with the help of\nBlockchain Technology. Food supply chain is the process of tracing a crop from\nthe farmer or producer to the buyer. With the advent of blockchain, providing a\nsafe and fraud-free environment for the provision of numerous agricultural\nnecessities has become much easier. Because of the globalization of trade, the\npresent supply chain market today includes various companies involving\nintegration of data, complex transactions and distribution. Information tamper\nresistance, supply-demand relationships, and traceable oversight are all\ndifficulties that arise as a result of this. Blockchain is a distributed ledger\ntechnology that can provide information that is resistant to tampering. This\nstrategy can eliminate the need for a centralized trusted authority,\nintermediaries, and business histories, allowing for increased production and\nsecurity while maintaining the highest levels of integrity, liability, and\nsafety. In order to have an integrity and transparency in food supply chain in\nthe agricultural sector, a framework is proposed here based on block chain and\nIoT.", "field": "Computer Science", "categories": "cs.CR,cs.AI"}, {"arxiv_id": "2401.09479", "title": "Uncertainty-Aware Hardware Trojan Detection Using Multimodal Deep\n  Learning", "abstract": "The risk of hardware Trojans being inserted at various stages of chip\nproduction has increased in a zero-trust fabless era. To counter this, various\nmachine learning solutions have been developed for the detection of hardware\nTrojans. While most of the focus has been on either a statistical or deep\nlearning approach, the limited number of Trojan-infected benchmarks affects the\ndetection accuracy and restricts the possibility of detecting zero-day Trojans.\nTo close the gap, we first employ generative adversarial networks to amplify\nour data in two alternative representation modalities, a graph and a tabular,\nensuring that the dataset is distributed in a representative manner. Further,\nwe propose a multimodal deep learning approach to detect hardware Trojans and\nevaluate the results from both early fusion and late fusion strategies. We also\nestimate the uncertainty quantification metrics of each prediction for\nrisk-aware decision-making. The outcomes not only confirms the efficacy of our\nproposed hardware Trojan detection method but also opens a new door for future\nstudies employing multimodality and uncertainty quantification to address other\nhardware security challenges.", "field": "Computer Science", "categories": "cs.CR,cs.AI,cs.LG"}, {"arxiv_id": "2401.09486", "title": "LoMA: Lossless Compressed Memory Attention", "abstract": "The ability to handle long texts is one of the most important capabilities of\nLarge Language Models (LLMs), but as the text length increases, the consumption\nof resources also increases dramatically. At present, reducing resource\nconsumption by compressing the KV cache is a common approach. Although there\nare many existing compression methods, they share a common drawback: the\ncompression is not lossless. That is, information is inevitably lost during the\ncompression process. If the compression rate is high, the probability of losing\nimportant information increases dramatically. We propose a new method, Lossless\nCompressed Memory Attention (LoMA), which allows for lossless compression of\ninformation into special memory token KV pairs according to a set compression\nratio. Our experiments have achieved remarkable results, demonstrating that\nLoMA can be efficiently trained and has very effective performance.", "field": "Computer Science", "categories": "cs.LG,cs.CL"}, {"arxiv_id": "2401.09488", "title": "A Universal System for OpenID Connect Sign-ins with Verifiable\n  Credentials and Cross-Device Flow", "abstract": "Self-Sovereign Identity (SSI), as a new and promising identity management\nparadigm, needs mechanisms that can ease a gradual transition of existing\nservices and developers towards it. Systems that bridge the gap between SSI and\nestablished identity and access management have been proposed but still lack\nadoption. We argue that they are all some combination of too complex, locked\ninto specific ecosystems, have no source code available, or are not\nsufficiently documented. We propose a comparatively simple system that enables\nSSI-based sign-ins for services that support the widespread OpenID Connect or\nOAuth 2.0 protocols. Its handling of claims is highly configurable through a\nsingle policy and designed for cross-device authentication flows involving a\nsmartphone identity wallet. For external interfaces, we solely rely on open\nstandards, such as the recent OpenID for Verifiable Credentials standards. We\nprovide our implementation as open-source software intended for prototyping and\nas a reference. Also, we contribute a detailed technical discussion of our\nparticular sign-in flow. To prove its feasibility, we have successfully tested\nit with existing software and realistic hardware.", "field": "Computer Science", "categories": "cs.CR,cs.SE"}, {"arxiv_id": "2401.09489", "title": "PUPAE: Intuitive and Actionable Explanations for Time Series Anomalies", "abstract": "In recent years there has been significant progress in time series anomaly\ndetection. However, after detecting an (perhaps tentative) anomaly, can we\nexplain it? Such explanations would be useful to triage anomalies. For example,\nin an oil refinery, should we respond to an anomaly by dispatching a hydraulic\nengineer, or an intern to replace the battery on a sensor? There have been some\nparallel efforts to explain anomalies, however many proposed techniques produce\nexplanations that are indirect, and often seem more complex than the anomaly\nthey seek to explain. Our review of the literature/checklists/user-manuals used\nby frontline practitioners in various domains reveals an interesting\nnear-universal commonality. Most practitioners discuss, explain and report\nanomalies in the following format: The anomaly would be like normal data A, if\nnot for the corruption B. The reader will appreciate that is a type of\ncounterfactual explanation. In this work we introduce a domain agnostic\ncounterfactual explanation technique to produce explanations for time series\nanomalies. As we will show, our method can produce both visual and text-based\nexplanations that are objectively correct, intuitive and in many circumstances,\ndirectly actionable.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.09491", "title": "Memory, Space, and Planning: Multiscale Predictive Representations", "abstract": "Memory is inherently entangled with prediction and planning. Flexible\nbehavior in biological and artificial agents depends on the interplay of\nlearning from the past and predicting the future in ever-changing environments.\nThis chapter reviews computational, behavioral, and neural evidence suggesting\nthese processes rely on learning the relational structure of experiences, known\nas cognitive maps, and draws two key takeaways. First, that these memory\nstructures are organized as multiscale, compact predictive representations in\nhippocampal and prefrontal cortex, or PFC, hierarchies. Second, we argue that\nsuch predictive memory structures are crucial to the complementary functions of\nthe hippocampus and PFC, both for enabling a recall of detailed and coherent\npast episodes as well as generalizing experiences at varying scales for\nefficient prediction and planning. These insights advance our understanding of\nmemory and planning mechanisms in the brain and hold significant implications\nfor advancing artificial intelligence systems.", "field": "Computer Science", "categories": "cs.AI"}, {"arxiv_id": "2401.09492", "title": "Uncertainty-Aware Calibration of a Hot-Wire Anemometer With Gaussian\n  Process Regression", "abstract": "Expensive ultrasonic anemometers are usually required to measure wind speed\naccurately. The aim of this work is to overcome the loss of accuracy of a low\ncost hot-wire anemometer caused by the changes of air temperature, by means of\na probabilistic calibration using Gaussian Process Regression. Gaussian Process\nRegression is a non-parametric, Bayesian, and supervised learning method\ndesigned to make predictions of an unknown target variable as a function of one\nor more known input variables. Our approach is validated against real datasets,\nobtaining a good performance in inferring the actual wind speed values. By\nperforming, before its real use in the field, a calibration of the hot-wire\nanemometer taking into account air temperature, permits that the wind speed can\nbe estimated for the typical range of ambient temperatures, including a\ngrounded uncertainty estimation for each speed measure.", "field": "Computer Science", "categories": "cs.LG,stat.AP,stat.ML"}, {"arxiv_id": "2401.09494", "title": "VeriBug: An Attention-based Framework for Bug-Localization in Hardware\n  Designs", "abstract": "In recent years, there has been an exponential growth in the size and\ncomplexity of System-on-Chip designs targeting different specialized\napplications. The cost of an undetected bug in these systems is much higher\nthan in traditional processor systems as it may imply the loss of property or\nlife. The problem is further exacerbated by the ever-shrinking time-to-market\nand ever-increasing demand to churn out billions of devices. Despite decades of\nresearch in simulation and formal methods for debugging and verification, it is\nstill one of the most time-consuming and resource intensive processes in\ncontemporary hardware design cycle. In this work, we propose VeriBug, which\nleverages recent advances in deep learning to accelerate debugging at the\nRegister-Transfer Level and generates explanations of likely root causes.\nFirst, VeriBug uses control-data flow graph of a hardware design and learns to\nexecute design statements by analyzing the context of operands and their\nassignments. Then, it assigns an importance score to each operand in a design\nstatement and uses that score for generating explanations for failures.\nFinally, VeriBug produces a heatmap highlighting potential buggy source code\nportions. Our experiments show that VeriBug can achieve an average bug\nlocalization coverage of 82.5% on open-source designs and different types of\ninjected bugs.", "field": "Computer Science", "categories": "cs.AR,cs.LG"}, {"arxiv_id": "2401.09495", "title": "IPR-NeRF: Ownership Verification meets Neural Radiance Field", "abstract": "Neural Radiance Field (NeRF) models have gained significant attention in the\ncomputer vision community in the recent past with state-of-the-art visual\nquality and produced impressive demonstrations. Since then, technopreneurs have\nsought to leverage NeRF models into a profitable business. Therefore, NeRF\nmodels make it worth the risk of plagiarizers illegally copying,\nre-distributing, or misusing those models. This paper proposes a comprehensive\nintellectual property (IP) protection framework for the NeRF model in both\nblack-box and white-box settings, namely IPR-NeRF. In the black-box setting, a\ndiffusion-based solution is introduced to embed and extract the watermark via a\ntwo-stage optimization process. In the white-box setting, a designated digital\nsignature is embedded into the weights of the NeRF model by adopting the sign\nloss objective. Our extensive experiments demonstrate that not only does our\napproach maintain the fidelity (\\ie, the rendering quality) of IPR-NeRF models,\nbut it is also robust against both ambiguity and removal attacks compared to\nprior arts.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.09496", "title": "Learning to Generalize over Subpartitions for Heterogeneity-aware Domain\n  Adaptive Nuclei Segmentation", "abstract": "Annotation scarcity and cross-modality/stain data distribution shifts are two\nmajor obstacles hindering the application of deep learning models for nuclei\nanalysis, which holds a broad spectrum of potential applications in digital\npathology. Recently, unsupervised domain adaptation (UDA) methods have been\nproposed to mitigate the distributional gap between different imaging\nmodalities for unsupervised nuclei segmentation in histopathology images.\nHowever, existing UDA methods are built upon the assumption that data\ndistributions within each domain should be uniform. Based on the\nover-simplified supposition, they propose to align the histopathology target\ndomain with the source domain integrally, neglecting severe intra-domain\ndiscrepancy over subpartitions incurred by mixed cancer types and sampling\norgans. In this paper, for the first time, we propose to explicitly consider\nthe heterogeneity within the histopathology domain and introduce open compound\ndomain adaptation (OCDA) to resolve the crux. In specific, a two-stage\ndisentanglement framework is proposed to acquire domain-invariant feature\nrepresentations at both image and instance levels. The holistic design\naddresses the limitations of existing OCDA approaches which struggle to capture\ninstance-wise variations. Two regularization strategies are specifically\ndevised herein to leverage the rich subpartition-specific characteristics in\nhistopathology images and facilitate subdomain decomposition. Moreover, we\npropose a dual-branch nucleus shape and structure preserving module to prevent\nnucleus over-generation and deformation in the synthesized images. Experimental\nresults on both cross-modality and cross-stain scenarios over a broad range of\ndiverse datasets demonstrate the superiority of our method compared with\nstate-of-the-art UDA and OCDA methods.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.09498", "title": "Technical Report: On the Convergence of Gossip Learning in the Presence\n  of Node Inaccessibility", "abstract": "Gossip learning (GL), as a decentralized alternative to federated learning\n(FL), is more suitable for resource-constrained wireless networks, such as\nFANETs that are formed by unmanned aerial vehicles (UAVs). GL can significantly\nenhance the efficiency and extend the battery life of UAV networks. Despite the\nadvantages, the performance of GL is strongly affected by data distribution,\ncommunication speed, and network connectivity. However, how these factors\ninfluence the GL convergence is still unclear. Existing work studied the\nconvergence of GL based on a virtual quantity for the sake of convenience,\nwhich fail to reflect the real state of the network when some nodes are\ninaccessible. In this paper, we formulate and investigate the impact of\ninaccessible nodes to GL under a dynamic network topology. We first decompose\nthe weight divergence by whether the node is accessible or not. Then, we\ninvestigate the GL convergence under the dynamic of node accessibility and\ntheoretically provide how the number of inaccessible nodes, data\nnon-i.i.d.-ness, and duration of inaccessibility affect the convergence.\nExtensive experiments are carried out in practical settings to comprehensively\nverify the correctness of our theoretical findings.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.09499", "title": "Functional Autoencoder for Smoothing and Representation Learning", "abstract": "A common pipeline in functional data analysis is to first convert the\ndiscretely observed data to smooth functions, and then represent the functions\nby a finite-dimensional vector of coefficients summarizing the information.\nExisting methods for data smoothing and dimensional reduction mainly focus on\nlearning the linear mappings from the data space to the representation space,\nhowever, learning only the linear representations may not be sufficient. In\nthis study, we propose to learn the nonlinear representations of functional\ndata using neural network autoencoders designed to process data in the form it\nis usually collected without the need of preprocessing. We design the encoder\nto employ a projection layer computing the weighted inner product of the\nfunctional data and functional weights over the observed timestamp, and the\ndecoder to apply a recovery layer that maps the finite-dimensional vector\nextracted from the functional data back to functional space using a set of\npredetermined basis functions. The developed architecture can accommodate both\nregularly and irregularly spaced data. Our experiments demonstrate that the\nproposed method outperforms functional principal component analysis in terms of\nprediction and classification, and maintains superior smoothing ability and\nbetter computational efficiency in comparison to the conventional autoencoders\nunder both linear and nonlinear settings.", "field": "Computer Science", "categories": "cs.LG,stat.ML"}, {"arxiv_id": "2401.09507", "title": "Deep Ensemble Shape Calibration: Multi-Field Post-hoc Calibration in\n  Online Advertising", "abstract": "In the e-commerce advertising scenario, estimating the true probabilities\n(known as a calibrated estimate) on CTR and CVR is critical and can directly\naffect the benefits of the buyer, seller and platform. Previous research has\nintroduced numerous solutions for addressing the calibration problem. These\nmethods typically involve the training of calibrators using a validation set\nand subsequently applying these calibrators to correct the original estimated\nvalues during online inference. However, what sets e-commerce advertising\nscenarios is the challenge of multi-field calibration. Multi-field calibration\ncan be subdivided into two distinct sub-problems: value calibration and shape\ncalibration. Value calibration is defined as no over- or under-estimation for\neach value under concerned fields. Shape calibration is defined as no over- or\nunder-estimation for each subset of the pCTR within the specified range under\ncondition of concerned fields. In order to achieve shape calibration and value\ncalibration, it is necessary to have a strong data utilization ability.Because\nthe quantity of pCTR specified range for single field-value sample is relative\nsmall, which makes the calibrator more difficult to train. However the existing\nmethods cannot simultaneously fulfill both value calibration and shape\ncalibration. To solve these problems, we propose a new method named Deep\nEnsemble Shape Calibration (DESC). We introduce innovative basis calibration\nfunctions, which enhance both function expression capabilities and data\nutilization by combining these basis calibration functions. A significant\nadvancement lies in the development of an allocator capable of allocating the\nmost suitable shape calibrators to different estimation error distributions\nwithin diverse fields and values.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.09509", "title": "Exploration of Activation Fault Reliability in Quantized Systolic\n  Array-Based DNN Accelerators", "abstract": "The stringent requirements for the Deep Neural Networks (DNNs) accelerator's\nreliability stand along with the need for reducing the computational burden on\nthe hardware platforms, i.e. reducing the energy consumption and execution time\nas well as increasing the efficiency of DNN accelerators. Moreover, the growing\ndemand for specialized DNN accelerators with tailored requirements,\nparticularly for safety-critical applications, necessitates a comprehensive\ndesign space exploration to enable the development of efficient and robust\naccelerators that meet those requirements. Therefore, the trade-off between\nhardware performance, i.e. area and delay, and the reliability of the DNN\naccelerator implementation becomes critical and requires tools for analysis.\nThis paper presents a comprehensive methodology for exploring and enabling a\nholistic assessment of the trilateral impact of quantization on model accuracy,\nactivation fault reliability, and hardware efficiency. A fully automated\nframework is introduced that is capable of applying various quantization-aware\ntechniques, fault injection, and hardware implementation, thus enabling the\nmeasurement of hardware parameters. Moreover, this paper proposes a novel\nlightweight protection technique integrated within the framework to ensure the\ndependable deployment of the final systolic-array-based FPGA implementation.\nThe experiments on established benchmarks demonstrate the analysis flow and the\nprofound implications of quantization on reliability, hardware performance, and\nnetwork accuracy, particularly concerning the transient faults in the network's\nactivations.", "field": "Computer Science", "categories": "cs.AR,cs.LG"}, {"arxiv_id": "2401.0951", "title": "Community Detection in the Multi-View Stochastic Block Model", "abstract": "This paper considers the problem of community detection on multiple\npotentially correlated graphs from an information-theoretical perspective. We\nfirst put forth a random graph model, called the multi-view stochastic block\nmodel (MVSBM), designed to generate correlated graphs on the same set of nodes\n(with cardinality $n$). The $n$ nodes are partitioned into two disjoint\ncommunities of equal size. The presence or absence of edges in the graphs for\neach pair of nodes depends on whether the two nodes belong to the same\ncommunity or not. The objective for the learner is to recover the hidden\ncommunities with observed graphs. Our technical contributions are two-fold: (i)\nWe establish an information-theoretic upper bound (Theorem~1) showing that\nexact recovery of community is achievable when the model parameters of MVSBM\nexceed a certain threshold. (ii) Conversely, we derive an information-theoretic\nlower bound (Theorem~2) showing that when the model parameters of MVSBM fall\nbelow the aforementioned threshold, then for any estimator, the expected number\nof misclassified nodes will always be greater than one. Our results for the\nMVSBM recover several prior results for community detection in the standard SBM\nas well as in multiple independent SBMs as special cases.", "field": "Computer Science", "categories": "cs.SI,cs.IT,cs.LG,eess.SP,math.IT"}, {"arxiv_id": "2401.09512", "title": "MLAAD: The Multi-Language Audio Anti-Spoofing Dataset", "abstract": "Text-to-Speech (TTS) technology brings significant advantages, such as giving\na voice to those with speech impairments, but also enables audio deepfakes and\nspoofs. The former mislead individuals and may propagate misinformation, while\nthe latter undermine voice biometric security systems. AI-based detection can\nhelp to address these challenges by automatically differentiating between\ngenuine and fabricated voice recordings. However, these models are only as good\nas their training data, which currently is severely limited due to an\noverwhelming concentration on English and Chinese audio in anti-spoofing\ndatabases, thus restricting its worldwide effectiveness. In response, this\npaper presents the Multi-Language Audio Anti-Spoof Dataset (MLAAD), created\nusing 52 TTS models, comprising 19 different architectures, to generate 160.1\nhours of synthetic voice in 23 different languages. We train and evaluate three\nstate-of-the-art deepfake detection models with MLAAD, and observe that MLAAD\ndemonstrates superior performance over comparable datasets like InTheWild or\nFakeOrReal when used as a training resource. Furthermore, in comparison with\nthe renowned ASVspoof 2019 dataset, MLAAD proves to be a complementary\nresource. In tests across eight datasets, MLAAD and ASVspoof 2019 alternately\noutperformed each other, both excelling on four datasets. By publishing MLAAD\nand making trained models accessible via an interactive webserver , we aim to\ndemocratize antispoofing technology, making it accessible beyond the realm of\nspecialists, thus contributing to global efforts against audio spoofing and\ndeepfakes.", "field": "Computer Science", "categories": "cs.SD,eess.AS"}, {"arxiv_id": "2401.09515", "title": "Enhancing Surveillance Camera FOV Quality via Semantic Line Detection\n  and Classification with Deep Hough Transform", "abstract": "The quality of recorded videos and images is significantly influenced by the\ncamera's field of view (FOV). In critical applications like surveillance\nsystems and self-driving cars, an inadequate FOV can give rise to severe safety\nand security concerns, including car accidents and thefts due to the failure to\ndetect individuals and objects. The conventional methods for establishing the\ncorrect FOV heavily rely on human judgment and lack automated mechanisms to\nassess video and image quality based on FOV. In this paper, we introduce an\ninnovative approach that harnesses semantic line detection and classification\nalongside deep Hough transform to identify semantic lines, thus ensuring a\nsuitable FOV by understanding 3D view through parallel lines. Our approach\nyields an effective F1 score of 0.729 on the public EgoCart dataset, coupled\nwith a notably high median score in the line placement metric. We illustrate\nthat our method offers a straightforward means of assessing the quality of the\ncamera's field of view, achieving a classification accuracy of 83.8\\%. This\nmetric can serve as a proxy for evaluating the potential performance of video\nand image quality applications.", "field": "Computer Science", "categories": "cs.CV,cs.LG"}, {"arxiv_id": "2401.09516", "title": "Accelerating Data Generation for Neural Operators via Krylov Subspace\n  Recycling", "abstract": "Learning neural operators for solving partial differential equations (PDEs)\nhas attracted great attention due to its high inference efficiency. However,\ntraining such operators requires generating a substantial amount of labeled\ndata, i.e., PDE problems together with their solutions. The data generation\nprocess is exceptionally time-consuming, as it involves solving numerous\nsystems of linear equations to obtain numerical solutions to the PDEs. Many\nexisting methods solve these systems independently without considering their\ninherent similarities, resulting in extremely redundant computations. To tackle\nthis problem, we propose a novel method, namely Sorting Krylov Recycling (SKR),\nto boost the efficiency of solving these systems, thus significantly\naccelerating data generation for neural operators training. To the best of our\nknowledge, SKR is the first attempt to address the time-consuming nature of\ndata generation for learning neural operators. The working horse of SKR is\nKrylov subspace recycling, a powerful technique for solving a series of\ninterrelated systems by leveraging their inherent similarities. Specifically,\nSKR employs a sorting algorithm to arrange these systems in a sequence, where\nadjacent systems exhibit high similarities. Then it equips a solver with Krylov\nsubspace recycling to solve the systems sequentially instead of independently,\nthus effectively enhancing the solving efficiency. Both theoretical analysis\nand extensive experiments demonstrate that SKR can significantly accelerate\nneural operator data generation, achieving a remarkable speedup of up to 13.9\ntimes.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.NA,math.NA"}, {"arxiv_id": "2401.09517", "title": "Dimensional Neuroimaging Endophenotypes: Neurobiological Representations\n  of Disease Heterogeneity Through Machine Learning", "abstract": "Machine learning has been increasingly used to obtain individualized\nneuroimaging signatures for disease diagnosis, prognosis, and response to\ntreatment in neuropsychiatric and neurodegenerative disorders. Therefore, it\nhas contributed to a better understanding of disease heterogeneity by\nidentifying disease subtypes that present significant differences in various\nbrain phenotypic measures. In this review, we first present a systematic\nliterature overview of studies using machine learning and multimodal MRI to\nunravel disease heterogeneity in various neuropsychiatric and neurodegenerative\ndisorders, including Alzheimer disease, schizophrenia, major depressive\ndisorder, autism spectrum disorder, multiple sclerosis, as well as their\npotential in transdiagnostic settings. Subsequently, we summarize relevant\nmachine learning methodologies and discuss an emerging paradigm which we call\ndimensional neuroimaging endophenotype (DNE). DNE dissects the neurobiological\nheterogeneity of neuropsychiatric and neurodegenerative disorders into a low\ndimensional yet informative, quantitative brain phenotypic representation,\nserving as a robust intermediate phenotype (i.e., endophenotype) largely\nreflecting underlying genetics and etiology. Finally, we discuss the potential\nclinical implications of the current findings and envision future research\navenues.", "field": "Computer Science", "categories": "cs.LG,eess.IV,q-bio.QM"}, {"arxiv_id": "2401.09518", "title": "On-Off Pattern Encoding and Path-Count Encoding as Deep Neural Network\n  Representations", "abstract": "Understanding the encoded representation of Deep Neural Networks (DNNs) has\nbeen a fundamental yet challenging objective. In this work, we focus on two\npossible directions for analyzing representations of DNNs by studying simple\nimage classification tasks. Specifically, we consider \\textit{On-Off pattern}\nand \\textit{PathCount} for investigating how information is stored in deep\nrepresentations. On-off pattern of a neuron is decided as `on' or `off'\ndepending on whether the neuron's activation after ReLU is non-zero or zero.\nPathCount is the number of paths that transmit non-zero energy from the input\nto a neuron. We investigate how neurons in the network encodes information by\nreplacing each layer's activation with On-Off pattern or PathCount and\nevaluating its effect on classification performance. We also examine\ncorrelation between representation and PathCount. Finally, we show a possible\nway to improve an existing DNN interpretation method, Class Activation Map\n(CAM), by directly utilizing On-Off or PathCount.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.09519", "title": "Privacy Engineering in Smart Home (SH) Systems: A Comprehensive Privacy\n  Threat Analysis and Risk Management Approach", "abstract": "Addressing trust concerns in Smart Home (SH) systems is imperative due to the\nlimited study on preservation approaches that focus on analyzing and evaluating\nprivacy threats for effective risk management. While most research focuses\nprimarily on user privacy, device data privacy, especially identity privacy, is\nalmost neglected, which can significantly impact overall user privacy within\nthe SH system. To this end, our study incorporates privacy engineering (PE)\nprinciples in the SH system that consider user and device data privacy. We\nstart with a comprehensive reference model for a typical SH system. Based on\nthe initial stage of LINDDUN PRO for the PE framework, we present a data flow\ndiagram (DFD) based on a typical SH reference model to better understand SH\nsystem operations. To identify potential areas of privacy threat and perform a\nprivacy threat analysis (PTA), we employ the LINDDUN PRO threat model. Then, a\nprivacy impact assessment (PIA) was carried out to implement privacy risk\nmanagement by prioritizing privacy threats based on their likelihood of\noccurrence and potential consequences. Finally, we suggest possible privacy\nenhancement techniques (PETs) that can mitigate some of these threats. The\nstudy aims to elucidate the main threats to privacy, associated risks, and\neffective prioritization of privacy control in SH systems. The outcomes of this\nstudy are expected to benefit SH stakeholders, including vendors, cloud\nproviders, users, researchers, and regulatory bodies in the SH systems domain.", "field": "Computer Science", "categories": "cs.CR"}, {"arxiv_id": "2401.0952", "title": "Port-Hamiltonian Neural ODE Networks on Lie Groups For Robot Dynamics\n  Learning and Control", "abstract": "Accurate models of robot dynamics are critical for safe and stable control\nand generalization to novel operational conditions. Hand-designed models,\nhowever, may be insufficiently accurate, even after careful parameter tuning.\nThis motivates the use of machine learning techniques to approximate the robot\ndynamics over a training set of state-control trajectories. The dynamics of\nmany robots are described in terms of their generalized coordinates on a matrix\nLie group, e.g. on SE(3) for ground, aerial, and underwater vehicles, and\ngeneralized velocity, and satisfy conservation of energy principles. This paper\nproposes a (port-)Hamiltonian formulation over a Lie group of the structure of\na neural ordinary differential equation (ODE) network to approximate the robot\ndynamics. In contrast to a black-box ODE network, our formulation guarantees\nenergy conservation principle and Lie group's constraints by construction and\nexplicitly accounts for energy-dissipation effect such as friction and drag\nforces in the dynamics model. We develop energy shaping and damping injection\ncontrol for the learned, potentially under-actuated Hamiltonian dynamics to\nenable a unified approach for stabilization and trajectory tracking with\nvarious robot platforms.", "field": "Computer Science", "categories": "cs.RO,cs.SY,eess.SY"}, {"arxiv_id": "2401.09543", "title": "Token Jumping in Planar Graphs has Linear Sized Kernels", "abstract": "Let $G$ be a planar graph and $I_s$ and $I_t$ be two independent sets in $G$,\neach of size $k$. We begin with a ``token'' on each vertex of $I_s$ and seek to\nmove all tokens to $I_t$, by repeated ``token jumping'', removing a single\ntoken from one vertex and placing it on another vertex. We require that each\nintermediate arrangement of tokens again specifies an independent set of size\n$k$. Given $G$, $I_s$, and $I_t$, we ask whether there exists a sequence of\ntoken jumps that transforms $I_s$ to $I_t$. When $k$ is part of the input, this\nproblem is known to be PSPACE-complete. However, it was shown by Ito,\nKami\\'nski, and Ono to be fixed-parameter tractable. That is, when $k$ is\nfixed, the problem can be solved in time polynomial in the order of $G$. Here\nwe strengthen the upper bound on the running time in terms of $k$ by showing\nthat the problem has a kernel of size linear in $k$. More precisely, we\ntransform an arbitrary input problem on a planar graph into an equivalent\nproblem on a (planar) graph with order $O(k)$.", "field": "Computer Science", "categories": "cs.DM,cs.CC,05C69, 05C10, 05C85"}, {"arxiv_id": "2401.09553", "title": "BERTologyNavigator: Advanced Question Answering with BERT-based\n  Semantics", "abstract": "The development and integration of knowledge graphs and language models has\nsignificance in artificial intelligence and natural language processing. In\nthis study, we introduce the BERTologyNavigator -- a two-phased system that\ncombines relation extraction techniques and BERT embeddings to navigate the\nrelationships within the DBLP Knowledge Graph (KG). Our approach focuses on\nextracting one-hop relations and labelled candidate pairs in the first phases.\nThis is followed by employing BERT's CLS embeddings and additional heuristics\nfor relation selection in the second phase. Our system reaches an F1 score of\n0.2175 on the DBLP QuAD Final test dataset for Scholarly QALD and 0.98 F1 score\non the subset of the DBLP QuAD test dataset during the QA phase.", "field": "Computer Science", "categories": "cs.CL,cs.AI,I.2.4; I.2.7"}, {"arxiv_id": "2401.09555", "title": "Improving Classification Performance With Human Feedback: Label a few,\n  we label the rest", "abstract": "In the realm of artificial intelligence, where a vast majority of data is\nunstructured, obtaining substantial amounts of labeled data to train supervised\nmachine learning models poses a significant challenge. To address this, we\ndelve into few-shot and active learning, where are goal is to improve AI models\nwith human feedback on a few labeled examples. This paper focuses on\nunderstanding how a continuous feedback loop can refine models, thereby\nenhancing their accuracy, recall, and precision through incremental human\ninput. By employing Large Language Models (LLMs) such as GPT-3.5, BERT, and\nSetFit, we aim to analyze the efficacy of using a limited number of labeled\nexamples to substantially improve model accuracy. We benchmark this approach on\nthe Financial Phrasebank, Banking, Craigslist, Trec, Amazon Reviews datasets to\nprove that with just a few labeled examples, we are able to surpass the\naccuracy of zero shot large language models to provide enhanced text\nclassification performance. We demonstrate that rather than needing to manually\nlabel millions of rows of data, we just need to label a few and the model can\neffectively predict the rest.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.CL"}, {"arxiv_id": "2401.09561", "title": "Sharing Knowledge in Multi-Task Deep Reinforcement Learning", "abstract": "We study the benefit of sharing representations among tasks to enable the\neffective use of deep neural networks in Multi-Task Reinforcement Learning. We\nleverage the assumption that learning from different tasks, sharing common\nproperties, is helpful to generalize the knowledge of them resulting in a more\neffective feature extraction compared to learning a single task. Intuitively,\nthe resulting set of features offers performance benefits when used by\nReinforcement Learning algorithms. We prove this by providing theoretical\nguarantees that highlight the conditions for which is convenient to share\nrepresentations among tasks, extending the well-known finite-time bounds of\nApproximate Value-Iteration to the multi-task setting. In addition, we\ncomplement our analysis by proposing multi-task extensions of three\nReinforcement Learning algorithms that we empirically evaluate on widely used\nReinforcement Learning benchmarks showing significant improvements over the\nsingle-task counterparts in terms of sample efficiency and performance.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.09566", "title": "Aligning Large Language Models with Counterfactual DPO", "abstract": "Advancements in large language models (LLMs) have demonstrated remarkable\ncapabilities across a diverse range of applications. These models excel in\ngenerating text completions that are contextually coherent and cover an\nextensive array of subjects. However, the vast datasets required for their\ntraining make aligning response styles during the pretraining and instruction\ntuning phases challenging. Consequently, an additional alignment phase is\ntypically employed, wherein the model is further trained with human preference\ndata to better align its outputs with human expectations. While this process\ndoesn't introduce new capabilities per se, it does accentuate generation styles\ninnate to the model. This paper explores the utilization of counterfactual\nprompting within the framework of Direct Preference Optimization (DPO) to align\nthe model's style without relying on human intervention. We demonstrate that\nthis method effectively instils desirable behaviour, mitigates undesirable\nones, and encourages the model to disregard inappropriate instructions. Our\nfindings suggest that counterfactual prompting with DPO presents a low-resource\nway to fine-tune LLMs to meet the demands for responsible and ethically aligned\nAI systems.", "field": "Computer Science", "categories": "cs.CL,cs.AI"}, {"arxiv_id": "2401.09572", "title": "Handling Large-scale Cardinality in building recommendation systems", "abstract": "Effective recommendation systems rely on capturing user preferences, often\nrequiring incorporating numerous features such as universally unique\nidentifiers (UUIDs) of entities. However, the exceptionally high cardinality of\nUUIDs poses a significant challenge in terms of model degradation and increased\nmodel size due to sparsity. This paper presents two innovative techniques to\naddress the challenge of high cardinality in recommendation systems.\nSpecifically, we propose a bag-of-words approach, combined with layer sharing,\nto substantially decrease the model size while improving performance. Our\ntechniques were evaluated through offline and online experiments on Uber use\ncases, resulting in promising results demonstrating our approach's\neffectiveness in optimizing recommendation systems and enhancing their overall\nperformance.", "field": "Computer Science", "categories": "cs.IR,cs.AI"}, {"arxiv_id": "2401.09574", "title": "Towards Scalable and Robust Model Versioning", "abstract": "As the deployment of deep learning models continues to expand across\nindustries, the threat of malicious incursions aimed at gaining access to these\ndeployed models is on the rise. Should an attacker gain access to a deployed\nmodel, whether through server breaches, insider attacks, or model inversion\ntechniques, they can then construct white-box adversarial attacks to manipulate\nthe model's classification outcomes, thereby posing significant risks to\norganizations that rely on these models for critical tasks. Model owners need\nmechanisms to protect themselves against such losses without the necessity of\nacquiring fresh training data - a process that typically demands substantial\ninvestments in time and capital.\n  In this paper, we explore the feasibility of generating multiple versions of\na model that possess different attack properties, without acquiring new\ntraining data or changing model architecture. The model owner can deploy one\nversion at a time and replace a leaked version immediately with a new version.\nThe newly deployed model version can resist adversarial attacks generated\nleveraging white-box access to one or all previously leaked versions. We show\ntheoretically that this can be accomplished by incorporating parameterized\nhidden distributions into the model training data, forcing the model to learn\ntask-irrelevant features uniquely defined by the chosen data. Additionally,\noptimal choices of hidden distributions can produce a sequence of model\nversions capable of resisting compound transferability attacks over time.\nLeveraging our analytical insights, we design and implement a practical model\nversioning method for DNN classifiers, which leads to significant robustness\nimprovements over existing methods. We believe our work presents a promising\ndirection for safeguarding DNN services beyond their initial deployment.", "field": "Computer Science", "categories": "cs.LG,cs.CR"}, {"arxiv_id": "2401.09575", "title": "Zero Trust Implementation in the Emerging Technologies Era: Survey", "abstract": "This paper presents a comprehensive analysis of the shift from the\ntraditional perimeter model of security to the Zero Trust (ZT) framework,\nemphasizing the key points in the transition and the practical application of\nZT. It outlines the differences between ZT policies and legacy security\npolicies, along with the significant events that have impacted the evolution of\nZT. Additionally, the paper explores the potential impacts of emerging\ntechnologies, such as Artificial Intelligence (AI) and quantum computing, on\nthe policy and implementation of ZT. The study thoroughly examines how AI can\nenhance ZT by utilizing Machine Learning (ML) algorithms to analyze patterns,\ndetect anomalies, and predict threats, thereby improving real-time\ndecision-making processes. Furthermore, the paper demonstrates how a chaos\ntheory-based approach, in conjunction with other technologies like eXtended\nDetection and Response (XDR), can effectively mitigate cyberattacks. As quantum\ncomputing presents new challenges to ZT and cybersecurity as a whole, the paper\ndelves into the intricacies of ZT migration, automation, and orchestration,\naddressing the complexities associated with these aspects. Finally, the paper\nprovides a best practice approach for the seamless implementation of ZT in\norganizations, laying out the proposed guidelines to facilitate organizations\nin their transition towards a more secure ZT model. The study aims to support\norganizations in successfully implementing ZT and enhancing their cybersecurity\nmeasures.", "field": "Computer Science", "categories": "cs.CR"}, {"arxiv_id": "2401.09582", "title": "eipy: An Open-Source Python Package for Multi-modal Data Integration\n  using Heterogeneous Ensembles", "abstract": "In this paper, we introduce eipy--an open-source Python package for\ndeveloping effective, multi-modal heterogeneous ensembles for classification.\neipy simultaneously provides both a rigorous, and user-friendly framework for\ncomparing and selecting the best-performing multi-modal data integration and\npredictive modeling methods by systematically evaluating their performance\nusing nested cross-validation. The package is designed to leverage\nscikit-learn-like estimators as components to build multi-modal predictive\nmodels. An up-to-date user guide, including API reference and tutorials, for\neipy is maintained at https://eipy.readthedocs.io . The main repository for\nthis project can be found on GitHub at https://github.com/GauravPandeyLab/eipy .", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.09585", "title": "Lower Bounds on $0$-Extension with Steiner Nodes", "abstract": "In the $0$-Extension problem, we are given an edge-weighted graph\n$G=(V,E,c)$, a set $T\\subseteq V$ of its vertices called terminals, and a\nsemi-metric $D$ over $T$, and the goal is to find an assignment $f$ of each\nnon-terminal vertex to a terminal, minimizing the sum, over all edges $(u,v)\\in\nE$, the product of the edge weight $c(u,v)$ and the distance $D(f(u),f(v))$\nbetween the terminals that $u,v$ are mapped to. Current best approximation\nalgorithms on $0$-Extension are based on rounding a linear programming\nrelaxation called the \\emph{semi-metric LP relaxation}. The integrality gap of\nthis LP, with best upper bound $O(\\log |T|/\\log\\log |T|)$ and best lower bound\n$\\Omega((\\log |T|)^{2/3})$, has been shown to be closely related to the best\nquality of cut and flow vertex sparsifiers.\n  We study a variant of the $0$-Extension problem where Steiner vertices are\nallowed. Specifically, we focus on the integrality gap of the same semi-metric\nLP relaxation to this new problem. Following from previous work, this new\nintegrality gap turns out to be closely related to the quality achievable by\ncut/flow vertex sparsifiers with Steiner nodes, a major open problem in graph\ncompression. Our main result is that the new integrality gap stays\nsuperconstant $\\Omega(\\log\\log |T|)$ even if we allow a super-linear\n$O(|T|\\log^{1-\\varepsilon}|T|)$ number of Steiner nodes.", "field": "Computer Science", "categories": "cs.DS"}, {"arxiv_id": "2401.09587", "title": "Bilevel Optimization under Unbounded Smoothness: A New Algorithm and\n  Convergence Analysis", "abstract": "Bilevel optimization is an important formulation for many machine learning\nproblems. Current bilevel optimization algorithms assume that the gradient of\nthe upper-level function is Lipschitz. However, recent studies reveal that\ncertain neural networks such as recurrent neural networks (RNNs) and\nlong-short-term memory networks (LSTMs) exhibit potential unbounded smoothness,\nrendering conventional bilevel optimization algorithms unsuitable. In this\npaper, we design a new bilevel optimization algorithm, namely BO-REP, to\naddress this challenge. This algorithm updates the upper-level variable using\nnormalized momentum and incorporates two novel techniques for updating the\nlower-level variable: \\textit{initialization refinement} and \\textit{periodic\nupdates}. Specifically, once the upper-level variable is initialized, a\nsubroutine is invoked to obtain a refined estimate of the corresponding optimal\nlower-level variable, and the lower-level variable is updated only after every\nspecific period instead of each iteration. When the upper-level problem is\nnonconvex and unbounded smooth, and the lower-level problem is strongly convex,\nwe prove that our algorithm requires $\\widetilde{\\mathcal{O}}(1/\\epsilon^4)$\niterations to find an $\\epsilon$-stationary point in the stochastic setting,\nwhere each iteration involves calling a stochastic gradient or Hessian-vector\nproduct oracle. Notably, this result matches the state-of-the-art complexity\nresults under the bounded smoothness setting and without mean-squared\nsmoothness of the stochastic gradient, up to logarithmic factors. Our proof\nrelies on novel technical lemmas for the periodically updated lower-level\nvariable, which are of independent interest. Our experiments on\nhyper-representation learning, hyperparameter optimization, and data\nhyper-cleaning for text classification tasks demonstrate the effectiveness of\nour proposed algorithm.", "field": "Computer Science", "categories": "cs.LG,math.OC"}, {"arxiv_id": "2401.09591", "title": "Bringing Social Computing to Secondary School Classrooms", "abstract": "Social computing is the study of how technology shapes human social\ninteractions. This topic has become increasingly relevant to secondary school\nstudents (ages 11--18) as more of young people's everyday social experiences\ntake place online, particularly with the continuing effects of the COVID-19\npandemic. However, social computing topics are rarely touched upon in existing\nmiddle and high school curricula. We seek to introduce concepts from social\ncomputing to secondary school students so they can understand how computing has\nwide-ranging social implications that touch upon their everyday lives, as well\nas think critically about both the positive and negative sides of different\nsocial technology designs.\n  In this report, we present a series of six lessons combining presentations\nand hands-on activities covering topics within social computing and detail our\nexperience teaching these lessons to approximately 1,405 students across 13\nmiddle and high schools in our local school district. We developed lessons\ncovering how social computing relates to the topics of Data Management,\nEncrypted Messaging, Human-Computer Interaction Careers, Machine Learning and\nBias, Misinformation, and Online Behavior. We found that 81.13% of students\nexpressed greater interest in the content of our lessons compared to their\ninterest in STEM overall. We also found from pre- and post-lesson comprehension\nquestions that 63.65% learned new concepts from the main activity. We release\nall lesson materials on a website for public use. From our experience, we\nobserved that students were engaged in these topics and found enjoyment in\nfinding connections between computing and their own lives.", "field": "Computer Science", "categories": "cs.CY"}, {"arxiv_id": "2401.09596", "title": "Efficient generative adversarial networks using linear\n  additive-attention Transformers", "abstract": "Although the capacity of deep generative models for image generation, such as\nDiffusion Models (DMs) and Generative Adversarial Networks (GANs), has\ndramatically improved in recent years, much of their success can be attributed\nto computationally expensive architectures. This has limited their adoption and\nuse to research laboratories and companies with large resources, while\nsignificantly raising the carbon footprint for training, fine-tuning, and\ninference. In this work, we present LadaGAN, an efficient generative\nadversarial network that is built upon a novel Transformer block named\nLadaformer. The main component of this block is a linear additive-attention\nmechanism that computes a single attention vector per head instead of the\nquadratic dot-product attention. We employ Ladaformer in both the generator and\ndiscriminator, which reduces the computational complexity and overcomes the\ntraining instabilities often associated with Transformer GANs. LadaGAN\nconsistently outperforms existing convolutional and Transformer GANs on\nbenchmark datasets at different resolutions while being significantly more\nefficient. Moreover, LadaGAN shows competitive performance compared to\nstate-of-the-art multi-step generative models (e.g. DMs) using orders of\nmagnitude less computational resources.", "field": "Computer Science", "categories": "cs.CV,cs.LG"}, {"arxiv_id": "2401.09601", "title": "Transient dynamics under structured perturbations: bridging unstructured\n  and structured pseudospectra", "abstract": "The structured $\\varepsilon$-stability radius is introduced as a quantity to\nassess the robustness of transient bounds of solutions to linear differential\nequations under structured perturbations of the matrix. This applies to general\nlinear structures such as complex or real matrices with a given sparsity\npattern or with restricted range and corange, or special classes such as\nToeplitz matrices. The notion conceptually combines unstructured and structured\npseudospectra in a joint pseudospectrum, allowing for the use of resolvent\nbounds as with unstructured pseudospectra and for structured perturbations as\nwith structured pseudospectra. We propose and study an algorithm for computing\nthe structured $\\varepsilon$-stability radius. This algorithm solves eigenvalue\noptimization problems via suitably discretized rank-1 matrix differential\nequations that originate from a gradient system. The proposed algorithm has\nessentially the same computational cost as the known rank-1 algorithms for\ncomputing unstructured and structured stability radii. Numerical experiments\nillustrate the behavior of the algorithm.", "field": "Computer Science", "categories": "math.NA,cs.NA,15A18, 65F15, 93D40"}, {"arxiv_id": "2401.09603", "title": "Rethinking FID: Towards a Better Evaluation Metric for Image Generation", "abstract": "As with many machine learning problems, the progress of image generation\nmethods hinges on good evaluation metrics. One of the most popular is the\nFrechet Inception Distance (FID). FID estimates the distance between a\ndistribution of Inception-v3 features of real images, and those of images\ngenerated by the algorithm. We highlight important drawbacks of FID:\nInception's poor representation of the rich and varied content generated by\nmodern text-to-image models, incorrect normality assumptions, and poor sample\ncomplexity. We call for a reevaluation of FID's use as the primary quality\nmetric for generated images. We empirically demonstrate that FID contradicts\nhuman raters, it does not reflect gradual improvement of iterative\ntext-to-image models, it does not capture distortion levels, and that it\nproduces inconsistent results when varying the sample size. We also propose an\nalternative new metric, CMMD, based on richer CLIP embeddings and the maximum\nmean discrepancy distance with the Gaussian RBF kernel. It is an unbiased\nestimator that does not make any assumptions on the probability distribution of\nthe embeddings and is sample efficient. Through extensive experiments and\nanalysis, we demonstrate that FID-based evaluations of text-to-image models may\nbe unreliable, and that CMMD offers a more robust and reliable assessment of\nimage quality.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.09604", "title": "MedBlindTuner: Towards Privacy-preserving Fine-tuning on Biomedical\n  Images with Transformers and Fully Homomorphic Encryption", "abstract": "Advancements in machine learning (ML) have significantly revolutionized\nmedical image analysis, prompting hospitals to rely on external ML services.\nHowever, the exchange of sensitive patient data, such as chest X-rays, poses\ninherent privacy risks when shared with third parties. Addressing this concern,\nwe propose MedBlindTuner, a privacy-preserving framework leveraging fully\nhomomorphic encryption (FHE) and a data-efficient image transformer (DEiT).\nMedBlindTuner enables the training of ML models exclusively on FHE-encrypted\nmedical images. Our experimental evaluation demonstrates that MedBlindTuner\nachieves comparable accuracy to models trained on non-encrypted images,\noffering a secure solution for outsourcing ML computations while preserving\npatient data privacy. To the best of our knowledge, this is the first work that\nuses data-efficient image transformers and fully homomorphic encryption in this\ndomain.", "field": "Computer Science", "categories": "cs.CR,cs.CV,cs.LG"}, {"arxiv_id": "2401.09605", "title": "Charting a Path to Efficient Onboarding: The Role of Software\n  Visualization", "abstract": "Background. Within the software industry, it is commonly estimated that\nsoftware professionals invest a substantial portion of their work hours in the\nprocess of understanding existing systems. In this context, an ineffective\ntechnical onboarding process, which introduces newcomers to software under\ndevelopment, can result in a prolonged period for them to absorb the necessary\nknowledge required to become productive in their roles. Goal. The present study\naims to explore the familiarity of managers, leaders, and developers with\nsoftware visualization tools and how these tools are employed to facilitate the\ntechnical onboarding of new team members. Method. To address the research\nproblem, we built upon the insights gained through the literature and embraced\na sequential exploratory approach. This approach incorporated quantitative and\nqualitative analyses of data collected from practitioners using questionnaires\nand semi-structured interviews. Findings. Our findings demonstrate a gap\nbetween the concept of software visualization and the practical use of\nonboarding tools and techniques. Overall, practitioners do not systematically\nincorporate software visualization tools into their technical onboarding\nprocesses due to a lack of conceptual understanding and awareness of their\npotential benefits. Conclusion. The software industry could benefit from\nstandardized and evolving onboarding models, improved by incorporating software\nvisualization techniques and tools to support program comprehension of\nnewcomers in the software projects.", "field": "Computer Science", "categories": "cs.SE"}, {"arxiv_id": "2401.09606", "title": "Robustness Evaluation of Machine Learning Models for Robot Arm Action\n  Recognition in Noisy Environments", "abstract": "In the realm of robot action recognition, identifying distinct but spatially\nproximate arm movements using vision systems in noisy environments poses a\nsignificant challenge. This paper studies robot arm action recognition in noisy\nenvironments using machine learning techniques. Specifically, a vision system\nis used to track the robot's movements followed by a deep learning model to\nextract the arm's key points. Through a comparative analysis of machine\nlearning methods, the effectiveness and robustness of this model are assessed\nin noisy environments. A case study was conducted using the Tic-Tac-Toe game in\na 3-by-3 grid environment, where the focus is to accurately identify the\nactions of the arms in selecting specific locations within this constrained\nenvironment. Experimental results show that our approach can achieve precise\nkey point detection and action classification despite the addition of noise and\nuncertainties to the dataset.", "field": "Computer Science", "categories": "cs.CV,cs.LG,cs.RO"}, {"arxiv_id": "2401.09607", "title": "Land Cover Image Classification", "abstract": "Land Cover (LC) image classification has become increasingly significant in\nunderstanding environmental changes, urban planning, and disaster management.\nHowever, traditional LC methods are often labor-intensive and prone to human\nerror. This paper explores state-of-the-art deep learning models for enhanced\naccuracy and efficiency in LC analysis. We compare convolutional neural\nnetworks (CNN) against transformer-based methods, showcasing their applications\nand advantages in LC studies. We used EuroSAT, a patch-based LC classification\ndata set based on Sentinel-2 satellite images and achieved state-of-the-art\nresults using current transformer models.", "field": "Computer Science", "categories": "cs.CV,cs.LG,eess.IV,I.2.10"}, {"arxiv_id": "2401.09608", "title": "Hidden Populations in Software Engineering: Challenges, Lessons Learned,\n  and Opportunities", "abstract": "The growing emphasis on studying equity, diversity, and inclusion within\nsoftware engineering has amplified the need to explore hidden populations\nwithin this field. Exploring hidden populations becomes important to obtain\ninvaluable insights into the experiences, challenges, and perspectives of\nunderrepresented groups in software engineering and, therefore, devise\nstrategies to make the software industry more diverse. However, studying these\nhidden populations presents multifaceted challenges, including the complexities\nassociated with identifying and engaging participants due to their marginalized\nstatus. In this paper, we discuss our experiences and lessons learned while\nconducting multiple studies involving hidden populations in software\nengineering. We emphasize the importance of recognizing and addressing these\nchallenges within the software engineering research community to foster a more\ninclusive and comprehensive understanding of diverse populations of software\nprofessionals.", "field": "Computer Science", "categories": "cs.SE"}, {"arxiv_id": "2401.09615", "title": "Learning Shortcuts: On the Misleading Promise of NLU in Language Models", "abstract": "The advent of large language models (LLMs) has enabled significant\nperformance gains in the field of natural language processing. However, recent\nstudies have found that LLMs often resort to shortcuts when performing tasks,\ncreating an illusion of enhanced performance while lacking generalizability in\ntheir decision rules. This phenomenon introduces challenges in accurately\nassessing natural language understanding in LLMs. Our paper provides a concise\nsurvey of relevant research in this area and puts forth a perspective on the\nimplications of shortcut learning in the evaluation of language models,\nspecifically for NLU tasks. This paper urges more research efforts to be put\ntowards deepening our comprehension of shortcut learning, contributing to the\ndevelopment of more robust language models, and raising the standards of NLU\nevaluation in real-world scenarios.", "field": "Computer Science", "categories": "cs.CL,cs.AI"}, {"arxiv_id": "2401.0962", "title": "Cost-effective and performant virtual WANs with CORNIFER", "abstract": "Virtual wide-area networks (WANs) are WAN-as-a-service cloud offerings that\naim to bring the performance benefits of dedicated wide-area interconnects to\nenterprise customers. In this work, we show that the topology of a virtual WAN\ncan render it both performance and cost inefficient. We develop Cornifer, a\ntool that designs virtual WAN topologies by deciding the number of virtual WAN\nnodes and their location in the cloud to minimize connection latency at low\ncost to enterprises. By leveraging millions of latency measurements from\nvantage points across the world to cloud points of presence, Cornifer designs\nvirtual WAN topologies that improve weighted client latency by 26% and lower\ncost by 28% compared to the state-of-the-art. Cornifer identifies virtual WAN\ntopologies at the Pareto frontier of the deployment cost vs. connection latency\ntrade-off and proposes a heuristic for automatic selection of Pareto-optimal\nvirtual WAN topologies for enterprises.", "field": "Computer Science", "categories": "cs.NI,cs.PF,C.2.1; C.4"}, {"arxiv_id": "2401.09621", "title": "XTable in Action: Seamless Interoperability in Data Lakes", "abstract": "Contemporary approaches to data management are increasingly relying on\nunified analytics and AI platforms to foster collaboration, interoperability,\nseamless access to reliable data, and high performance. Data Lakes featuring\nopen standard table formats such as Delta Lake, Apache Hudi, and Apache Iceberg\nare central components of these data architectures. Choosing the right format\nfor managing a table is crucial for achieving the objectives mentioned above.\nThe challenge lies in selecting the best format, a task that is onerous and can\nyield temporary results, as the ideal choice may shift over time with data\ngrowth, evolving workloads, and the competitive development of table formats\nand processing engines. Moreover, restricting data access to a single format\ncan hinder data sharing resulting in diminished business value over the long\nterm. The ability to seamlessly interoperate between formats and with\nnegligible overhead can effectively address these challenges. Our solution in\nthis direction is an innovative omni-directional translator, XTable, that\nfacilitates writing data in one format and reading it in any format, thus\nachieving the desired format interoperability. In this work, we demonstrate the\neffectiveness of XTable through application scenarios inspired by real-world\nuse cases.", "field": "Computer Science", "categories": "cs.DB"}, {"arxiv_id": "2401.09622", "title": "SMOOTHIE: A Theory of Hyper-parameter Optimization for Software\n  Analytics", "abstract": "Hyper-parameter optimization is the black art of tuning a learner's control\nparameters. In software analytics, a repeated result is that such tuning can\nresult in dramatic performance improvements. Despite this, hyper-parameter\noptimization is often applied rarely or poorly in software analytics--perhaps\ndue to the CPU cost of exploring all those parameter options can be\nprohibitive.\n  We theorize that learners generalize better when the loss landscape is\n``smooth''. This theory is useful since the influence on ``smoothness'' of\ndifferent hyper-parameter choices can be tested very quickly (e.g. for a deep\nlearner, after just one epoch).\n  To test this theory, this paper implements and tests SMOOTHIE, a novel\nhyper-parameter optimizer that guides its optimizations via considerations of\n``smothness''. The experiments of this paper test SMOOTHIE on numerous SE tasks\nincluding (a) GitHub issue lifetime prediction; (b) detecting false alarms in\nstatic code warnings; (c) defect prediction, and (d) a set of standard ML\ndatasets. In all these experiments, SMOOTHIE out-performed state-of-the-art\noptimizers. Better yet, SMOOTHIE ran 300% faster than the prior state-of-the\nart. We hence conclude that this theory (that hyper-parameter optimization is\nbest viewed as a ``smoothing'' function for the decision landscape), is both\ntheoretically interesting and practically very useful.\n  To support open science and other researchers working in this area, all our\nscripts and datasets are available on-line at\nhttps://github.com/yrahul3910/smoothness-hpo/.", "field": "Computer Science", "categories": "cs.SE,cs.LG"}, {"arxiv_id": "2401.09628", "title": "Polynomial Convergence of Bandit No-Regret Dynamics in Congestion Games", "abstract": "We introduce an online learning algorithm in the bandit feedback model that,\nonce adopted by all agents of a congestion game, results in game-dynamics that\nconverge to an $\\epsilon$-approximate Nash Equilibrium in a polynomial number\nof rounds with respect to $1/\\epsilon$, the number of players and the number of\navailable resources. The proposed algorithm also guarantees sublinear regret to\nany agent adopting it. As a result, our work answers an open question from\narXiv:2206.01880 and extends the recent results of arXiv:2306.15543 to the\nbandit feedback model. We additionally establish that our online learning\nalgorithm can be implemented in polynomial time for the important special case\nof Network Congestion Games on Directed Acyclic Graphs (DAG) by constructing an\nexact $1$-barycentric spanner for DAGs.", "field": "Computer Science", "categories": "cs.GT"}, {"arxiv_id": "2401.09629", "title": "Multiple Locally Linear Kernel Machines", "abstract": "In this paper we propose a new non-linear classifier based on a combination\nof locally linear classifiers. A well known optimization formulation is given\nas we cast the problem in a $\\ell_1$ Multiple Kernel Learning (MKL) problem\nusing many locally linear kernels. Since the number of such kernels is huge, we\nprovide a scalable generic MKL training algorithm handling streaming kernels.\nWith respect to the inference time, the resulting classifier fits the gap\nbetween high accuracy but slow non-linear classifiers (such as classical MKL)\nand fast but low accuracy linear classifiers.", "field": "Computer Science", "categories": "cs.LG,stat.ML"}, {"arxiv_id": "2401.09631", "title": "Physics-Informed Calibration of Aeromagnetic Compensation in Magnetic\n  Navigation Systems using Liquid Time-Constant Networks", "abstract": "Magnetic navigation (MagNav) is a rising alternative to the Global\nPositioning System (GPS) and has proven useful for aircraft navigation.\nTraditional aircraft navigation systems, while effective, face limitations in\nprecision and reliability in certain environments and against attacks. Airborne\nMagNav leverages the Earth's magnetic field to provide accurate positional\ninformation. However, external magnetic fields induced by aircraft electronics\nand Earth's large-scale magnetic fields disrupt the weaker signal of interest.\nWe introduce a physics-informed approach using Tolles-Lawson coefficients for\ncompensation and Liquid Time-Constant Networks (LTCs) to remove complex, noisy\nsignals derived from the aircraft's magnetic sources. Using real flight data\nwith magnetometer measurements and aircraft measurements, we observe up to a\n64% reduction in aeromagnetic compensation error (RMSE nT), outperforming\nconventional models. This significant improvement underscores the potential of\na physics-informed, machine learning approach for extracting clean, reliable,\nand accurate magnetic signals for MagNav positional estimation.", "field": "Computer Science", "categories": "cs.LG,cs.SY,eess.SY,physics.comp-ph,physics.geo-ph"}, {"arxiv_id": "2401.09637", "title": "Impact of Large Language Model Assistance on Patients Reading Clinical\n  Notes: A Mixed-Methods Study", "abstract": "Patients derive numerous benefits from reading their clinical notes,\nincluding an increased sense of control over their health and improved\nunderstanding of their care plan. However, complex medical concepts and jargon\nwithin clinical notes hinder patient comprehension and may lead to anxiety. We\ndeveloped a patient-facing tool to make clinical notes more readable,\nleveraging large language models (LLMs) to simplify, extract information from,\nand add context to notes. We prompt engineered GPT-4 to perform these\naugmentation tasks on real clinical notes donated by breast cancer survivors\nand synthetic notes generated by a clinician, a total of 12 notes with 3868\nwords. In June 2023, 200 female-identifying US-based participants were randomly\nassigned three clinical notes with varying levels of augmentations using our\ntool. Participants answered questions about each note, evaluating their\nunderstanding of follow-up actions and self-reported confidence. We found that\naugmentations were associated with a significant increase in action\nunderstanding score (0.63 $\\pm$ 0.04 for select augmentations, compared to 0.54\n$\\pm$ 0.02 for the control) with p=0.002. In-depth interviews of\nself-identifying breast cancer patients (N=7) were also conducted via video\nconferencing. Augmentations, especially definitions, elicited positive\nresponses among the seven participants, with some concerns about relying on\nLLMs. Augmentations were evaluated for errors by clinicians, and we found\nmisleading errors occur, with errors more common in real donated notes than\nsynthetic notes, illustrating the importance of carefully written clinical\nnotes. Augmentations improve some but not all readability metrics. This work\ndemonstrates the potential of LLMs to improve patients' experience with\nclinical notes at a lower burden to clinicians. However, having a human in the\nloop is important to correct potential model errors.", "field": "Computer Science", "categories": "cs.HC,cs.AI,cs.CL"}, {"arxiv_id": "2401.0964", "title": "Blackout Mitigation via Physics-guided RL", "abstract": "This paper considers the sequential design of remedial control actions in\nresponse to system anomalies for the ultimate objective of preventing\nblackouts. A physics-guided reinforcement learning (RL) framework is designed\nto identify effective sequences of real-time remedial look-ahead decisions\naccounting for the long-term impact on the system's stability. The paper\nconsiders a space of control actions that involve both discrete-valued\ntransmission line-switching decisions (line reconnections and removals) and\ncontinuous-valued generator adjustments. To identify an effective blackout\nmitigation policy, a physics-guided approach is designed that uses power-flow\nsensitivity factors associated with the power transmission network to guide the\nRL exploration during agent training. Comprehensive empirical evaluations using\nthe open-source Grid2Op platform demonstrate the notable advantages of\nincorporating physical signals into RL decisions, establishing the gains of the\nproposed physics-guided approach compared to its black box counterparts. One\nimportant observation is that strategically~\\emph{removing} transmission lines,\nin conjunction with multiple real-time generator adjustments, often renders\neffective long-term decisions that are likely to prevent or delay blackouts.", "field": "Computer Science", "categories": "eess.SY,cs.AI,cs.SY"}, {"arxiv_id": "2401.09641", "title": "Functional Linear Non-Gaussian Acyclic Model for Causal Discovery", "abstract": "In causal discovery, non-Gaussianity has been used to characterize the\ncomplete configuration of a Linear Non-Gaussian Acyclic Model (LiNGAM),\nencompassing both the causal ordering of variables and their respective\nconnection strengths. However, LiNGAM can only deal with the finite-dimensional\ncase. To expand this concept, we extend the notion of variables to encompass\nvectors and even functions, leading to the Functional Linear Non-Gaussian\nAcyclic Model (Func-LiNGAM). Our motivation stems from the desire to identify\ncausal relationships in brain-effective connectivity tasks involving, for\nexample, fMRI and EEG datasets. We demonstrate why the original LiNGAM fails to\nhandle these inherently infinite-dimensional datasets and explain the\navailability of functional data analysis from both empirical and theoretical\nperspectives. {We establish theoretical guarantees of the identifiability of\nthe causal relationship among non-Gaussian random vectors and even random\nfunctions in infinite-dimensional Hilbert spaces.} To address the issue of\nsparsity in discrete time points within intrinsic infinite-dimensional\nfunctional data, we propose optimizing the coordinates of the vectors using\nfunctional principal component analysis. Experimental results on synthetic data\nverify the ability of the proposed framework to identify causal relationships\namong multivariate functions using the observed samples. For real data, we\nfocus on analyzing the brain connectivity patterns derived from fMRI data.", "field": "Computer Science", "categories": "cs.LG,math.ST,q-bio.NC,stat.ME,stat.TH"}, {"arxiv_id": "2401.09646", "title": "ClimateGPT: Towards AI Synthesizing Interdisciplinary Research on\n  Climate Change", "abstract": "This paper introduces ClimateGPT, a model family of domain-specific large\nlanguage models that synthesize interdisciplinary research on climate change.\nWe trained two 7B models from scratch on a science-oriented dataset of 300B\ntokens. For the first model, the 4.2B domain-specific tokens were included\nduring pre-training and the second was adapted to the climate domain after\npre-training. Additionally, ClimateGPT-7B, 13B and 70B are continuously\npre-trained from Llama~2 on a domain-specific dataset of 4.2B tokens. Each\nmodel is instruction fine-tuned on a high-quality and human-generated\ndomain-specific dataset that has been created in close cooperation with climate\nscientists. To reduce the number of hallucinations, we optimize the model for\nretrieval augmentation and propose a hierarchical retrieval strategy. To\nincrease the accessibility of our model to non-English speakers, we propose to\nmake use of cascaded machine translation and show that this approach can\nperform comparably to natively multilingual models while being easier to scale\nto a large number of languages. Further, to address the intrinsic\ninterdisciplinary aspect of climate change we consider different research\nperspectives. Therefore, the model can produce in-depth answers focusing on\ndifferent perspectives in addition to an overall answer. We propose a suite of\nautomatic climate-specific benchmarks to evaluate LLMs. On these benchmarks,\nClimateGPT-7B performs on par with the ten times larger Llama-2-70B Chat model\nwhile not degrading results on general domain benchmarks. Our human evaluation\nconfirms the trends we saw in our benchmarks. All models were trained and\nevaluated using renewable energy and are released publicly.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.CL"}, {"arxiv_id": "2401.09647", "title": "Characterizing Online Eating Disorder Communities with Large Language\n  Models", "abstract": "The rise in eating disorders, a dangerous mental health condition with high\nmortality and morbidity, has been linked to the proliferation of idealized body\nimages on social media. However, the link between social media and eating\ndisorders is far more complex. We argue that social media platforms create a\nfeedback loop that amplifies the growth of content and communities that promote\neating disorders like anorexia and bulimia. Specifically, social media\nplatforms make it easy for vulnerable individuals to find and connect to\nlike-minded others, while group dynamic processes encourage them to stay\nengaged within communities that promote and glorify harmful behaviors linked to\neating disorders. We characterize this dynamic empirically through a\ncombination of network and language analysis. We describe a novel framework\nthat leverages large language models to analyze the discourse within online\ncommunities and probe their attitudes on topics related to eating disorders to\nidentify potentially harmful content. Our work emphasizes the need for better\nsocial media moderation to disrupt harmful feedback loops and protect\nvulnerable individuals.", "field": "Computer Science", "categories": "cs.SI,cs.CL,cs.CY"}, {"arxiv_id": "2401.09651", "title": "Convex and Bilevel Optimization for Neuro-Symbolic Inference and\n  Learning", "abstract": "We address a key challenge for neuro-symbolic (NeSy) systems by leveraging\nconvex and bilevel optimization techniques to develop a general gradient-based\nframework for end-to-end neural and symbolic parameter learning. The\napplicability of our framework is demonstrated with NeuPSL, a state-of-the-art\nNeSy architecture. To achieve this, we propose a smooth primal and dual\nformulation of NeuPSL inference and show learning gradients are functions of\nthe optimal dual variables. Additionally, we develop a dual block coordinate\ndescent algorithm for the new formulation that naturally exploits warm-starts.\nThis leads to over 100x learning runtime improvements over the current best\nNeuPSL inference method. Finally, we provide extensive empirical evaluations\nacross $8$ datasets covering a range of tasks and demonstrate our learning\nframework achieves up to a 16% point prediction performance improvement over\nalternative learning methods.", "field": "Computer Science", "categories": "cs.LG,cs.AI,math.OC"}, {"arxiv_id": "2401.09654", "title": "User Study: Comparison of Picture Passwords and Current Login Approaches", "abstract": "In this research, we conduct a user study that compares different\ncomputer/system authentication methods. More specifically, we look into\ncomparing regular password authentication with picture authentication. Picture\nauthentication means selecting a sequence of pictures from a set of pictures\n(30). We present users with both interfaces; various metrics are tracked while\nthe participants conduct a variety of user authentication-related tasks. Other\nmetrics include user perception of security with such technologies.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.09656", "title": "Mobility Accelerates Learning: Convergence Analysis on Hierarchical\n  Federated Learning in Vehicular Networks", "abstract": "Hierarchical federated learning (HFL) enables distributed training of models\nacross multiple devices with the help of several edge servers and a cloud edge\nserver in a privacy-preserving manner. In this paper, we consider HFL with\nhighly mobile devices, mainly targeting at vehicular networks. Through\nconvergence analysis, we show that mobility influences the convergence speed by\nboth fusing the edge data and shuffling the edge models. While mobility is\nusually considered as a challenge from the perspective of communication, we\nprove that it increases the convergence speed of HFL with edge-level\nheterogeneous data, since more diverse data can be incorporated. Furthermore,\nwe demonstrate that a higher speed leads to faster convergence, since it\naccelerates the fusion of data. Simulation results show that mobility increases\nthe model accuracy of HFL by up to 15.1% when training a convolutional neural\nnetwork on the CIFAR-10 dataset.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.DC"}, {"arxiv_id": "2401.09658", "title": "An adaptive optimal control approach to monocular depth observability\n  maximization", "abstract": "This paper presents an integral concurrent learning (ICL)-based observer for\na monocular camera to accurately estimate the Euclidean distance to features on\na stationary object, under the restriction that state information is\nunavailable. Using distance estimates, an infinite horizon optimal regulation\nproblem is solved, which aims to regulate the camera to a goal location while\nmaximizing feature observability. Lyapunov-based stability analysis is used to\nguarantee exponential convergence of depth estimates and input-to-state\nstability of the goal location relative to the camera. The effectiveness of the\nproposed approach is verified in simulation, and a table illustrating improved\nobservability is provided.", "field": "Computer Science", "categories": "eess.SY,cs.SY"}, {"arxiv_id": "2401.09666", "title": "Traffic Smoothing Controllers for Autonomous Vehicles Using Deep\n  Reinforcement Learning and Real-World Trajectory Data", "abstract": "Designing traffic-smoothing cruise controllers that can be deployed onto\nautonomous vehicles is a key step towards improving traffic flow, reducing\ncongestion, and enhancing fuel efficiency in mixed autonomy traffic. We bypass\nthe common issue of having to carefully fine-tune a large traffic\nmicrosimulator by leveraging real-world trajectory data from the I-24 highway\nin Tennessee, replayed in a one-lane simulation. Using standard deep\nreinforcement learning methods, we train energy-reducing wave-smoothing\npolicies. As an input to the agent, we observe the speed and distance of only\nthe vehicle in front, which are local states readily available on most recent\nvehicles, as well as non-local observations about the downstream state of the\ntraffic. We show that at a low 4% autonomous vehicle penetration rate, we\nachieve significant fuel savings of over 15% on trajectories exhibiting many\nstop-and-go waves. Finally, we analyze the smoothing effect of the controllers\nand demonstrate robustness to adding lane-changing into the simulation as well\nas the removal of downstream information.", "field": "Computer Science", "categories": "eess.SY,cs.AI,cs.MA,cs.SY"}, {"arxiv_id": "2401.0967", "title": "DistServe: Disaggregating Prefill and Decoding for Goodput-optimized\n  Large Language Model Serving", "abstract": "DistServe improves the performance of large language models (LLMs) serving by\ndisaggregating the prefill and decoding computation. Existing LLM serving\nsystems colocate the two phases and batch the computation of prefill and\ndecoding across all users and requests. We find that this strategy not only\nleads to strong prefill-decoding interferences but also couples the resource\nallocation and parallelism plans for both phases. LLM applications often\nemphasize individual latency for each phase: time to first token (TTFT) for the\nprefill phase and time per output token (TPOT) of each request for the decoding\nphase. In the presence of stringent latency requirements, existing systems have\nto prioritize one latency over the other, or over-provision compute resources\nto meet both.\n  DistServe assigns prefill and decoding computation to different GPUs, hence\neliminating prefill-decoding interferences. Given the application's TTFT and\nTPOT requirements, DistServe co-optimizes the resource allocation and\nparallelism strategy tailored for each phase. DistServe also places the two\nphases according to the serving cluster's bandwidth to minimize the\ncommunication caused by disaggregation. As a result, DistServe significantly\nimproves LLM serving performance in terms of the maximum rate that can be\nserved within both TTFT and TPOT constraints on each GPU. Our evaluations show\nthat on various popular LLMs, applications, and latency requirements, DistServe\ncan serve 4.48x more requests or 10.2x tighter SLO, compared to\nstate-of-the-art systems, while staying within latency constraints for > 90% of\nrequests.", "field": "Computer Science", "categories": "cs.DC"}, {"arxiv_id": "2401.09671", "title": "Towards Identifiable Unsupervised Domain Translation: A Diversified\n  Distribution Matching Approach", "abstract": "Unsupervised domain translation (UDT) aims to find functions that convert\nsamples from one domain (e.g., sketches) to another domain (e.g., photos)\nwithout changing the high-level semantic meaning (also referred to as\n``content''). The translation functions are often sought by probability\ndistribution matching of the transformed source domain and target domain.\nCycleGAN stands as arguably the most representative approach among this line of\nwork. However, it was noticed in the literature that CycleGAN and variants\ncould fail to identify the desired translation functions and produce\ncontent-misaligned translations. This limitation arises due to the presence of\nmultiple translation functions -- referred to as ``measure-preserving\nautomorphism\" (MPA) -- in the solution space of the learning criteria. Despite\nawareness of such identifiability issues, solutions have remained elusive. This\nstudy delves into the core identifiability inquiry and introduces an MPA\nelimination theory. Our analysis shows that MPA is unlikely to exist, if\nmultiple pairs of diverse cross-domain conditional distributions are matched by\nthe learning function. Our theory leads to a UDT learner using distribution\nmatching over auxiliary variable-induced subsets of the domains -- other than\nover the entire data domains as in the classical approaches. The proposed\nframework is the first to rigorously establish translation identifiability\nunder reasonable UDT settings, to our best knowledge. Experiments corroborate\nwith our theoretical claims.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.CV"}, {"arxiv_id": "2401.09673", "title": "Artwork Protection Against Neural Style Transfer Using Locally Adaptive\n  Adversarial Color Attack", "abstract": "Neural style transfer (NST) is widely adopted in computer vision to generate\nnew images with arbitrary styles. This process leverages neural networks to\nmerge aesthetic elements of a style image with the structural aspects of a\ncontent image into a harmoniously integrated visual result. However,\nunauthorized NST can exploit artwork. Such misuse raises socio-technical\nconcerns regarding artists' rights and motivates the development of technical\napproaches for the proactive protection of original creations. Adversarial\nattack is a concept primarily explored in machine learning security. Our work\nintroduces this technique to protect artists' intellectual property. In this\npaper Locally Adaptive Adversarial Color Attack (LAACA), a method for altering\nimages in a manner imperceptible to the human eyes but disruptive to NST.\nSpecifically, we design perturbations targeting image areas rich in\nhigh-frequency content, generated by disrupting intermediate features. Our\nexperiments and user study confirm that by attacking NST using the proposed\nmethod results in visually worse neural style transfer, thus making it an\neffective solution for visual artwork protection.", "field": "Computer Science", "categories": "cs.CV,cs.CR,cs.LG,eess.IV"}, {"arxiv_id": "2401.09674", "title": "QoS-Aware 3D Coverage Deployment of UAVs for Internet of Vehicles in\n  Intelligent Transportation", "abstract": "It is a challenging problem to characterize the air-to-ground (A2G) channel\nand identify the best deployment location for 3D UAVs with the QoS awareness.\nTo address this problem, we propose a QoS-aware UAV 3D coverage deployment\nalgorithm, which simulates the three-dimensional urban road scenario, considers\nthe UAV communication resource capacity and vehicle communication QoS\nrequirements comprehensively, and then obtains the optimal UAV deployment\nposition by improving the genetic algorithm. Specifically, the K-means\nclustering algorithm is used to cluster the vehicles, and the center locations\nof these clusters serve as the initial UAV positions to generate the initial\npopulation. Subsequently, we employ the K-means initialized grey wolf\noptimization (KIGWO) algorithm to achieve the UAV location with an optimal\nfitness value by performing an optimal search within the grey wolf population.\nTo enhance the algorithm's diversity and global search capability, we randomly\nsubstitute this optimal location with one of the individual locations from the\ninitial population. The fitness value is determined by the total number of\nvehicles covered by UAVs in the system, while the allocation scheme's\nfeasibility is evaluated based on the corresponding QoS requirements.\nCompetitive selection operations are conducted to retain individuals with\nhigher fitness values, while crossover and mutation operations are employed to\nmaintain the diversity of solutions. Finally, the individual with the highest\nfitness, which represents the UAV deployment position that covers the maximum\nnumber of vehicles in the entire system, is selected as the optimal solution.\nExtensive experimental results demonstrate that the proposed algorithm can\neffectively enhance the reliability and vehicle communication QoS.", "field": "Computer Science", "categories": "eess.SY,cs.SY"}, {"arxiv_id": "2401.09677", "title": "Eye Motion Matters for 3D Face Reconstruction", "abstract": "Recent advances in single-image 3D face reconstruction have shown remarkable\nprogress in various applications. Nevertheless, prevailing techniques tend to\nprioritize the global facial contour and expression, often neglecting the\nnuanced dynamics of the eye region. In response, we introduce an Eye Landmark\nAdjustment Module, complemented by a Local Dynamic Loss, designed to capture\nthe dynamic features of the eyes area. Our module allows for flexible\nadjustment of landmarks, resulting in accurate recreation of various eye\nstates. In this paper, we present a comprehensive evaluation of our approach,\nconducting extensive experiments on two datasets. The results underscore the\nsuperior performance of our approach, highlighting its significant\ncontributions in addressing this particular challenge.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.09678", "title": "Integrating Graceful Degradation and Recovery through Requirement-driven\n  Adaptation", "abstract": "Cyber-physical systems (CPS) are subject to environmental uncertainties such\nas adverse operating conditions, malicious attacks, and hardware degradation.\nThese uncertainties may lead to failures that put the system in a sub-optimal\nor unsafe state. Systems that are resilient to such uncertainties rely on two\ntypes of operations: (1) graceful degradation, to ensure that the system\nmaintains an acceptable level of safety during unexpected environmental\nconditions and (2) recovery, to facilitate the resumption of normal system\nfunctions. Typically, mechanisms for degradation and recovery are developed\nindependently from each other, and later integrated into a system, requiring\nthe designer to develop an additional, ad-hoc logic for activating and\ncoordinating between the two operations. In this paper, we propose a\nself-adaptation approach for improving system resiliency through automated\ntriggering and coordination of graceful degradation and recovery.The key idea\nbehind our approach is to treat degradation and recovery as requirement-driven\nadaptation tasks: Degradation can be thought of as temporarily weakening an\noriginal (i.e., ideal) system requirement to be achieved by the system, and\nrecovery as strengthening the weakened requirement when the environment returns\nwithin an expected operating boundary. Furthermore, by treating weakening and\nstrengthening as dual operations, we argue that a single requirement-based\nadaptation method is sufficient to enable coordination between degradation and\nrecovery. Given system requirements specified in signal temporal logic (STL),\nwe propose a run-time adaptation framework that automatically performs\ndegradation and recovery in response to environmental changes. We describe a\nprototype implementation of our framework and demonstrate the feasibility of\nthe proposed approach using a case study in unmanned underwater vehicles\n(UUVs).", "field": "Computer Science", "categories": "cs.SE,cs.FL,cs.LO,cs.SY,eess.SY"}, {"arxiv_id": "2401.0968", "title": "Tiny Multi-Agent DRL for Twins Migration in UAV Metaverses: A\n  Multi-Leader Multi-Follower Stackelberg Game Approach", "abstract": "The synergy between Unmanned Aerial Vehicles (UAVs) and metaverses is giving\nrise to an emerging paradigm named UAV metaverses, which create a unified\necosystem that blends physical and virtual spaces, transforming drone\ninteraction and virtual exploration. UAV Twins (UTs), as the digital twins of\nUAVs that revolutionize UAV applications by making them more immersive,\nrealistic, and informative, are deployed and updated on ground base stations,\ne.g., RoadSide Units (RSUs), to offer metaverse services for UAV Metaverse\nUsers (UMUs). Due to the dynamic mobility of UAVs and limited communication\ncoverages of RSUs, it is essential to perform real-time UT migration to ensure\nseamless immersive experiences for UMUs. However, selecting appropriate RSUs\nand optimizing the required bandwidth is challenging for achieving reliable and\nefficient UT migration. To address the challenges, we propose a tiny machine\nlearning-based Stackelberg game framework based on pruning techniques for\nefficient UT migration in UAV metaverses. Specifically, we formulate a\nmulti-leader multi-follower Stackelberg model considering a new immersion\nmetric of UMUs in the utilities of UAVs. Then, we design a Tiny Multi-Agent\nDeep Reinforcement Learning (Tiny MADRL) algorithm to obtain the tiny networks\nrepresenting the optimal game solution. Specifically, the actor-critic network\nleverages the pruning techniques to reduce the number of network parameters and\nachieve model size and computation reduction, allowing for efficient\nimplementation of Tiny MADRL. Numerical results demonstrate that our proposed\nschemes have better performance than traditional schemes.", "field": "Computer Science", "categories": "cs.AI,cs.GT"}, {"arxiv_id": "2401.09681", "title": "Harnessing Density Ratios for Online Reinforcement Learning", "abstract": "The theories of offline and online reinforcement learning, despite having\nevolved in parallel, have begun to show signs of the possibility for a\nunification, with algorithms and analysis techniques for one setting often\nhaving natural counterparts in the other. However, the notion of density ratio\nmodeling, an emerging paradigm in offline RL, has been largely absent from\nonline RL, perhaps for good reason: the very existence and boundedness of\ndensity ratios relies on access to an exploratory dataset with good coverage,\nbut the core challenge in online RL is to collect such a dataset without having\none to start. In this work we show -- perhaps surprisingly -- that density\nratio-based algorithms have online counterparts. Assuming only the existence of\nan exploratory distribution with good coverage, a structural condition known as\ncoverability (Xie et al., 2023), we give a new algorithm (GLOW) that uses\ndensity ratio realizability and value function realizability to perform\nsample-efficient online exploration. GLOW addresses unbounded density ratios\nvia careful use of truncation, and combines this with optimism to guide\nexploration. GLOW is computationally inefficient; we complement it with a more\nefficient counterpart, HyGLOW, for the Hybrid RL setting (Song et al., 2022)\nwherein online RL is augmented with additional offline data. HyGLOW is derived\nas a special case of a more general meta-algorithm that provides a provable\nblack-box reduction from hybrid RL to offline RL, which may be of independent\ninterest.", "field": "Computer Science", "categories": "cs.LG,stat.ML"}, {"arxiv_id": "2401.09682", "title": "Comparative Study on the Performance of Categorical Variable Encoders in\n  Classification and Regression Tasks", "abstract": "Categorical variables often appear in datasets for classification and\nregression tasks, and they need to be encoded into numerical values before\ntraining. Since many encoders have been developed and can significantly impact\nperformance, choosing the appropriate encoder for a task becomes a\ntime-consuming yet important practical issue. This study broadly classifies\nmachine learning models into three categories: 1) ATI models that implicitly\nperform affine transformations on inputs, such as multi-layer perceptron neural\nnetwork; 2) Tree-based models that are based on decision trees, such as random\nforest; and 3) the rest, such as kNN. Theoretically, we prove that the one-hot\nencoder is the best choice for ATI models in the sense that it can mimic any\nother encoders by learning suitable weights from the data. We also explain why\nthe target encoder and its variants are the most suitable encoders for\ntree-based models. This study conducted comprehensive computational experiments\nto evaluate 14 encoders, including one-hot and target encoders, along with\neight common machine-learning models on 28 datasets. The computational results\nagree with our theoretical analysis. The findings in this study shed light on\nhow to select the suitable encoder for data scientists in fields such as fraud\ndetection, disease diagnosis, etc.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.09691", "title": "Imitation Learning Inputting Image Feature to Each Layer of Neural\n  Network", "abstract": "Imitation learning enables robots to learn and replicate human behavior from\ntraining data. Recent advances in machine learning enable end-to-end learning\napproaches that directly process high-dimensional observation data, such as\nimages. However, these approaches face a critical challenge when processing\ndata from multiple modalities, inadvertently ignoring data with a lower\ncorrelation to the desired output, especially when using short sampling\nperiods. This paper presents a useful method to address this challenge, which\namplifies the influence of data with a relatively low correlation to the output\nby inputting the data into each neural network layer. The proposed approach\neffectively incorporates diverse data sources into the learning process.\nThrough experiments using a simple pick-and-place operation with raw images and\njoint information as input, significant improvements in success rates are\ndemonstrated even when dealing with data from short sampling periods.", "field": "Computer Science", "categories": "cs.RO,cs.AI,cs.LG"}, {"arxiv_id": "2401.09693", "title": "EfficientRec an unlimited user-item scale recommendation system based on\n  clustering and users interaction embedding profile", "abstract": "Recommendation systems are highly interested in technology companies\nnowadays. The businesses are constantly growing users and products, causing the\nnumber of users and items to continuously increase over time, to very large\nnumbers. Traditional recommendation algorithms with complexity dependent on the\nnumber of users and items make them difficult to adapt to the industrial\nenvironment. In this paper, we introduce a new method applying graph neural\nnetworks with a contrastive learning framework in extracting user preferences.\nWe incorporate a soft clustering architecture that significantly reduces the\ncomputational cost of the inference process. Experiments show that the model is\nable to learn user preferences with low computational cost in both training and\nprediction phases. At the same time, the model gives a very good accuracy. We\ncall this architecture EfficientRec with the implication of model compactness\nand the ability to scale to unlimited users and products.", "field": "Computer Science", "categories": "cs.IR,cs.LG"}, {"arxiv_id": "2401.09694", "title": "A Multi-Area Architecture for Real-Time Feedback-Based Optimization of\n  Distribution Grids", "abstract": "A challenge in transmission-distribution coordination is how to quickly and\nreliably coordinate Distributed Energy Resources (DERs) across large\nmulti-stakeholder Distribution Networks (DNs) to support the Transmission\nNetwork (TN), while ensuring operational constraints continue to be met within\nthe DN. Here we propose a hierarchical feedback-based control architecture for\ncoordination of DERs in DNs, enabling the DN to quickly respond to power\nset-point requests from the Transmission System Operator (TSO) while\nmaintaining local DN constraints. Our scheme allows for multiple\nindependently-managed areas within the DN to optimize their local resources\nwhile coordinating to support the TN, and while maintaining data privacy; the\nonly required inter-area communication is between physically adjacent areas\nwithin the DN control hierarchy. We conduct a rigorous stability analysis,\nestablishing intuitive conditions for closed-loop stability, and provide\ndetailed tuning recommendations. The proposal is validated via case studies on\nmultiple feeders, including IEEE-123 and IEEE-8500, using a custom MATLAB-based\napplication which integrates with OpenDSS. The simulation results show that the\nproposed structure is highly scalable and can quickly coordinate DERs in\nresponse to TSO commands, while responding to local disturbances within the DN\nand maintaining DN operational limits.", "field": "Computer Science", "categories": "eess.SY,cs.SY"}, {"arxiv_id": "2401.09695", "title": "Should ChatGPT Write Your Breakup Text? Exploring the Role of AI in\n  Relationship Dissolution", "abstract": "Relationships are essential to our happiness and wellbeing. The dissolution\nof a relationship, the final stage of relationship's lifecycle and one of the\nmost stressful events in an individual's life, can have profound and\nlong-lasting impacts on people. With the breakup process increasingly\nfacilitated by computer-mediated communication (CMC), and the likely future\ninfluence of AI-mediated communication (AIMC) tools, we conducted a\nsemi-structured interview study with 21 participants. We aim to understand: 1)\nthe current role of technology in the breakup process, 2) the needs and support\nindividuals have during the process, and 3) how AI might address these needs.\nOur research shows that people have distinct needs at various stages of ending\na relationship. Presently, technology is used for information gathering and\ncommunity support, acting as a catalyst for breakups, enabling ghosting and\nblocking, and facilitating communication. Participants anticipate that AI could\naid in sense-making of their relationship leading up to the breakup, act as a\nmediator, assist in crafting appropriate wording, tones, and language during\nbreakup conversations, and support companionship, reflection, recovery, and\ngrowth after a breakup. Our findings also demonstrate an overlap between the\nbreakup process and the Transtheoretical Model (TTM) of behavior change.\nThrough the lens of TTM, we explore the potential support and affordances AI\ncould offer in breakups, including its benefits and the necessary precautions\nregarding AI's role in this sensitive process.", "field": "Computer Science", "categories": "cs.HC,cs.AI"}, {"arxiv_id": "2401.09699", "title": "Curriculum Recommendations Using Transformer Base Model with InfoNCE\n  Loss And Language Switching Method", "abstract": "The Curriculum Recommendations paradigm is dedicated to fostering learning\nequality within the ever-evolving realms of educational technology and\ncurriculum development. In acknowledging the inherent obstacles posed by\nexisting methodologies, such as content conflicts and disruptions from language\ntranslation, this paradigm aims to confront and overcome these challenges.\nNotably, it addresses content conflicts and disruptions introduced by language\ntranslation, hindrances that can impede the creation of an all-encompassing and\npersonalized learning experience. The paradigm's objective is to cultivate an\neducational environment that not only embraces diversity but also customizes\nlearning experiences to suit the distinct needs of each learner. To overcome\nthese challenges, our approach builds upon notable contributions in curriculum\ndevelopment and personalized learning, introducing three key innovations. These\ninclude the integration of Transformer Base Model to enhance computational\nefficiency, the implementation of InfoNCE Loss for accurate content-topic\nmatching, and the adoption of a language switching strategy to alleviate\ntranslation-related ambiguities. Together, these innovations aim to\ncollectively tackle inherent challenges and contribute to forging a more\nequitable and effective learning journey for a diverse range of learners.\nCompetitive cross-validation scores underscore the efficacy of\nsentence-transformers/LaBSE, achieving 0.66314, showcasing our methodology's\neffectiveness in diverse linguistic nuances for content alignment prediction.\nIndex Terms-Curriculum Recommendation, Transformer model with InfoNCE Loss,\nLanguage Switching.", "field": "Computer Science", "categories": "cs.CL,cs.AI,68T50"}, {"arxiv_id": "2401.097", "title": "Fully Dynamic Min-Cut of Superconstant Size in Subpolynomial Time", "abstract": "We present a deterministic fully dynamic algorithm with subpolynomial\nworst-case time per graph update such that after processing each update of the\ngraph, the algorithm outputs a minimum cut of the graph if the graph has a cut\nof size at most $c$ for some $c = (\\log n)^{o(1)}$. Previously, the best update\ntime was $\\widetilde O(\\sqrt{n})$ for any $c > 2$ and $c = O(\\log n)$ [Thorup,\nCombinatorica'07].", "field": "Computer Science", "categories": "cs.DS"}, {"arxiv_id": "2401.09703", "title": "Fast Updating Truncated SVD for Representation Learning with Sparse\n  Matrices", "abstract": "Updating a truncated Singular Value Decomposition (SVD) is crucial in\nrepresentation learning, especially when dealing with large-scale data matrices\nthat continuously evolve in practical scenarios. Aligning SVD-based models with\nfast-paced updates becomes increasingly important. Existing methods for\nupdating truncated SVDs employ Rayleigh-Ritz projection procedures, where\nprojection matrices are augmented based on original singular vectors. However,\nthese methods suffer from inefficiency due to the densification of the update\nmatrix and the application of the projection to all singular vectors. To\naddress these limitations, we introduce a novel method for dynamically\napproximating the truncated SVD of a sparse and temporally evolving matrix. Our\napproach leverages sparsity in the orthogonalization process of augmented\nmatrices and utilizes an extended decomposition to independently store\nprojections in the column space of singular vectors. Numerical experiments\ndemonstrate a remarkable efficiency improvement of an order of magnitude\ncompared to previous methods. Remarkably, this improvement is achieved while\nmaintaining a comparable precision to existing approaches.", "field": "Computer Science", "categories": "math.NA,cs.NA"}, {"arxiv_id": "2401.09705", "title": "Learning Hybrid Policies for MPC with Application to Drone Flight in\n  Unknown Dynamic Environments", "abstract": "In recent years, drones have found increased applications in a wide array of\nreal-world tasks. Model predictive control (MPC) has emerged as a practical\nmethod for drone flight control, owing to its robustness against modeling\nerrors/uncertainties and external disturbances. However, MPC's sensitivity to\nmanually tuned parameters can lead to rapid performance degradation when faced\nwith unknown environmental dynamics. This paper addresses the challenge of\ncontrolling a drone as it traverses a swinging gate characterized by unknown\ndynamics. This paper introduces a parameterized MPC approach named hyMPC that\nleverages high-level decision variables to adapt to uncertain environmental\nconditions. To derive these decision variables, a novel policy search framework\naimed at training a high-level Gaussian policy is presented. Subsequently, we\nharness the power of neural network policies, trained on data gathered through\nthe repeated execution of the Gaussian policy, to provide real-time decision\nvariables. The effectiveness of hyMPC is validated through numerical\nsimulations, achieving a 100\\% success rate in 20 drone flight tests traversing\na swinging gate, demonstrating its capability to achieve safe and precise\nflight with limited prior knowledge of environmental dynamics.", "field": "Computer Science", "categories": "cs.RO,cs.SY,eess.SY"}, {"arxiv_id": "2401.09706", "title": "A HPC Co-Scheduler with Reinforcement Learning", "abstract": "Although High Performance Computing (HPC) users understand basic resource\nrequirements such as the number of CPUs and memory limits, internal\ninfrastructural utilization data is exclusively leveraged by cluster operators,\nwho use it to configure batch schedulers. This task is challenging and\nincreasingly complex due to ever larger cluster scales and heterogeneity of\nmodern scientific workflows. As a result, HPC systems achieve low utilization\nwith long job completion times (makespans). To tackle these challenges, we\npropose a co-scheduling algorithm based on an adaptive reinforcement learning\nalgorithm, where application profiling is combined with cluster monitoring. The\nresulting cluster scheduler matches resource utilization to application\nperformance in a fine-grained manner (i.e., operating system level). As opposed\nto nominal allocations, we apply decision trees to model applications' actual\nresource usage, which are used to estimate how much resource capacity from one\nallocation can be co-allocated to additional applications. Our algorithm learns\nfrom incorrect co-scheduling decisions and adapts from changing environment\nconditions, and evaluates when such changes cause resource contention that\nimpacts quality of service metrics such as jobs slowdowns. We integrate our\nalgorithm in an HPC resource manager that combines Slurm and Mesos for job\nscheduling and co-allocation, respectively. Our experimental evaluation\nperformed in a dedicated cluster executing a mix of four real different\nscientific workflows demonstrates improvements on cluster utilization of up to\n51% even in high load scenarios, with 55% average queue makespan reductions\nunder low loads.", "field": "Computer Science", "categories": "cs.DC"}, {"arxiv_id": "2401.09709", "title": "P2Seg: Pointly-supervised Segmentation via Mutual Distillation", "abstract": "Point-level Supervised Instance Segmentation (PSIS) aims to enhance the\napplicability and scalability of instance segmentation by utilizing low-cost\nyet instance-informative annotations. Existing PSIS methods usually rely on\npositional information to distinguish objects, but predicting precise\nboundaries remains challenging due to the lack of contour annotations.\nNevertheless, weakly supervised semantic segmentation methods are proficient in\nutilizing intra-class feature consistency to capture the boundary contours of\nthe same semantic regions. In this paper, we design a Mutual Distillation\nModule (MDM) to leverage the complementary strengths of both instance position\nand semantic information and achieve accurate instance-level object perception.\nThe MDM consists of Semantic to Instance (S2I) and Instance to Semantic (I2S).\nS2I is guided by the precise boundaries of semantic regions to learn the\nassociation between annotated points and instance contours. I2S leverages\ndiscriminative relationships between instances to facilitate the\ndifferentiation of various objects within the semantic map. Extensive\nexperiments substantiate the efficacy of MDM in fostering the synergy between\ninstance and semantic information, consequently improving the quality of\ninstance-level object representations. Our method achieves 55.7 mAP$_{50}$ and\n17.6 mAP on the PASCAL VOC and MS COCO datasets, significantly outperforming\nrecent PSIS methods and several box-supervised instance segmentation\ncompetitors.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.09711", "title": "Joint Beam Direction Control and Radio Resource Allocation in Dynamic\n  Multi-beam LEO Satellite Networks", "abstract": "Multi-beam low earth orbit (LEO) satellites are emerging as key components in\nbeyond 5G and 6G to provide global coverage and high data rate. To fully\nunleash the potential of LEO satellite communication, resource management plays\na key role. However, the uneven distribution of users, the coupling of\nmulti-dimensional resources, complex inter-beam interference, and time-varying\nnetwork topologies all impose significant challenges on effective communication\nresource management. In this paper, we study the joint optimization of beam\ndirection and the allocation of spectrum, time, and power resource in a dynamic\nmulti-beam LEO satellite network. The objective is to improve long-term user\nsum data rate while taking user fairness into account. Since the concerned\nresource management problem is mixed-integer non-convex programming, the\nproblem is decomposed into three subproblems, namely beam direction control and\ntime slot allocation, user subchannel assignment, and beam power allocation.\nThen, these subproblems are solved iteratively by leveraging matching with\nexternalities and successive convex approximation, and the proposed algorithms\nare analyzed in terms of stability, convergence, and complexity. Extensive\nsimulations are conducted, and the results demonstrate that our proposal can\nimprove the number of served users by up to two times and the sum user data\nrate by up to 68%, compared to baseline schemes.", "field": "Computer Science", "categories": "cs.IT,cs.SY,eess.SY,math.IT"}, {"arxiv_id": "2401.09712", "title": "SkyEyeGPT: Unifying Remote Sensing Vision-Language Tasks via Instruction\n  Tuning with Large Language Model", "abstract": "Large language models (LLMs) have recently been extended to the\nvision-language realm, obtaining impressive general multi-modal capabilities.\nHowever, the exploration of multi-modal large language models (MLLMs) for\nremote sensing (RS) data is still in its infancy, and the performance is not\nsatisfactory. In this work, we introduce SkyEyeGPT, a unified multi-modal large\nlanguage model specifically designed for RS vision-language understanding. To\nthis end, we meticulously curate an RS multi-modal instruction tuning dataset,\nincluding single-task and multi-task conversation instructions. After manual\nverification, we obtain a high-quality RS instruction-following dataset with\n968k samples. Our research demonstrates that with a simple yet effective\ndesign, SkyEyeGPT works surprisingly well on considerably different tasks\nwithout the need for extra encoding modules. Specifically, after projecting RS\nvisual features to the language domain via an alignment layer, they are fed\njointly with task-specific instructions into an LLM-based RS decoder to predict\nanswers for RS open-ended tasks. In addition, we design a two-stage tuning\nmethod to enhance instruction-following and multi-turn dialogue ability at\ndifferent granularities. Experiments on 8 datasets for RS vision-language tasks\ndemonstrate SkyEyeGPT's superiority in image-level and region-level tasks, such\nas captioning and visual grounding. In particular, SkyEyeGPT exhibits\nencouraging results compared to GPT-4V in some qualitative tests. The online\ndemo, code, and dataset will be released in\nhttps://github.com/ZhanYang-nwpu/SkyEyeGPT.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.09714", "title": "Robust virtual element methods for coupled stress-assisted diffusion\n  problems", "abstract": "This paper aims first to perform robust continuous analysis of a mixed\nnonlinear formulation for stress-assisted diffusion of a solute that interacts\nwith an elastic material, and second to propose and analyse a virtual element\nformulation of the model problem. The two-way coupling mechanisms between the\nHerrmann formulation for linear elasticity and the reaction-diffusion equation\n(written in mixed form) consist of diffusion-induced active stress and\nstress-dependent diffusion. The two sub-problems are analysed using the\nextended Babu\\v{s}ka--Brezzi--Braess theory for perturbed saddle-point\nproblems. The well-posedness of the nonlinearly coupled system is established\nusing a Banach fixed-point strategy under the smallness assumption on data. The\nvirtual element formulations for the uncoupled sub-problems are proven uniquely\nsolvable by a fixed-point argument in conjunction with appropriate projection\noperators. We derive the a priori error estimates, and test the accuracy and\nperformance of the proposed method through computational simulations.", "field": "Computer Science", "categories": "math.NA,cs.NA,65N30, 65N12, 65N15, 74F25"}, {"arxiv_id": "2401.09716", "title": "HCVP: Leveraging Hierarchical Contrastive Visual Prompt for Domain\n  Generalization", "abstract": "Domain Generalization (DG) endeavors to create machine learning models that\nexcel in unseen scenarios by learning invariant features. In DG, the prevalent\npractice of constraining models to a fixed structure or uniform\nparameterization to encapsulate invariant features can inadvertently blend\nspecific aspects. Such an approach struggles with nuanced differentiation of\ninter-domain variations and may exhibit bias towards certain domains, hindering\nthe precise learning of domain-invariant features. Recognizing this, we\nintroduce a novel method designed to supplement the model with domain-level and\ntask-specific characteristics. This approach aims to guide the model in more\neffectively separating invariant features from specific characteristics,\nthereby boosting the generalization. Building on the emerging trend of visual\nprompts in the DG paradigm, our work introduces the novel \\textbf{H}ierarchical\n\\textbf{C}ontrastive \\textbf{V}isual \\textbf{P}rompt (HCVP) methodology. This\nrepresents a significant advancement in the field, setting itself apart with a\nunique generative approach to prompts, alongside an explicit model structure\nand specialized loss functions. Differing from traditional visual prompts that\nare often shared across entire datasets, HCVP utilizes a hierarchical prompt\ngeneration network enhanced by prompt contrastive learning. These generative\nprompts are instance-dependent, catering to the unique characteristics inherent\nto different domains and tasks. Additionally, we devise a prompt modulation\nnetwork that serves as a bridge, effectively incorporating the generated visual\nprompts into the vision transformer backbone. Experiments conducted on five DG\ndatasets demonstrate the effectiveness of HCVP, outperforming both established\nDG algorithms and adaptation protocols.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.0972", "title": "GaussianBody: Clothed Human Reconstruction via 3d Gaussian Splatting", "abstract": "In this work, we propose a novel clothed human reconstruction method called\nGaussianBody, based on 3D Gaussian Splatting. Compared with the costly neural\nradiance based models, 3D Gaussian Splatting has recently demonstrated great\nperformance in terms of training time and rendering quality. However, applying\nthe static 3D Gaussian Splatting model to the dynamic human reconstruction\nproblem is non-trivial due to complicated non-rigid deformations and rich cloth\ndetails. To address these challenges, our method considers explicit pose-guided\ndeformation to associate dynamic Gaussians across the canonical space and the\nobservation space, introducing a physically-based prior with regularized\ntransformations helps mitigate ambiguity between the two spaces. During the\ntraining process, we further propose a pose refinement strategy to update the\npose regression for compensating the inaccurate initial estimation and a\nsplit-with-scale mechanism to enhance the density of regressed point clouds.\nThe experiments validate that our method can achieve state-of-the-art\nphotorealistic novel-view rendering results with high-quality details for\ndynamic clothed human bodies, along with explicit geometry reconstruction.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.09721", "title": "fast graph-based denoising for point cloud color information", "abstract": "Point clouds are utilized in various 3D applications such as cross-reality\n(XR) and realistic 3D displays. In some applications, e.g., for live streaming\nusing a 3D point cloud, real-time point cloud denoising methods are required to\nenhance the visual quality. However, conventional high-precision denoising\nmethods cannot be executed in real time for large-scale point clouds owing to\nthe complexity of graph constructions with K nearest neighbors and noise level\nestimation. This paper proposes a fast graph-based denoising (FGBD) for a\nlarge-scale point cloud. First, high-speed graph construction is achieved by\nscanning a point cloud in various directions and searching adjacent\nneighborhoods on the scanning lines. Second, we propose a fast noise level\nestimation method using eigenvalues of the covariance matrix on a graph.\nFinally, we also propose a new low-cost filter selection method to enhance\ndenoising accuracy to compensate for the degradation caused by the acceleration\nalgorithms. In our experiments, we succeeded in reducing the processing time\ndramatically while maintaining accuracy relative to conventional denoising\nmethods. Denoising was performed at 30fps, with frames containing approximately\n1 million points.", "field": "Computer Science", "categories": "cs.CV,eess.IV,eess.SP"}, {"arxiv_id": "2401.09724", "title": "Predicting Viral Rumors and Vulnerable Users for Infodemic Surveillance", "abstract": "In the age of the infodemic, it is crucial to have tools for effectively\nmonitoring the spread of rampant rumors that can quickly go viral, as well as\nidentifying vulnerable users who may be more susceptible to spreading such\nmisinformation. This proactive approach allows for timely preventive measures\nto be taken, mitigating the negative impact of false information on society. We\npropose a novel approach to predict viral rumors and vulnerable users using a\nunified graph neural network model. We pre-train network-based user embeddings\nand leverage a cross-attention mechanism between users and posts, together with\na community-enhanced vulnerability propagation (CVP) method to improve user and\npropagation graph representations. Furthermore, we employ two multi-task\ntraining strategies to mitigate negative transfer effects among tasks in\ndifferent settings, enhancing the overall performance of our approach. We also\nconstruct two datasets with ground-truth annotations on information virality\nand user vulnerability in rumor and non-rumor events, which are automatically\nderived from existing rumor detection datasets. Extensive evaluation results of\nour joint learning model confirm its superiority over strong baselines in all\nthree tasks: rumor detection, virality prediction, and user vulnerability\nscoring. For instance, compared to the best baselines based on the Weibo\ndataset, our model makes 3.8\\% and 3.0\\% improvements on Accuracy and MacF1 for\nrumor detection, and reduces mean squared error (MSE) by 23.9\\% and 16.5\\% for\nvirality prediction and user vulnerability scoring, respectively. Our findings\nsuggest that our approach effectively captures the correlation between rumor\nvirality and user vulnerability, leveraging this information to improve\nprediction performance and provide a valuable tool for infodemic surveillance.", "field": "Computer Science", "categories": "cs.SI,cs.CL"}, {"arxiv_id": "2401.09725", "title": "Enhancing Image-Text Matching with Adaptive Feature Aggregation", "abstract": "Image-text matching aims to find matched cross-modal pairs accurately. While\ncurrent methods often rely on projecting cross-modal features into a common\nembedding space, they frequently suffer from imbalanced feature representations\nacross different modalities, leading to unreliable retrieval results. To\naddress these limitations, we introduce a novel Feature Enhancement Module that\nadaptively aggregates single-modal features for more balanced and robust\nimage-text retrieval. Additionally, we propose a new loss function that\novercomes the shortcomings of original triplet ranking loss, thereby\nsignificantly improving retrieval performance. The proposed model has been\nevaluated on two public datasets and achieves competitive retrieval performance\nwhen compared with several state-of-the-art models. Implementation codes can be\nfound here.", "field": "Computer Science", "categories": "cs.IR,cs.MM"}, {"arxiv_id": "2401.09727", "title": "Large Language Model Lateral Spear Phishing: A Comparative Study in\n  Large-Scale Organizational Settings", "abstract": "The critical threat of phishing emails has been further exacerbated by the\npotential of LLMs to generate highly targeted, personalized, and automated\nspear phishing attacks. Two critical problems concerning LLM-facilitated\nphishing require further investigation: 1) Existing studies on lateral phishing\nlack specific examination of LLM integration for large-scale attacks targeting\nthe entire organization, and 2) Current anti-phishing infrastructure, despite\nits extensive development, lacks the capability to prevent LLM-generated\nattacks, potentially impacting both employees and IT security incident\nmanagement. However, the execution of such investigative studies necessitates a\nreal-world environment, one that functions during regular business operations\nand mirrors the complexity of a large organizational infrastructure. This\nsetting must also offer the flexibility required to facilitate a diverse array\nof experimental conditions, particularly the incorporation of phishing emails\ncrafted by LLMs. This study is a pioneering exploration into the use of Large\nLanguage Models (LLMs) for the creation of targeted lateral phishing emails,\ntargeting a large tier 1 university's operation and workforce of approximately\n9,000 individuals over an 11-month period. It also evaluates the capability of\nemail filtering infrastructure to detect such LLM-generated phishing attempts,\nproviding insights into their effectiveness and identifying potential areas for\nimprovement. Based on our findings, we propose machine learning-based detection\ntechniques for such emails to detect LLM-generated phishing emails that were\nmissed by the existing infrastructure, with an F1-score of 98.96.", "field": "Computer Science", "categories": "cs.CR,cs.CL"}, {"arxiv_id": "2401.09728", "title": "Offline Imitation Learning by Controlling the Effective Planning Horizon", "abstract": "In offline imitation learning (IL), we generally assume only a handful of\nexpert trajectories and a supplementary offline dataset from suboptimal\nbehaviors to learn the expert policy. While it is now common to minimize the\ndivergence between state-action visitation distributions so that the agent also\nconsiders the future consequences of an action, a sampling error in an offline\ndataset may lead to erroneous estimates of state-action visitations in the\noffline case. In this paper, we investigate the effect of controlling the\neffective planning horizon (i.e., reducing the discount factor) as opposed to\nimposing an explicit regularizer, as previously studied. Unfortunately, it\nturns out that the existing algorithms suffer from magnified approximation\nerrors when the effective planning horizon is shortened, which results in a\nsignificant degradation in performance. We analyze the main cause of the\nproblem and provide the right remedies to correct the algorithm. We show that\nthe corrected algorithm improves on popular imitation learning benchmarks by\ncontrolling the effective planning horizon rather than an explicit\nregularization.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.09732", "title": "Instance Brownian Bridge as Texts for Open-vocabulary Video Instance\n  Segmentation", "abstract": "Temporally locating objects with arbitrary class texts is the primary pursuit\nof open-vocabulary Video Instance Segmentation (VIS). Because of the\ninsufficient vocabulary of video data, previous methods leverage image-text\npretraining model for recognizing object instances by separately aligning each\nframe and class texts, ignoring the correlation between frames. As a result,\nthe separation breaks the instance movement context of videos, causing inferior\nalignment between video and text. To tackle this issue, we propose to link\nframe-level instance representations as a Brownian Bridge to model instance\ndynamics and align bridge-level instance representation to class texts for more\nprecisely open-vocabulary VIS (BriVIS). Specifically, we build our system upon\na frozen video segmentor to generate frame-level instance queries, and design\nTemporal Instance Resampler (TIR) to generate queries with temporal context\nfrom frame queries. To mold instance queries to follow Brownian bridge and\naccomplish alignment with class texts, we design Bridge-Text Alignment (BTA) to\nlearn discriminative bridge-level representations of instances via contrastive\nobjectives. Setting MinVIS as the basic video segmentor, BriVIS surpasses the\nOpen-vocabulary SOTA (OV2Seg) by a clear margin. For example, on the\nchallenging large-vocabulary VIS dataset (BURST), BriVIS achieves 7.43 mAP and\nexhibits 49.49% improvement compared to OV2Seg (4.97 mAP).", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.09733", "title": "ASA -- The Adaptive Scheduling Algorithm", "abstract": "In High Performance Computing (HPC) infrastructures, the control of resources\nby batch systems can lead to prolonged queue waiting times and adverse effects\non the overall execution times of applications, particularly in data-intensive\nand low-latency workflows where efficient processing hinges on resource\nplanning and timely allocation. Allocating the maximum capacity upfront ensures\nthe fastest execution but results in spare and idle resources, extended queue\nwaits, and costly usage. Conversely, dynamic allocation based on workflow stage\nrequirements optimizes resource usage but may negatively impact the total\nworkflow makespan. To address these issues, we introduce ASA, the Adaptive\nScheduling Algorithm. ASA is a novel, convergence-proven scheduling technique\nthat minimizes jobs inter-stage waiting times by estimating the queue waiting\ntimes to proactively submit resource change requests ahead of time. It strikes\na balance between exploration and exploitation, considering both learning\n(waiting times) and applying learnt insights. Real-world experiments over two\nsupercomputers centers with scientific workflows demonstrate ASA's\neffectiveness, achieving near-optimal resource utilization and accuracy, with\nup to 10% and 2% reductions in average workflow queue waiting times and\nmakespan, respectively.", "field": "Computer Science", "categories": "cs.DC"}, {"arxiv_id": "2401.09736", "title": "Measuring the Discrepancy between 3D Geometric Models using Directional\n  Distance Fields", "abstract": "Qualifying the discrepancy between 3D geometric models, which could be\nrepresented with either point clouds or triangle meshes, is a pivotal issue\nwith board applications. Existing methods mainly focus on directly establishing\nthe correspondence between two models and then aggregating point-wise distance\nbetween corresponding points, resulting in them being either inefficient or\nineffective. In this paper, we propose DirDist, an efficient, effective,\nrobust, and differentiable distance metric for 3D geometry data. Specifically,\nwe construct DirDist based on the proposed implicit representation of 3D\nmodels, namely directional distance field (DDF), which defines the directional\ndistances of 3D points to a model to capture its local surface geometry. We\nthen transfer the discrepancy between two 3D geometric models as the\ndiscrepancy between their DDFs defined on an identical domain, naturally\nestablishing model correspondence. To demonstrate the advantage of our DirDist,\nwe explore various distance metric-driven 3D geometric modeling tasks,\nincluding template surface fitting, rigid registration, non-rigid registration,\nscene flow estimation and human pose optimization. Extensive experiments show\nthat our DirDist achieves significantly higher accuracy under all tasks. As a\ngeneric distance metric, DirDist has the potential to advance the field of 3D\ngeometric modeling. The source code is available at\n\\url{https://github.com/rsy6318/DirDist}.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.0974", "title": "Hijacking Attacks against Neural Networks by Analyzing Training Data", "abstract": "Backdoors and adversarial examples are the two primary threats currently\nfaced by deep neural networks (DNNs). Both attacks attempt to hijack the model\nbehaviors with unintended outputs by introducing (small) perturbations to the\ninputs. Backdoor attacks, despite the high success rates, often require a\nstrong assumption, which is not always easy to achieve in reality. Adversarial\nexample attacks, which put relatively weaker assumptions on attackers, often\ndemand high computational resources, yet do not always yield satisfactory\nsuccess rates when attacking mainstream black-box models in the real world.\nThese limitations motivate the following research question: can model hijacking\nbe achieved more simply, with a higher attack success rate and more reasonable\nassumptions? In this paper, we propose CleanSheet, a new model hijacking attack\nthat obtains the high performance of backdoor attacks without requiring the\nadversary to tamper with the model training process. CleanSheet exploits\nvulnerabilities in DNNs stemming from the training data. Specifically, our key\nidea is to treat part of the clean training data of the target model as\n\"poisoned data,\" and capture the characteristics of these data that are more\nsensitive to the model (typically called robust features) to construct\n\"triggers.\" These triggers can be added to any input example to mislead the\ntarget model, similar to backdoor attacks. We validate the effectiveness of\nCleanSheet through extensive experiments on 5 datasets, 79 normally trained\nmodels, 68 pruned models, and 39 defensive models. Results show that CleanSheet\nexhibits performance comparable to state-of-the-art backdoor attacks, achieving\nan average attack success rate (ASR) of 97.5% on CIFAR-100 and 92.4% on GTSRB,\nrespectively. Furthermore, CleanSheet consistently maintains a high ASR, when\nconfronted with various mainstream backdoor defenses.", "field": "Computer Science", "categories": "cs.CR"}, {"arxiv_id": "2401.09742", "title": "Image Translation as Diffusion Visual Programmers", "abstract": "We introduce the novel Diffusion Visual Programmer (DVP), a neuro-symbolic\nimage translation framework. Our proposed DVP seamlessly embeds a\ncondition-flexible diffusion model within the GPT architecture, orchestrating a\ncoherent sequence of visual programs (i.e., computer vision models) for various\npro-symbolic steps, which span RoI identification, style transfer, and position\nmanipulation, facilitating transparent and controllable image translation\nprocesses. Extensive experiments demonstrate DVP's remarkable performance,\nsurpassing concurrent arts. This success can be attributed to several key\nfeatures of DVP: First, DVP achieves condition-flexible translation via\ninstance normalization, enabling the model to eliminate sensitivity caused by\nthe manual guidance and optimally focus on textual descriptions for\nhigh-quality content generation. Second, the framework enhances in-context\nreasoning by deciphering intricate high-dimensional concepts in feature spaces\ninto more accessible low-dimensional symbols (e.g., [Prompt], [RoI object]),\nallowing for localized, context-free editing while maintaining overall\ncoherence. Last but not least, DVP improves systemic controllability and\nexplainability by offering explicit symbolic representations at each\nprogramming stage, empowering users to intuitively interpret and modify\nresults. Our research marks a substantial step towards harmonizing artificial\nimage translation processes with cognitive intelligence, promising broader\napplications.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.09747", "title": "Stochastic theta methods for random periodic solution of stochastic\n  differential equations under non-globally Lipschitz conditions", "abstract": "This work focuses on the numerical approximations of random periodic\nsolutions of stochastic differential equations (SDEs). Under non-globally\nLipschitz conditions, we prove the existence and uniqueness of random periodic\nsolutions for the considered equations and its numerical approximations\ngenerated by the stochastic theta (ST) methods with theta within (1/2,1]. It is\nshown that the random periodic solution of each ST method converges strongly in\nthe mean square sense to that of SDEs for all step size. More precisely, the\nmean square convergence order is 1/2 for SDEs with multiplicative noise and 1\nfor SDEs with additive noise. Numerical results are finally reported to confirm\nthese theoretical findings.", "field": "Computer Science", "categories": "math.NA,cs.NA"}, {"arxiv_id": "2401.09748", "title": "Bootstrapping OTS-Funcimg Pre-training Model (Botfip) -- A Comprehensive\n  Symbolic Regression Framework", "abstract": "In the field of scientific computing, many problem-solving approaches tend to\nfocus only on the process and final outcome, even in AI for science, there is a\nlack of deep multimodal information mining behind the data, missing a\nmultimodal framework akin to that in the image-text domain. In this paper, we\ntake Symbolic Regression(SR) as our focal point and, drawing inspiration from\nthe BLIP model in the image-text domain, propose a scientific computing\nmultimodal framework based on Function Images (Funcimg) and Operation Tree\nSequence (OTS), named Bootstrapping OTS-Funcimg Pre-training Model (Botfip). In\nSR experiments, we validate the advantages of Botfip in low-complexity SR\nproblems, showcasing its potential. As a MED framework, Botfip holds promise\nfor future applications in a broader range of scientific computing problems.", "field": "Computer Science", "categories": "cs.SC,cs.AI,cs.LG"}, {"arxiv_id": "2401.0975", "title": "Exploration and Anti-Exploration with Distributional Random Network\n  Distillation", "abstract": "Exploration remains a critical issue in deep reinforcement learning for an\nagent to attain high returns in unknown environments. Although the prevailing\nexploration Random Network Distillation (RND) algorithm has been demonstrated\nto be effective in numerous environments, it often needs more discriminative\npower in bonus allocation. This paper highlights the ``bonus inconsistency''\nissue within RND, pinpointing its primary limitation. To address this issue, we\nintroduce the Distributional RND (DRND), a derivative of the RND. DRND enhances\nthe exploration process by distilling a distribution of random networks and\nimplicitly incorporating pseudo counts to improve the precision of bonus\nallocation. This refinement encourages agents to engage in more extensive\nexploration. Our method effectively mitigates the inconsistency issue without\nintroducing significant computational overhead. Both theoretical analysis and\nexperimental results demonstrate the superiority of our approach over the\noriginal RND algorithm. Our method excels in challenging online exploration\nscenarios and effectively serves as an anti-exploration mechanism in D4RL\noffline tasks.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.09752", "title": "Improving Speaker-independent Speech Emotion Recognition Using Dynamic\n  Joint Distribution Adaptation", "abstract": "In speaker-independent speech emotion recognition, the training and testing\nsamples are collected from diverse speakers, leading to a multi-domain shift\nchallenge across the feature distributions of data from different speakers.\nConsequently, when the trained model is confronted with data from new speakers,\nits performance tends to degrade. To address the issue, we propose a Dynamic\nJoint Distribution Adaptation (DJDA) method under the framework of multi-source\ndomain adaptation. DJDA firstly utilizes joint distribution adaptation (JDA),\ninvolving marginal distribution adaptation (MDA) and conditional distribution\nadaptation (CDA), to more precisely measure the multi-domain distribution\nshifts caused by different speakers. This helps eliminate speaker bias in\nemotion features, allowing for learning discriminative and speaker-invariant\nspeech emotion features from coarse-level to fine-level. Furthermore, we\nquantify the adaptation contributions of MDA and CDA within JDA by using a\ndynamic balance factor based on $\\mathcal{A}$-Distance, promoting to\neffectively handle the unknown distributions encountered in data from new\nspeakers. Experimental results demonstrate the superior performance of our DJDA\nas compared to other state-of-the-art (SOTA) methods.", "field": "Computer Science", "categories": "cs.SD,cs.LG,eess.AS"}, {"arxiv_id": "2401.09753", "title": "Applications of Machine Learning to Optimizing Polyolefin Manufacturing", "abstract": "This chapter is a preprint from our book by , focusing on leveraging machine\nlearning (ML) in chemical and polyolefin manufacturing optimization. It's\ncrafted for both novices and seasoned professionals keen on the latest ML\napplications in chemical processes. We trace the evolution of AI and ML in\nchemical industries, delineate core ML components, and provide resources for ML\nbeginners. A detailed discussion on various ML methods is presented, covering\nregression, classification, and unsupervised learning techniques, with\nperformance metrics and examples. Ensemble methods, deep learning networks,\nincluding MLP, DNNs, RNNs, CNNs, and transformers, are explored for their\ngrowing role in chemical applications. Practical workshops guide readers\nthrough predictive modeling using advanced ML algorithms. The chapter\nculminates with insights into science-guided ML, advocating for a hybrid\napproach that enhances model accuracy. The extensive bibliography offers\nresources for further research and practical implementation. This chapter aims\nto be a thorough primer on ML's practical application in chemical engineering,\nparticularly for polyolefin production, and sets the stage for continued\nlearning in subsequent chapters. Please cite the original work [169,170] when\nreferencing.", "field": "Computer Science", "categories": "cs.LG,cs.CE"}, {"arxiv_id": "2401.09754", "title": "Universally Robust Graph Neural Networks by Preserving Neighbor\n  Similarity", "abstract": "Despite the tremendous success of graph neural networks in learning\nrelational data, it has been widely investigated that graph neural networks are\nvulnerable to structural attacks on homophilic graphs. Motivated by this, a\nsurge of robust models is crafted to enhance the adversarial robustness of\ngraph neural networks on homophilic graphs. However, the vulnerability based on\nheterophilic graphs remains a mystery to us. To bridge this gap, in this paper,\nwe start to explore the vulnerability of graph neural networks on heterophilic\ngraphs and theoretically prove that the update of the negative classification\nloss is negatively correlated with the pairwise similarities based on the\npowered aggregated neighbor features. This theoretical proof explains the\nempirical observations that the graph attacker tends to connect dissimilar node\npairs based on the similarities of neighbor features instead of ego features\nboth on homophilic and heterophilic graphs. In this way, we novelly introduce a\nnovel robust model termed NSPGNN which incorporates a dual-kNN graphs pipeline\nto supervise the neighbor similarity-guided propagation. This propagation\nutilizes the low-pass filter to smooth the features of node pairs along the\npositive kNN graphs and the high-pass filter to discriminate the features of\nnode pairs along the negative kNN graphs. Extensive experiments on both\nhomophilic and heterophilic graphs validate the universal robustness of NSPGNN\ncompared to the state-of-the-art methods.", "field": "Computer Science", "categories": "cs.LG,cs.CR,cs.SI"}, {"arxiv_id": "2401.09756", "title": "Explaining Drift using Shapley Values", "abstract": "Machine learning models often deteriorate in their performance when they are\nused to predict the outcomes over data on which they were not trained. These\nscenarios can often arise in real world when the distribution of data changes\ngradually or abruptly due to major events like a pandemic. There have been many\nattempts in machine learning research to come up with techniques that are\nresilient to such Concept drifts. However, there is no principled framework to\nidentify the drivers behind the drift in model performance. In this paper, we\npropose a novel framework - DBShap that uses Shapley values to identify the\nmain contributors of the drift and quantify their respective contributions. The\nproposed framework not only quantifies the importance of individual features in\ndriving the drift but also includes the change in the underlying relation\nbetween the input and output as a possible driver. The explanation provided by\nDBShap can be used to understand the root cause behind the drift and use it to\nmake the model resilient to the drift.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.09757", "title": "Cooperative Tri-Point Model-Based Ground-to-Air Coverage Extension in\n  Beyond 5G Networks", "abstract": "The utilization of existing terrestrial infrastructures to provide coverage\nfor aerial users is a potentially low-cost solution. However, the already\ndeployed terrestrial base stations (TBSs) result in weak ground-to-air (G2A)\ncoverage due to the down-tilted antennas. Furthermore, achieving optimal\ncoverage across the entire airspace through antenna adjustment is challenging\ndue to the complex signal coverage requirements in three-dimensional space,\nespecially in the vertical direction. In this paper, we propose a cooperative\ntri-point (CoTP) model-based method that utilizes cooperative beams to enhance\nthe G2A coverage extension. To utilize existing TBSs for establishing effective\ncooperation, we prove that the cooperation among three TBSs can ensure G2A\ncoverage with a minimum coverage overlap, and design the CoTP model to analyze\nthe G2A coverage extension. Using the model, a cooperative coverage structure\nbased on Delaunay triangulation is designed to divide triangular prism-shaped\nsubspaces and corresponding TBS cooperation sets. To enable TBSs in the\ncooperation set to cover different height subspaces while maintaining ground\ncoverage, we design a cooperative beam generation algorithm to maximize the\ncoverage in the triangular prism-shaped airspace. The simulation results and\nfield trials demonstrate that the proposed method can efficiently enhance the\nG2A coverage extension while guaranteeing ground coverage.", "field": "Computer Science", "categories": "cs.IT,cs.AI,math.IT"}, {"arxiv_id": "2401.09758", "title": "Resolving Regular Polysemy in Named Entities", "abstract": "Word sense disambiguation primarily addresses the lexical ambiguity of common\nwords based on a predefined sense inventory. Conversely, proper names are\nusually considered to denote an ad-hoc real-world referent. Once the reference\nis decided, the ambiguity is purportedly resolved. However, proper names also\nexhibit ambiguities through appellativization, i.e., they act like common words\nand may denote different aspects of their referents. We proposed to address the\nambiguities of proper names through the light of regular polysemy, which we\nformalized as dot objects. This paper introduces a combined word sense\ndisambiguation (WSD) model for disambiguating common words against Chinese\nWordnet (CWN) and proper names as dot objects. The model leverages the\nflexibility of a gloss-based model architecture, which takes advantage of the\nglosses and example sentences of CWN. We show that the model achieves\ncompetitive results on both common and proper nouns, even on a relatively\nsparse sense dataset. Aside from being a performant WSD tool, the model further\nfacilitates the future development of the lexical resource.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.09759", "title": "SlideAVSR: A Dataset of Paper Explanation Videos for Audio-Visual Speech\n  Recognition", "abstract": "Audio-visual speech recognition (AVSR) is a multimodal extension of automatic\nspeech recognition (ASR), using video as a complement to audio. In AVSR,\nconsiderable efforts have been directed at datasets for facial features such as\nlip-readings, while they often fall short in evaluating the image comprehension\ncapabilities in broader contexts. In this paper, we construct SlideAVSR, an\nAVSR dataset using scientific paper explanation videos. SlideAVSR provides a\nnew benchmark where models transcribe speech utterances with texts on the\nslides on the presentation recordings. As technical terminologies that are\nfrequent in paper explanations are notoriously challenging to transcribe\nwithout reference texts, our SlideAVSR dataset spotlights a new aspect of AVSR\nproblems. As a simple yet effective baseline, we propose DocWhisper, an AVSR\nmodel that can refer to textual information from slides, and confirm its\neffectiveness on SlideAVSR.", "field": "Computer Science", "categories": "cs.CV,cs.MM,cs.SD,eess.AS"}, {"arxiv_id": "2401.0976", "title": "A Comparative Study on Annotation Quality of Crowdsourcing and LLM via\n  Label Aggregation", "abstract": "Whether Large Language Models (LLMs) can outperform crowdsourcing on the data\nannotation task is attracting interest recently. Some works verified this issue\nwith the average performance of individual crowd workers and LLM workers on\nsome specific NLP tasks by collecting new datasets. However, on the one hand,\nexisting datasets for the studies of annotation quality in crowdsourcing are\nnot yet utilized in such evaluations, which potentially provide reliable\nevaluations from a different viewpoint. On the other hand, the quality of these\naggregated labels is crucial because, when utilizing crowdsourcing, the\nestimated labels aggregated from multiple crowd labels to the same instances\nare the eventually collected labels. Therefore, in this paper, we first\ninvestigate which existing crowdsourcing datasets can be used for a comparative\nstudy and create a benchmark. We then compare the quality between individual\ncrowd labels and LLM labels and make the evaluations on the aggregated labels.\nIn addition, we propose a Crowd-LLM hybrid label aggregation method and verify\nthe performance. We find that adding LLM labels from good LLMs to existing\ncrowdsourcing datasets can enhance the quality of the aggregated labels of the\ndatasets, which is also higher than the quality of LLM labels themselves.", "field": "Computer Science", "categories": "cs.CL,cs.HC"}, {"arxiv_id": "2401.09763", "title": "CLIP Model for Images to Textual Prompts Based on Top-k Neighbors", "abstract": "Text-to-image synthesis, a subfield of multimodal generation, has gained\nsignificant attention in recent years. We propose a cost-effective approach for\nimage-to-prompt generation that leverages generative models to generate textual\nprompts without the need for large amounts of annotated data. We divide our\nmethod into two stages: online stage and offline stage. We use a combination of\nthe CLIP model and K-nearest neighbors (KNN) algorithm. The proposed system\nconsists of two main parts: an offline task and an online task. Our method owns\nthe highest metric 0.612 among these models, which is 0.013, 0.055, 0.011\nhigher than Clip, Clip + KNN(top 10) respectively.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.09764", "title": "Generation of weighted trees, block trees and block graphs", "abstract": "We present a general framework to generate trees every vertex of which has a\nnon-negative weight and a color. The colors are used to impose certain\nrestrictions on the weight and colors of other vertices. We first extend the\nenumeration algorithms of unweighted trees given in [19, 20] to generate\nweighted trees that allow zero weight. We avoid isomorphisms by generalizing\nthe concept of centroids to weighted trees and then using the so-called\ncentroid-rooted canonical weighted trees. We provide a time complexity analysis\nof unranking algorithms and also show that the output delay complexity of\nenumeration is linear. The framework can be used to generate graph classes\ntaking advantage of their tree-based decompositions/representations. We\ndemonstrate our framework by generating weighted block trees which are in\none-to-one correspondence with connected block graphs. All connected block\ngraphs up to 19 vertices are publicly available at [1].", "field": "Computer Science", "categories": "cs.DM,cs.DS"}, {"arxiv_id": "2401.09767", "title": "On the Effectiveness of Function-Level Vulnerability Detectors for\n  Inter-Procedural Vulnerabilities", "abstract": "Software vulnerabilities are a major cyber threat and it is important to\ndetect them. One important approach to detecting vulnerabilities is to use deep\nlearning while treating a program function as a whole, known as function-level\nvulnerability detectors. However, the limitation of this approach is not\nunderstood. In this paper, we investigate its limitation in detecting one class\nof vulnerabilities known as inter-procedural vulnerabilities, where the\nto-be-patched statements and the vulnerability-triggering statements belong to\ndifferent functions. For this purpose, we create the first Inter-Procedural\nVulnerability Dataset (InterPVD) based on C/C++ open-source software, and we\npropose a tool dubbed VulTrigger for identifying vulnerability-triggering\nstatements across functions. Experimental results show that VulTrigger can\neffectively identify vulnerability-triggering statements and inter-procedural\nvulnerabilities. Our findings include: (i) inter-procedural vulnerabilities are\nprevalent with an average of 2.8 inter-procedural layers; and (ii)\nfunction-level vulnerability detectors are much less effective in detecting\nto-be-patched functions of inter-procedural vulnerabilities than detecting\ntheir counterparts of intra-procedural vulnerabilities.", "field": "Computer Science", "categories": "cs.CR,cs.SE"}, {"arxiv_id": "2401.09769", "title": "Towards Learning from Graphs with Heterophily: Progress and Future", "abstract": "Graphs are structured data that models complex relations between real-world\nentities. Heterophilous graphs, where linked nodes are prone to be with\ndifferent labels or dissimilar features, have recently attracted significant\nattention and found many applications. Meanwhile, increasing efforts have been\nmade to advance learning from heterophilous graphs. Although there exist\nsurveys on the relevant topic, they focus on heterophilous GNNs, which are only\nsub-topics of heterophilous graph learning. In this survey, we comprehensively\noverview existing works on learning from graphs with heterophily.First, we\ncollect over 180 publications and introduce the development of this field.\nThen, we systematically categorize existing methods based on a hierarchical\ntaxonomy including learning strategies, model architectures and practical\napplications. Finally, we discuss the primary challenges of existing studies\nand highlight promising avenues for future research.More publication details\nand corresponding open-source codes can be accessed and will be continuously\nupdated at our\nrepositories:https://github.com/gongchenghua/Awesome-Survey-Graphs-with-Heterophily.", "field": "Computer Science", "categories": "cs.SI,cs.AI,cs.LG"}, {"arxiv_id": "2401.0977", "title": "Reliability-based G1 Continuous Arc Spline Approximation", "abstract": "In this paper, we present an algorithm to approximate a set of data points\nwith G1 continuous arcs, using points' covariance data. To the best of our\nknowledge, previous arc spline approximation approaches assumed that all data\npoints contribute equally (i.e. have the same weights) during the approximation\nprocess. However, this assumption may cause serious instability in the\nalgorithm, if the collected data contains outliers. To resolve this issue, a\nrobust method for arc spline approximation is suggested in this work, assuming\nthat the 2D covariance for each data point is given. Starting with the\ndefinition of models and parameters for single arc approximation, the framework\nis extended to multiple-arc approximation for general usage. Then the proposed\nalgorithm is verified using generated noisy data and real-world collected data\nvia vehicle experiment in Sejong City, South Korea.", "field": "Computer Science", "categories": "cs.CG"}, {"arxiv_id": "2401.09772", "title": "Robotic Test Tube Rearrangement Using Combined Reinforcement Learning\n  and Motion Planning", "abstract": "A combined task-level reinforcement learning and motion planning framework is\nproposed in this paper to address a multi-class in-rack test tube rearrangement\nproblem. At the task level, the framework uses reinforcement learning to infer\na sequence of swap actions while ignoring robotic motion details. At the motion\nlevel, the framework accepts the swapping action sequences inferred by\ntask-level agents and plans the detailed robotic pick-and-place motion. The\ntask and motion-level planning form a closed loop with the help of a condition\nset maintained for each rack slot, which allows the framework to perform\nreplanning and effectively find solutions in the presence of low-level\nfailures. Particularly for reinforcement learning, the framework leverages a\ndistributed deep Q-learning structure with the Dueling Double Deep Q Network\n(D3QN) to acquire near-optimal policies and uses an A${}^\\star$-based\npost-processing technique to amplify the collected training data. The D3QN and\ndistributed learning help increase training efficiency. The post-processing\nhelps complete unfinished action sequences and remove redundancy, thus making\nthe training data more effective. We carry out both simulations and real-world\nstudies to understand the performance of the proposed framework. The results\nverify the performance of the RL and post-processing and show that the\nclosed-loop combination improves robustness. The framework is ready to\nincorporate various sensory feedback. The real-world studies also demonstrated\nthe incorporation.", "field": "Computer Science", "categories": "cs.RO"}, {"arxiv_id": "2401.09773", "title": "SEINE: Structure Encoding and Interaction Network for Nuclei Instance\n  Segmentation", "abstract": "Nuclei instance segmentation in histopathological images is of great\nimportance for biological analysis and cancer diagnosis but remains challenging\nfor two reasons. (1) Similar visual presentation of intranuclear and\nextranuclear regions of chromophobe nuclei often causes under-segmentation, and\n(2) current methods lack the exploration of nuclei structure, resulting in\nfragmented instance predictions. To address these problems, this paper proposes\na structure encoding and interaction network, termed SEINE, which develops the\nstructure modeling scheme of nuclei and exploits the structure similarity\nbetween nuclei to improve the integrality of each segmented instance.\nConcretely, SEINE introduces a contour-based structure encoding (SE) that\nconsiders the correlation between nuclei structure and semantics, realizing a\nreasonable representation of the nuclei structure. Based on the encoding, we\npropose a structure-guided attention (SGA) that takes the clear nuclei as\nprototypes to enhance the structure learning for the fuzzy nuclei. To\nstrengthen the structural learning ability, a semantic feature fusion (SFF) is\npresented to boost the semantic consistency of semantic and structure branches.\nFurthermore, a position enhancement (PE) method is applied to suppress\nincorrect nuclei boundary predictions. Extensive experiments demonstrate the\nsuperiority of our approaches, and SEINE achieves state-of-the-art (SOTA)\nperformance on four datasets. The code is available at\n\\href{https://github.com/zhangye-zoe/SEINE}{https://github.com/zhangye-zoe/SEINE}.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.09774", "title": "On the Audio Hallucinations in Large Audio-Video Language Models", "abstract": "Large audio-video language models can generate descriptions for both video\nand audio. However, they sometimes ignore audio content, producing audio\ndescriptions solely reliant on visual information. This paper refers to this as\naudio hallucinations and analyzes them in large audio-video language models. We\ngather 1,000 sentences by inquiring about audio information and annotate them\nwhether they contain hallucinations. If a sentence is hallucinated, we also\ncategorize the type of hallucination. The results reveal that 332 sentences are\nhallucinated with distinct trends observed in nouns and verbs for each\nhallucination type. Based on this, we tackle a task of audio hallucination\nclassification using pre-trained audio-text models in the zero-shot and\nfine-tuning settings. Our experimental results reveal that the zero-shot models\nachieve higher performance (52.2% in F1) than the random (40.3%) and the\nfine-tuning models achieve 87.9%, outperforming the zero-shot models.", "field": "Computer Science", "categories": "cs.MM,cs.CL,cs.CV,cs.SD,eess.AS"}, {"arxiv_id": "2401.09775", "title": "Controllable Decontextualization of Yes/No Question and Answers into\n  Factual Statements", "abstract": "Yes/No or polar questions represent one of the main linguistic question\ncategories. They consist of a main interrogative clause, for which the answer\nis binary (assertion or negation). Polar questions and answers (PQA) represent\na valuable knowledge resource present in many community and other curated QA\nsources, such as forums or e-commerce applications. Using answers to polar\nquestions alone in other contexts is not trivial. Answers are contextualized,\nand presume that the interrogative question clause and any shared knowledge\nbetween the asker and answerer are provided.\n  We address the problem of controllable rewriting of answers to polar\nquestions into decontextualized and succinct factual statements. We propose a\nTransformer sequence to sequence model that utilizes soft-constraints to ensure\ncontrollable rewriting, such that the output statement is semantically\nequivalent to its PQA input. Evaluation on three separate PQA datasets as\nmeasured through automated and human evaluation metrics show that our proposed\napproach achieves the best performance when compared to existing baselines.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.09783", "title": "Leveraging Biases in Large Language Models: \"bias-kNN'' for Effective\n  Few-Shot Learning", "abstract": "Large Language Models (LLMs) have shown significant promise in various\napplications, including zero-shot and few-shot learning. However, their\nperformance can be hampered by inherent biases. Instead of traditionally sought\nmethods that aim to minimize or correct these biases, this study introduces a\nnovel methodology named ``bias-kNN''. This approach capitalizes on the biased\noutputs, harnessing them as primary features for kNN and supplementing with\ngold labels. Our comprehensive evaluations, spanning diverse domain text\nclassification datasets and different GPT-2 model sizes, indicate the\nadaptability and efficacy of the ``bias-kNN'' method. Remarkably, this approach\nnot only outperforms conventional in-context learning in few-shot scenarios but\nalso demonstrates robustness across a spectrum of samples, templates and\nverbalizers. This study, therefore, presents a unique perspective on harnessing\nbiases, transforming them into assets for enhanced model performance.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.09785", "title": "Instant Answering in E-Commerce Buyer-Seller Messaging", "abstract": "E-commerce customers frequently seek detailed product information for\npurchase decisions, commonly contacting sellers directly with extended queries.\nThis manual response requirement imposes additional costs and disrupts buyer's\nshopping experience with response time fluctuations ranging from hours to days.\nWe seek to automate buyer inquiries to sellers in a leading e-commerce store\nusing a domain-specific federated Question Answering (QA) system. The main\nchallenge is adapting current QA systems, designed for single questions, to\naddress detailed customer queries. We address this with a low-latency,\nsequence-to-sequence approach, MESSAGE-TO-QUESTION ( M2Q ). It reformulates\nbuyer messages into succinct questions by identifying and extracting the most\nsalient information from a message. Evaluation against baselines shows that M2Q\nyields relative increases of 757% in question understanding, and 1,746% in\nanswering rate from the federated QA system. Live deployment shows that\nautomatic answering saves sellers from manually responding to millions of\nmessages per year, and also accelerates customer purchase decisions by\neliminating the need for buyers to wait for a reply", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.09786", "title": "Adaptive Self-training Framework for Fine-grained Scene Graph Generation", "abstract": "Scene graph generation (SGG) models have suffered from inherent problems\nregarding the benchmark datasets such as the long-tailed predicate distribution\nand missing annotation problems. In this work, we aim to alleviate the\nlong-tailed problem of SGG by utilizing unannotated triplets. To this end, we\nintroduce a Self-Training framework for SGG (ST-SGG) that assigns pseudo-labels\nfor unannotated triplets based on which the SGG models are trained. While there\nhas been significant progress in self-training for image recognition, designing\na self-training framework for the SGG task is more challenging due to its\ninherent nature such as the semantic ambiguity and the long-tailed distribution\nof predicate classes. Hence, we propose a novel pseudo-labeling technique for\nSGG, called Class-specific Adaptive Thresholding with Momentum (CATM), which is\na model-agnostic framework that can be applied to any existing SGG models.\nFurthermore, we devise a graph structure learner (GSL) that is beneficial when\nadopting our proposed self-training framework to the state-of-the-art\nmessage-passing neural network (MPNN)-based SGG models. Our extensive\nexperiments verify the effectiveness of ST-SGG on various SGG models,\nparticularly in enhancing the performance on fine-grained predicate classes.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.09787", "title": "Querying Easily Flip-flopped Samples for Deep Active Learning", "abstract": "Active learning is a machine learning paradigm that aims to improve the\nperformance of a model by strategically selecting and querying unlabeled data.\nOne effective selection strategy is to base it on the model's predictive\nuncertainty, which can be interpreted as a measure of how informative a sample\nis. The sample's distance to the decision boundary is a natural measure of\npredictive uncertainty, but it is often intractable to compute, especially for\ncomplex decision boundaries formed in multiclass classification tasks. To\naddress this issue, this paper proposes the {\\it least disagree metric} (LDM),\ndefined as the smallest probability of disagreement of the predicted label, and\nan estimator for LDM proven to be asymptotically consistent under mild\nassumptions. The estimator is computationally efficient and can be easily\nimplemented for deep learning models using parameter perturbation. The\nLDM-based active learning is performed by querying unlabeled data with the\nsmallest LDM. Experimental results show that our LDM-based active learning\nalgorithm obtains state-of-the-art overall performance on all considered\ndatasets and deep architectures.", "field": "Computer Science", "categories": "cs.LG,cs.AI,stat.ML"}, {"arxiv_id": "2401.09789", "title": "A Semantic Approach for Big Data Exploration in Industry 4.0", "abstract": "The growing trends in automation, Internet of Things, big data and cloud\ncomputing technologies have led to the fourth industrial revolution (Industry\n4.0), where it is possible to visualize and identify patterns and insights,\nwhich results in a better understanding of the data and can improve the\nmanufacturing process. However, many times, the task of data exploration\nresults difficult for manufacturing experts because they might be interested in\nanalyzing also data that does not appear in pre-designed visualizations and\ntherefore they must be assisted by Information Technology experts. In this\npaper, we present a proposal materialized in a semantic-based visual query\nsystem developed for a real Industry 4.0 scenario that allows domain experts to\nexplore and visualize data in a friendly way. The main novelty of the system is\nthe combined use that it makes of captured data that are semantically annotated\nfirst, and a 2D customized digital representation of a machine that is also\nlinked with semantic descriptions. Those descriptions are expressed using terms\nof an ontology, where, among others, the sensors that are used to capture\nindicators about the performance of a machine that belongs to a Industry 4.0\nscenario have been modeled. Moreover, this semantic description allows to:\nformulate queries at a higher level of abstraction, provide customized\ngraphical visualizations of the results based on the format and nature of the\ndata, and download enriched data enabling further types of analysis.", "field": "Computer Science", "categories": "cs.AI,cs.DB"}, {"arxiv_id": "2401.09793", "title": "PatchAD: Patch-based MLP-Mixer for Time Series Anomaly Detection", "abstract": "Anomaly detection stands as a crucial aspect of time series analysis, aiming\nto identify abnormal events in time series samples. The central challenge of\nthis task lies in effectively learning the representations of normal and\nabnormal patterns in a label-lacking scenario. Previous research mostly relied\non reconstruction-based approaches, restricting the representational abilities\nof the models. In addition, most of the current deep learning-based methods are\nnot lightweight enough, which prompts us to design a more efficient framework\nfor anomaly detection. In this study, we introduce PatchAD, a novel multi-scale\npatch-based MLP-Mixer architecture that leverages contrastive learning for\nrepresentational extraction and anomaly detection. Specifically, PatchAD is\ncomposed of four distinct MLP Mixers, exclusively utilizing the MLP\narchitecture for high efficiency and lightweight architecture. Additionally, we\nalso innovatively crafted a dual project constraint module to mitigate\npotential model degradation. Comprehensive experiments demonstrate that PatchAD\nachieves state-of-the-art results across multiple real-world multivariate time\nseries datasets. Our code is publicly\navailable.\\footnote{\\url{https://github.com/EmorZz1G/PatchAD}}", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.09794", "title": "Wavelet-Guided Acceleration of Text Inversion in Diffusion-Based Image\n  Editing", "abstract": "In the field of image editing, Null-text Inversion (NTI) enables fine-grained\nediting while preserving the structure of the original image by optimizing null\nembeddings during the DDIM sampling process. However, the NTI process is\ntime-consuming, taking more than two minutes per image. To address this, we\nintroduce an innovative method that maintains the principles of the NTI while\naccelerating the image editing process. We propose the WaveOpt-Estimator, which\ndetermines the text optimization endpoint based on frequency characteristics.\nUtilizing wavelet transform analysis to identify the image's frequency\ncharacteristics, we can limit text optimization to specific timesteps during\nthe DDIM sampling process. By adopting the Negative-Prompt Inversion (NPI)\nconcept, a target prompt representing the original image serves as the initial\ntext value for optimization. This approach maintains performance comparable to\nNTI while reducing the average editing time by over 80% compared to the NTI\nmethod. Our method presents a promising approach for efficient, high-quality\nimage editing based on diffusion models.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.09795", "title": "A Comparative Analysis on Metaheuristic Algorithms Based Vision\n  Transformer Model for Early Detection of Alzheimer's Disease", "abstract": "A number of life threatening neuro-degenerative disorders had degraded the\nquality of life for the older generation in particular. Dementia is one such\nsymptom which may lead to a severe condition called Alzheimer's disease if not\ndetected at an early stage. It has been reported that the progression of such\ndisease from a normal stage is due to the change in several parameters inside\nthe human brain. In this paper, an innovative metaheuristic algorithms based\nViT model has been proposed for the identification of dementia at different\nstage. A sizeable number of test data have been utilized for the validation of\nthe proposed scheme. It has also been demonstrated that our model exhibits\nsuperior performance in terms of accuracy, precision, recall as well as\nF1-score.", "field": "Computer Science", "categories": "cs.NE,cs.AI"}, {"arxiv_id": "2401.09796", "title": "A Fast, Performant, Secure Distributed Training Framework For Large\n  Language Model", "abstract": "The distributed (federated) LLM is an important method for co-training the\ndomain-specific LLM using siloed data. However, maliciously stealing model\nparameters and data from the server or client side has become an urgent problem\nto be solved. In this paper, we propose a secure distributed LLM based on model\nslicing. In this case, we deploy the Trusted Execution Environment (TEE) on\nboth the client and server side, and put the fine-tuned structure (LoRA or\nembedding of P-tuning v2) into the TEE. Then, secure communication is executed\nin the TEE and general environments through lightweight encryption. In order to\nfurther reduce the equipment cost as well as increase the model performance and\naccuracy, we propose a split fine-tuning scheme. In particular, we split the\nLLM by layers and place the latter layers in a server-side TEE (the client does\nnot need a TEE). We then combine the proposed Sparsification Parameter\nFine-tuning (SPF) with the LoRA part to improve the accuracy of the downstream\ntask. Numerous experiments have shown that our method guarantees accuracy while\nmaintaining security.", "field": "Computer Science", "categories": "cs.LG,cs.CR"}, {"arxiv_id": "2401.09798", "title": "All in How You Ask for It: Simple Black-Box Method for Jailbreak Attacks", "abstract": "Large Language Models (LLMs) like ChatGPT face `jailbreak' challenges, where\nsafeguards are bypassed to produce ethically harmful prompts. This study\nintroduces a simple black-box method to effectively generate jailbreak prompts,\novercoming the limitations of high complexity and computational costs\nassociated with existing methods. The proposed technique iteratively rewrites\nharmful prompts into non-harmful expressions using the target LLM itself, based\non the hypothesis that LLMs can directly sample safeguard-bypassing\nexpressions. Demonstrated through experiments with ChatGPT (GPT-3.5 and GPT-4)\nand Gemini-Pro, this method achieved an attack success rate of over 80% within\nan average of 5 iterations and remained effective despite model updates. The\njailbreak prompts generated were naturally-worded and concise, suggesting they\nare less detectable. The results indicate that creating effective jailbreak\nprompts is simpler than previously considered, and black-box jailbreak attacks\npose a more serious security threat.", "field": "Computer Science", "categories": "cs.CL,cs.AI,cs.CY"}, {"arxiv_id": "2401.098", "title": "Power System Fault Diagnosis with Quantum Computing and Efficient Gate\n  Decomposition", "abstract": "Power system fault diagnosis is crucial for identifying the location and\ncauses of faults and providing decision-making support for power dispatchers.\nHowever, most classical methods suffer from significant time-consuming, memory\noverhead, and computational complexity issues as the scale of the power system\nconcerned increases. With rapid development of quantum computing technology,\nthe combinatorial optimization method based on quantum computing has shown\ncertain advantages in computational time over existing methods. Given this\nbackground, this paper proposes a quantum computing based power system fault\ndiagnosis method with the Quantum Approximate Optimization Algorithm (QAOA).\nThe proposed method reformulates the fault diagnosis problem as a Hamiltonian\nby using Ising model, which completely preserves the coupling relationship\nbetween faulty components and various operations of protective relays and\ncircuit breakers. Additionally, to enhance problem-solving efficiency under\ncurrent equipment limitations, the symmetric equivalent decomposition method of\nmulti-z-rotation gate is proposed. Furthermore, the small probability\ncharacteristics of power system events is utilized to reduce the number of\nqubits. Simulation results based on the test system show that the proposed\nmethods can achieve the same optimal results with a faster speed compared with\nthe classical higher-order solver provided by D-Wave.", "field": "Computer Science", "categories": "eess.SY,cs.SY"}, {"arxiv_id": "2401.09804", "title": "Clickbait vs. Quality: How Engagement-Based Optimization Shapes the\n  Content Landscape in Online Platforms", "abstract": "Online content platforms commonly use engagement-based optimization when\nmaking recommendations. This encourages content creators to invest in quality,\nbut also rewards gaming tricks such as clickbait. To understand the total\nimpact on the content landscape, we study a game between content creators\ncompeting on the basis of engagement metrics and analyze the equilibrium\ndecisions about investment in quality and gaming. First, we show the content\ncreated at equilibrium exhibits a positive correlation between quality and\ngaming, and we empirically validate this finding on a Twitter dataset. Using\nthe equilibrium structure of the content landscape, we then examine the\ndownstream performance of engagement-based optimization along several axes.\nPerhaps counterintuitively, the average quality of content consumed by users\ncan decrease at equilibrium as gaming tricks become more costly for content\ncreators to employ. Moreover, engagement-based optimization can perform worse\nin terms of user utility than a baseline with random recommendations, and\nengagement-based optimization is also suboptimal in terms of realized\nengagement relative to quality-based optimization. Altogether, our results\nhighlight the need to consider content creator incentives when evaluating a\nplatform's choice of optimization metric.", "field": "Computer Science", "categories": "cs.GT,cs.CY,cs.LG"}, {"arxiv_id": "2401.09808", "title": "SensoDat: Simulation-based Sensor Dataset of Self-driving Cars", "abstract": "Developing tools in the context of autonomous systems [22, 24 ], such as\nself-driving cars (SDCs), is time-consuming and costly since researchers and\npractitioners rely on expensive computing hardware and simulation software. We\npropose SensoDat, a dataset of 32,580 executed simulation-based SDC test cases\ngenerated with state-of-the-art test generators for SDCs. The dataset consists\nof trajectory logs and a variety of sensor data from the SDCs (e.g., rpm, wheel\nspeed, brake thermals, transmission, etc.) represented as a time series. In\ntotal, SensoDat provides data from 81 different simulated sensors. Future\nresearch in the domain of SDCs does not necessarily depend on executing\nexpensive test cases when using SensoDat. Furthermore, with the high amount and\nvariety of sensor data, we think SensoDat can contribute to research,\nparticularly for AI development, regression testing techniques for\nsimulation-based SDC testing, flakiness in simulation, etc. Link to the\ndataset: https://doi.org/10.5281/zenodo.10307479", "field": "Computer Science", "categories": "cs.SE"}, {"arxiv_id": "2401.09815", "title": "Simple and effective data augmentation for compositional generalization", "abstract": "Compositional generalization, the ability to predict complex meanings from\ntraining on simpler sentences, poses challenges for powerful pretrained seq2seq\nmodels. In this paper, we show that data augmentation methods that sample MRs\nand backtranslate them can be effective for compositional generalization, but\nonly if we sample from the right distribution. Remarkably, sampling from a\nuniform distribution performs almost as well as sampling from the test\ndistribution, and greatly outperforms earlier methods that sampled from the\ntraining distribution. We further conduct experiments to investigate the reason\nwhy this happens and where the benefit of such data augmentation methods come\nfrom.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.09819", "title": "PPNet: A Novel Neural Network Structure for End-to-End Near-Optimal Path\n  Planning", "abstract": "The classical path planners, such as sampling-based path planners, have the\nlimitations of sensitivity to the initial solution and slow convergence to the\noptimal solution. However, finding a near-optimal solution in a short period is\nchallenging in many applications such as the autonomous vehicle with limited\npower/fuel. To achieve an end-to-end near-optimal path planner, we first divide\nthe path planning problem into two subproblems, which are path's space\nsegmentation and waypoints generation in the given path's space. We further\npropose a two-level cascade neural network named Path Planning Network (PPNet)\nto solve the path planning problem by solving the abovementioned subproblems.\nMoreover, we propose a novel efficient data generation method for path planning\nnamed EDaGe-PP. The results show the total computation time is less than 1/33\nand the success rate of PPNet trained by the dataset that is generated by\nEDaGe-PP is about $2 \\times$ compared to other methods. We validate PPNet\nagainst state-of-the-art path planning methods. The results show PPNet can find\na near-optimal solution in 15.3ms, which is much shorter than the\nstate-of-the-art path planners.", "field": "Computer Science", "categories": "cs.RO,cs.AI,cs.LG"}, {"arxiv_id": "2401.09823", "title": "Enhancing Small Object Encoding in Deep Neural Networks: Introducing\n  Fast&Focused-Net with Volume-wise Dot Product Layer", "abstract": "In this paper, we introduce Fast&Focused-Net, a novel deep neural network\narchitecture tailored for efficiently encoding small objects into fixed-length\nfeature vectors. Contrary to conventional Convolutional Neural Networks (CNNs),\nFast&Focused-Net employs a series of our newly proposed layer, the Volume-wise\nDot Product (VDP) layer, designed to address several inherent limitations of\nCNNs. Specifically, CNNs often exhibit a smaller effective receptive field than\ntheir theoretical counterparts, limiting their vision span. Additionally, the\ninitial layers in CNNs produce low-dimensional feature vectors, presenting a\nbottleneck for subsequent learning. Lastly, the computational overhead of CNNs,\nparticularly in capturing diverse image regions by parameter sharing, is\nsignificantly high. The VDP layer, at the heart of Fast&Focused-Net, aims to\nremedy these issues by efficiently covering the entire image patch information\nwith reduced computational demand. Experimental results demonstrate the prowess\nof Fast&Focused-Net in a variety of applications. For small object\nclassification tasks, our network outperformed state-of-the-art methods on\ndatasets such as CIFAR-10, CIFAR-100, STL-10, SVHN-Cropped, and Fashion-MNIST.\nIn the context of larger image classification, when combined with a transformer\nencoder (ViT), Fast&Focused-Net produced competitive results for OpenImages V6,\nImageNet-1K, and Places365 datasets. Moreover, the same combination showcased\nunparalleled performance in text recognition tasks across SVT, IC15, SVTP, and\nHOST datasets. This paper presents the architecture, the underlying motivation,\nand extensive empirical evidence suggesting that Fast&Focused-Net is a\npromising direction for efficient and focused deep learning.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.09824", "title": "Conning the Crypto Conman: End-to-End Analysis of Cryptocurrency-based\n  Technical Support Scams", "abstract": "The mainstream adoption of cryptocurrencies has led to a surge in\nwallet-related issues reported by ordinary users on social media platforms. In\nparallel, there is an increase in an emerging fraud trend called\ncryptocurrency-based technical support scam, in which fraudsters offer fake\nwallet recovery services and target users experiencing wallet-related issues.\n  In this paper, we perform a comprehensive study of cryptocurrency-based\ntechnical support scams. We present an analysis apparatus called HoneyTweet to\nanalyze this kind of scam. Through HoneyTweet, we lure over 9K scammers by\nposting 25K fake wallet support tweets (so-called honey tweets). We then deploy\nautomated systems to interact with scammers to analyze their modus operandi. In\nour experiments, we observe that scammers use Twitter as a starting point for\nthe scam, after which they pivot to other communication channels (eg email,\nInstagram, or Telegram) to complete the fraud activity. We track scammers\nacross those communication channels and bait them into revealing their payment\nmethods. Based on the modes of payment, we uncover two categories of scammers\nthat either request secret key phrase submissions from their victims or direct\npayments to their digital wallets. Furthermore, we obtain scam confirmation by\ndeploying honey wallet addresses and validating private key theft. We also\ncollaborate with the prominent payment service provider by sharing scammer data\ncollections. The payment service provider feedback was consistent with our\nfindings, thereby supporting our methodology and results. By consolidating our\nanalysis across various vantage points, we provide an end-to-end scam lifecycle\nanalysis and propose recommendations for scam mitigation.", "field": "Computer Science", "categories": "cs.CR"}, {"arxiv_id": "2401.09826", "title": "Boosting Few-Shot Semantic Segmentation Via Segment Anything Model", "abstract": "In semantic segmentation, accurate prediction masks are crucial for\ndownstream tasks such as medical image analysis and image editing. Due to the\nlack of annotated data, few-shot semantic segmentation (FSS) performs poorly in\npredicting masks with precise contours. Recently, we have noticed that the\nlarge foundation model segment anything model (SAM) performs well in processing\ndetailed features. Inspired by SAM, we propose FSS-SAM to boost FSS methods by\naddressing the issue of inaccurate contour. The FSS-SAM is training-free. It\nworks as a post-processing tool for any FSS methods and can improve the\naccuracy of predicted masks. Specifically, we use predicted masks from FSS\nmethods to generate prompts and then use SAM to predict new masks. To avoid\npredicting wrong masks with SAM, we propose a prediction result selection (PRS)\nalgorithm. The algorithm can remarkably decrease wrong predictions. Experiment\nresults on public datasets show that our method is superior to base FSS methods\nin both quantitative and qualitative aspects.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.09828", "title": "Enhanced Automated Quality Assessment Network for Interactive Building\n  Segmentation in High-Resolution Remote Sensing Imagery", "abstract": "In this research, we introduce the enhanced automated quality assessment\nnetwork (IBS-AQSNet), an innovative solution for assessing the quality of\ninteractive building segmentation within high-resolution remote sensing\nimagery. This is a new challenge in segmentation quality assessment, and our\nproposed IBS-AQSNet allievate this by identifying missed and mistaken segment\nareas. First of all, to acquire robust image features, our method combines a\nrobust, pre-trained backbone with a lightweight counterpart for comprehensive\nfeature extraction from imagery and segmentation results. These features are\nthen fused through a simple combination of concatenation, convolution layers,\nand residual connections. Additionally, ISR-AQSNet incorporates a multi-scale\ndifferential quality assessment decoder, proficient in pinpointing areas where\nsegmentation result is either missed or mistaken. Experiments on a newly-built\nEVLab-BGZ dataset, which includes over 39,198 buildings, demonstrate the\nsuperiority of the proposed method in automating segmentation quality\nassessment, thereby setting a new benchmark in the field.", "field": "Computer Science", "categories": "cs.CV,cs.HC"}, {"arxiv_id": "2401.09831", "title": "Measuring Object Rotation via Visuo-Tactile Segmentation", "abstract": "When carrying out robotic manipulation tasks, objects occasionally fall as a\nresult of the rotation caused by slippage. This can be prevented by obtaining\ntactile information that provides better knowledge on the physical properties\nof the grasping. In this paper, we estimate the rotation angle of a grasped\nobject when slippage occurs. We implement a system made up of a neural network\nwith which to segment the contact region and an algorithm with which to\nestimate the rotated angle of that region. This method is applied to DIGIT\ntactile sensors. Our system has additionally been trained and tested with our\npublicly available dataset which is, to the best of our knowledge, the first\ndataset related to tactile segmentation from non-synthetic images to appear in\nthe literature, and with which we have attained results of 95% and 90% as\nregards Dice and IoU metrics in the worst scenario. Moreover, we have obtained\na maximum error of 3 degrees when testing with objects not previously seen by\nour system in 45 different lifts. This, therefore, proved that our approach is\nable to detect the slippage movement, thus providing a possible reaction that\nwill prevent the object from falling.", "field": "Computer Science", "categories": "cs.RO"}, {"arxiv_id": "2401.09834", "title": "Convergence of a spatial semidiscretization for a three-dimensional\n  stochastic Allen-Cahn equation with multiplicative noise", "abstract": "This paper studies the convergence of a spatial semidiscretization of a\nthree-dimensional stochastic Allen-Cahn equation with multiplicative noise. For\nnon-smooth initial values, the regularity of the mild solution is investigated,\nand an error estimate is derived with the spatial $ L^2 $-norm. For smooth\ninitial values, two error estimates with the general spatial $ L^q $-norms are\nestablished.", "field": "Computer Science", "categories": "math.NA,cs.NA,math.PR,65M60, 60H15, 60H35"}, {"arxiv_id": "2401.09836", "title": "Exploring Latent Cross-Channel Embedding for Accurate 3D Human Pose\n  Reconstruction in a Diffusion Framework", "abstract": "Monocular 3D human pose estimation poses significant challenges due to the\ninherent depth ambiguities that arise during the reprojection process from 2D\nto 3D. Conventional approaches that rely on estimating an over-fit projection\nmatrix struggle to effectively address these challenges and often result in\nnoisy outputs. Recent advancements in diffusion models have shown promise in\nincorporating structural priors to address reprojection ambiguities. However,\nthere is still ample room for improvement as these methods often overlook the\nexploration of correlation between the 2D and 3D joint-level features. In this\nstudy, we propose a novel cross-channel embedding framework that aims to fully\nexplore the correlation between joint-level features of 3D coordinates and\ntheir 2D projections. In addition, we introduce a context guidance mechanism to\nfacilitate the propagation of joint graph attention across latent channels\nduring the iterative diffusion process. To evaluate the effectiveness of our\nproposed method, we conduct experiments on two benchmark datasets, namely\nHuman3.6M and MPI-INF-3DHP. Our results demonstrate a significant improvement\nin terms of reconstruction accuracy compared to state-of-the-art methods. The\ncode for our method will be made available online for further reference.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.09838", "title": "CATMA: Conformance Analysis Tool For Microservice Applications", "abstract": "The microservice architecture allows developers to divide the core\nfunctionality of their software system into multiple smaller services. However,\nthis architectural style also makes it harder for them to debug and assess\nwhether the system's deployment conforms to its implementation. We present\nCATMA, an automated tool that detects non-conformances between the system's\ndeployment and implementation. It automatically visualizes and generates\npotential interpretations for the detected discrepancies. Our evaluation of\nCATMA shows promising results in terms of performance and providing useful\ninsights. CATMA is available at\n\\url{https://cyber-analytics.nl/catma.github.io/}, and a demonstration video is\navailable at \\url{https://youtu.be/WKP1hG-TDKc}.", "field": "Computer Science", "categories": "cs.SE"}, {"arxiv_id": "2401.09839", "title": "MatSciRE: Leveraging Pointer Networks to Automate Entity and Relation\n  Extraction for Material Science Knowledge-base Construction", "abstract": "Material science literature is a rich source of factual information about\nvarious categories of entities (like materials and compositions) and various\nrelations between these entities, such as conductivity, voltage, etc.\nAutomatically extracting this information to generate a material science\nknowledge base is a challenging task. In this paper, we propose MatSciRE\n(Material Science Relation Extractor), a Pointer Network-based encoder-decoder\nframework, to jointly extract entities and relations from material science\narticles as a triplet ($entity1, relation, entity2$). Specifically, we target\nthe battery materials and identify five relations to work on - conductivity,\ncoulombic efficiency, capacity, voltage, and energy. Our proposed approach\nachieved a much better F1-score (0.771) than a previous attempt using\nChemDataExtractor (0.716). The overall graphical framework of MatSciRE is shown\nin Fig 1. The material information is extracted from material science\nliterature in the form of entity-relation triplets using MatSciRE.", "field": "Computer Science", "categories": "cs.CL,cs.CE,cs.IR"}, {"arxiv_id": "2401.09851", "title": "Behavioral Simulation: Exploring A Possible Next Paradigm for Science", "abstract": "Simulation technologies have been widely utilized in many scientific research\nfields such as weather forecasting, fluid mechanics and biological populations.\nIt is the best tool to handle problems in complex systems, where closed-form\nexpressions are unavailable and the target distribution in the representation\nspace is too complex to be fully represented by a deep learning (DL) model. We\nbelieve that the development of simulation technologies is consistent with\nscientific paradigms. This paper induces the evolution of scientific paradigms\nfrom the perspective of data, algorithms, and computational power. Building\nupon this perspective, we divide simulation technologies into three stages\naligning with the emergence of new paradigms, and find that advanced simulation\ntechnologies are typical instances of paradigms integration. Moreover, we\npropose the concept of behavioral simulation (BS), specifically sophisticated\nbehavioral simulation (SBS), representing a higher degree of paradigms\nintegration based on foundation models to simulate complex social systems\ninvolving sophisticated human strategies and behaviors. BS and further SBS are\ndesigned to tackle challenges concerning the complex human system that\nsurpasses the capacity of traditional agent-based modeling simulation (ABMS),\nwhich can be regarded as a possible next paradigm for science. Through this\nwork, we look forward to more powerful BS and SBS applications in scientific\nresearch branches within social science.", "field": "Computer Science", "categories": "cs.AI"}, {"arxiv_id": "2401.09852", "title": "Enhancing the Fairness and Performance of Edge Cameras with Explainable\n  AI", "abstract": "The rising use of Artificial Intelligence (AI) in human detection on Edge\ncamera systems has led to accurate but complex models, challenging to interpret\nand debug. Our research presents a diagnostic method using Explainable AI (XAI)\nfor model debugging, with expert-driven problem identification and solution\ncreation. Validated on the Bytetrack model in a real-world office Edge network,\nwe found the training dataset as the main bias source and suggested model\naugmentation as a solution. Our approach helps identify model biases, essential\nfor achieving fair and trustworthy models.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.09853", "title": "Game-theoretic Model Predictive Control for Modelling Competitive Supply\n  Chains", "abstract": "Supply chains transform raw materials into finished goods and distribute them\nto end consumers. The vast majority of products we use daily are supplied to us\nthrough complex global supply chains. This paper proposes a modelling\nmethodology for dynamic competitive supply chains based on game theory and\nmodel predictive control. We model each manufacturer in the supply chain as a\nrational utility maximizing agent that selects their actions by finding an\nopen-loop generalized Nash equilibrium of a multi-stage game. To react to\ncompetitors and the state of the market, every agent re-plans their actions in\na receding horizon manner based on estimates of market and supplier parameters\nthereby creating an approximate closed-loop equilibrium policy. We demonstrate\nthrough numerical simulations that this modelling approach is computationally\ntractable and generates economically interpretable behaviors in a variety of\nsettings such as demand spikes, supply shocks, and information asymmetry.", "field": "Computer Science", "categories": "eess.SY,cs.SY"}, {"arxiv_id": "2401.09854", "title": "A Survey on Energy Consumption and Environmental Impact of Video\n  Streaming", "abstract": "Climate change challenges require a notable decrease in worldwide greenhouse\ngas (GHG) emissions across technology sectors. Digital technologies, especially\nvideo streaming, accounting for most Internet traffic, make no exception. Video\nstreaming demand increases with remote working, multimedia communication\nservices (e.g., WhatsApp, Skype), video streaming content (e.g., YouTube,\nNetflix), video resolution (4K/8K, 50 fps/60 fps), and multi-view video, making\nenergy consumption and environmental footprint critical. This survey\ncontributes to a better understanding of sustainable and efficient video\nstreaming technologies by providing insights into the state-of-the-art and\npotential future directions for researchers, developers, and engineers, service\nproviders, hosting platforms, and consumers. We widen this survey's focus on\ncontent provisioning and content consumption based on the observation that\ncontinuously active network equipment underneath video streaming consumes\nsubstantial energy independent of the transmitted data type. We propose a\ntaxonomy of factors that affect the energy consumption in video streaming, such\nas encoding schemes, resource requirements, storage, content retrieval,\ndecoding, and display. We identify notable weaknesses in video streaming that\nrequire further research for improved energy efficiency: (1) fixed bitrate\nladders in HTTP live streaming; (2) inefficient hardware utilization of\nexisting video players; (3) lack of comprehensive open energy measurement\ndataset covering various device types and coding parameters for reproducible\nresearch.", "field": "Computer Science", "categories": "cs.MM"}, {"arxiv_id": "2401.09856", "title": "EDAF: An End-to-End Delay Analytics Framework for 5G-and-Beyond Networks", "abstract": "Supporting applications in emerging domains like cyber-physical systems and\nhuman-in-the-loop scenarios typically requires adherence to strict end-to-end\ndelay guarantees. Contributions of many tandem processes unfolding layer by\nlayer within the wireless network result in violations of delay constraints,\nthereby severely degrading application performance. Meeting the application's\nstringent requirements necessitates coordinated optimization of the end-to-end\ndelay by fine-tuning all contributing processes. To achieve this task, we\ndesigned and implemented EDAF, a framework to decompose packets' end-to-end\ndelays and determine each component's significance for 5G network. We showcase\nEDAF on OpenAirInterface 5G uplink, modified to report timestamps across the\ndata plane. By applying the obtained insights, we optimized end-to-end uplink\ndelay by eliminating segmentation and frame-alignment delays, decreasing\naverage delay from 12ms to 4ms.", "field": "Computer Science", "categories": "cs.NI"}, {"arxiv_id": "2401.09858", "title": "The Distortion of Threshold Approval Matching", "abstract": "We study matching settings in which a set of agents have private utilities\nover a set of items. Each agent reports a partition of the items into approval\nsets of different threshold utility levels. Given this limited information on\ninput, the goal is to compute an assignment of the items to the agents (subject\nto cardinality constraints depending on the application) that (approximately)\nmaximizes the social welfare (the total utility of the agents for their\nassigned items). We first consider the well-known, simple one-sided matching\nproblem in which each of $n$ agents is to be assigned exactly one of $n$ items.\nWe show that with $t$ threshold utility levels, the distortion of deterministic\nmatching algorithms is $\\Theta(\\sqrt[t]{n})$ while that of randomized\nalgorithms is $\\Theta(\\sqrt[t+1]{n})$. We then show that our distortion bounds\nextend to a more general setting in which there are multiple copies of the\nitems, each agent can be assigned a number of items (even copies of the same\none) up to a capacity, and the utility of an agent for an item depends on the\nnumber of its copies that the agent is given.", "field": "Computer Science", "categories": "cs.GT"}, {"arxiv_id": "2401.09859", "title": "Improving the Accuracy of Analog-Based In-Memory Computing Accelerators\n  Post-Training", "abstract": "Analog-Based In-Memory Computing (AIMC) inference accelerators can be used to\nefficiently execute Deep Neural Network (DNN) inference workloads. However, to\nmitigate accuracy losses, due to circuit and device non-idealities,\nHardware-Aware (HWA) training methodologies must be employed. These typically\nrequire significant information about the underlying hardware. In this paper,\nwe propose two Post-Training (PT) optimization methods to improve accuracy\nafter training is performed. For each crossbar, the first optimizes the\nconductance range of each column, and the second optimizes the input, i.e,\nDigital-to-Analog Converter (DAC), range. It is demonstrated that, when these\nmethods are employed, the complexity during training, and the amount of\ninformation about the underlying hardware can be reduced, with no notable\nchange in accuracy ($\\leq$0.1%) when finetuning the pretrained RoBERTa\ntransformer model for all General Language Understanding Evaluation (GLUE)\nbenchmark tasks. Additionally, it is demonstrated that further optimizing\nlearned parameters PT improves accuracy.", "field": "Computer Science", "categories": "cs.ET"}, {"arxiv_id": "2401.0986", "title": "Succinctness of Cosafety Fragments of LTL via Combinatorial Proof\n  Systems (extended version)", "abstract": "This paper focuses on succinctness results for fragments of Linear Temporal\nLogic with Past (LTL) devoid of binary temporal operators like until, and\nprovides methods to establish them. We prove that there is a family of cosafety\nlanguages (Ln)_{n>=1} such that Ln can be expressed with a pure future formula\nof size O(n), but it requires formulae of size 2^{\\Omega}(n) to be captured\nwith past formulae. As a by-product, such a succinctness result shows the\noptimality of the pastification algorithm proposed in [Artale et al., KR,\n2023]. We show that, in the considered case, succinctness cannot be proven by\nrelying on the classical automata-based method introduced in [Markey, Bull.\nEATCS, 2003]. In place of this method, we devise and apply a combinatorial\nproof system whose deduction trees represent LTL formulae. The system can be\nseen as a proof-centric (one-player) view on the games used by Adler and\nImmerman to study the succinctness of CTL.", "field": "Computer Science", "categories": "cs.LO,cs.FL,F.3.1; F.4.3"}, {"arxiv_id": "2401.09861", "title": "Temporal Insight Enhancement: Mitigating Temporal Hallucination in\n  Multimodal Large Language Models", "abstract": "Recent advancements in Multimodal Large Language Models (MLLMs) have\nsignificantly enhanced the comprehension of multimedia content, bringing\ntogether diverse modalities such as text, images, and videos. However, a\ncritical challenge faced by these models, especially when processing video\ninputs, is the occurrence of hallucinations - erroneous perceptions or\ninterpretations, particularly at the event level. This study introduces an\ninnovative method to address event-level hallucinations in MLLMs, focusing on\nspecific temporal understanding in video content. Our approach leverages a\nnovel framework that extracts and utilizes event-specific information from both\nthe event query and the provided video to refine MLLMs' response. We propose a\nunique mechanism that decomposes on-demand event queries into iconic actions.\nSubsequently, we employ models like CLIP and BLIP2 to predict specific\ntimestamps for event occurrences. Our evaluation, conducted using the\nCharades-STA dataset, demonstrates a significant reduction in temporal\nhallucinations and an improvement in the quality of event-related responses.\nThis research not only provides a new perspective in addressing a critical\nlimitation of MLLMs but also contributes a quantitatively measurable method for\nevaluating MLLMs in the context of temporal-related questions.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.09862", "title": "Evolutionary Multi-Objective Optimization of Large Language Model\n  Prompts for Balancing Sentiments", "abstract": "The advent of large language models (LLMs) such as ChatGPT has attracted\nconsiderable attention in various domains due to their remarkable performance\nand versatility. As the use of these models continues to grow, the importance\nof effective prompt engineering has come to the fore. Prompt optimization\nemerges as a crucial challenge, as it has a direct impact on model performance\nand the extraction of relevant information. Recently, evolutionary algorithms\n(EAs) have shown promise in addressing this issue, paving the way for novel\noptimization strategies. In this work, we propose a evolutionary\nmulti-objective (EMO) approach specifically tailored for prompt optimization\ncalled EMO-Prompts, using sentiment analysis as a case study. We use sentiment\nanalysis capabilities as our experimental targets. Our results demonstrate that\nEMO-Prompts effectively generates prompts capable of guiding the LLM to produce\ntexts embodying two conflicting emotions simultaneously.", "field": "Computer Science", "categories": "cs.NE,cs.AI,cs.CL,cs.LG"}, {"arxiv_id": "2401.09865", "title": "Improving fine-grained understanding in image-text pre-training", "abstract": "We introduce SPARse Fine-grained Contrastive Alignment (SPARC), a simple\nmethod for pretraining more fine-grained multimodal representations from\nimage-text pairs. Given that multiple image patches often correspond to single\nwords, we propose to learn a grouping of image patches for every token in the\ncaption. To achieve this, we use a sparse similarity metric between image\npatches and language tokens and compute for each token a language-grouped\nvision embedding as the weighted average of patches. The token and\nlanguage-grouped vision embeddings are then contrasted through a fine-grained\nsequence-wise loss that only depends on individual samples and does not require\nother batch samples as negatives. This enables more detailed information to be\nlearned in a computationally inexpensive manner. SPARC combines this\nfine-grained loss with a contrastive loss between global image and text\nembeddings to learn representations that simultaneously encode global and local\ninformation. We thoroughly evaluate our proposed method and show improved\nperformance over competing approaches both on image-level tasks relying on\ncoarse-grained information, e.g. classification, as well as region-level tasks\nrelying on fine-grained information, e.g. retrieval, object detection, and\nsegmentation. Moreover, SPARC improves model faithfulness and captioning in\nfoundational vision-language models.", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.LG"}, {"arxiv_id": "2401.09866", "title": "Boosting Few-Shot Segmentation via Instance-Aware Data Augmentation and\n  Local Consensus Guided Cross Attention", "abstract": "Few-shot segmentation aims to train a segmentation model that can fast adapt\nto a novel task for which only a few annotated images are provided. Most recent\nmodels have adopted a prototype-based paradigm for few-shot inference. These\napproaches may have limited generalization capacity beyond the standard 1- or\n5-shot settings. In this paper, we closely examine and reevaluate the\nfine-tuning based learning scheme that fine-tunes the classification layer of a\ndeep segmentation network pre-trained on diverse base classes. To improve the\ngeneralizability of the classification layer optimized with sparsely annotated\nsamples, we introduce an instance-aware data augmentation (IDA) strategy that\naugments the support images based on the relative sizes of the target objects.\nThe proposed IDA effectively increases the support set's diversity and promotes\nthe distribution consistency between support and query images. On the other\nhand, the large visual difference between query and support images may hinder\nknowledge transfer and cripple the segmentation performance. To cope with this\nchallenge, we introduce the local consensus guided cross attention (LCCA) to\nalign the query feature with support features based on their dense correlation,\nfurther improving the model's generalizability to the query image. The\nsignificant performance improvements on the standard few-shot segmentation\nbenchmarks PASCAL-$5^i$ and COCO-$20^i$ verify the efficacy of our proposed\nmethod.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.0987", "title": "Reconciling Spatial and Temporal Abstractions for Goal Representation", "abstract": "Goal representation affects the performance of Hierarchical Reinforcement\nLearning (HRL) algorithms by decomposing the complex learning problem into\neasier subtasks. Recent studies show that representations that preserve\ntemporally abstract environment dynamics are successful in solving difficult\nproblems and provide theoretical guarantees for optimality. These methods\nhowever cannot scale to tasks where environment dynamics increase in complexity\ni.e. the temporally abstract transition relations depend on larger number of\nvariables. On the other hand, other efforts have tried to use spatial\nabstraction to mitigate the previous issues. Their limitations include\nscalability to high dimensional environments and dependency on prior knowledge.\n  In this paper, we propose a novel three-layer HRL algorithm that introduces,\nat different levels of the hierarchy, both a spatial and a temporal goal\nabstraction. We provide a theoretical study of the regret bounds of the learned\npolicies. We evaluate the approach on complex continuous control tasks,\ndemonstrating the effectiveness of spatial and temporal abstractions learned by\nthis approach.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.09877", "title": "Accurate and Scalable Many-Node Simulation", "abstract": "Accurate performance estimation of future many-node machines is challenging\nbecause it requires detailed simulation models of both node and network.\nHowever, simulating the full system in detail is unfeasible in terms of compute\nand memory resources. State-of-the-art techniques use a two-phase approach that\ncombines detailed simulation of a single node with network-only simulation of\nthe full system. We show that these techniques, where the detailed node\nsimulation is done in isolation, are inaccurate because they ignore two\nimportant node-level effects: compute time variability, and inter-node\ncommunication.\n  We propose a novel three-stage simulation method to allow scalable and\naccurate many-node simulation, combining native profiling, detailed node\nsimulation and high-level network simulation. By including timing variability\nand the impact of external nodes, our method leads to more accurate estimates.\nWe validate our technique against measurements on a multi-node cluster, and\nreport an average 6.7% error on 64 nodes (maximum error of 12%), compared to on\naverage 27% error and up to 54% when timing variability and the scaling\noverhead are ignored. At higher node counts, the prediction error of ignoring\nvariable timings and scaling overhead continues to increase compared to our\ntechnique, and may lead to selecting the wrong optimal cluster configuration.\n  Using our technique, we are able to accurately project performance to\nthousands of nodes within a day of simulation time, using only a single or a\nfew simulation hosts. Our method can be used to quickly explore large many-node\ndesign spaces, including node micro-architecture, node count and network\nconfiguration.", "field": "Computer Science", "categories": "cs.PF"}, {"arxiv_id": "2401.09878", "title": "A Comparison Benchmark for Distributed Hybrid MPC Control Methods:\n  Distributed Vehicle Platooning", "abstract": "Distributed model predictive control (MPC) is currently being investigated as\na solution to the important control challenge presented by networks of hybrid\ndynamical systems. However, a benchmark problem for distributed hybrid MPC is\nabsent from the literature. We propose distributed control of a platoon of\nautonomous vehicles as a comparison benchmark problem. The problem provides a\ncomplex and adaptable case study, upon which existing and future approaches to\ndistributed MPC for hybrid systems can be evaluated. Two hybrid modeling\nframeworks are presented for the vehicle dynamics. Five hybrid MPC controllers\nare then evaluated and extensively assessed on the fleet of vehicles. Finally,\nwe comment on the need for new efficient and high performing distributed MPC\nschemes for hybrid systems.", "field": "Computer Science", "categories": "eess.SY,cs.SY"}, {"arxiv_id": "2401.0988", "title": "Attention-Based Recurrent Neural Network For Automatic Behavior Laying\n  Hen Recognition", "abstract": "One of the interests of modern poultry farming is the vocalization of laying\nhens which contain very useful information on health behavior. This information\nis used as health and well-being indicators that help breeders better monitor\nlaying hens, which involves early detection of problems for rapid and more\neffective intervention. In this work, we focus on the sound analysis for the\nrecognition of the types of calls of the laying hens in order to propose a\nrobust system of characterization of their behavior for a better monitoring. To\ndo this, we first collected and annotated laying hen call signals, then\ndesigned an optimal acoustic characterization based on the combination of time\nand frequency domain features. We then used these features to build the\nmulti-label classification models based on recurrent neural network to assign a\nsemantic class to the vocalization that characterize the laying hen behavior.\nThe results show an overall performance with our model based on the combination\nof time and frequency domain features that obtained the highest F1-score\n(F1=92.75) with a gain of 17% on the models using the frequency domain features\nand of 8% on the compared approaches from the litterature.", "field": "Computer Science", "categories": "cs.SD,cs.AI,cs.CL,cs.LG,eess.AS"}, {"arxiv_id": "2401.09881", "title": "GA-SmaAt-GNet: Generative Adversarial Small Attention GNet for Extreme\n  Precipitation Nowcasting", "abstract": "In recent years, data-driven modeling approaches have gained considerable\ntraction in various meteorological applications, particularly in the realm of\nweather forecasting. However, these approaches often encounter challenges when\ndealing with extreme weather conditions. In light of this, we propose\nGA-SmaAt-GNet, a novel generative adversarial architecture that makes use of\ntwo methodologies aimed at enhancing the performance of deep learning models\nfor extreme precipitation nowcasting. Firstly, it uses a novel SmaAt-GNet built\nupon the successful SmaAt-UNet architecture as generator. This network\nincorporates precipitation masks (binarized precipitation maps) as an\nadditional data source, leveraging valuable information for improved\npredictions. Additionally, GA-SmaAt-GNet utilizes an attention-augmented\ndiscriminator inspired by the well-established Pix2Pix architecture.\nFurthermore, we assess the performance of GA-SmaAt-GNet using real-life\nprecipitation dataset from the Netherlands. Our experimental results reveal a\nnotable improvement in both overall performance and for extreme precipitation\nevents. Furthermore, we conduct uncertainty analysis on the proposed\nGA-SmaAt-GNet model as well as on the precipitation dataset, providing\nadditional insights into the predictive capabilities of the model. Finally, we\noffer further insights into the predictions of our proposed model using\nGrad-CAM. This visual explanation technique generates activation heatmaps,\nillustrating areas of the input that are more activated for various parts of\nthe network.", "field": "Computer Science", "categories": "cs.LG,physics.ao-ph,I.2; I.5"}, {"arxiv_id": "2401.09883", "title": "Question-Answer Cross Language Image Matching for Weakly Supervised\n  Semantic Segmentation", "abstract": "Class Activation Map (CAM) has emerged as a popular tool for weakly\nsupervised semantic segmentation (WSSS), allowing the localization of object\nregions in an image using only image-level labels. However, existing CAM\nmethods suffer from under-activation of target object regions and\nfalse-activation of background regions due to the fact that a lack of detailed\nsupervision can hinder the model's ability to understand the image as a whole.\nIn this paper, we propose a novel Question-Answer Cross-Language-Image Matching\nframework for WSSS (QA-CLIMS), leveraging the vision-language foundation model\nto maximize the text-based understanding of images and guide the generation of\nactivation maps. First, a series of carefully designed questions are posed to\nthe VQA (Visual Question Answering) model with Question-Answer Prompt\nEngineering (QAPE) to generate a corpus of both foreground target objects and\nbackgrounds that are adaptive to query images. We then employ contrastive\nlearning in a Region Image Text Contrastive (RITC) network to compare the\nobtained foreground and background regions with the generated corpus. Our\napproach exploits the rich textual information from the open vocabulary as\nadditional supervision, enabling the model to generate high-quality CAMs with a\nmore complete object region and reduce false-activation of background regions.\nWe conduct extensive analysis to validate the proposed method and show that our\napproach performs state-of-the-art on both PASCAL VOC 2012 and MS COCO\ndatasets. Code is available at: https://github.com/CVI-SZU/QA-CLIMS", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.09885", "title": "Source Code Clone Detection Using Unsupervised Similarity Measures", "abstract": "Assessing similarity in source code has gained significant attention in\nrecent years due to its importance in software engineering tasks such as clone\ndetection and code search and recommendation. This work presents a comparative\nanalysis of unsupervised similarity measures for identifying source code clone\ndetection. The goal is to overview the current state-of-the-art techniques,\ntheir strengths, and weaknesses. To do that, we compile the existing\nunsupervised strategies and evaluate their performance on a benchmark dataset\nto guide software engineers in selecting appropriate methods for their specific\nuse cases. The source code of this study is available at\n\\url{https://github.com/jorge-martinez-gil/codesim}", "field": "Computer Science", "categories": "cs.SE,cs.IR"}, {"arxiv_id": "2401.09886", "title": "Cooperative Edge Caching Based on Elastic Federated and Multi-Agent Deep\n  Reinforcement Learning in Next-Generation Network", "abstract": "Edge caching is a promising solution for next-generation networks by\nempowering caching units in small-cell base stations (SBSs), which allows user\nequipments (UEs) to fetch users' requested contents that have been pre-cached\nin SBSs. It is crucial for SBSs to predict accurate popular contents through\nlearning while protecting users' personal information. Traditional federated\nlearning (FL) can protect users' privacy but the data discrepancies among UEs\ncan lead to a degradation in model quality. Therefore, it is necessary to train\npersonalized local models for each UE to predict popular contents accurately.\nIn addition, the cached contents can be shared among adjacent SBSs in\nnext-generation networks, thus caching predicted popular contents in different\nSBSs may affect the cost to fetch contents. Hence, it is critical to determine\nwhere the popular contents are cached cooperatively. To address these issues,\nwe propose a cooperative edge caching scheme based on elastic federated and\nmulti-agent deep reinforcement learning (CEFMR) to optimize the cost in the\nnetwork. We first propose an elastic FL algorithm to train the personalized\nmodel for each UE, where adversarial autoencoder (AAE) model is adopted for\ntraining to improve the prediction accuracy, then {a popular} content\nprediction algorithm is proposed to predict the popular contents for each SBS\nbased on the trained AAE model. Finally, we propose a multi-agent deep\nreinforcement learning (MADRL) based algorithm to decide where the predicted\npopular contents are collaboratively cached among SBSs. Our experimental\nresults demonstrate the superiority of our proposed scheme to existing baseline\ncaching schemes.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.0989", "title": "A Survey on Hardware Accelerators for Large Language Models", "abstract": "Large Language Models (LLMs) have emerged as powerful tools for natural\nlanguage processing tasks, revolutionizing the field with their ability to\nunderstand and generate human-like text. As the demand for more sophisticated\nLLMs continues to grow, there is a pressing need to address the computational\nchallenges associated with their scale and complexity. This paper presents a\ncomprehensive survey on hardware accelerators designed to enhance the\nperformance and energy efficiency of Large Language Models. By examining a\ndiverse range of accelerators, including GPUs, FPGAs, and custom-designed\narchitectures, we explore the landscape of hardware solutions tailored to meet\nthe unique computational demands of LLMs. The survey encompasses an in-depth\nanalysis of architecture, performance metrics, and energy efficiency\nconsiderations, providing valuable insights for researchers, engineers, and\ndecision-makers aiming to optimize the deployment of LLMs in real-world\napplications.", "field": "Computer Science", "categories": "cs.AR,cs.CL,cs.LG,B.5; C.1; C.3"}, {"arxiv_id": "2401.09895", "title": "Skeleton-Guided Instance Separation for Fine-Grained Segmentation in\n  Microscopy", "abstract": "One of the fundamental challenges in microscopy (MS) image analysis is\ninstance segmentation (IS), particularly when segmenting cluster regions where\nmultiple objects of varying sizes and shapes may be connected or even\noverlapped in arbitrary orientations. Existing IS methods usually fail in\nhandling such scenarios, as they rely on coarse instance representations such\nas keypoints and horizontal bounding boxes (h-bboxes). In this paper, we\npropose a novel one-stage framework named A2B-IS to address this challenge and\nenhance the accuracy of IS in MS images. Our approach represents each instance\nwith a pixel-level mask map and a rotated bounding box (r-bbox). Unlike\ntwo-stage methods that use box proposals for segmentations, our method\ndecouples mask and box predictions, enabling simultaneous processing to\nstreamline the model pipeline. Additionally, we introduce a Gaussian skeleton\nmap to aid the IS task in two key ways: (1) It guides anchor placement,\nreducing computational costs while improving the model's capacity to learn\nRoI-aware features by filtering out noise from background regions. (2) It\nensures accurate isolation of densely packed instances by rectifying erroneous\nbox predictions near instance boundaries. To further enhance the performance,\nwe integrate two modules into the framework: (1) An Atrous Attention Block\n(A2B) designed to extract high-resolution feature maps with fine-grained\nmultiscale information, and (2) A Semi-Supervised Learning (SSL) strategy that\nleverages both labeled and unlabeled images for model training. Our method has\nbeen thoroughly validated on two large-scale MS datasets, demonstrating its\nsuperiority over most state-of-the-art approaches.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.09896", "title": "Experimental Shake Gesture Detection API for Apple Watch", "abstract": "In this paper we present the WatchShaker project The project involves an\nexperimental API that detects the Apple Watchs shake gesturea surprisingly\nabsent natively feature Through a simple heuristic leveraging the Apple Watchs\naccelerometer data the API discerns not just the occurrence of shake gestures\nbut also their direction enhancing the interactivity potential of the device\nDespite the projects simplicity and lack of formal testing it has garnered\nsignificant attention indicating a genuine interest and need within the\ndeveloper community for such functionality The WatchShaker project exemplifies\nhow a minimalistic approach can yield a practical and impactful tool in\nwearable technology providing a springboard for further research and\ndevelopment in intuitive gesture recognition", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.09899", "title": "Meme-ingful Analysis: Enhanced Understanding of Cyberbullying in Memes\n  Through Multimodal Explanations", "abstract": "Internet memes have gained significant influence in communicating political,\npsychological, and sociocultural ideas. While memes are often humorous, there\nhas been a rise in the use of memes for trolling and cyberbullying. Although a\nwide variety of effective deep learning-based models have been developed for\ndetecting offensive multimodal memes, only a few works have been done on\nexplainability aspect. Recent laws like \"right to explanations\" of General Data\nProtection Regulation, have spurred research in developing interpretable models\nrather than only focusing on performance. Motivated by this, we introduce {\\em\nMultiBully-Ex}, the first benchmark dataset for multimodal explanation from\ncode-mixed cyberbullying memes. Here, both visual and textual modalities are\nhighlighted to explain why a given meme is cyberbullying. A Contrastive\nLanguage-Image Pretraining (CLIP) projection-based multimodal shared-private\nmultitask approach has been proposed for visual and textual explanation of a\nmeme. Experimental results demonstrate that training with multimodal\nexplanations improves performance in generating textual justifications and more\naccurately identifying the visual evidence supporting a decision with reliable\nperformance improvements.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.099", "title": "XAI-Enhanced Semantic Segmentation Models for Visual Quality Inspection", "abstract": "Visual quality inspection systems, crucial in sectors like manufacturing and\nlogistics, employ computer vision and machine learning for precise, rapid\ndefect detection. However, their unexplained nature can hinder trust, error\nidentification, and system improvement. This paper presents a framework to\nbolster visual quality inspection by using CAM-based explanations to refine\nsemantic segmentation models. Our approach consists of 1) Model Training, 2)\nXAI-based Model Explanation, 3) XAI Evaluation, and 4) Annotation Augmentation\nfor Model Enhancement, informed by explanations and expert insights.\nEvaluations show XAI-enhanced models surpass original DeepLabv3-ResNet101\nmodels, especially in intricate object segmentation.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.09906", "title": "BUMP: A Benchmark of Reproducible Breaking Dependency Updates", "abstract": "Third-party dependency updates can cause a build to fail if the new\ndependency version introduces a change that is incompatible with the usage:\nthis is called a breaking dependency update. Research on breaking dependency\nupdates is active, with works on characterization, understanding, automatic\nrepair of breaking updates, and other software engineering aspects. All such\nresearch projects require a benchmark of breaking updates that has the\nfollowing properties: 1) it contains real-world breaking updates; 2) the\nbreaking updates can be executed; 3) the benchmark provides stable scientific\nartifacts of breaking updates over time, a property we call reproducibility. To\nthe best of our knowledge, such a benchmark is missing. To address this\nproblem, we present BUMP, a new benchmark that contains reproducible breaking\ndependency updates in the context of Java projects built with the Maven build\nsystem. BUMP contains 571 breaking dependency updates collected from 153 Java\nprojects. BUMP ensures long-term reproducibility of dependency updates on\ndifferent platforms, guaranteeing consistent build failures. We categorize the\ndifferent causes of build breakage in BUMP, providing novel insights for future\nwork on breaking update engineering. To our knowledge, BUMP is the first of its\nkind, providing hundreds of real-world breaking updates that have all been made\nreproducible.", "field": "Computer Science", "categories": "cs.SE"}, {"arxiv_id": "2401.0991", "title": "Deep Back-Filling: a Split Window Technique for Deep Online Cluster Job\n  Scheduling", "abstract": "Job scheduling is a critical component of workload management systems that\ncan significantly influence system performance, e.g., in HPC clusters. The\nscheduling objectives are often mixed, such as maximizing resource utilization\nand minimizing job waiting time. An increasing number of researchers are moving\nfrom heuristic-based approaches to Deep Reinforcement Learning approaches in\norder to optimize scheduling objectives. However, the job scheduler's state\nspace is partially observable to a DRL-based agent because the job queue is\npractically unbounded. The agent's observation of the state space is constant\nin size since the input size of the neural networks is predefined. All existing\nsolutions to this problem intuitively allow the agent to observe a fixed window\nsize of jobs at the head of the job queue. In our research, we have seen that\nsuch an approach can lead to \"window staleness\" where the window becomes full\nof jobs that can not be scheduled until the cluster has completed sufficient\nwork. In this paper, we propose a novel general technique that we call\n\\emph{split window}, which allows the agent to observe both the head \\emph{and\ntail} of the queue. With this technique, the agent can observe all arriving\njobs at least once, which completely eliminates the window staleness problem.\nBy leveraging the split window, the agent can significantly reduce the average\njob waiting time and average queue length, alternatively allowing the use of\nmuch smaller windows and, therefore, faster training times. We show a range of\nsimulation results using HPC job scheduling trace data that supports the\neffectiveness of our technique.", "field": "Computer Science", "categories": "cs.DC"}, {"arxiv_id": "2401.09916", "title": "Enabling On-device Continual Learning with Binary Neural Networks", "abstract": "On-device learning remains a formidable challenge, especially when dealing\nwith resource-constrained devices that have limited computational capabilities.\nThis challenge is primarily rooted in two key issues: first, the memory\navailable on embedded devices is typically insufficient to accommodate the\nmemory-intensive back-propagation algorithm, which often relies on\nfloating-point precision. Second, the development of learning algorithms on\nmodels with extreme quantization levels, such as Binary Neural Networks (BNNs),\nis critical due to the drastic reduction in bit representation. In this study,\nwe propose a solution that combines recent advancements in the field of\nContinual Learning (CL) and Binary Neural Networks to enable on-device training\nwhile maintaining competitive performance. Specifically, our approach leverages\nbinary latent replay (LR) activations and a novel quantization scheme that\nsignificantly reduces the number of bits required for gradient computation. The\nexperimental validation demonstrates a significant accuracy improvement in\ncombination with a noticeable reduction in memory requirement, confirming the\nsuitability of our approach in expanding the practical applications of deep\nlearning in real-world scenarios.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.09918", "title": "Probabilistic Truly Unordered Rule Sets", "abstract": "Rule set learning has recently been frequently revisited because of its\ninterpretability. Existing methods have several shortcomings though. First,\nmost existing methods impose orders among rules, either explicitly or\nimplicitly, which makes the models less comprehensible. Second, due to the\ndifficulty of handling conflicts caused by overlaps (i.e., instances covered by\nmultiple rules), existing methods often do not consider probabilistic rules.\nThird, learning classification rules for multi-class target is understudied, as\nmost existing methods focus on binary classification or multi-class\nclassification via the ``one-versus-rest\" approach.\n  To address these shortcomings, we propose TURS, for Truly Unordered Rule\nSets. To resolve conflicts caused by overlapping rules, we propose a novel\nmodel that exploits the probabilistic properties of our rule sets, with the\nintuition of only allowing rules to overlap if they have similar probabilistic\noutputs. We next formalize the problem of learning a TURS model based on the\nMDL principle and develop a carefully designed heuristic algorithm. We\nbenchmark against a wide range of rule-based methods and demonstrate that our\nmethod learns rule sets that have lower model complexity and highly competitive\npredictive performance. In addition, we empirically show that rules in our\nmodel are empirically ``independent\" and hence truly unordered.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.09919", "title": "Tractability of linear ill-posed problems in Hilbert space", "abstract": "We introduce a notion of tractability for ill-posed operator equations in\nHilbert space. For such operator equations the\n  asymptotics of the best possible rate of reconstruction in terms of the\nunderlying noise level is known in many cases. However, the relevant question\nis, which level of discretization, again driven by the noise level, is required\nin order to\n  achieve this best possible accuracy. The proposed concept adapts the one from\nInformation-based Complexity.\n  Several examples indicate the relevance of this concept in the light of the\ncurse of dimensionality.", "field": "Computer Science", "categories": "math.NA,cs.NA,65D15, 68Q27"}, {"arxiv_id": "2401.09921", "title": "BlenDA: Domain Adaptive Object Detection through diffusion-based\n  blending", "abstract": "Unsupervised domain adaptation (UDA) aims to transfer a model learned using\nlabeled data from the source domain to unlabeled data in the target domain. To\naddress the large domain gap issue between the source and target domains, we\npropose a novel regularization method for domain adaptive object detection,\nBlenDA, by generating the pseudo samples of the intermediate domains and their\ncorresponding soft domain labels for adaptation training. The intermediate\nsamples are generated by dynamically blending the source images with their\ncorresponding translated images using an off-the-shelf pre-trained\ntext-to-image diffusion model which takes the text label of the target domain\nas input and has demonstrated superior image-to-image translation quality.\nBased on experimental results from two adaptation benchmarks, our proposed\napproach can significantly enhance the performance of the state-of-the-art\ndomain adaptive object detector, Adversarial Query Transformer (AQT).\nParticularly, in the Cityscapes to Foggy Cityscapes adaptation, we achieve an\nimpressive 53.4% mAP on the Foggy Cityscapes dataset, surpassing the previous\nstate-of-the-art by 1.5%. It is worth noting that our proposed method is also\napplicable to various paradigms of domain adaptive object detection. The code\nis available at:https://github.com/aiiu-lab/BlenDA", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.09923", "title": "MAMBA: Multi-level Aggregation via Memory Bank for Video Object\n  Detection", "abstract": "State-of-the-art video object detection methods maintain a memory structure,\neither a sliding window or a memory queue, to enhance the current frame using\nattention mechanisms. However, we argue that these memory structures are not\nefficient or sufficient because of two implied operations: (1) concatenating\nall features in memory for enhancement, leading to a heavy computational cost;\n(2) frame-wise memory updating, preventing the memory from capturing more\ntemporal information. In this paper, we propose a multi-level aggregation\narchitecture via memory bank called MAMBA. Specifically, our memory bank\nemploys two novel operations to eliminate the disadvantages of existing\nmethods: (1) light-weight key-set construction which can significantly reduce\nthe computational cost; (2) fine-grained feature-wise updating strategy which\nenables our method to utilize knowledge from the whole video. To better enhance\nfeatures from complementary levels, i.e., feature maps and proposals, we\nfurther propose a generalized enhancement operation (GEO) to aggregate\nmulti-level features in a unified manner. We conduct extensive evaluations on\nthe challenging ImageNetVID dataset. Compared with existing state-of-the-art\nmethods, our method achieves superior performance in terms of both speed and\naccuracy. More remarkably, MAMBA achieves mAP of 83.7/84.6% at 12.6/9.1 FPS\nwith ResNet-101. Code is available at\nhttps://github.com/guanxiongsun/video_feature_enhancement.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.09926", "title": "Discretization of fractional fully nonlinear equations by powers of\n  discrete Laplacians", "abstract": "We study discretizations of fractional fully nonlinear equations by powers of\ndiscrete Laplacians. Our problems are parabolic and of order $\\sigma\\in(0,2)$\nsince they involve fractional Laplace operators $(-\\Delta)^{\\sigma/2}$. They\narise e.g.~in control and game theory as dynamic programming equations, and\nsolutions are non-smooth in general and should be interpreted as viscosity\nsolutions. Our approximations are realized as finite-difference quadrature\napproximations and are 2nd order accurate for all values of $\\sigma$. The\naccuracy of previous approximations depend on $\\sigma$ and are worse when\n$\\sigma$ is close to $2$. We show that the schemes are monotone, consistent,\n$L^\\infty$-stable, and convergent using a priori estimates, viscosity solutions\ntheory, and the method of half-relaxed limits. We present several numerical\nexamples.", "field": "Computer Science", "categories": "math.NA,cs.NA,math.AP,65-02 (Primary) 65M22, 35A99 (Secondary)"}, {"arxiv_id": "2401.09937", "title": "From Cash to Cashless: UPI's Impact on Spending Behavior among Indian\n  Users", "abstract": "The emergence of digital payment systems has transformed how individuals\nconduct financial transactions, offering convenience, security, and efficiency.\nOne groundbreaking innovation making waves in the Indian financial landscape is\nthe Unified Payments Interface (UPI), developed by the National Payments\nCorporation of India (NPCI). Existing work has explored how digital payments\nbenefit a country's economy and GDP. However, our study explores how the\nintroduction of UPI has influenced spending behavior among Indian users on an\n\"individual\" level. We gathered 235 valid survey responses encompassing diverse\ndemographics and conducted semi-structured interviews with 20 survey\nrespondents. Approximately 75% of the survey respondents reported increased\nspending due to UPI, with only 7% indicating reduced spending. Significantly,\n91.5% of the respondents reported satisfaction with their UPI usage. Also 95.2%\nof the survey respondents found making payments via UPI convenient. Our\nresearch also provides suggestions for UPI applications and various\nstakeholders to enhance digital payment systems, enabling users to make\ninformed decisions and fostering responsible financial management.", "field": "Computer Science", "categories": "cs.CY,cs.HC"}, {"arxiv_id": "2401.09939", "title": "ICGNet: A Unified Approach for Instance-Centric Grasping", "abstract": "Accurate grasping is the key to several robotic tasks including assembly and\nhousehold robotics. Executing a successful grasp in a cluttered environment\nrequires multiple levels of scene understanding: First, the robot needs to\nanalyze the geometric properties of individual objects to find feasible grasps.\nThese grasps need to be compliant with the local object geometry. Second, for\neach proposed grasp, the robot needs to reason about the interactions with\nother objects in the scene. Finally, the robot must compute a collision-free\ngrasp trajectory while taking into account the geometry of the target object.\nMost grasp detection algorithms directly predict grasp poses in a monolithic\nfashion, which does not capture the composability of the environment. In this\npaper, we introduce an end-to-end architecture for object-centric grasping. The\nmethod uses pointcloud data from a single arbitrary viewing direction as an\ninput and generates an instance-centric representation for each partially\nobserved object in the scene. This representation is further used for object\nreconstruction and grasp detection in cluttered table-top scenes. We show the\neffectiveness of the proposed method by extensively evaluating it against\nstate-of-the-art methods on synthetic datasets, indicating superior performance\nfor grasping and reconstruction. Additionally, we demonstrate real-world\napplicability by decluttering scenes with varying numbers of objects.", "field": "Computer Science", "categories": "cs.RO,cs.CV"}, {"arxiv_id": "2401.0994", "title": "Biases in Expected Goals Models Confound Finishing Ability", "abstract": "Expected Goals (xG) has emerged as a popular tool for evaluating finishing\nskill in soccer analytics. It involves comparing a player's cumulative xG with\ntheir actual goal output, where consistent overperformance indicates strong\nfinishing ability. However, the assessment of finishing skill in soccer using\nxG remains contentious due to players' difficulty in consistently outperforming\ntheir cumulative xG. In this paper, we aim to address the limitations and\nnuances surrounding the evaluation of finishing skill using xG statistics.\nSpecifically, we explore three hypotheses: (1) the deviation between actual and\nexpected goals is an inadequate metric due to the high variance of shot\noutcomes and limited sample sizes, (2) the inclusion of all shots in cumulative\nxG calculation may be inappropriate, and (3) xG models contain biases arising\nfrom interdependencies in the data that affect skill measurement. We found that\nsustained overperformance of cumulative xG requires both high shot volumes and\nexceptional finishing, including all shot types can obscure the finishing\nability of proficient strikers, and that there is a persistent bias that makes\nthe actual and expected goals closer for excellent finishers than it really is.\nOverall, our analysis indicates that we need more nuanced quantitative\napproaches for investigating a player's finishing ability, which we achieved\nusing a technique from AI fairness to learn an xG model that is calibrated for\nmultiple subgroups of players. As a concrete use case, we show that (1) the\nstandard biased xG model underestimates Messi's GAX by 17% and (2) Messi's GAX\nis 27% higher than the typical elite high-shot-volume attacker, indicating that\nMessi is even a more exceptional finisher than people commonly believed.", "field": "Computer Science", "categories": "cs.LG,stat.AP"}, {"arxiv_id": "2401.09942", "title": "Multi-task Learning for Joint Re-identification, Team Affiliation, and\n  Role Classification for Sports Visual Tracking", "abstract": "Effective tracking and re-identification of players is essential for\nanalyzing soccer videos. But, it is a challenging task due to the non-linear\nmotion of players, the similarity in appearance of players from the same team,\nand frequent occlusions. Therefore, the ability to extract meaningful\nembeddings to represent players is crucial in developing an effective tracking\nand re-identification system. In this paper, a multi-purpose part-based person\nrepresentation method, called PRTreID, is proposed that performs three tasks of\nrole classification, team affiliation, and re-identification, simultaneously.\nIn contrast to available literature, a single network is trained with\nmulti-task supervision to solve all three tasks, jointly. The proposed joint\nmethod is computationally efficient due to the shared backbone. Also, the\nmulti-task learning leads to richer and more discriminative representations, as\ndemonstrated by both quantitative and qualitative results. To demonstrate the\neffectiveness of PRTreID, it is integrated with a state-of-the-art tracking\nmethod, using a part-based post-processing module to handle long-term tracking.\nThe proposed tracking method outperforms all existing tracking methods on the\nchallenging SoccerNet tracking dataset.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.09943", "title": "Infinite-Horizon Graph Filters: Leveraging Power Series to Enhance\n  Sparse Information Aggregation", "abstract": "Graph Neural Networks (GNNs) have shown considerable effectiveness in a\nvariety of graph learning tasks, particularly those based on the\nmessage-passing approach in recent years. However, their performance is often\nconstrained by a limited receptive field, a challenge that becomes more acute\nin the presence of sparse graphs. In light of the power series, which possesses\ninfinite expansion capabilities, we propose a novel \\underline{G}raph\n\\underline{P}ower \\underline{F}ilter \\underline{N}eural Network (GPFN) that\nenhances node classification by employing a power series graph filter to\naugment the receptive field. Concretely, our GPFN designs a new way to build a\ngraph filter with an infinite receptive field based on the convergence power\nseries, which can be analyzed in the spectral and spatial domains. Besides, we\ntheoretically prove that our GPFN is a general framework that can integrate any\npower series and capture long-range dependencies. Finally, experimental results\non three datasets demonstrate the superiority of our GPFN over state-of-the-art\nbaselines.", "field": "Computer Science", "categories": "cs.LG,cs.SI"}, {"arxiv_id": "2401.09944", "title": "WindSeer: Real-time volumetric wind prediction over complex terrain\n  aboard a small UAV", "abstract": "Real-time high-resolution wind predictions are beneficial for various\napplications including safe manned and unmanned aviation. Current weather\nmodels require too much compute and lack the necessary predictive capabilities\nas they are valid only at the scale of multiple kilometers and hours - much\nlower spatial and temporal resolutions than these applications require. Our\nwork, for the first time, demonstrates the ability to predict low-altitude wind\nin real-time on limited-compute devices, from only sparse measurement data. We\ntrain a neural network, WindSeer, using only synthetic data from computational\nfluid dynamics simulations and show that it can successfully predict real wind\nfields over terrain with known topography from just a few noisy and spatially\nclustered wind measurements. WindSeer can generate accurate predictions at\ndifferent resolutions and domain sizes on previously unseen topography without\nretraining. We demonstrate that the model successfully predicts historical wind\ndata collected by weather stations and wind measured onboard drones.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.RO"}, {"arxiv_id": "2401.09945", "title": "HGAttack: Transferable Heterogeneous Graph Adversarial Attack", "abstract": "Heterogeneous Graph Neural Networks (HGNNs) are increasingly recognized for\ntheir performance in areas like the web and e-commerce, where resilience\nagainst adversarial attacks is crucial. However, existing adversarial attack\nmethods, which are primarily designed for homogeneous graphs, fall short when\napplied to HGNNs due to their limited ability to address the structural and\nsemantic complexity of HGNNs. This paper introduces HGAttack, the first\ndedicated gray box evasion attack method for heterogeneous graphs. We design a\nnovel surrogate model to closely resemble the behaviors of the target HGNN and\nutilize gradient-based methods for perturbation generation. Specifically, the\nproposed surrogate model effectively leverages heterogeneous information by\nextracting meta-path induced subgraphs and applying GNNs to learn node\nembeddings with distinct semantics from each subgraph. This approach improves\nthe transferability of generated attacks on the target HGNN and significantly\nreduces memory costs. For perturbation generation, we introduce a\nsemantics-aware mechanism that leverages subgraph gradient information to\nautonomously identify vulnerable edges across a wide range of relations within\na constrained perturbation budget. We validate HGAttack's efficacy with\ncomprehensive experiments on three datasets, providing empirical analyses of\nits generated perturbations. Outperforming baseline methods, HGAttack\ndemonstrated significant efficacy in diminishing the performance of target HGNN\nmodels, affirming the effectiveness of our approach in evaluating the\nrobustness of HGNNs against adversarial attacks.", "field": "Computer Science", "categories": "cs.LG,cs.CR,cs.IR"}, {"arxiv_id": "2401.09949", "title": "SymbolNet: Neural Symbolic Regression with Adaptive Dynamic Pruning", "abstract": "Contrary to the use of genetic programming, the neural network approach to\nsymbolic regression can scale well with high input dimension and leverage\ngradient methods for faster equation searching. Common ways of constraining\nexpression complexity have relied on multistage pruning methods with\nfine-tuning, but these often lead to significant performance loss. In this\nwork, we propose SymbolNet, a neural network approach to symbolic regression in\na novel framework that enables dynamic pruning of model weights, input\nfeatures, and mathematical operators in a single training, where both training\nloss and expression complexity are optimized simultaneously. We introduce a\nsparsity regularization term per pruning type, which can adaptively adjust its\nown strength and lead to convergence to a target sparsity level. In contrast to\nmost existing symbolic regression methods that cannot efficiently handle\ndatasets with more than $O$(10) inputs, we demonstrate the effectiveness of our\nmodel on the LHC jet tagging task (16 inputs), MNIST (784 inputs), and SVHN\n(3072 inputs).", "field": "Computer Science", "categories": "cs.LG,hep-ex,physics.ins-det"}, {"arxiv_id": "2401.09953", "title": "Through the Dual-Prism: A Spectral Perspective on Graph Data\n  Augmentation for Graph Classification", "abstract": "Graph Neural Networks (GNNs) have become the preferred tool to process graph\ndata, with their efficacy being boosted through graph data augmentation\ntechniques. Despite the evolution of augmentation methods, issues like graph\nproperty distortions and restricted structural changes persist. This leads to\nthe question: Is it possible to develop more property-conserving and\nstructure-sensitive augmentation methods? Through a spectral lens, we\ninvestigate the interplay between graph properties, their augmentation, and\ntheir spectral behavior, and found that keeping the low-frequency eigenvalues\nunchanged can preserve the critical properties at a large scale when generating\naugmented graphs. These observations inform our introduction of the Dual-Prism\n(DP) augmentation method, comprising DP-Noise and DP-Mask, which adeptly\nretains essential graph properties while diversifying augmented graphs.\nExtensive experiments validate the efficiency of our approach, providing a new\nand promising direction for graph data augmentation.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.09957", "title": "Most General Winning Secure Equilibria Synthesis in Graph Games", "abstract": "This paper considers the problem of co-synthesis in $k$-player games over a\nfinite graph where each player has an individual $\\omega$-regular specification\n$\\phi_i$. In this context, a secure equilibrium (SE) is a Nash equilibrium\nw.r.t. the lexicographically ordered objectives of each player to first satisfy\ntheir own specification, and second, to falsify other players' specifications.\nA winning secure equilibrium (WSE) is an SE strategy profile\n$(\\pi_i)_{i\\in[1;k]}$ that ensures the specification\n$\\phi:=\\bigwedge_{i\\in[1;k]}\\phi_i$ if no player deviates from their strategy\n$\\pi_i$. Distributed implementations generated from a WSE make components act\nrationally by ensuring that a deviation from the WSE strategy profile is\nimmediately punished by a retaliating strategy that makes the involved players\nlose.\n  In this paper, we move from deviation punishment in WSE-based implementations\nto a distributed, assume-guarantee based realization of WSE. This shift is\nobtained by generalizing WSE from strategy profiles to specification profiles\n$(\\varphi_i)_{i\\in[1;k]}$ with $\\bigwedge_{i\\in[1;k]}\\varphi_i = \\phi$, which\nwe call most general winning secure equilibria (GWSE). Such GWSE have the\nproperty that each player can individually pick a strategy $\\pi_i$ winning for\n$\\varphi_i$ (against all other players) and all resulting strategy profiles\n$(\\pi_i)_{i\\in[1;k]}$ are guaranteed to be a WSE. The obtained flexibility in\nplayers' strategy choices can be utilized for robustness and adaptability of\nlocal implementations.\n  Concretely, our contribution is three-fold: (1) we formalize GWSE for\n$k$-player games over finite graphs, where each player has an $\\omega$-regular\nspecification $\\phi_i$; (2) we devise an iterative semi-algorithm for GWSE\nsynthesis in such games, and (3) obtain an exponential-time algorithm for GWSE\nsynthesis with parity specifications $\\phi_i$.", "field": "Computer Science", "categories": "cs.GT"}, {"arxiv_id": "2401.0996", "title": "A Comprehensive Scalable Framework for Cloud-Native Pattern Detection\n  with Enhanced Expressiveness", "abstract": "Detecting complex patterns in large volumes of event logs has diverse\napplications in various domains, such as business processes and fraud\ndetection. Existing systems like ELK are commonly used to tackle this\nchallenge, but their performance deteriorates for large patterns, while they\nsuffer from limitations in terms of expressiveness and explanatory capabilities\nfor their responses. In this work, we propose a solution that integrates a\nComplex Event Processing (CEP) engine into a broader query processsor on top of\na decoupled storage infrastructure containing inverted indices of log events.\nThe results demonstrate that our system excels in scalability and robustness,\nparticularly in handling complex queries. Notably, our proposed system delivers\nresponses for large complex patterns within seconds, while ELK experiences\ntimeouts after 10 minutes. It also significantly outperforms solutions relying\non FlinkCEP and executing MATCH_RECOGNIZE SQL queries.", "field": "Computer Science", "categories": "cs.DB"}, {"arxiv_id": "2401.09962", "title": "CustomVideo: Customizing Text-to-Video Generation with Multiple Subjects", "abstract": "Customized text-to-video generation aims to generate high-quality videos\nguided by text prompts and subject references. Current approaches designed for\nsingle subjects suffer from tackling multiple subjects, which is a more\nchallenging and practical scenario. In this work, we aim to promote\nmulti-subject guided text-to-video customization. We propose CustomVideo, a\nnovel framework that can generate identity-preserving videos with the guidance\nof multiple subjects. To be specific, firstly, we encourage the co-occurrence\nof multiple subjects via composing them in a single image. Further, upon a\nbasic text-to-video diffusion model, we design a simple yet effective attention\ncontrol strategy to disentangle different subjects in the latent space of\ndiffusion model. Moreover, to help the model focus on the specific object area,\nwe segment the object from given reference images and provide a corresponding\nobject mask for attention learning. Also, we collect a multi-subject\ntext-to-video generation dataset as a comprehensive benchmark, with 69\nindividual subjects and 57 meaningful pairs. Extensive qualitative,\nquantitative, and user study results demonstrate the superiority of our method,\ncompared with the previous state-of-the-art approaches.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.09964", "title": "When Neural Code Completion Models Size up the Situation: Attaining\n  Cheaper and Faster Completion through Dynamic Model Inference", "abstract": "Leveraging recent advancements in large language models, modern neural code\ncompletion models have demonstrated the capability to generate highly accurate\ncode suggestions. However, their massive size poses challenges in terms of\ncomputational costs and environmental impact, hindering their widespread\nadoption in practical scenarios. Dynamic inference emerges as a promising\nsolution, as it allocates minimal computation during inference while\nmaintaining the model's performance. In this research, we explore dynamic\ninference within the context of code completion. Initially, we conducted an\nempirical investigation on GPT-2, focusing on the inference capabilities of\nintermediate layers for code completion. We found that 54.4% of tokens can be\naccurately generated using just the first layer, signifying significant\ncomputational savings potential. Moreover, despite using all layers, the model\nstill fails to predict 14.5% of tokens correctly, and the subsequent\ncompletions continued from them are rarely considered helpful, with only a 4.2%\nAcceptance Rate. These findings motivate our exploration of dynamic inference\nin code completion and inspire us to enhance it with a decision-making\nmechanism that stops the generation of incorrect code. We thus propose a novel\ndynamic inference method specifically tailored for code completion models. This\nmethod aims not only to produce correct predictions with largely reduced\ncomputation but also to prevent incorrect predictions proactively. Our\nextensive evaluation shows that it can averagely skip 1.7 layers out of 16\nlayers in the models, leading to an 11.2% speedup with only a marginal 1.1%\nreduction in ROUGE-L.", "field": "Computer Science", "categories": "cs.SE,cs.AI"}, {"arxiv_id": "2401.09966", "title": "Towards Generative Abstract Reasoning: Completing Raven's Progressive\n  Matrix via Rule Abstraction and Selection", "abstract": "Endowing machines with abstract reasoning ability has been a long-term\nresearch topic in artificial intelligence. Raven's Progressive Matrix (RPM) is\nwidely used to probe abstract visual reasoning in machine intelligence, where\nmodels need to understand the underlying rules and select the missing\nbottom-right images out of candidate sets to complete image matrices. The\nparticipators can display powerful reasoning ability by inferring the\nunderlying attribute-changing rules and imagining the missing images at\narbitrary positions. However, existing solvers can hardly manifest such an\nability in realistic RPM problems. In this paper, we propose a conditional\ngenerative model to solve answer generation problems through Rule AbstractIon\nand SElection (RAISE) in the latent space. RAISE encodes image attributes as\nlatent concepts and decomposes underlying rules into atomic rules by means of\nconcepts, which are abstracted as global learnable parameters. When generating\nthe answer, RAISE selects proper atomic rules out of the global knowledge set\nfor each concept and composes them into the integrated rule of an RPM. In most\nconfigurations, RAISE outperforms the compared generative solvers in tasks of\ngenerating bottom-right and arbitrary-position answers. We test RAISE in the\nodd-one-out task and two held-out configurations to demonstrate how learning\ndecoupled latent concepts and atomic rules helps find the image breaking the\nunderlying rules and handle RPMs with unseen combinations of rules and\nattributes.", "field": "Computer Science", "categories": "cs.AI"}, {"arxiv_id": "2401.09967", "title": "Sketch-Guided Constrained Decoding for Boosting Blackbox Large Language\n  Models without Logit Access", "abstract": "Constrained decoding, a technique for enforcing constraints on language model\noutputs, offers a way to control text generation without retraining or\narchitectural modifications. Its application is, however, typically restricted\nto models that give users access to next-token distributions (usually via\nsoftmax logits), which poses a limitation with blackbox large language models\n(LLMs). This paper introduces sketch-guided constrained decoding (SGCD), a\nnovel approach to constrained decoding for blackbox LLMs, which operates\nwithout access to the logits of the blackbox LLM. SGCD utilizes a locally\nhosted auxiliary model to refine the output of an unconstrained blackbox LLM,\neffectively treating this initial output as a \"sketch\" for further elaboration.\nThis approach is complementary to traditional logit-based techniques and\nenables the application of constrained decoding in settings where full model\ntransparency is unavailable. We demonstrate the efficacy of SGCD through\nexperiments in closed information extraction and constituency parsing, showing\nhow it enhances the utility and flexibility of blackbox LLMs for complex NLP\ntasks.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.09972", "title": "Better Explain Transformers by Illuminating Important Information", "abstract": "Transformer-based models excel in various natural language processing (NLP)\ntasks, attracting countless efforts to explain their inner workings. Prior\nmethods explain Transformers by focusing on the raw gradient and attention as\ntoken attribution scores, where non-relevant information is often considered\nduring explanation computation, resulting in confusing results. In this work,\nwe propose highlighting the important information and eliminating irrelevant\ninformation by a refined information flow on top of the layer-wise relevance\npropagation (LRP) method. Specifically, we consider identifying syntactic and\npositional heads as important attention heads and focus on the relevance\nobtained from these important heads. Experimental results demonstrate that\nirrelevant information does distort output attribution scores and then should\nbe masked during explanation computation. Compared to eight baselines on both\nclassification and question-answering datasets, our method consistently\noutperforms with over 3\\% to 33\\% improvement on explanation metrics, providing\nsuperior explanation performance. Our anonymous code repository is available\nat: https://github.com/LinxinS97/Mask-LRP", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.09973", "title": "Accelerated Bounded Model Checking", "abstract": "Bounded Model Checking (BMC) is a powerful technique for proving reachability\nof error states, i.e., unsafety. However, finding deep counterexamples that\nrequire a large bound is challenging for BMC. On the other hand, acceleration\ntechniques compute \"shortcuts\" that \"compress\" many execution steps into a\nsingle one. In this paper, we tightly integrate acceleration techniques into\nSMT-based bounded model checking. By adding suitable \"shortcuts\" to the\nSMT-problem on the fly, our approach can quickly detect deep counterexamples,\neven when only using small bounds. Moreover, using so-called blocking clauses,\nour approach can prove safety of examples where BMC diverges. An empirical\ncomparison with other state-of-the-art techniques shows that our approach is\nhighly competitive for proving unsafety, and orthogonal to existing techniques\nfor proving safety.", "field": "Computer Science", "categories": "cs.LO"}, {"arxiv_id": "2401.09977", "title": "Material-Response-Informed DeepONet and its Application to Polycrystal\n  Stress-strain Prediction in Crystal Plasticity", "abstract": "Crystal plasticity (CP) simulations are a tool for understanding how\nmicrostructure morphology and texture affect mechanical properties and are an\nessential component of elucidating the structure-property relations. However,\nit can be computationally expensive. Hence, data-driven machine learning models\nhave been applied to predict the mean-field response of a polycrystal\nrepresentative volume element to reduce computation time. In this work, we\nproposed a novel Deep Operator Network (DeepONet) architecture for predicting\nmicrostructure stress-strain response. It employs a convolutional neural\nnetwork in the trunk to encode the microstructure. To account for different\nmaterial properties, boundary conditions, and loading, we proposed using single\ncrystal stress-strain curves as inputs to the branch network, furnishing a\nmaterial-response-informed DeepONet. Using four numerical examples, we\ndemonstrate that the current DeepONet can be trained on a single material and\nloading and then generalized to new conditions via transfer learning. Results\nshow that using single crystal responses as input outperforms a similar model\nusing material properties as inputs and overcomes limitations with changing\nboundary conditions and temporal resolution. In all cases, the new model\nachieved a $R^2$ value of above 0.99, and over 95\\% of predicted stresses have\na relative error of $\\le$ 5\\%, indicating superior accuracy. With as few as 20\nnew data points and under 1min training time, the trained DeepONet can be\nfine-tuned to generate accurate predictions on different materials and loading.\nOnce trained, the prediction speed is almost $1\\times10^{4}$ times faster the\nCP simulations. The efficiency and high generalizability of our DeepONet render\nit a powerful data-driven surrogate model for CP simulations in multi-scale\nanalyses.", "field": "Computer Science", "categories": "cs.CE"}, {"arxiv_id": "2401.09983", "title": "Multiobjective Optimization Analysis for Finding Infrastructure-as-Code\n  Deployment Configurations", "abstract": "Multiobjective optimization is a hot topic in the artificial intelligence and\noperations research communities. The design and development of multiobjective\nmethods is a frequent task for researchers and practitioners. As a result of\nthis vibrant activity, a myriad of techniques have been proposed in the\nliterature to date, demonstrating a significant effectiveness for dealing with\nsituations coming from a wide range of real-world areas. This paper is focused\non a multiobjective problem related to optimizing Infrastructure-as-Code\ndeployment configurations. The system implemented for solving this problem has\nbeen coined as IaC Optimizer Platform (IOP). Despite the fact that a\nprototypical version of the IOP has been introduced in the literature before, a\ndeeper analysis focused on the resolution of the problem is needed, in order to\ndetermine which is the most appropriate multiobjective method for embedding in\nthe IOP. The main motivation behind the analysis conducted in this work is to\nenhance the IOP performance as much as possible. This is a crucial aspect of\nthis system, deeming that it will be deployed in a real environment, as it is\nbeing developed as part of a H2020 European project. Going deeper, we resort in\nthis paper to nine different evolutionary computation-based multiobjective\nalgorithms. For assessing the quality of the considered solvers, 12 different\nproblem instances have been generated based on real-world settings. Results\nobtained by each method after 10 independent runs have been compared using\nFriedman's non-parametric tests. Findings reached from the tests carried out\nlad to the creation of a multi-algorithm system, capable of applying different\ntechniques according to the user's needs.", "field": "Computer Science", "categories": "cs.NE,cs.AI"}, {"arxiv_id": "2401.09984", "title": "Gradable ChatGPT Translation Evaluation", "abstract": "ChatGPT, as a language model based on large-scale pre-training, has exerted a\nprofound influence on the domain of machine translation. In ChatGPT, a \"Prompt\"\nrefers to a segment of text or instruction employed to steer the model towards\ngenerating a specific category of response. The design of the translation\nprompt emerges as a key aspect that can wield influence over factors such as\nthe style, precision and accuracy of the translation to a certain extent.\nHowever, there is a lack of a common standard and methodology on how to design\nand select a translation prompt. Accordingly, this paper proposes a generic\ntaxonomy, which defines gradable translation prompts in terms of expression\ntype, translation style, POS information and explicit statement, thus\nfacilitating the construction of prompts endowed with distinct attributes\ntailored for various translation tasks. Specific experiments and cases are\nselected to validate and illustrate the effectiveness of the method.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.09985", "title": "WorldDreamer: Towards General World Models for Video Generation via\n  Predicting Masked Tokens", "abstract": "World models play a crucial role in understanding and predicting the dynamics\nof the world, which is essential for video generation. However, existing world\nmodels are confined to specific scenarios such as gaming or driving, limiting\ntheir ability to capture the complexity of general world dynamic environments.\nTherefore, we introduce WorldDreamer, a pioneering world model to foster a\ncomprehensive comprehension of general world physics and motions, which\nsignificantly enhances the capabilities of video generation. Drawing\ninspiration from the success of large language models, WorldDreamer frames\nworld modeling as an unsupervised visual sequence modeling challenge. This is\nachieved by mapping visual inputs to discrete tokens and predicting the masked\nones. During this process, we incorporate multi-modal prompts to facilitate\ninteraction within the world model. Our experiments show that WorldDreamer\nexcels in generating videos across different scenarios, including natural\nscenes and driving environments. WorldDreamer showcases versatility in\nexecuting tasks such as text-to-video conversion, image-tovideo synthesis, and\nvideo editing. These results underscore WorldDreamer's effectiveness in\ncapturing dynamic elements within diverse general world environments.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.09986", "title": "FLex&Chill: Improving Local Federated Learning Training with Logit\n  Chilling", "abstract": "Federated learning are inherently hampered by data heterogeneity: non-iid\ndistributed training data over local clients. We propose a novel model training\napproach for federated learning, FLex&Chill, which exploits the Logit Chilling\nmethod. Through extensive evaluations, we demonstrate that, in the presence of\nnon-iid data characteristics inherent in federated learning systems, this\napproach can expedite model convergence and improve inference accuracy.\nQuantitatively, from our experiments, we observe up to 6X improvement in the\nglobal federated learning model convergence time, and up to 3.37% improvement\nin inference accuracy.", "field": "Computer Science", "categories": "cs.LG,cs.AI,68,I.2.11"}, {"arxiv_id": "2401.09987", "title": "A-KIT: Adaptive Kalman-Informed Transformer", "abstract": "The extended Kalman filter (EKF) is a widely adopted method for sensor fusion\nin navigation applications. A crucial aspect of the EKF is the online\ndetermination of the process noise covariance matrix reflecting the model\nuncertainty. While common EKF implementation assumes a constant process noise,\nin real-world scenarios, the process noise varies, leading to inaccuracies in\nthe estimated state and potentially causing the filter to diverge. To cope with\nsuch situations, model-based adaptive EKF methods were proposed and\ndemonstrated performance improvements, highlighting the need for a robust\nadaptive approach. In this paper, we derive and introduce A-KIT, an adaptive\nKalman-informed transformer to learn the varying process noise covariance\nonline. The A-KIT framework is applicable to any type of sensor fusion. Here,\nwe present our approach to nonlinear sensor fusion based on an inertial\nnavigation system and Doppler velocity log. By employing real recorded data\nfrom an autonomous underwater vehicle, we show that A-KIT outperforms the\nconventional EKF by more than 49.5% and model-based adaptive EKF by an average\nof 35.4% in terms of position accuracy.", "field": "Computer Science", "categories": "cs.RO,cs.AI,cs.SY,eess.SY"}, {"arxiv_id": "2401.09988", "title": "Developing an AI-based Integrated System for Bee Health Evaluation", "abstract": "Honey bees pollinate about one-third of the world's food supply, but bee\ncolonies have alarmingly declined by nearly 40% over the past decade due to\nseveral factors, including pesticides and pests. Traditional methods for\nmonitoring beehives, such as human inspection, are subjective, disruptive, and\ntime-consuming. To overcome these limitations, artificial intelligence has been\nused to assess beehive health. However, previous studies have lacked an\nend-to-end solution and primarily relied on data from a single source, either\nbee images or sounds. This study introduces a comprehensive system consisting\nof bee object detection and health evaluation. Additionally, it utilized a\ncombination of visual and audio signals to analyze bee behaviors. An\nAttention-based Multimodal Neural Network (AMNN) was developed to adaptively\nfocus on key features from each type of signal for accurate bee health\nassessment. The AMNN achieved an overall accuracy of 92.61%, surpassing eight\nexisting single-signal Convolutional Neural Networks and Recurrent Neural\nNetworks. It outperformed the best image-based model by 32.51% and the top\nsound-based model by 13.98% while maintaining efficient processing times.\nFurthermore, it improved prediction robustness, attaining an F1-score higher\nthan 90% across all four evaluated health conditions. The study also shows that\naudio signals are more reliable than images for assessing bee health. By\nseamlessly integrating AMNN with image and sound data in a comprehensive bee\nhealth monitoring system, this approach provides a more efficient and\nnon-invasive solution for the early detection of bee diseases and the\npreservation of bee colonies.", "field": "Computer Science", "categories": "cs.LG,cs.CV,cs.SD,eess.AS"}, {"arxiv_id": "2401.09989", "title": "Power Grid Parameter Estimation Without Phase Measurements: Theory and\n  Empirical Validation", "abstract": "Reliable integration and operation of renewable distributed energy resources\nrequires accurate distribution grid models. However, obtaining precise models\nis often prohibitively expensive, given their large scale and the ongoing\nnature of grid operations. To address this challenge, considerable efforts have\nbeen devoted to harnessing abundant consumption data for automatic model\ninference. The primary result of the paper is that, while the impedance of a\nline or a network can be estimated without synchronized phase angle\nmeasurements in a consistent way, the admittance cannot. Furthermore, a\ndetailed statistical analysis is presented, quantifying the expected estimation\nerrors of four prevalent admittance estimation methods. Such errors constitute\nfundamental model inference limitations that cannot be resolved with more data.\nThese findings are empirically validated using synthetic data and real\nmeasurements from the town of Walenstadt, Switzerland, confirming the theory.\nThe results contribute to our understanding of grid estimation limitations and\nuncertainties, offering guidance for both practitioners and researchers in the\npursuit of more reliable and cost-effective solutions.", "field": "Computer Science", "categories": "eess.SY,cs.SY,stat.AP"}, {"arxiv_id": "2401.09997", "title": "BPDO:Boundary Points Dynamic Optimization for Arbitrary Shape Scene Text\n  Detection", "abstract": "Arbitrary shape scene text detection is of great importance in scene\nunderstanding tasks. Due to the complexity and diversity of text in natural\nscenes, existing scene text algorithms have limited accuracy for detecting\narbitrary shape text. In this paper, we propose a novel arbitrary shape scene\ntext detector through boundary points dynamic optimization(BPDO). The proposed\nmodel is designed with a text aware module (TAM) and a boundary point dynamic\noptimization module (DOM). Specifically, the model designs a text aware module\nbased on segmentation to obtain boundary points describing the central region\nof the text by extracting a priori information about the text region. Then,\nbased on the idea of deformable attention, it proposes a dynamic optimization\nmodel for boundary points, which gradually optimizes the exact position of the\nboundary points based on the information of the adjacent region of each\nboundary point. Experiments on CTW-1500, Total-Text, and MSRA-TD500 datasets\nshow that the model proposed in this paper achieves a performance that is\nbetter than or comparable to the state-of-the-art algorithm, proving the\neffectiveness of the model.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10002", "title": "Distantly Supervised Morpho-Syntactic Model for Relation Extraction", "abstract": "The task of Information Extraction (IE) involves automatically converting\nunstructured textual content into structured data. Most research in this field\nconcentrates on extracting all facts or a specific set of relationships from\ndocuments. In this paper, we present a method for the extraction and\ncategorisation of an unrestricted set of relationships from text. Our method\nrelies on morpho-syntactic extraction patterns obtained by a distant\nsupervision method, and creates Syntactic and Semantic Indices to extract and\nclassify candidate graphs. We evaluate our approach on six datasets built on\nWikidata and Wikipedia. The evaluation shows that our approach can achieve\nPrecision scores of up to 0.85, but with lower Recall and F1 scores. Our\napproach allows to quickly create rule-based systems for Information Extraction\nand to build annotated datasets to train machine-learning and deep-learning\nbased classifiers.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.10005", "title": "Advancing Large Multi-modal Models with Explicit Chain-of-Reasoning and\n  Visual Question Generation", "abstract": "The increasing demand for intelligent systems capable of interpreting and\nreasoning about visual content requires the development of Large Multi-Modal\nModels (LMMs) that are not only accurate but also have explicit reasoning\ncapabilities. This paper presents a novel approach to imbue an LMM with the\nability to conduct explicit reasoning based on visual content and textual\ninstructions. We introduce a system that can ask a question to acquire\nnecessary knowledge, thereby enhancing the robustness and explicability of the\nreasoning process. Our method comprises the development of a novel dataset\ngenerated by a Large Language Model (LLM), designed to promote chain-of-thought\nreasoning combined with a question-asking mechanism. We designed an LMM, which\nhas high capabilities on region awareness to address the intricate requirements\nof image-text alignment. The model undergoes a three-stage training phase,\nstarting with large-scale image-text alignment using a large-scale datasets,\nfollowed by instruction tuning, and fine-tuning with a focus on\nchain-of-thought reasoning. The results demonstrate a stride toward a more\nrobust, accurate, and interpretable LMM, capable of reasoning explicitly and\nseeking information proactively when confronted with ambiguous visual input.", "field": "Computer Science", "categories": "cs.CV,cs.CL"}, {"arxiv_id": "2401.10007", "title": "Spintronic logic: from transducers to logic gates and circuits", "abstract": "While magnetic solid-state memory has found commercial applications to date,\nmagnetic logic has rather remained on a conceptual level so far. Here, we\ndiscuss open challenges of different spintronic logic approaches, which use\nmagnetic excitations for computation. While different logic gate designs have\nbeen proposed and proof of concept experiments have been reported, no\nnontrivial operational spintronic circuit has been demonstrated due to many\nopen challenges in spintronic circuit and system design. Furthermore, the\nintegration of spintronic circuits in CMOS systems will require the usage of\ntransducers between the electric (CMOS) and magnetic domains. We show that\nthese transducers can limit the performance as well as the energy consumption\nof hybrid CMOS-spintronic systems. Hence, the optimization of transducer\nefficiency will be a major step towards competitive spintronic logic system.", "field": "Computer Science", "categories": "cs.ET"}, {"arxiv_id": "2401.10008", "title": "Attack tree metrics are operad algebras", "abstract": "Attack Trees (ATs) are a widely used tool for security analysis. ATs can be\nemployed in quantitative security analysis through metrics, which assign a\nsecurity value to an AT. Many different AT metrics exist, and there exist\nmultiple general definitions that aim to study a wide variety of AT metrics at\nonce. However, these all have drawbacks: they do not capture all metrics, and\nthey do not easily generalize to extensions of ATs. In this paper, we introduce\na definition of AT metrics based on category theory, specifically operad\nalgebras. This encompasses all previous definitions of AT metrics, and is\neasily generalized to extensions of ATs. Furthermore, we show that under easily\nexpressed operad-theoretic conditions, existing metric calculation algorithms\ncan be extended in considerable generality.", "field": "Computer Science", "categories": "cs.CR,math.CT"}, {"arxiv_id": "2401.10011", "title": "CPCL: Cross-Modal Prototypical Contrastive Learning for Weakly\n  Supervised Text-based Person Re-Identification", "abstract": "Weakly supervised text-based person re-identification (TPRe-ID) seeks to\nretrieve images of a target person using textual descriptions, without relying\non identity annotations and is more challenging and practical. The primary\nchallenge is the intra-class differences, encompassing intra-modal feature\nvariations and cross-modal semantic gaps. Prior works have focused on\ninstance-level samples and ignored prototypical features of each person which\nare intrinsic and invariant. Toward this, we propose a Cross-Modal Prototypical\nContrastive Learning (CPCL) method. In practice, the CPCL introduces the CLIP\nmodel to weakly supervised TPRe-ID for the first time, mapping visual and\ntextual instances into a shared latent space. Subsequently, the proposed\nPrototypical Multi-modal Memory (PMM) module captures associations between\nheterogeneous modalities of image-text pairs belonging to the same person\nthrough the Hybrid Cross-modal Matching (HCM) module in a many-to-many mapping\nfashion. Moreover, the Outlier Pseudo Label Mining (OPLM) module further\ndistinguishes valuable outlier samples from each modality, enhancing the\ncreation of more reliable clusters by mining implicit relationships between\nimage-text pairs. Experimental results demonstrate that our proposed CPCL\nattains state-of-the-art performance on all three public datasets, with a\nsignificant improvement of 11.58%, 8.77% and 5.25% in Rank@1 accuracy on\nCUHK-PEDES, ICFG-PEDES and RSTPReid datasets, respectively. The code is\navailable at https://github.com/codeGallery24/CPCL.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10014", "title": "Optimizing Medication Decisions for Patients with Atrial Fibrillation\n  through Path Development Network", "abstract": "Atrial fibrillation (AF) is a common cardiac arrhythmia characterized by\nrapid and irregular contractions of the atria. It significantly elevates the\nrisk of strokes due to slowed blood flow in the atria, especially in the left\natrial appendage, which is prone to blood clot formation. Such clots can\nmigrate into cerebral arteries, leading to ischemic stroke. To assess whether\nAF patients should be prescribed anticoagulants, doctors often use the\nCHA2DS2-VASc scoring system. However, anticoagulant use must be approached with\ncaution as it can impact clotting functions. This study introduces a machine\nlearning algorithm that predicts whether patients with AF should be recommended\nanticoagulant therapy using 12-lead ECG data. In this model, we use STOME to\nenhance time-series data and then process it through a Convolutional Neural\nNetwork (CNN). By incorporating a path development layer, the model achieves a\nspecificity of 30.6% under the condition of an NPV of 1. In contrast, LSTM\nalgorithms without path development yield a specificity of only 2.7% under the\nsame NPV condition.", "field": "Computer Science", "categories": "cs.LG,eess.SP"}, {"arxiv_id": "2401.10015", "title": "Towards Hierarchical Spoken Language Dysfluency Modeling", "abstract": "Speech dysfluency modeling is the bottleneck for both speech therapy and\nlanguage learning. However, there is no AI solution to systematically tackle\nthis problem. We first propose to define the concept of dysfluent speech and\ndysfluent speech modeling. We then present Hierarchical Unconstrained\nDysfluency Modeling (H-UDM) approach that addresses both dysfluency\ntranscription and detection to eliminate the need for extensive manual\nannotation. Furthermore, we introduce a simulated dysfluent dataset called\nVCTK++ to enhance the capabilities of H-UDM in phonetic transcription. Our\nexperimental results demonstrate the effectiveness and robustness of our\nproposed methods in both transcription and detection tasks.", "field": "Computer Science", "categories": "cs.CL,eess.AS"}, {"arxiv_id": "2401.10016", "title": "Gender Bias in Machine Translation and The Era of Large Language Models", "abstract": "This chapter examines the role of Machine Translation in perpetuating gender\nbias, highlighting the challenges posed by cross-linguistic settings and\nstatistical dependencies. A comprehensive overview of relevant existing work\nrelated to gender bias in both conventional Neural Machine Translation\napproaches and Generative Pretrained Transformer models employed as Machine\nTranslation systems is provided. Through an experiment using ChatGPT (based on\nGPT-3.5) in an English-Italian translation context, we further assess ChatGPT's\ncurrent capacity to address gender bias. The findings emphasize the ongoing\nneed for advancements in mitigating bias in Machine Translation systems and\nunderscore the importance of fostering fairness and inclusivity in language\ntechnologies.", "field": "Computer Science", "categories": "cs.CL,cs.AI,cs.CY"}, {"arxiv_id": "2401.10017", "title": "Text Region Multiple Information Perception Network for Scene Text\n  Detection", "abstract": "Segmentation-based scene text detection algorithms can handle arbitrary shape\nscene texts and have strong robustness and adaptability, so it has attracted\nwide attention. Existing segmentation-based scene text detection algorithms\nusually only segment the pixels in the center region of the text, while\nignoring other information of the text region, such as edge information,\ndistance information, etc., thus limiting the detection accuracy of the\nalgorithm for scene text. This paper proposes a plug-and-play module called the\nRegion Multiple Information Perception Module (RMIPM) to enhance the detection\nperformance of segmentation-based algorithms. Specifically, we design an\nimproved module that can perceive various types of information about scene text\nregions, such as text foreground classification maps, distance maps, direction\nmaps, etc. Experiments on MSRA-TD500 and TotalText datasets show that our\nmethod achieves comparable performance with current state-of-the-art\nalgorithms.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10019", "title": "R-Judge: Benchmarking Safety Risk Awareness for LLM Agents", "abstract": "Large language models (LLMs) have exhibited great potential in autonomously\ncompleting tasks across real-world applications. Despite this, these LLM agents\nintroduce unexpected safety risks when operating in interactive environments.\nInstead of centering on LLM-generated content safety in most prior studies,\nthis work addresses the imperative need for benchmarking the behavioral safety\nof LLM agents within diverse environments. We introduce R-Judge, a benchmark\ncrafted to evaluate the proficiency of LLMs in judging safety risks given agent\ninteraction records. R-Judge comprises 162 agent interaction records,\nencompassing 27 key risk scenarios among 7 application categories and 10 risk\ntypes. It incorporates human consensus on safety with annotated safety risk\nlabels and high-quality risk descriptions. Utilizing R-Judge, we conduct a\ncomprehensive evaluation of 8 prominent LLMs commonly employed as the backbone\nfor agents. The best-performing model, GPT-4, achieves 72.29% in contrast to\nthe human score of 89.38%, showing considerable room for enhancing the risk\nawareness of LLMs. Notably, leveraging risk descriptions as environment\nfeedback significantly improves model performance, revealing the importance of\nsalient safety risk feedback. Furthermore, we design an effective chain of\nsafety analysis technique to help the judgment of safety risks and conduct an\nin-depth case study to facilitate future research. R-Judge is publicly\navailable at https://github.com/Lordog/R-Judge.", "field": "Computer Science", "categories": "cs.CL,cs.AI"}, {"arxiv_id": "2401.1002", "title": "Self-Rewarding Language Models", "abstract": "We posit that to achieve superhuman agents, future models require superhuman\nfeedback in order to provide an adequate training signal. Current approaches\ncommonly train reward models from human preferences, which may then be\nbottlenecked by human performance level, and secondly these separate frozen\nreward models cannot then learn to improve during LLM training. In this work,\nwe study Self-Rewarding Language Models, where the language model itself is\nused via LLM-as-a-Judge prompting to provide its own rewards during training.\nWe show that during Iterative DPO training that not only does instruction\nfollowing ability improve, but also the ability to provide high-quality rewards\nto itself. Fine-tuning Llama 2 70B on three iterations of our approach yields a\nmodel that outperforms many existing systems on the AlpacaEval 2.0 leaderboard,\nincluding Claude 2, Gemini Pro, and GPT-4 0613. While only a preliminary study,\nthis work opens the door to the possibility of models that can continually\nimprove in both axes.", "field": "Computer Science", "categories": "cs.CL,cs.AI"}, {"arxiv_id": "2401.10029", "title": "Cardiac Digital Twin Pipeline for Virtual Therapy Evaluation", "abstract": "Cardiac digital twins are computational tools capturing key functional and\nanatomical characteristics of patient hearts for investigating disease\nphenotypes and predicting responses to therapy. When paired with large-scale\ncomputational resources and large clinical datasets, digital twin technology\ncan enable virtual clinical trials on virtual cohorts to fast-track therapy\ndevelopment. Here, we present an automated pipeline for personalising\nventricular anatomy and electrophysiological function based on routinely\nacquired cardiac magnetic resonance (CMR) imaging data and the standard 12-lead\nelectrocardiogram (ECG). Using CMR-based anatomical models, a sequential\nMonte-Carlo approximate Bayesian computational inference method is extended to\ninfer electrical activation and repolarisation characteristics from the ECG.\nFast simulations are conducted with a reaction-Eikonal model, including the\nPurkinje network and biophysically-detailed subcellular ionic current dynamics\nfor repolarisation. For each patient, parameter uncertainty is represented by\ninferring a population of ventricular models rather than a single one, which\nmeans that parameter uncertainty can be propagated to therapy evaluation.\nFurthermore, we have developed techniques for translating from reaction-Eikonal\nto monodomain simulations, which allows more realistic simulations of cardiac\nelectrophysiology. The pipeline is demonstrated in a healthy female subject,\nwhere our inferred reaction-Eikonal models reproduced the patient's ECG with a\nPearson's correlation coefficient of 0.93, and the translated monodomain\nsimulations have a correlation coefficient of 0.89. We then apply the effect of\nDofetilide to the monodomain population of models for this subject and show\ndose-dependent QT and T-peak to T-end prolongations that are in keeping with\nlarge population drug response data.", "field": "Computer Science", "categories": "cs.CE,q-bio.TO"}, {"arxiv_id": "2401.1003", "title": "Framing Analysis of Health-Related Narratives: Conspiracy versus\n  Mainstream Media", "abstract": "Understanding how online media frame issues is crucial due to their impact on\npublic opinion. Research on framing using natural language processing\ntechniques mainly focuses on specific content features in messages and neglects\ntheir narrative elements. Also, the distinction between framing in different\nsources remains an understudied problem. We address those issues and\ninvestigate how the framing of health-related topics, such as COVID-19 and\nother diseases, differs between conspiracy and mainstream websites. We\nincorporate narrative information into the framing analysis by introducing a\nnovel frame extraction approach based on semantic graphs. We find that\nhealth-related narratives in conspiracy media are predominantly framed in terms\nof beliefs, while mainstream media tend to present them in terms of science. We\nhope our work offers new ways for a more nuanced frame analysis.", "field": "Computer Science", "categories": "cs.CL,cs.CY"}, {"arxiv_id": "2401.10034", "title": "Evolutionary Computation in the Era of Large Language Model: Survey and\n  Roadmap", "abstract": "Large Language Models (LLMs), built upon Transformer-based architectures with\nmassive pretraining on diverse data, have not only revolutionized natural\nlanguage processing but also extended their prowess to various domains, marking\na significant stride towards artificial general intelligence. The interplay\nbetween LLMs and Evolutionary Algorithms (EAs), despite differing in objectives\nand methodologies, reveals intriguing parallels, especially in their shared\noptimization nature, black-box characteristics, and proficiency in handling\ncomplex problems. Meanwhile, EA can not only provide an optimization framework\nfor LLM's further enhancement under black-box settings but also empower LLM\nwith flexible global search and iterative mechanism in applications. On the\nother hand, LLM's abundant domain knowledge enables EA to perform smarter\nsearches, while its text processing capability assist in deploying EA across\nvarious tasks. Based on their complementary advantages, this paper presents a\ncomprehensive review and forward-looking roadmap, categorizing their mutual\ninspiration into LLM-enhanced evolutionary optimization and EA-enhanced LLM.\nSome integrated synergy methods are further introduced to exemplify the\namalgamation of LLMs and EAs in various application scenarios, including neural\narchitecture search, code generation, software engineering, and text\ngeneration. As the first comprehensive review specifically focused on the EA\nresearch in the era of LLMs, this paper provides a foundational stepping stone\nfor understanding and harnessing the collaborative potential of LLMs and EAs.\nBy presenting a comprehensive review, categorization, and critical analysis, we\ncontribute to the ongoing discourse on the cross-disciplinary study of these\ntwo powerful paradigms. The identified challenges and future directions offer\nguidance to unlock the full potential of this innovative collaboration.", "field": "Computer Science", "categories": "cs.NE,cs.AI,cs.CL"}, {"arxiv_id": "2401.10036", "title": "LOCALINTEL: Generating Organizational Threat Intelligence from Global\n  and Local Cyber Knowledge", "abstract": "Security Operations Center (SoC) analysts gather threat reports from openly\naccessible global threat databases and customize them manually to suit a\nparticular organization's needs. These analysts also depend on internal\nrepositories, which act as private local knowledge database for an\norganization. Credible cyber intelligence, critical operational details, and\nrelevant organizational information are all stored in these local knowledge\ndatabases. Analysts undertake a labor intensive task utilizing these global and\nlocal knowledge databases to manually create organization's unique threat\nresponse and mitigation strategies. Recently, Large Language Models (LLMs) have\nshown the capability to efficiently process large diverse knowledge sources. We\nleverage this ability to process global and local knowledge databases to\nautomate the generation of organization-specific threat intelligence.\n  In this work, we present LOCALINTEL, a novel automated knowledge\ncontextualization system that, upon prompting, retrieves threat reports from\nthe global threat repositories and uses its local knowledge database to\ncontextualize them for a specific organization. LOCALINTEL comprises of three\nkey phases: global threat intelligence retrieval, local knowledge retrieval,\nand contextualized completion generation. The former retrieves intelligence\nfrom global threat repositories, while the second retrieves pertinent knowledge\nfrom the local knowledge database. Finally, the fusion of these knowledge\nsources is orchestrated through a generator to produce a contextualized\ncompletion.", "field": "Computer Science", "categories": "cs.CR,cs.AI,cs.IR,cs.LO"}, {"arxiv_id": "2401.10037", "title": "Depth Over RGB: Automatic Evaluation of Open Surgery Skills Using Depth\n  Camera", "abstract": "Purpose: In this paper, we present a novel approach to the automatic\nevaluation of open surgery skills using depth cameras. This work is intended to\nshow that depth cameras achieve similar results to RGB cameras, which is the\ncommon method in the automatic evaluation of open surgery skills. Moreover,\ndepth cameras offer advantages such as robustness to lighting variations,\ncamera positioning, simplified data compression, and enhanced privacy, making\nthem a promising alternative to RGB cameras.\n  Methods: Experts and novice surgeons completed two simulators of open\nsuturing. We focused on hand and tool detection, and action segmentation in\nsuturing procedures. YOLOv8 was used for tool detection in RGB and depth\nvideos. Furthermore, UVAST and MSTCN++ were used for action segmentation. Our\nstudy includes the collection and annotation of a dataset recorded with Azure\nKinect.\n  Results: We demonstrated that using depth cameras in object detection and\naction segmentation achieves comparable results to RGB cameras. Furthermore, we\nanalyzed 3D hand path length, revealing significant differences between experts\nand novice surgeons, emphasizing the potential of depth cameras in capturing\nsurgical skills. We also investigated the influence of camera angles on\nmeasurement accuracy, highlighting the advantages of 3D cameras in providing a\nmore accurate representation of hand movements.\n  Conclusion: Our research contributes to advancing the field of surgical skill\nassessment by leveraging depth cameras for more reliable and privacy\nevaluations. The findings suggest that depth cameras can be valuable in\nassessing surgical skills and provide a foundation for future research in this\narea.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10039", "title": "GPT4Ego: Unleashing the Potential of Pre-trained Models for Zero-Shot\n  Egocentric Action Recognition", "abstract": "Vision-Language Models (VLMs), pre-trained on large-scale datasets, have\nshown impressive performance in various visual recognition tasks. This\nadvancement paves the way for notable performance in Zero-Shot Egocentric\nAction Recognition (ZS-EAR). Typically, VLMs handle ZS-EAR as a global\nvideo-text matching task, which often leads to suboptimal alignment of vision\nand linguistic knowledge. We propose a refined approach for ZS-EAR using VLMs,\nemphasizing fine-grained concept-description alignment that capitalizes on the\nrich semantic and contextual details in egocentric videos. In this paper, we\nintroduce GPT4Ego, a straightforward yet remarkably potent VLM framework for\nZS-EAR, designed to enhance the fine-grained alignment of concept and\ndescription between vision and language. Extensive experiments demonstrate\nGPT4Ego significantly outperforms existing VLMs on three large-scale egocentric\nvideo benchmarks, i.e., EPIC-KITCHENS-100 (33.2%, +9.4%), EGTEA (39.6%, +5.5%),\nand CharadesEgo (31.5%, +2.6%).", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.1004", "title": "Large Language Models for Scientific Information Extraction: An\n  Empirical Study for Virology", "abstract": "In this paper, we champion the use of structured and semantic content\nrepresentation of discourse-based scholarly communication, inspired by tools\nlike Wikipedia infoboxes or structured Amazon product descriptions. These\nrepresentations provide users with a concise overview, aiding scientists in\nnavigating the dense academic landscape. Our novel automated approach leverages\nthe robust text generation capabilities of LLMs to produce structured scholarly\ncontribution summaries, offering both a practical solution and insights into\nLLMs' emergent abilities.\n  For LLMs, the prime focus is on improving their general intelligence as\nconversational agents. We argue that these models can also be applied\neffectively in information extraction (IE), specifically in complex IE tasks\nwithin terse domains like Science. This paradigm shift replaces the traditional\nmodular, pipelined machine learning approach with a simpler objective expressed\nthrough instructions. Our results show that finetuned FLAN-T5 with 1000x fewer\nparameters than the state-of-the-art GPT-davinci is competitive for the task.", "field": "Computer Science", "categories": "cs.CL,cs.AI,cs.DL,cs.IT,math.IT"}, {"arxiv_id": "2401.10041", "title": "CMFN: Cross-Modal Fusion Network for Irregular Scene Text Recognition", "abstract": "Scene text recognition, as a cross-modal task involving vision and text, is\nan important research topic in computer vision. Most existing methods use\nlanguage models to extract semantic information for optimizing visual\nrecognition. However, the guidance of visual cues is ignored in the process of\nsemantic mining, which limits the performance of the algorithm in recognizing\nirregular scene text. To tackle this issue, we propose a novel cross-modal\nfusion network (CMFN) for irregular scene text recognition, which incorporates\nvisual cues into the semantic mining process. Specifically, CMFN consists of a\nposition self-enhanced encoder, a visual recognition branch and an iterative\nsemantic recognition branch. The position self-enhanced encoder provides\ncharacter sequence position encoding for both the visual recognition branch and\nthe iterative semantic recognition branch. The visual recognition branch\ncarries out visual recognition based on the visual features extracted by CNN\nand the position encoding information provided by the position self-enhanced\nencoder. The iterative semantic recognition branch, which consists of a\nlanguage recognition module and a cross-modal fusion gate, simulates the way\nthat human recognizes scene text and integrates cross-modal visual cues for\ntext recognition. The experiments demonstrate that the proposed CMFN algorithm\nachieves comparable performance to state-of-the-art algorithms, indicating its\neffectiveness.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10042", "title": "BlockAMC: Scalable In-Memory Analog Matrix Computing for Solving Linear\n  Systems", "abstract": "Recently, in-memory analog matrix computing (AMC) with nonvolatile resistive\nmemory has been developed for solving matrix problems in one step, e.g., matrix\ninversion of solving linear systems. However, the analog nature sets up a\nbarrier to the scalability of AMC, due to the limits on the manufacturability\nand yield of resistive memory arrays, non-idealities of device and circuit, and\ncost of hardware implementations. Aiming to deliver a scalable AMC approach for\nsolving linear systems, this work presents BlockAMC, which partitions a large\noriginal matrix into smaller ones on different memory arrays. A macro is\ndesigned to perform matrix inversion and matrix-vector multiplication with the\nblock matrices, obtaining the partial solutions to recover the original\nsolution. The size of block matrices can be exponentially reduced by performing\nmultiple stages of divide-and-conquer, resulting in a two-stage solver design\nthat enhances the scalability of this approach. BlockAMC is also advantageous\nin alleviating the accuracy issue of AMC, especially in the presence of device\nand circuit non-idealities, such as conductance variations and interconnect\nresistances. Compared to a single AMC circuit solving the same problem,\nBlockAMC improves the area and energy efficiency by 48.83% and 40%,\nrespectively.", "field": "Computer Science", "categories": "cs.AR,cs.DC"}, {"arxiv_id": "2401.10044", "title": "Deep spatial context: when attention-based models meet spatial\n  regression", "abstract": "We propose 'Deep spatial context' (DSCon) method, which serves for\ninvestigation of the attention-based vision models using the concept of spatial\ncontext. It was inspired by histopathologists, however, the method can be\napplied to various domains. The DSCon allows for a quantitative measure of the\nspatial context's role using three Spatial Context Measures: $SCM_{features}$,\n$SCM_{targets}$, $SCM_{residuals}$ to distinguish whether the spatial context\nis observable within the features of neighboring regions, their target values\n(attention scores) or residuals, respectively. It is achieved by integrating\nspatial regression into the pipeline. The DSCon helps to verify research\nquestions. The experiments reveal that spatial relationships are much bigger in\nthe case of the classification of tumor lesions than normal tissues. Moreover,\nit turns out that the larger the size of the neighborhood taken into account\nwithin spatial regression, the less valuable contextual information is.\nFurthermore, it is observed that the spatial context measure is the largest\nwhen considered within the feature space as opposed to the targets and\nresiduals.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10045", "title": "Antonym vs Synonym Distinction using InterlaCed Encoder NETworks\n  (ICE-NET)", "abstract": "Antonyms vs synonyms distinction is a core challenge in lexico-semantic\nanalysis and automated lexical resource construction. These pairs share a\nsimilar distributional context which makes it harder to distinguish them.\nLeading research in this regard attempts to capture the properties of the\nrelation pairs, i.e., symmetry, transitivity, and trans-transitivity. However,\nthe inability of existing research to appropriately model the relation-specific\nproperties limits their end performance. In this paper, we propose InterlaCed\nEncoder NETworks (i.e., ICE-NET) for antonym vs synonym distinction, that aim\nto capture and model the relation-specific properties of the antonyms and\nsynonyms pairs in order to perform the classification task in a\nperformance-enhanced manner. Experimental evaluation using the benchmark\ndatasets shows that ICE-NET outperforms the existing research by a relative\nscore of upto 1.8% in F1-measure. We release the codes for ICE-NET at\nhttps://github.com/asif6827/ICENET.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.1005", "title": "ContextMix: A context-aware data augmentation method for industrial\n  visual inspection systems", "abstract": "While deep neural networks have achieved remarkable performance, data\naugmentation has emerged as a crucial strategy to mitigate overfitting and\nenhance network performance. These techniques hold particular significance in\nindustrial manufacturing contexts. Recently, image mixing-based methods have\nbeen introduced, exhibiting improved performance on public benchmark datasets.\nHowever, their application to industrial tasks remains challenging. The\nmanufacturing environment generates massive amounts of unlabeled data on a\ndaily basis, with only a few instances of abnormal data occurrences. This leads\nto severe data imbalance. Thus, creating well-balanced datasets is not\nstraightforward due to the high costs associated with labeling. Nonetheless,\nthis is a crucial step for enhancing productivity. For this reason, we\nintroduce ContextMix, a method tailored for industrial applications and\nbenchmark datasets. ContextMix generates novel data by resizing entire images\nand integrating them into other images within the batch. This approach enables\nour method to learn discriminative features based on varying sizes from resized\nimages and train informative secondary features for object recognition using\noccluded images. With the minimal additional computation cost of image\nresizing, ContextMix enhances performance compared to existing augmentation\ntechniques. We evaluate its effectiveness across classification, detection, and\nsegmentation tasks using various network architectures on public benchmark\ndatasets. Our proposed method demonstrates improved results across a range of\nrobustness tasks. Its efficacy in real industrial environments is particularly\nnoteworthy, as demonstrated using the passive component dataset.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10052", "title": "Unconstrained Parameterization of Stable LPV Input-Output Models: with\n  Application to System Identification", "abstract": "Ensuring stability of discrete-time (DT) linear parameter-varying (LPV)\ninput-output (IO) models estimated via system identification methods is a\nchallenging problem as known stability constraints can only be numerically\nverified, e.g., through solving Linear Matrix Inequalities. In this paper, an\nunconstrained DT-LPV-IO parameterization is developed which gives a stable\nmodel for any choice of model parameters. To achieve this, it is shown that\n\\textit{all} quadratically stable DT-LPV-IO models can be generated by a\nmapping of transformed coefficient functions that are constrained to the unit\nball, i.e., a small-gain condition. The unit ball is then reparameterized\nthrough a Cayley transformation, resulting in an unconstrained parameterization\nof all quadratically stable DT-LPV-IO models. As a special case, an\nunconstrained parameterization of all stable DT linear time-invariant transfer\nfunctions is obtained. Identification using the stable DT-LPV-IO model with\nneural network coefficient functions is demonstrated on a simulation example of\na position-varying mass-damper-spring system.", "field": "Computer Science", "categories": "eess.SY,cs.SY"}, {"arxiv_id": "2401.10061", "title": "DiffusionGPT: LLM-Driven Text-to-Image Generation System", "abstract": "Diffusion models have opened up new avenues for the field of image\ngeneration, resulting in the proliferation of high-quality models shared on\nopen-source platforms. However, a major challenge persists in current\ntext-to-image systems are often unable to handle diverse inputs, or are limited\nto single model results. Current unified attempts often fall into two\northogonal aspects: i) parse Diverse Prompts in input stage; ii) activate\nexpert model to output. To combine the best of both worlds, we propose\nDiffusionGPT, which leverages Large Language Models (LLM) to offer a unified\ngeneration system capable of seamlessly accommodating various types of prompts\nand integrating domain-expert models. DiffusionGPT constructs domain-specific\nTrees for various generative models based on prior knowledge. When provided\nwith an input, the LLM parses the prompt and employs the Trees-of-Thought to\nguide the selection of an appropriate model, thereby relaxing input constraints\nand ensuring exceptional performance across diverse domains. Moreover, we\nintroduce Advantage Databases, where the Tree-of-Thought is enriched with human\nfeedback, aligning the model selection process with human preferences. Through\nextensive experiments and comparisons, we demonstrate the effectiveness of\nDiffusionGPT, showcasing its potential for pushing the boundaries of image\nsynthesis in diverse domains.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.10065", "title": "Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs", "abstract": "Reasoning is a fundamental component for achieving language understanding.\nAmong the multiple types of reasoning, conditional reasoning, the ability to\ndraw different conclusions depending on some condition, has been understudied\nin large language models (LLMs). Recent prompting methods, such as chain of\nthought, have significantly improved LLMs on reasoning tasks. Nevertheless,\nthere is still little understanding of what triggers reasoning abilities in\nLLMs. We hypothesize that code prompts can trigger conditional reasoning in\nLLMs trained on text and code. We propose a chain of prompts that transforms a\nnatural language problem into code and prompts the LLM with the generated code.\nOur experiments find that code prompts exhibit a performance boost between 2.6\nand 7.7 points on GPT 3.5 across multiple datasets requiring conditional\nreasoning. We then conduct experiments to discover how code prompts elicit\nconditional reasoning abilities and through which features. We observe that\nprompts need to contain natural language text accompanied by high-quality code\nthat closely represents the semantics of the instance text. Furthermore, we\nshow that code prompts are more efficient, requiring fewer demonstrations, and\nthat they trigger superior state tracking of variables or key entities.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.10068", "title": "GPU Acceleration of a Conjugate Exponential Model for Cancer Tissue\n  Heterogeneity", "abstract": "Heterogeneity in the cell population of cancer tissues poses many challenges\nin cancer diagnosis and treatment. Studying the heterogeneity in cell\npopulations from gene expression measurement data in the context of cancer\nresearch is a problem of paramount importance. In addition, reducing the\ncomputation time of the algorithms that deal with high volumes of data has its\nobvious merits. Parallelizable models using Markov chain Monte Carlo methods\nare typically slow. This paper shows a novel, computationally efficient, and\nparallelizable model to analyze heterogeneity in cancer tissues using GPUs.\nBecause our model is parallelizable, the input data size does not affect the\ncomputation time much, provided the hardware resources are not exhausted. Our\nmodel uses qPCR (quantitative polymerase chain reaction) gene expression\nmeasurements to study heterogeneity in cancer tissue. We compute the cell\nproportion breakup by accelerating variational methods on a GPU. We test this\nmodel on synthetic and real-world gene expression data collected from\nfibroblasts and compare the performance of our algorithm with those of MCMC and\nExpectation Maximization. Our new model is computationally less complex and\nfaster than existing Bayesian models for cancer tissue heterogeneity.", "field": "Computer Science", "categories": "cs.DC,q-bio.QM"}, {"arxiv_id": "2401.1007", "title": "Communication-Efficient Personalized Federated Learning for\n  Speech-to-Text Tasks", "abstract": "To protect privacy and meet legal regulations, federated learning (FL) has\ngained significant attention for training speech-to-text (S2T) systems,\nincluding automatic speech recognition (ASR) and speech translation (ST).\nHowever, the commonly used FL approach (i.e., \\textsc{FedAvg}) in S2T tasks\ntypically suffers from extensive communication overhead due to multi-round\ninteractions based on the whole model and performance degradation caused by\ndata heterogeneity among clients.To address these issues, we propose a\npersonalized federated S2T framework that introduces \\textsc{FedLoRA}, a\nlightweight LoRA module for client-side tuning and interaction with the server\nto minimize communication overhead, and \\textsc{FedMem}, a global model\nequipped with a $k$-nearest-neighbor ($k$NN) classifier that captures\nclient-specific distributional shifts to achieve personalization and overcome\ndata heterogeneity. Extensive experiments based on Conformer and Whisper\nbackbone models on CoVoST and GigaSpeech benchmarks show that our approach\nsignificantly reduces the communication overhead on all S2T tasks and\neffectively personalizes the global model to overcome data heterogeneity.", "field": "Computer Science", "categories": "cs.CL,cs.SD,eess.AS"}, {"arxiv_id": "2401.10082", "title": "Analyzing and Improving Hardware Modeling of Accel-Sim", "abstract": "GPU architectures have become popular for executing general-purpose programs.\nTheir many-core architecture supports a large number of threads that run\nconcurrently to hide the latency among dependent instructions. In modern GPU\narchitectures, each SM/core is typically composed of several sub-cores, where\neach sub-core has its own independent pipeline.\n  Simulators are a key tool for investigating novel concepts in computer\narchitecture. They must be performance-accurate and have a proper model related\nto the target hardware to explore the different bottlenecks properly.\n  This paper presents a wide analysis of different parts of Accel-sim, a\npopular GPGPU simulator, and some improvements of its model. First, we focus on\nthe front-end and developed a more realistic model. Then, we analyze the way\nthe result bus works and develop a more realistic one. Next, we describe the\ncurrent memory pipeline model and propose a model for a more cost-effective\ndesign. Finally, we discuss other areas of improvement of the simulator.", "field": "Computer Science", "categories": "cs.AR"}, {"arxiv_id": "2401.10083", "title": "A locally statistical active contour model for SAR image segmentation\n  can be solved by denoising algorithms", "abstract": "In this paper, we propose a novel locally statistical variational active\ncontour model based on I-divergence-TV denoising model, which hybrides geodesic\nactive contour (GAC) model with active contours without edges (ACWE) model, and\ncan be used to segment images corrupted by multiplicative gamma noise. By\nadding a diffusion term into the level set evolution (LSE) equation of the\nproposed model, we construct a reaction-diffusion (RD) equation, which can\ngradually regularize the level set function (LSF) to be piecewise constant in\neach segment domain and gain the stable solution. We further transform the\nproposed model into classic ROF model by adding a proximity term. Inspired by a\nfast denoising algorithm proposed by Jia-Zhao recently, we propose two fast\nfixed point algorithms to solve SAR image segmentation question. Experimental\nresults for real SAR images show that the proposed image segmentation model can\nefficiently stop the contours at weak or blurred edges, and can automatically\ndetect the exterior and interior boundaries of images with multiplicative gamma\nnoise. The proposed FPRD1/FPRD2 models are about 1/2 (or less than) of the time\nrequired for the SBRD model based on the Split Bregman technique.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10085", "title": "CLIP feature-based randomized control using images and text for multiple\n  tasks and robots", "abstract": "This study presents a control framework leveraging vision language models\n(VLMs) for multiple tasks and robots. Notably, existing control methods using\nVLMs have achieved high performance in various tasks and robots in the training\nenvironment. However, these methods incur high costs for learning control\npolicies for tasks and robots other than those in the training environment.\nConsidering the application of industrial and household robots, learning in\nnovel environments where robots are introduced is challenging. To address this\nissue, we propose a control framework that does not require learning control\npolicies. Our framework combines the vision-language CLIP model with a\nrandomized control. CLIP computes the similarity between images and texts by\nembedding them in the feature space. This study employs CLIP to compute the\nsimilarity between camera images and text representing the target state. In our\nmethod, the robot is controlled by a randomized controller that simultaneously\nexplores and increases the similarity gradients. Moreover, we fine-tune the\nCLIP to improve the performance of the proposed method. Consequently, we\nconfirm the effectiveness of our approach through a multitask simulation and a\nreal robot experiment using a two-wheeled robot and robot arm.", "field": "Computer Science", "categories": "cs.RO"}, {"arxiv_id": "2401.10088", "title": "Stability theory of TASE-Runge-Kutta methods with inexact Jacobian", "abstract": "This paper analyzes the stability of the class of Time-Accurate and\nHighly-Stable Explicit Runge-Kutta (TASE-RK) methods, introduced in 2021 by\nBassenne et al. (J. Comput. Phys.) for the numerical solution of stiff Initial\nValue Problems (IVPs). Such numerical methods are easy to implement and require\nthe solution of a limited number of linear systems per step, whose coefficient\nmatrices involve the exact Jacobian $J$ of the problem. To significantly reduce\nthe computational cost of TASE-RK methods without altering their consistency\nproperties, it is possible to replace $J$ with a matrix $A$ (not necessarily\ntied to $J$) in their formulation, for instance fixed for a certain number of\nconsecutive steps or even constant. However, the stability properties of\nTASE-RK methods strongly depend on this choice, and so far have been studied\nassuming $A=J$.\n  In this manuscript, we theoretically investigate the conditional and\nunconditional stability of TASE-RK methods by considering arbitrary $A$. To\nthis end, we first split the Jacobian as $J=A+B$. Then, through the use of\nstability diagrams and their connections with the field of values, we analyze\nboth the case in which $A$ and $B$ are simultaneously diagonalizable and not.\nNumerical experiments, conducted on Partial Differential Equations (PDEs)\narising from applications, show the correctness and utility of the theoretical\nresults derived in the paper, as well as the good stability and efficiency of\nTASE-RK methods when $A$ is suitably chosen.", "field": "Computer Science", "categories": "math.NA,cs.NA,65L04, 65L06, 65L07, 65L20, 65M12, 65M20"}, {"arxiv_id": "2401.10089", "title": "Polynomial approximations for the matrix logarithm with computation\n  graphs", "abstract": "The most popular method for computing the matrix logarithm is a combination\nof the inverse scaling and squaring method in conjunction with a Pad\\'e\napproximation, sometimes accompanied by the Schur decomposition. The main\ncomputational effort lies in matrix-matrix multiplications and left matrix\ndivision. In this work we illustrate that the number of such operations can be\nsubstantially reduced, by using a graph based representation of an efficient\npolynomial evaluation scheme. A technique to analyze the rounding error is\nproposed, and backward error analysis is adapted. We provide substantial\nsimulations illustrating competitiveness both in terms of computation time and\nrounding errors.", "field": "Computer Science", "categories": "math.NA,cs.NA"}, {"arxiv_id": "2401.1009", "title": "Cross-Modality Perturbation Synergy Attack for Person Re-identification", "abstract": "In recent years, there has been significant research focusing on addressing\nsecurity concerns in single-modal person re-identification (ReID) systems that\nare based on RGB images. However, the safety of cross-modality scenarios, which\nare more commonly encountered in practical applications involving images\ncaptured by infrared cameras, has not received adequate attention. The main\nchallenge in cross-modality ReID lies in effectively dealing with visual\ndifferences between different modalities. For instance, infrared images are\ntypically grayscale, unlike visible images that contain color information.\nExisting attack methods have primarily focused on the characteristics of the\nvisible image modality, overlooking the features of other modalities and the\nvariations in data distribution among different modalities. This oversight can\npotentially undermine the effectiveness of these methods in image retrieval\nacross diverse modalities. This study represents the first exploration into the\nsecurity of cross-modality ReID models and proposes a universal perturbation\nattack specifically designed for cross-modality ReID. This attack optimizes\nperturbations by leveraging gradients from diverse modality data, thereby\ndisrupting the discriminator and reinforcing the differences between\nmodalities. We conducted experiments on two widely used cross-modality\ndatasets, namely RegDB and SYSU, which not only demonstrated the effectiveness\nof our method but also provided insights for future enhancements in the\nrobustness of cross-modality ReID systems.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10091", "title": "Power in Numbers: Robust reading comprehension by finetuning with four\n  adversarial sentences per example", "abstract": "Recent models have achieved human level performance on the Stanford Question\nAnswering Dataset when using F1 scores to evaluate the reading comprehension\ntask. Yet, teaching machines to comprehend text has not been solved in the\ngeneral case. By appending one adversarial sentence to the context paragraph,\npast research has shown that the F1 scores from reading comprehension models\ndrop almost in half. In this paper, I replicate past adversarial research with\na new model, ELECTRA-Small, and demonstrate that the new model's F1 score drops\nfrom 83.9% to 29.2%. To improve ELECTRA-Small's resistance to this attack, I\nfinetune the model on SQuAD v1.1 training examples with one to five adversarial\nsentences appended to the context paragraph. Like past research, I find that\nthe finetuned model on one adversarial sentence does not generalize well across\nevaluation datasets. However, when finetuned on four or five adversarial\nsentences the model attains an F1 score of more than 70% on most evaluation\ndatasets with multiple appended and prepended adversarial sentences. The\nresults suggest that with enough examples we can make models robust to\nadversarial attacks.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.10101", "title": "Counterfactual Reasoning with Probabilistic Graphical Models for\n  Analyzing Socioecological Systems", "abstract": "Causal and counterfactual reasoning are emerging directions in data science\nthat allow us to reason about hypothetical scenarios. This is particularly\nuseful in domains where experimental data are usually not available. In the\ncontext of environmental and ecological sciences, causality enables us, for\nexample, to predict how an ecosystem would respond to hypothetical\ninterventions. A structural causal model is a class of probabilistic graphical\nmodels for causality, which, due to its intuitive nature, can be easily\nunderstood by experts in multiple fields. However, certain queries, called\nunidentifiable, cannot be calculated in an exact and precise manner. This paper\nproposes applying a novel and recent technique for bounding unidentifiable\nqueries within the domain of socioecological systems. Our findings indicate\nthat traditional statistical analysis, including probabilistic graphical\nmodels, can identify the influence between variables. However, such methods do\nnot offer insights into the nature of the relationship, specifically whether it\ninvolves necessity or sufficiency. This is where counterfactual reasoning\nbecomes valuable.", "field": "Computer Science", "categories": "cs.AI,math.PR,stat.AP"}, {"arxiv_id": "2401.10109", "title": "Information sets from defining sets for Reed-Muller codes of first and\n  second order", "abstract": "Reed-Muller codes belong to the family of affine-invariant codes. As such\ncodes they have a defining set that determines them uniquely, and they are\nextensions of cyclic group codes. In this paper we identify those cyclic codes\nwith multidimensional abelian codes and we use the techniques introduced in\n\\cite{BS} to construct information sets for them from their defining set. For\nfirst and second order Reed-Muller codes, we describe a direct method to\nconstruct information sets in terms of their basic parameters.", "field": "Computer Science", "categories": "cs.IT,math.IT"}, {"arxiv_id": "2401.1011", "title": "VIPTR: A Vision Permutable Extractor for Fast and Efficient Scene Text\n  Recognition", "abstract": "Scene Text Recognition (STR) is a challenging task that involves recognizing\ntext within images of natural scenes. Although current state-of-the-art models\nfor STR exhibit high performance, they typically suffer from low inference\nefficiency due to their reliance on hybrid architectures comprised of visual\nencoders and sequence decoders. In this work, we propose the VIsion Permutable\nextractor for fast and efficient scene Text Recognition (VIPTR), which achieves\nan impressive balance between high performance and rapid inference speeds in\nthe domain of STR. Specifically, VIPTR leverages a visual-semantic extractor\nwith a pyramid structure, characterized by multiple self-attention layers,\nwhile eschewing the traditional sequence decoder. This design choice results in\na lightweight and efficient model capable of handling inputs of varying sizes.\nExtensive experimental results on various standard datasets for both Chinese\nand English scene text recognition validate the superiority of VIPTR. Notably,\nthe VIPTR-T (Tiny) variant delivers highly competitive accuracy on par with\nother lightweight models and achieves SOTA inference speeds. Meanwhile, the\nVIPTR-L (Large) variant attains greater recognition accuracy, while maintaining\na low parameter count and favorable inference speed. Our proposed method\nprovides a compelling solution for the STR challenge, which blends high\naccuracy with efficiency and greatly benefits real-world applications requiring\nfast and reliable text recognition. The code is publicly available at\nhttps://github.com/cxfyxl/VIPTR.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10111", "title": "Marrying Adapters and Mixup to Efficiently Enhance the Adversarial\n  Robustness of Pre-Trained Language Models for Text Classification", "abstract": "Existing works show that augmenting training data of neural networks using\nboth clean and adversarial examples can enhance their generalizability under\nadversarial attacks. However, this training approach often leads to performance\ndegradation on clean inputs. Additionally, it requires frequent re-training of\nthe entire model to account for new attack types, resulting in significant and\ncostly computations. Such limitations make adversarial training mechanisms less\npractical, particularly for complex Pre-trained Language Models (PLMs) with\nmillions or even billions of parameters. To overcome these challenges while\nstill harnessing the theoretical benefits of adversarial training, this study\ncombines two concepts: (1) adapters, which enable parameter-efficient\nfine-tuning, and (2) Mixup, which train NNs via convex combinations of pairs\ndata pairs. Intuitively, we propose to fine-tune PLMs through convex\ncombinations of non-data pairs of fine-tuned adapters, one trained with clean\nand another trained with adversarial examples. Our experiments show that the\nproposed method achieves the best trade-off between training efficiency and\npredictive performance, both with and without attacks compared to other\nbaselines on a variety of downstream tasks.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.10113", "title": "Exposing Lip-syncing Deepfakes from Mouth Inconsistencies", "abstract": "A lip-syncing deepfake is a digitally manipulated video in which a person's\nlip movements are created convincingly using AI models to match altered or\nentirely new audio. Lip-syncing deepfakes are a dangerous type of deepfakes as\nthe artifacts are limited to the lip region and more difficult to discern. In\nthis paper, we describe a novel approach, LIP-syncing detection based on mouth\nINConsistency (LIPINC), for lip-syncing deepfake detection by identifying\ntemporal inconsistencies in the mouth region. These inconsistencies are seen in\nthe adjacent frames and throughout the video. Our model can successfully\ncapture these irregularities and outperforms the state-of-the-art methods on\nseveral benchmark deepfake datasets.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10118", "title": "Techniques for Authenticating Quantile Digests", "abstract": "We investigate two possible techniques to authenticate the q-digest data\nstructure, along with a worst-case study of the computational complexity both\nin time and space of the proposed solutions, and considerations on the\nfeasibility of the presented approaches in real-world scenarios. We conclude\nthe discussion by presenting some considerations on the information complexity\nof the queries in the two proposed approaches, and by presenting some\ninteresting ideas that could be the subject of future studies on the topic.", "field": "Computer Science", "categories": "cs.DS,cs.DC,E.1"}, {"arxiv_id": "2401.10119", "title": "Towards Principled Graph Transformers", "abstract": "Graph learning architectures based on the k-dimensional Weisfeiler-Leman\n(k-WL) hierarchy offer a theoretically well-understood expressive power.\nHowever, such architectures often fail to deliver solid predictive performance\non real-world tasks, limiting their practical impact. In contrast, global\nattention-based models such as graph transformers demonstrate strong\nperformance in practice, but comparing their expressive power with the k-WL\nhierarchy remains challenging, particularly since these architectures rely on\npositional or structural encodings for their expressivity and predictive\nperformance. To address this, we show that the recently proposed Edge\nTransformer, a global attention model operating on node pairs instead of nodes,\nhas at least 3-WL expressive power. Empirically, we demonstrate that the Edge\nTransformer surpasses other theoretically aligned architectures regarding\npredictive performance while not relying on positional or structural encodings.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.10122", "title": "Differentially Private Approval-Based Committee Voting", "abstract": "In this paper, we investigate tradeoffs between differential privacy (DP) and\nseveral voting axioms for approval-based committee voting, including\nproportionality, Pareto efficiency, Condorcet criterion, and strategyproofness.\nFor all the axioms except strategyproofness, we show their incompatibility with\nDP, and provide both upper and lower bounds for their tradeoffs with DP.\nFurthermore, we show that any $\\epsilon$-DP mechanism satisfies\n$e^{-\\epsilon}$-cardinality strategyproofness, and the satisfaction can be\nfurther improved if the mechanism satisfies monotonicity.", "field": "Computer Science", "categories": "cs.GT"}, {"arxiv_id": "2401.10133", "title": "Interplay between Sensing and Communication in Cell-Free Massive MIMO\n  with URLLC Users", "abstract": "This paper studies integrated sensing and communication (ISAC) in the\ndownlink of a cell-free massive multiple-input multiple-output (MIMO) system\nwith multi-static sensing and ultra-reliable low-latency communication (URLLC)\nusers. We propose a successive convex approximation-based power allocation\nalgorithm that maximizes energy efficiency while satisfying the sensing and\nURLLC requirements. In addition, we provide a new definition for network\navailability, which accounts for both sensing and URLLC requirements. The\nimpact of blocklength, sensing requirement, and required reliability as a\nfunction of decoding error probability on network availability and energy\nefficiency is investigated. The proposed power allocation algorithm is compared\nto a communication-centric approach where only the URLLC requirement is\nconsidered. It is shown that the URLLC-only approach is incapable of meeting\nsensing requirements, while the proposed ISAC algorithm fulfills both sensing\nand URLLC requirements, albeit with an associated increase in energy\nconsumption. This increment can be reduced up to 75% by utilizing additional\nsymbols for sensing. It is also demonstrated that larger blocklengths enhance\nnetwork availability and offer greater robustness against stringent reliability\nrequirements.", "field": "Computer Science", "categories": "cs.IT,eess.SP,math.IT"}, {"arxiv_id": "2401.10134", "title": "Spatial-Temporal Large Language Model for Traffic Prediction", "abstract": "Traffic prediction, a critical component for intelligent transportation\nsystems, endeavors to foresee future traffic at specific locations using\nhistorical data. Although existing traffic prediction models often emphasize\ndeveloping complex neural network structures, their accuracy has not seen\nimprovements accordingly. Recently, Large Language Models (LLMs) have shown\noutstanding capabilities in time series analysis. Differing from existing\nmodels, LLMs progress mainly through parameter expansion and extensive\npre-training while maintaining their fundamental structures. In this paper, we\npropose a Spatial-Temporal Large Language Model (ST-LLM) for traffic\nprediction. Specifically, ST-LLM redefines the timesteps at each location as\ntokens and incorporates a spatial-temporal embedding module to learn the\nspatial location and global temporal representations of tokens. Then these\nrepresentations are fused to provide each token with unified spatial and\ntemporal information. Furthermore, we propose a novel partially frozen\nattention strategy of the LLM, which is designed to capture spatial-temporal\ndependencies for traffic prediction. Comprehensive experiments on real traffic\ndatasets offer evidence that ST-LLM outperforms state-of-the-art models.\nNotably, the ST-LLM also exhibits robust performance in both few-shot and\nzero-shot prediction scenarios.", "field": "Computer Science", "categories": "cs.LG,cs.CL"}, {"arxiv_id": "2401.10135", "title": "Residual Based Error Estimator for Chemical-Mechanically Coupled Battery\n  Active Particles", "abstract": "Adaptive finite element methods are a powerful tool to obtain numerical\nsimulation results in a reasonable time. Due to complex chemical and mechanical\ncouplings in lithium-ion batteries, numerical simulations are very helpful to\ninvestigate promising new battery active materials such as amorphous silicon\nfeaturing a higher energy density than graphite. Based on a thermodynamically\nconsistent continuum model with large deformation and chemo-mechanically\ncoupled approach, we compare three different spatial adaptive refinement\nstrategies: Kelly-, gradient recovery- and residual based error estimation. For\nthe residual based case, the strong formulation of the residual is explicitly\nderived. With amorphous silicon as example material, we investigate two 3D\nrepresentative host particle geometries, reduced with symmetry assumptions to a\n1D unit interval and a 2D elliptical domain. Our numerical studies show that\nthe Kelly estimator overestimates the error, whereas the gradient recovery\nestimator leads to lower refinement levels and a good capture of the change of\nthe lithium flux. The residual based error estimator reveals a strong\ndependency on the cell error part which can be improved by a more suitable\nchoice of constants to be more efficient. In a 2D domain, the concentration has\na larger influence on the mesh distribution than the Cauchy stress.", "field": "Computer Science", "categories": "math.NA,cs.NA"}, {"arxiv_id": "2401.10136", "title": "The Role of Data Filtering in Open Source Software Ranking and Selection", "abstract": "Faced with over 100M open source projects most empirical investigations\nselect a subset. Most research papers in leading venues investigated filtering\nprojects by some measure of popularity with explicit or implicit arguments that\nunpopular projects are not of interest, may not even represent \"real\" software\nprojects, or that less popular projects are not worthy of study. However, such\nfiltering may have enormous effects on the results of the studies if and\nprecisely because the sought-out response or prediction is in any way related\nto the filtering criteria.\n  We exemplify the impact of this practice on research outcomes: how filtering\nof projects listed on GitHub affects the assessment of their popularity. We\nrandomly sample over 100,000 repositories and use multiple regression to model\nthe number of stars (a proxy for popularity) based on the number of commits,\nthe duration of the project, the number of authors, and the number of core\ndevelopers. Comparing control with the entire dataset with a filtered model\nprojects having ten or more authors we find that while certain characteristics\nof the repository consistently predict popularity, the filtering process\nsignificantly alters the relation ships between these characteristics and the\nresponse. The number of commits exhibited a positive correlation with\npopularity in the control sample but showed a negative correlation in the\nfiltered sample. These findings highlight the potential biases introduced by\ndata filtering and emphasize the need for careful sample selection in empirical\nresearch of mining software repositories. We recommend that empirical work\nshould either analyze complete datasets such as World of Code, or employ\nstratified random sampling from a complete dataset to ensure that filtering is\nnot biasing the results.", "field": "Computer Science", "categories": "cs.SE"}, {"arxiv_id": "2401.10139", "title": "Model Compression Techniques in Biometrics Applications: A Survey", "abstract": "The development of deep learning algorithms has extensively empowered\nhumanity's task automatization capacity. However, the huge improvement in the\nperformance of these models is highly correlated with their increasing level of\ncomplexity, limiting their usefulness in human-oriented applications, which are\nusually deployed in resource-constrained devices. This led to the development\nof compression techniques that drastically reduce the computational and memory\ncosts of deep learning models without significant performance degradation. This\npaper aims to systematize the current literature on this topic by presenting a\ncomprehensive survey of model compression techniques in biometrics\napplications, namely quantization, knowledge distillation and pruning. We\nconduct a critical analysis of the comparative value of these techniques,\nfocusing on their advantages and disadvantages and presenting suggestions for\nfuture work directions that can potentially improve the current methods.\nAdditionally, we discuss and analyze the link between model bias and model\ncompression, highlighting the need to direct compression research toward model\nfairness in future works.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.10141", "title": "Optimally truncated WKB approximation for the 1D stationary\n  Schr\u00f6dinger equation in the highly oscillatory regime", "abstract": "This paper is dedicated to the efficient numerical computation of solutions\nto the 1D stationary Schr\\\"odinger equation in the highly oscillatory regime.\nWe compute an approximate solution based on the well-known WKB-ansatz, which\nrelies on an asymptotic expansion w.r.t. the small parameter $\\varepsilon$.\nAssuming that the coefficient in the equation is analytic, we derive an\nexplicit error estimate for the truncated WKB series, in terms of $\\varepsilon$\nand the truncation order $N$. For any fixed $\\varepsilon$, this allows to\ndetermine the optimal truncation order $N_{opt}$ which turns out to be\nproportional to $\\varepsilon^{-1}$. When chosen this way, the resulting error\nof the optimally truncated WKB series behaves like\n$\\mathcal{O}(\\varepsilon^{-2}\\exp(-r/\\varepsilon))$, with some parameter $r>0$.\nThe theoretical results established in this paper are confirmed by several\nnumerical examples.", "field": "Computer Science", "categories": "math.NA,cs.NA,34E20, 81Q20, 65L11, 65M70"}, {"arxiv_id": "2401.10148", "title": "Explicitly Disentangled Representations in Object-Centric Learning", "abstract": "Extracting structured representations from raw visual data is an important\nand long-standing challenge in machine learning. Recently, techniques for\nunsupervised learning of object-centric representations have raised growing\ninterest. In this context, enhancing the robustness of the latent features can\nimprove the efficiency and effectiveness of the training of downstream tasks. A\npromising step in this direction is to disentangle the factors that cause\nvariation in the data. Previously, Invariant Slot Attention disentangled\nposition, scale, and orientation from the remaining features. Extending this\napproach, we focus on separating the shape and texture components. In\nparticular, we propose a novel architecture that biases object-centric models\ntoward disentangling shape and texture components into two non-overlapping\nsubsets of the latent space dimensions. These subsets are known a priori, hence\nbefore the training process. Experiments on a range of object-centric\nbenchmarks reveal that our approach achieves the desired disentanglement while\nalso numerically improving baseline performance in most cases. In addition, we\nshow that our method can generate novel textures for a specific object or\ntransfer textures between objects with distinct shapes.", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.LG"}, {"arxiv_id": "2401.10149", "title": "Multi-Agent Reinforcement Learning for Maritime Operational Technology\n  Cyber Security", "abstract": "This paper demonstrates the potential for autonomous cyber defence to be\napplied on industrial control systems and provides a baseline environment to\nfurther explore Multi-Agent Reinforcement Learning's (MARL) application to this\nproblem domain. It introduces a simulation environment, IPMSRL, of a generic\nIntegrated Platform Management System (IPMS) and explores the use of MARL for\nautonomous cyber defence decision-making on generic maritime based IPMS\nOperational Technology (OT). OT cyber defensive actions are less mature than\nthey are for Enterprise IT. This is due to the relatively brittle nature of OT\ninfrastructure originating from the use of legacy systems, design-time\nengineering assumptions, and lack of full-scale modern security controls. There\nare many obstacles to be tackled across the cyber landscape due to continually\nincreasing cyber-attack sophistication and the limitations of traditional\nIT-centric cyber defence solutions. Traditional IT controls are rarely deployed\non OT infrastructure, and where they are, some threats aren't fully addressed.\nIn our experiments, a shared critic implementation of Multi Agent Proximal\nPolicy Optimisation (MAPPO) outperformed Independent Proximal Policy\nOptimisation (IPPO). MAPPO reached an optimal policy (episode outcome mean of\n1) after 800K timesteps, whereas IPPO was only able to reach an episode outcome\nmean of 0.966 after one million timesteps. Hyperparameter tuning greatly\nimproved training performance. Across one million timesteps the tuned\nhyperparameters reached an optimal policy whereas the default hyperparameters\nonly managed to win sporadically, with most simulations resulting in a draw. We\ntested a real-world constraint, attack detection alert success, and found that\nwhen alert success probability is reduced to 0.75 or 0.9, the MARL defenders\nwere still able to win in over 97.5% or 99.5% of episodes, respectively.", "field": "Computer Science", "categories": "cs.LG,cs.CR,cs.MA"}, {"arxiv_id": "2401.1015", "title": "Motion-Zero: Zero-Shot Moving Object Control Framework for\n  Diffusion-Based Video Generation", "abstract": "Recent large-scale pre-trained diffusion models have demonstrated a powerful\ngenerative ability to produce high-quality videos from detailed text\ndescriptions. However, exerting control over the motion of objects in videos\ngenerated by any video diffusion model is a challenging problem. In this paper,\nwe propose a novel zero-shot moving object trajectory control framework,\nMotion-Zero, to enable a bounding-box-trajectories-controlled text-to-video\ndiffusion model.To this end, an initial noise prior module is designed to\nprovide a position-based prior to improve the stability of the appearance of\nthe moving object and the accuracy of position. In addition, based on the\nattention map of the U-net, spatial constraints are directly applied to the\ndenoising process of diffusion models, which further ensures the positional and\nspatial consistency of moving objects during the inference. Furthermore,\ntemporal consistency is guaranteed with a proposed shift temporal attention\nmechanism. Our method can be flexibly applied to various state-of-the-art video\ndiffusion models without any training process. Extensive experiments\ndemonstrate our proposed method can control the motion trajectories of objects\nand generate high-quality videos.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10153", "title": "Importance-Aware Image Segmentation-based Semantic Communication for\n  Autonomous Driving", "abstract": "This article studies the problem of image segmentation-based semantic\ncommunication in autonomous driving. In real traffic scenes, detecting the key\nobjects (e.g., vehicles, pedestrians and obstacles) is more crucial than that\nof other objects to guarantee driving safety. Therefore, we propose a vehicular\nimage segmentation-oriented semantic communication system, termed VIS-SemCom,\nwhere image segmentation features of important objects are transmitted to\nreduce transmission redundancy. First, to accurately extract image semantics,\nwe develop a semantic codec based on Swin Transformer architecture, which\nexpands the perceptual field thus improving the segmentation accuracy. Next, we\npropose a multi-scale semantic extraction scheme via assigning the number of\nSwin Transformer blocks for diverse resolution features, thus highlighting the\nimportant objects' accuracy. Furthermore, the importance-aware loss is invoked\nto emphasize the important objects, and an online hard sample mining (OHEM)\nstrategy is proposed to handle small sample issues in the dataset. Experimental\nresults demonstrate that the proposed VIS-SemCom can achieve a coding gain of\nnearly 6 dB with a 60% mean intersection over union (mIoU), reduce the\ntransmitted data amount by up to 70% with a 60% mIoU, and improve the\nsegmentation intersection over union (IoU) of important objects by 4%, compared\nto traditional transmission scheme.", "field": "Computer Science", "categories": "cs.NI,cs.CV"}, {"arxiv_id": "2401.10155", "title": "A novel hybrid time-varying graph neural network for traffic flow\n  forecasting", "abstract": "Real-time and accurate traffic flow prediction is the foundation for ensuring\nthe efficient operation of intelligent transportation systems.In existing\ntraffic flow prediction methods based on graph neural networks (GNNs),\npre-defined graphs were usually used to describe the spatial correlations of\ndifferent traffic nodes in urban road networks. However, the ability of\npre-defined graphs used to describe spatial correlation was limited by prior\nknowledge and graph generation methods. Although time-varying graphs based on\ndata-driven learning can partially overcome the drawbacks of pre-defined\ngraphs, the learning ability of existing adaptive graphs was limited. For\nexample, time-varying graphs cannot adequately capture the inherent spatial\ncorrelations in traffic flow data.In order to solve these problems, we have\nproposed a hybrid time-varying graph neural network (HTVGNN) for traffic flow\nprediction.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.10156", "title": "Model-Assisted Learning for Adaptive Cooperative Perception of Connected\n  Autonomous Vehicles", "abstract": "Cooperative perception (CP) is a key technology to facilitate consistent and\naccurate situational awareness for connected and autonomous vehicles (CAVs). To\ntackle the network resource inefficiency issue in traditional broadcast-based\nCP, unicast-based CP has been proposed to associate CAV pairs for cooperative\nperception via vehicle-to-vehicle transmission. In this paper, we investigate\nunicast-based CP among CAV pairs. With the consideration of dynamic perception\nworkloads and channel conditions due to vehicle mobility and dynamic radio\nresource availability, we propose an adaptive cooperative perception scheme for\nCAV pairs in a mixed-traffic autonomous driving scenario with both CAVs and\nhuman-driven vehicles. We aim to determine when to switch between cooperative\nperception and stand-alone perception for each CAV pair, and allocate\ncommunication and computing resources to cooperative CAV pairs for maximizing\nthe computing efficiency gain under perception task delay requirements. A\nmodel-assisted multi-agent reinforcement learning (MARL) solution is developed,\nwhich integrates MARL for an adaptive CAV cooperation decision and an\noptimization model for communication and computing resource allocation.\nSimulation results demonstrate the effectiveness of the proposed scheme in\nachieving high computing efficiency gain, as compared with benchmark schemes.", "field": "Computer Science", "categories": "cs.NI,eess.SP"}, {"arxiv_id": "2401.10158", "title": "DISTINQT: A Distributed Privacy Aware Learning Framework for QoS\n  Prediction for Future Mobile and Wireless Networks", "abstract": "Beyond 5G and 6G networks are expected to support new and challenging use\ncases and applications that depend on a certain level of Quality of Service\n(QoS) to operate smoothly. Predicting the QoS in a timely manner is of high\nimportance, especially for safety-critical applications as in the case of\nvehicular communications. Although until recent years the QoS prediction has\nbeen carried out by centralized Artificial Intelligence (AI) solutions, a\nnumber of privacy, computational, and operational concerns have emerged.\nAlternative solutions have been surfaced (e.g. Split Learning, Federated\nLearning), distributing AI tasks of reduced complexity across nodes, while\npreserving the privacy of the data. However, new challenges rise when it comes\nto scalable distributed learning approaches, taking into account the\nheterogeneous nature of future wireless networks. The current work proposes\nDISTINQT, a privacy-aware distributed learning framework for QoS prediction.\nOur framework supports multiple heterogeneous nodes, in terms of data types and\nmodel architectures, by sharing computations across them. This, enables the\nincorporation of diverse knowledge into a sole learning process that will\nenhance the robustness and generalization capabilities of the final QoS\nprediction model. DISTINQT also contributes to data privacy preservation by\nencoding any raw input data into a non-linear latent representation before any\ntransmission. Evaluation results showcase that our framework achieves a\nstatistically identical performance compared to its centralized version and an\naverage performance improvement of up to 65% against six state-of-the-art\ncentralized baseline solutions in the Tele-Operated Driving use case.", "field": "Computer Science", "categories": "cs.NI,cs.AI,cs.CR,cs.DC,cs.LG"}, {"arxiv_id": "2401.10166", "title": "VMamba: Visual State Space Model", "abstract": "Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) stand as\nthe two most popular foundation models for visual representation learning.\nWhile CNNs exhibit remarkable scalability with linear complexity w.r.t. image\nresolution, ViTs surpass them in fitting capabilities despite contending with\nquadratic complexity. A closer inspection reveals that ViTs achieve superior\nvisual modeling performance through the incorporation of global receptive\nfields and dynamic weights. This observation motivates us to propose a novel\narchitecture that inherits these components while enhancing computational\nefficiency. To this end, we draw inspiration from the recently introduced state\nspace model and propose the Visual State Space Model (VMamba), which achieves\nlinear complexity without sacrificing global receptive fields. To address the\nencountered direction-sensitive issue, we introduce the Cross-Scan Module (CSM)\nto traverse the spatial domain and convert any non-causal visual image into\norder patch sequences. Extensive experimental results substantiate that VMamba\nnot only demonstrates promising capabilities across various visual perception\ntasks, but also exhibits more pronounced advantages over established benchmarks\nas the image resolution increases. Source code has been available at\nhttps://github.com/MzeroMiko/VMamba.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10171", "title": "SHINOBI: Shape and Illumination using Neural Object Decomposition via\n  BRDF Optimization In-the-wild", "abstract": "We present SHINOBI, an end-to-end framework for the reconstruction of shape,\nmaterial, and illumination from object images captured with varying lighting,\npose, and background. Inverse rendering of an object based on unconstrained\nimage collections is a long-standing challenge in computer vision and graphics\nand requires a joint optimization over shape, radiance, and pose. We show that\nan implicit shape representation based on a multi-resolution hash encoding\nenables faster and robust shape reconstruction with joint camera alignment\noptimization that outperforms prior work. Further, to enable the editing of\nillumination and object reflectance (i.e. material) we jointly optimize BRDF\nand illumination together with the object's shape. Our method is class-agnostic\nand works on in-the-wild image collections of objects to produce relightable 3D\nassets for several use cases such as AR/VR, movies, games, etc. Project page:\nhttps://shinobi.aengelhardt.com Video:\nhttps://www.youtube.com/watch?v=iFENQ6AcYd8&feature=youtu.be", "field": "Computer Science", "categories": "cs.CV,cs.GR"}, {"arxiv_id": "2401.10175", "title": "DualTake: Predicting Takeovers across Mobilities for Future Personalized\n  Mobility Services", "abstract": "A hybrid society is expected to emerge in the near future, with different\nmobilities interacting together, including cars, micro-mobilities, pedestrians,\nand robots. People may utilize multiple types of mobilities in their daily\nlives. As vehicle automation advances, driver modeling flourishes to provide\npersonalized intelligent services. Thus, modeling drivers across mobilities\nwould pave the road for future society mobility-as-a-service, and it is\nparticularly interesting to predict driver behaviors in newer mobilities with\ntraditional mobility data. In this work, we present takeover prediction on a\nmicro-mobility, with car simulation data.The promising model performance\ndemonstrates the feasibility of driver modeling across mobilities, as the first\nin the field.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.10176", "title": "Comprehensive OOD Detection Improvements", "abstract": "As machine learning becomes increasingly prevalent in impactful decisions,\nrecognizing when inference data is outside the model's expected input\ndistribution is paramount for giving context to predictions.\nOut-of-distribution (OOD) detection methods have been created for this task.\nSuch methods can be split into representation-based or logit-based methods from\nwhether they respectively utilize the model's embeddings or predictions for OOD\ndetection. In contrast to most papers which solely focus on one such group, we\naddress both. We employ dimensionality reduction on feature embeddings in\nrepresentation-based methods for both time speedups and improved performance.\nAdditionally, we propose DICE-COL, a modification of the popular logit-based\nmethod Directed Sparsification (DICE) that resolves an unnoticed flaw. We\ndemonstrate the effectiveness of our methods on the OpenOODv1.5 benchmark\nframework, where they significantly improve performance and set\nstate-of-the-art results.", "field": "Computer Science", "categories": "cs.LG,cs.CV"}, {"arxiv_id": "2401.10178", "title": "Neural Echos: Depthwise Convolutional Filters Replicate Biological\n  Receptive Fields", "abstract": "In this study, we present evidence suggesting that depthwise convolutional\nkernels are effectively replicating the structural intricacies of the\nbiological receptive fields observed in the mammalian retina. We provide\nanalytics of trained kernels from various state-of-the-art models\nsubstantiating this evidence. Inspired by this intriguing discovery, we propose\nan initialization scheme that draws inspiration from the biological receptive\nfields. Experimental analysis of the ImageNet dataset with multiple CNN\narchitectures featuring depthwise convolutions reveals a marked enhancement in\nthe accuracy of the learned model when initialized with biologically derived\nweights. This underlies the potential for biologically inspired computational\nmodels to further our understanding of vision processing systems and to improve\nthe efficacy of convolutional networks.", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.NE"}, {"arxiv_id": "2401.10184", "title": "Comparing Traditional and LLM-based Search for Image Geolocation", "abstract": "Web search engines have long served as indispensable tools for information\nretrieval; user behavior and query formulation strategies have been well\nstudied. The introduction of search engines powered by large language models\n(LLMs) suggested more conversational search and new types of query strategies.\nIn this paper, we compare traditional and LLM-based search for the task of\nimage geolocation, i.e., determining the location where an image was captured.\nOur work examines user interactions, with a particular focus on query\nformulation strategies. In our study, 60 participants were assigned either\ntraditional or LLM-based search engines as assistants for geolocation.\nParticipants using traditional search more accurately predicted the location of\nthe image compared to those using the LLM-based search. Distinct strategies\nemerged between users depending on the type of assistant. Participants using\nthe LLM-based search issued longer, more natural language queries, but had\nshorter search sessions. When reformulating their search queries, traditional\nsearch participants tended to add more terms to their initial queries, whereas\nparticipants using the LLM-based search consistently rephrased their initial\nqueries.", "field": "Computer Science", "categories": "cs.IR,cs.HC"}, {"arxiv_id": "2401.10185", "title": "Transfer Learning in Human Activity Recognition: A Survey", "abstract": "Sensor-based human activity recognition (HAR) has been an active research\narea, owing to its applications in smart environments, assisted living,\nfitness, healthcare, etc. Recently, deep learning based end-to-end training has\nresulted in state-of-the-art performance in domains such as computer vision and\nnatural language, where large amounts of annotated data are available. However,\nlarge quantities of annotated data are not available for sensor-based HAR.\nMoreover, the real-world settings on which the HAR is performed differ in terms\nof sensor modalities, classification tasks, and target users. To address this\nproblem, transfer learning has been employed extensively. In this survey, we\nfocus on these transfer learning methods in the application domains of smart\nhome and wearables-based HAR. In particular, we provide a problem-solution\nperspective by categorizing and presenting the works in terms of their\ncontributions and the challenges they address. We also present an updated view\nof the state-of-the-art for both application domains. Based on our analysis of\n205 papers, we highlight the gaps in the literature and provide a roadmap for\naddressing them. This survey provides a reference to the HAR community, by\nsummarizing the existing works and providing a promising research agenda.", "field": "Computer Science", "categories": "cs.LG,eess.SP"}, {"arxiv_id": "2401.10186", "title": "Beyond Reference-Based Metrics: Analyzing Behaviors of Open LLMs on\n  Data-to-Text Generation", "abstract": "We investigate to which extent open large language models (LLMs) can generate\ncoherent and relevant text from structured data. To prevent bias from\nbenchmarks leaked into LLM training data, we collect Quintd-1: an ad-hoc\nbenchmark for five data-to-text (D2T) generation tasks, consisting of\nstructured data records in standard formats gathered from public APIs. We\nleverage reference-free evaluation metrics and LLMs' in-context learning\ncapabilities, allowing us to test the models with no human-written references.\nOur evaluation focuses on annotating semantic accuracy errors on token-level,\ncombining human annotators and a metric based on GPT-4. Our systematic\nexamination of the models' behavior across domains and tasks suggests that\nstate-of-the-art open LLMs with 7B parameters can generate fluent and coherent\ntext from various standard data formats in zero-shot settings. However, we also\nshow that semantic accuracy of the outputs remains a major issue: on our\nbenchmark, 80% of outputs of open LLMs contain a semantic error according to\nhuman annotators (91% according to GPT-4). Our code, data, and model outputs\nare available at https://d2t-llm.github.io.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.10187", "title": "Fast Kronecker Matrix-Matrix Multiplication on GPUs", "abstract": "Kronecker Matrix-Matrix Multiplication (Kron-Matmul) is the multiplication of\na matrix with the Kronecker Product of several smaller matrices. Kron-Matmul is\na core operation for many scientific and machine learning computations.\nState-of-the-art Kron-Matmul implementations utilize existing tensor algebra\noperations, such as matrix multiplication, transpose, and tensor matrix\nmultiplication. However, this design choice prevents several Kron-Matmul\nspecific optimizations, thus, leaving significant performance on the table. To\naddress this issue, we present FastKron, an efficient technique for Kron-Matmul\non single and multiple GPUs. FastKron is independent of linear algebra\noperations enabling several new optimizations for Kron-Matmul. Thus, it\nperforms up to 40.7x and 7.85x faster than existing implementations on 1 and 16\nGPUs respectively.", "field": "Computer Science", "categories": "cs.DC"}, {"arxiv_id": "2401.10189", "title": "Chem-FINESE: Validating Fine-Grained Few-shot Entity Extraction through\n  Text Reconstruction", "abstract": "Fine-grained few-shot entity extraction in the chemical domain faces two\nunique challenges. First, compared with entity extraction tasks in the general\ndomain, sentences from chemical papers usually contain more entities. Moreover,\nentity extraction models usually have difficulty extracting entities of\nlong-tailed types. In this paper, we propose Chem-FINESE, a novel\nsequence-to-sequence (seq2seq) based few-shot entity extraction approach, to\naddress these two challenges. Our Chem-FINESE has two components: a seq2seq\nentity extractor to extract named entities from the input sentence and a\nseq2seq self-validation module to reconstruct the original input sentence from\nextracted entities. Inspired by the fact that a good entity extraction system\nneeds to extract entities faithfully, our new self-validation module leverages\nentity extraction results to reconstruct the original input sentence. Besides,\nwe design a new contrastive loss to reduce excessive copying during the\nextraction process. Finally, we release ChemNER+, a new fine-grained chemical\nentity extraction dataset that is annotated by domain experts with the ChemNER\nschema. Experiments in few-shot settings with both ChemNER+ and CHEMET datasets\nshow that our newly proposed framework has contributed up to 8.26% and 6.84%\nabsolute F1-score gains respectively.", "field": "Computer Science", "categories": "cs.CL,cs.AI,cs.LG"}, {"arxiv_id": "2401.10191", "title": "Divide and not forget: Ensemble of selectively trained experts in\n  Continual Learning", "abstract": "Class-incremental learning is becoming more popular as it helps models widen\ntheir applicability while not forgetting what they already know. A trend in\nthis area is to use a mixture-of-expert technique, where different models work\ntogether to solve the task. However, the experts are usually trained all at\nonce using whole task data, which makes them all prone to forgetting and\nincreasing computational burden. To address this limitation, we introduce a\nnovel approach named SEED. SEED selects only one, the most optimal expert for a\nconsidered task, and uses data from this task to fine-tune only this expert.\nFor this purpose, each expert represents each class with a Gaussian\ndistribution, and the optimal expert is selected based on the similarity of\nthose distributions. Consequently, SEED increases diversity and heterogeneity\nwithin the experts while maintaining the high stability of this ensemble\nmethod. The extensive experiments demonstrate that SEED achieves\nstate-of-the-art performance in exemplar-free settings across various\nscenarios, showing the potential of expert diversification through data in\ncontinual learning.", "field": "Computer Science", "categories": "cs.LG,cs.CV"}, {"arxiv_id": "2401.10194", "title": "Impact of Flexible and Bidirectional Charging in Medium- and Heavy-Duty\n  Trucks on California's Decarbonization Pathway", "abstract": "California has committed to ambitious decarbonization targets across multiple\nsectors, including decarbonizing the electrical grid by 2045. In addition, the\nmedium- and heavy-duty truck fleets are expected to see rapid electrification\nover the next two decades. Considering these two pathways in tandem is critical\nfor ensuring cost optimality and reliable power system operation. In\nparticular, we examine the potential cost savings of electrical generation\ninfrastructure by enabling flexible charging and bidirectional charging for\nthese trucks. We also examine costs adjacent to enabling these services, such\nas charger upgrades and battery degradation. We deploy a large mixed-integer\ndecarbonization planning model to quantify the costs associated with the\nelectric generation decarbonization pathway. Example scenarios governing truck\ndriving and charging behaviors are implemented to reveal the sensitivity of\ntemporal driving patterns. Our experiments show that cost savings on the order\nof multiple billions of dollars are possible by enabling flexible and\nbidirectional charging in medium- and heavy-duty trucks in California.", "field": "Computer Science", "categories": "eess.SY,cs.SY"}, {"arxiv_id": "2401.10204", "title": "Maximal-Capacity Discrete Memoryless Channel Identification", "abstract": "The problem of identifying the channel with the highest capacity among\nseveral discrete memoryless channels (DMCs) is considered. The problem is cast\nas a pure-exploration multi-armed bandit problem, which follows the practical\nuse of training sequences to sense the communication channel statistics. A\ncapacity estimator is proposed and tight confidence bounds on the estimator\nerror are derived. Based on this capacity estimator, a gap-elimination\nalgorithm termed BestChanID is proposed, which is oblivious to the\ncapacity-achieving input distribution and is guaranteed to output the DMC with\nthe largest capacity, with a desired confidence. Furthermore, two additional\nalgorithms NaiveChanSel and MedianChanEl, that output with certain confidence a\nDMC with capacity close to the maximal, are introduced. Each of those\nalgorithms is beneficial in a different regime and can be used as a subroutine\nin BestChanID. The sample complexity of all algorithms is analyzed as a\nfunction of the desired confidence parameter, the number of channels, and the\nchannels' input and output alphabet sizes. The cost of best channel\nidentification is shown to scale quadratically with the alphabet size, and a\nfundamental lower bound for the required number of channel senses to identify\nthe best channel with a certain confidence is derived.", "field": "Computer Science", "categories": "cs.IT,math.IT,stat.ML"}, {"arxiv_id": "2401.10205", "title": "Effective Communication of Scientific Results", "abstract": "Communication is essential for the advancement of Science. Technology\nadvances and the proliferation of personal devices have changed the ways in\nwhich people communicate in all aspects of life. Scientific communication has\nalso been profoundly affected by such changes, and thus it is important to\nreflect on effective ways to communicate scientific results to scientists that\nare flooded with information. This article advocates for receiver-oriented\ncommunication in Science, discusses how effective oral presentations should be\nprepared and delivered, provides advice on the thought process that can lead to\nscientific papers that communicate effectively, discusses suitable methodology\nto produce experimental data that is relevant and offers advice on how to\npresent such data in ways that lead to the formulation of correct claims that\nare supported by the data.", "field": "Computer Science", "categories": "cs.DL"}, {"arxiv_id": "2401.10207", "title": "Eclectic Rule Extraction for Explainability of Deep Neural Network based\n  Intrusion Detection Systems", "abstract": "This paper addresses trust issues created from the ubiquity of black box\nalgorithms and surrogate explainers in Explainable Intrusion Detection Systems\n(X-IDS). While Explainable Artificial Intelligence (XAI) aims to enhance\ntransparency, black box surrogate explainers, such as Local Interpretable\nModel-Agnostic Explanation (LIME) and SHapley Additive exPlanation (SHAP), are\ndifficult to trust. The black box nature of these surrogate explainers makes\nthe process behind explanation generation opaque and difficult to understand.\nTo avoid this problem, one can use transparent white box algorithms such as\nRule Extraction (RE). There are three types of RE algorithms: pedagogical,\ndecompositional, and eclectic. Pedagogical methods offer fast but untrustworthy\nwhite-box explanations, while decompositional RE provides trustworthy\nexplanations with poor scalability. This work explores eclectic rule\nextraction, which strikes a balance between scalability and trustworthiness. By\ncombining techniques from pedagogical and decompositional approaches, eclectic\nrule extraction leverages the advantages of both, while mitigating some of\ntheir drawbacks. The proposed Hybrid X-IDS architecture features eclectic RE as\na white box surrogate explainer for black box Deep Neural Networks (DNN). The\npresented eclectic RE algorithm extracts human-readable rules from hidden\nlayers, facilitating explainable and trustworthy rulesets. Evaluations on\nUNSW-NB15 and CIC-IDS-2017 datasets demonstrate the algorithm's ability to\ngenerate rulesets with 99.9% accuracy, mimicking DNN outputs. The contributions\nof this work include the hybrid X-IDS architecture, the eclectic rule\nextraction algorithm applicable to intrusion detection datasets, and a thorough\nanalysis of performance and explainability, demonstrating the trade-offs\ninvolved in rule extraction speed and accuracy.", "field": "Computer Science", "categories": "cs.CR,cs.AI,cs.LG"}, {"arxiv_id": "2401.10208", "title": "MM-Interleaved: Interleaved Image-Text Generative Modeling via\n  Multi-modal Feature Synchronizer", "abstract": "Developing generative models for interleaved image-text data has both\nresearch and practical value. It requires models to understand the interleaved\nsequences and subsequently generate images and text. However, existing attempts\nare limited by the issue that the fixed number of visual tokens cannot\nefficiently capture image details, which is particularly problematic in the\nmulti-image scenarios. To address this, this paper presents MM-Interleaved, an\nend-to-end generative model for interleaved image-text data. It introduces a\nmulti-scale and multi-image feature synchronizer module, allowing direct access\nto fine-grained image features in the previous context during the generation\nprocess. MM-Interleaved is end-to-end pre-trained on both paired and\ninterleaved image-text corpora. It is further enhanced through a supervised\nfine-tuning phase, wherein the model improves its ability to follow complex\nmulti-modal instructions. Experiments demonstrate the versatility of\nMM-Interleaved in recognizing visual details following multi-modal instructions\nand generating consistent images following both textual and visual conditions.\nCode and models are available at\n\\url{https://github.com/OpenGVLab/MM-Interleaved}.", "field": "Computer Science", "categories": "cs.CV,cs.CL"}, {"arxiv_id": "2401.10209", "title": "Synchronization and Control of Chaotic Spur Gear System Using Type-II\n  Fuzzy Controller Optimized via Whale Optimization Algorithm", "abstract": "Interval type-II Fuzzy Inference System (FIS) assumes a crucial role in\ndetermining the coefficients of the PID controller, thereby augmenting the\ncontroller's flexibility. Controlling chaotic systems presents inherent\nchallenges and difficulties due to their sensitivity to initial conditions and\nthe intricate dynamics that require precise and adaptive control strategies.\nThis paper offers an exhaustive exploration into the coordination and\nregulation of a chaotic spur gear system, employing a Type-II Fuzzy Controller.\nThe initial control parameters of the PID controller undergo optimization using\nthe Whale Optimization Algorithm (WOA) to increase the overall system\nperformance. The adaptability and strength of the suggested control system are\ntested in various scenarios, covering diverse reference inputs and\nuncertainties. The investigation comprehensively assesses the operational\nefficacy of the formulated controller, contrasting its performance with other\nmethodologies. The outcomes highlight the impressive efficiency of the\nsuggested strategy, confirming its supremacy in attaining synchronization and\ncontrol within the turbulent spur gear system under demanding circumstances", "field": "Computer Science", "categories": "eess.SY,cs.SY"}, {"arxiv_id": "2401.1021", "title": "Mastery Guided Non-parametric Clustering to Scale-up Strategy Prediction", "abstract": "Predicting the strategy (sequence of concepts) that a student is likely to\nuse in problem-solving helps Adaptive Instructional Systems (AISs) better adapt\nthemselves to different types of learners based on their learning abilities.\nThis can lead to a more dynamic, engaging, and personalized experience for\nstudents. To scale up training a prediction model (such as LSTMs) over\nlarge-scale education datasets, we develop a non-parametric approach to cluster\nsymmetric instances in the data. Specifically, we learn a representation based\non Node2Vec that encodes symmetries over mastery or skill level since, to solve\na problem, it is natural that a student's strategy is likely to involve\nconcepts in which they have gained mastery. Using this representation, we use\nDP-Means to group symmetric instances through a coarse-to-fine refinement of\nthe clusters. We apply our model to learn strategies for Math learning from\nlarge-scale datasets from MATHia, a leading AIS for middle-school math\nlearning. Our results illustrate that our approach can consistently achieve\nhigh accuracy using a small sample that is representative of the full dataset.\nFurther, we show that this approach helps us learn strategies with high\naccuracy for students at different skill levels, i.e., leveraging symmetries\nimproves fairness in the prediction model.", "field": "Computer Science", "categories": "cs.CY,cs.AI,cs.LG"}, {"arxiv_id": "2401.10213", "title": "Improving automatic detection of driver fatigue and distraction using\n  machine learning", "abstract": "Changes and advances in information technology have played an important role\nin the development of intelligent vehicle systems in recent years. Driver\nfatigue and distracted driving are important factors in traffic accidents.\nThus, onboard monitoring of driving behavior has become a crucial component of\nadvanced driver assistance systems for intelligent vehicles. In this article,\nwe present techniques for simultaneously detecting fatigue and distracted\ndriving behaviors using vision-based and machine learning-based approaches. In\ndriving fatigue detection, we use facial alignment networks to identify facial\nfeature points in the images, and calculate the distance of the facial feature\npoints to detect the opening and closing of the eyes and mouth. Furthermore, we\nuse a convolutional neural network (CNN) based on the MobileNet architecture to\nidentify various distracted driving behaviors. Experiments are performed on a\nPC based setup with a webcam and results are demonstrated using public datasets\nas well as custom datasets created for training and testing. Compared to\nprevious approaches, we build our own datasets and provide better results in\nterms of accuracy and computation time.", "field": "Computer Science", "categories": "cs.CV,cs.CY,cs.LG"}, {"arxiv_id": "2401.10214", "title": "Tailoring Semantic Communication at Network Edge: A Novel Approach Using\n  Dynamic Knowledge Distillation", "abstract": "Semantic Communication (SemCom) systems, empowered by deep learning (DL),\nrepresent a paradigm shift in data transmission. These systems prioritize the\nsignificance of content over sheer data volume. However, existing SemCom\ndesigns face challenges when applied to diverse computational capabilities and\nnetwork conditions, particularly in time-sensitive applications. A key\nchallenge is the assumption that diverse devices can uniformly benefit from a\nstandard, large DL model in SemCom systems. This assumption becomes\nincreasingly impractical, especially in high-speed, high-reliability\napplications such as industrial automation or critical healthcare. Therefore,\nthis paper introduces a novel SemCom framework tailored for heterogeneous,\nresource-constrained edge devices and computation-intensive servers. Our\napproach employs dynamic knowledge distillation (KD) to customize semantic\nmodels for each device, balancing computational and communication constraints\nwhile ensuring Quality of Service (QoS). We formulate an optimization problem\nand develop an adaptive algorithm that iteratively refines semantic knowledge\non edge devices, resulting in better models tailored to their resource\nprofiles. This algorithm strategically adjusts the granularity of distilled\nknowledge, enabling devices to maintain high semantic accuracy for precise\ninference tasks, even under unstable network conditions. Extensive simulations\ndemonstrate that our approach significantly reduces model complexity for edge\ndevices, leading to better semantic extraction and achieving the desired QoS.", "field": "Computer Science", "categories": "cs.NI"}, {"arxiv_id": "2401.10215", "title": "GPAvatar: Generalizable and Precise Head Avatar from Image(s)", "abstract": "Head avatar reconstruction, crucial for applications in virtual reality,\nonline meetings, gaming, and film industries, has garnered substantial\nattention within the computer vision community. The fundamental objective of\nthis field is to faithfully recreate the head avatar and precisely control\nexpressions and postures. Existing methods, categorized into 2D-based warping,\nmesh-based, and neural rendering approaches, present challenges in maintaining\nmulti-view consistency, incorporating non-facial information, and generalizing\nto new identities. In this paper, we propose a framework named GPAvatar that\nreconstructs 3D head avatars from one or several images in a single forward\npass. The key idea of this work is to introduce a dynamic point-based\nexpression field driven by a point cloud to precisely and effectively capture\nexpressions. Furthermore, we use a Multi Tri-planes Attention (MTA) fusion\nmodule in the tri-planes canonical field to leverage information from multiple\ninput images. The proposed method achieves faithful identity reconstruction,\nprecise expression control, and multi-view consistency, demonstrating promising\nresults for free-viewpoint rendering and novel view synthesis.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10216", "title": "Enabling Efficient Equivariant Operations in the Fourier Basis via Gaunt\n  Tensor Products", "abstract": "Developing equivariant neural networks for the E(3) group plays an important\nrole in modeling 3D data across real-world applications. Enforcing this\nequivariance primarily involves the tensor products of irreducible\nrepresentations (irreps). However, the computational complexity of such\noperations increases significantly as higher-order tensors are used. In this\nwork, we propose a systematic approach to substantially accelerate the\ncomputation of the tensor products of irreps. We mathematically connect the\ncommonly used Clebsch-Gordan coefficients to the Gaunt coefficients, which are\nintegrals of products of three spherical harmonics. Through Gaunt coefficients,\nthe tensor product of irreps becomes equivalent to the multiplication between\nspherical functions represented by spherical harmonics. This perspective\nfurther allows us to change the basis for the equivariant operations from\nspherical harmonics to a 2D Fourier basis. Consequently, the multiplication\nbetween spherical functions represented by a 2D Fourier basis can be\nefficiently computed via the convolution theorem and Fast Fourier Transforms.\nThis transformation reduces the complexity of full tensor products of irreps\nfrom $\\mathcal{O}(L^6)$ to $\\mathcal{O}(L^3)$, where $L$ is the max degree of\nirreps. Leveraging this approach, we introduce the Gaunt Tensor Product, which\nserves as a new method to construct efficient equivariant operations across\ndifferent model architectures. Our experiments on the Open Catalyst Project and\n3BPA datasets demonstrate both the increased efficiency and improved\nperformance of our approach.", "field": "Computer Science", "categories": "cs.LG,cond-mat.mtrl-sci,math.GR,physics.chem-ph,q-bio.BM"}, {"arxiv_id": "2401.10217", "title": "Explaining the Implicit Neural Canvas: Connecting Pixels to Neurons by\n  Tracing their Contributions", "abstract": "The many variations of Implicit Neural Representations (INRs), where a neural\nnetwork is trained as a continuous representation of a signal, have tremendous\npractical utility for downstream tasks including novel view synthesis, video\ncompression, and image superresolution. Unfortunately, the inner workings of\nthese networks are seriously under-studied. Our work, eXplaining the Implicit\nNeural Canvas (XINC), is a unified framework for explaining properties of INRs\nby examining the strength of each neuron's contribution to each output pixel.\nWe call the aggregate of these contribution maps the Implicit Neural Canvas and\nwe use this concept to demonstrate that the INRs which we study learn to\n''see'' the frames they represent in surprising ways. For example, INRs tend to\nhave highly distributed representations. While lacking high-level object\nsemantics, they have a significant bias for color and edges, and are almost\nentirely space-agnostic. We arrive at our conclusions by examining how objects\nare represented across time in video INRs, using clustering to visualize\nsimilar neurons across layers and architectures, and show that this is\ndominated by motion. These insights demonstrate the general usefulness of our\nanalysis framework. Our project page is available at\nhttps://namithap10.github.io/xinc.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10219", "title": "Edit One for All: Interactive Batch Image Editing", "abstract": "In recent years, image editing has advanced remarkably. With increased human\ncontrol, it is now possible to edit an image in a plethora of ways; from\nspecifying in text what we want to change, to straight up dragging the contents\nof the image in an interactive point-based manner. However, most of the focus\nhas remained on editing single images at a time. Whether and how we can\nsimultaneously edit large batches of images has remained understudied. With the\ngoal of minimizing human supervision in the editing process, this paper\npresents a novel method for interactive batch image editing using StyleGAN as\nthe medium. Given an edit specified by users in an example image (e.g., make\nthe face frontal), our method can automatically transfer that edit to other\ntest images, so that regardless of their initial state (pose), they all arrive\nat the same final state (e.g., all facing front). Extensive experiments\ndemonstrate that edits performed using our method have similar visual quality\nto existing single-image-editing methods, while having more visual consistency\nand saving significant time and human effort.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.1022", "title": "AutoFT: Robust Fine-Tuning by Optimizing Hyperparameters on OOD Data", "abstract": "Foundation models encode rich representations that can be adapted to a\ndesired task by fine-tuning on task-specific data. However, fine-tuning a model\non one particular data distribution often compromises the model's original\nperformance on other distributions. Current methods for robust fine-tuning\nutilize hand-crafted regularization techniques to constrain the fine-tuning\nprocess towards the base foundation model. Yet, it is hard to precisely specify\nwhat characteristics of the foundation model to retain during fine-tuning, as\nthis depends on how the pre-training, fine-tuning, and evaluation data\ndistributions relate to each other. We propose AutoFT, a data-driven approach\nfor guiding foundation model fine-tuning. AutoFT optimizes fine-tuning\nhyperparameters to maximize performance on a small out-of-distribution (OOD)\nvalidation set. To guide fine-tuning in a granular way, AutoFT searches a\nhighly expressive hyperparameter space that includes weight coefficients for\nmany different losses, in addition to learning rate and weight decay values. We\nevaluate AutoFT on nine natural distribution shifts which include domain shifts\nand subpopulation shifts. Our experiments show that AutoFT significantly\nimproves generalization to new OOD data, outperforming existing robust\nfine-tuning methods. Notably, AutoFT achieves new state-of-the-art performance\non the WILDS-iWildCam and WILDS-FMoW benchmarks, outperforming the previous\nbest methods by $6.0\\%$ and $1.5\\%$, respectively.", "field": "Computer Science", "categories": "cs.CV,cs.LG"}, {"arxiv_id": "2401.10222", "title": "Supervised Fine-tuning in turn Improves Visual Foundation Models", "abstract": "Image-text training like CLIP has dominated the pretraining of vision\nfoundation models in recent years. Subsequent efforts have been made to\nintroduce region-level visual learning into CLIP's pretraining but face\nscalability challenges due to the lack of large-scale region-level datasets.\nDrawing inspiration from supervised fine-tuning (SFT) in natural language\nprocessing such as instruction tuning, we explore the potential of fine-grained\nSFT in enhancing the generation of vision foundation models after their\npretraining. Thus a two-stage method ViSFT (Vision SFT) is proposed to unleash\nthe fine-grained knowledge of vision foundation models. In ViSFT, the vision\nfoundation model is enhanced by performing visual joint learning on some\nin-domain tasks and then tested on out-of-domain benchmarks. With updating\nusing ViSFT on 8 V100 GPUs in less than 2 days, a vision transformer with over\n4.4B parameters shows improvements across various out-of-domain benchmarks\nincluding vision and vision-linguistic scenarios.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.10224", "title": "The Manga Whisperer: Automatically Generating Transcriptions for Comics", "abstract": "In the past few decades, Japanese comics, commonly referred to as Manga, have\ntranscended both cultural and linguistic boundaries to become a true worldwide\nsensation. Yet, the inherent reliance on visual cues and illustration within\nmanga renders it largely inaccessible to individuals with visual impairments.\nIn this work, we seek to address this substantial barrier, with the aim of\nensuring that manga can be appreciated and actively engaged by everyone.\nSpecifically, we tackle the problem of diarisation i.e. generating a\ntranscription of who said what and when, in a fully automatic way.\n  To this end, we make the following contributions: (1) we present a unified\nmodel, Magi, that is able to (a) detect panels, text boxes and character boxes,\n(b) cluster characters by identity (without knowing the number of clusters\napriori), and (c) associate dialogues to their speakers; (2) we propose a novel\napproach that is able to sort the detected text boxes in their reading order\nand generate a dialogue transcript; (3) we annotate an evaluation benchmark for\nthis task using publicly available [English] manga pages. The code, evaluation\ndatasets and the pre-trained model can be found at:\nhttps://github.com/ragavsachdeva/magi.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10225", "title": "ChatQA: Building GPT-4 Level Conversational QA Models", "abstract": "In this work, we introduce ChatQA, a family of conversational question\nanswering (QA) models, that obtain GPT-4 level accuracies. Specifically, we\npropose a two-stage instruction tuning method that can significantly improve\nthe zero-shot conversational QA results from large language models (LLMs). To\nhandle retrieval in conversational QA, we fine-tune a dense retriever on a\nmulti-turn QA dataset, which provides comparable results to using the\nstate-of-the-art query rewriting model while largely reducing deployment cost.\nNotably, our ChatQA-70B can outperform GPT-4 in terms of average score on 10\nconversational QA datasets (54.14 vs. 53.90), without relying on any synthetic\ndata from OpenAI GPT models.", "field": "Computer Science", "categories": "cs.CL,cs.AI,cs.IR,cs.LG"}, {"arxiv_id": "2401.10226", "title": "Towards Language-Driven Video Inpainting via Multimodal Large Language\n  Models", "abstract": "We introduce a new task -- language-driven video inpainting, which uses\nnatural language instructions to guide the inpainting process. This approach\novercomes the limitations of traditional video inpainting methods that depend\non manually labeled binary masks, a process often tedious and labor-intensive.\nWe present the Remove Objects from Videos by Instructions (ROVI) dataset,\ncontaining 5,650 videos and 9,091 inpainting results, to support training and\nevaluation for this task. We also propose a novel diffusion-based\nlanguage-driven video inpainting framework, the first end-to-end baseline for\nthis task, integrating Multimodal Large Language Models to understand and\nexecute complex language-based inpainting requests effectively. Our\ncomprehensive results showcase the dataset's versatility and the model's\neffectiveness in various language-instructed inpainting scenarios. We will make\ndatasets, code, and models publicly available.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10227", "title": "A Simple Latent Diffusion Approach for Panoptic Segmentation and Mask\n  Inpainting", "abstract": "Panoptic and instance segmentation networks are often trained with\nspecialized object detection modules, complex loss functions, and ad-hoc\npost-processing steps to handle the permutation-invariance of the instance\nmasks. This work builds upon Stable Diffusion and proposes a latent diffusion\napproach for panoptic segmentation, resulting in a simple architecture which\nomits these complexities. Our training process consists of two steps: (1)\ntraining a shallow autoencoder to project the segmentation masks to latent\nspace; (2) training a diffusion model to allow image-conditioned sampling in\nlatent space. The use of a generative model unlocks the exploration of mask\ncompletion or inpainting, which has applications in interactive segmentation.\nThe experimental validation yields promising results for both panoptic\nsegmentation and mask inpainting. While not setting a new state-of-the-art, our\nmodel's simplicity, generality, and mask completion capability are desirable\nproperties.", "field": "Computer Science", "categories": "cs.CV,cs.LG"}, {"arxiv_id": "2401.10228", "title": "RAP-SAM: Towards Real-Time All-Purpose Segment Anything", "abstract": "Advanced by transformer architecture, vision foundation models (VFMs) achieve\nremarkable progress in performance and generalization ability. Segment Anything\nModel (SAM) is one remarkable model that can achieve generalized segmentation.\nHowever, most VFMs cannot run in realtime, which makes it difficult to transfer\nthem into several products. On the other hand, current real-time segmentation\nmainly has one purpose, such as semantic segmentation on the driving scene. We\nargue that diverse outputs are needed for real applications. Thus, this work\nexplores a new real-time segmentation setting, named all-purpose segmentation\nin real-time, to transfer VFMs in real-time deployment. It contains three\ndifferent tasks, including interactive segmentation, panoptic segmentation, and\nvideo segmentation. We aim to use one model to achieve the above tasks in\nreal-time. We first benchmark several strong baselines. Then, we present\nReal-Time All Purpose SAM (RAP-SAM). It contains an efficient encoder and an\nefficient decoupled decoder to perform prompt-driven decoding. Moreover, we\nfurther explore different training strategies and tuning methods to boost\nco-training performance further. Our code and model are available at\nhttps://github.com/xushilin1/RAP-SAM/.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10229", "title": "OMG-Seg: Is One Model Good Enough For All Segmentation?", "abstract": "In this work, we address various segmentation tasks, each traditionally\ntackled by distinct or partially unified models. We propose OMG-Seg, One Model\nthat is Good enough to efficiently and effectively handle all the segmentation\ntasks, including image semantic, instance, and panoptic segmentation, as well\nas their video counterparts, open vocabulary settings, prompt-driven,\ninteractive segmentation like SAM, and video object segmentation. To our\nknowledge, this is the first model to handle all these tasks in one model and\nachieve satisfactory performance. We show that OMG-Seg, a transformer-based\nencoder-decoder architecture with task-specific queries and outputs, can\nsupport over ten distinct segmentation tasks and yet significantly reduce\ncomputational and parameter overhead across various tasks and datasets. We\nrigorously evaluate the inter-task influences and correlations during\nco-training. Code and models are available at https://github.com/lxtGH/OMG-Seg.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.1023", "title": "Simultaneous Tactile Estimation and Control for Extrinsic Dexterity", "abstract": "We introduce a novel approach that combines tactile estimation and control\nfor in-hand object manipulation. By integrating measurements from robot\nkinematics and an image-based tactile sensor, our framework estimates and\ntracks object pose while simultaneously generating motion plans to control the\npose of a grasped object. This approach consists of a discrete pose estimator\nthat uses the Viterbi decoding algorithm to find the most likely sequence of\nobject poses in a coarsely discretized grid, and a continuous pose\nestimator-controller to refine the pose estimate and accurately manipulate the\npose of the grasped object. Our method is tested on diverse objects and\nconfigurations, achieving desired manipulation objectives and outperforming\nsingle-shot methods in estimation accuracy. The proposed approach holds\npotential for tasks requiring precise manipulation in scenarios where visual\nperception is limited, laying the foundation for closed-loop behavior\napplications such as assembly and tool use. Please see supplementary videos for\nreal-world demonstration at https://sites.google.com/view/texterity.", "field": "Computer Science", "categories": "cs.RO"}, {"arxiv_id": "2401.10232", "title": "ParaHome: Parameterizing Everyday Home Activities Towards 3D Generative\n  Modeling of Human-Object Interactions", "abstract": "To enable machines to learn how humans interact with the physical world in\nour daily activities, it is crucial to provide rich data that encompasses the\n3D motion of humans as well as the motion of objects in a learnable 3D\nrepresentation. Ideally, this data should be collected in a natural setup,\ncapturing the authentic dynamic 3D signals during human-object interactions. To\naddress this challenge, we introduce the ParaHome system, designed to capture\nand parameterize dynamic 3D movements of humans and objects within a common\nhome environment. Our system consists of a multi-view setup with 70\nsynchronized RGB cameras, as well as wearable motion capture devices equipped\nwith an IMU-based body suit and hand motion capture gloves. By leveraging the\nParaHome system, we collect a novel large-scale dataset of human-object\ninteraction. Notably, our dataset offers key advancement over existing datasets\nin three main aspects: (1) capturing 3D body and dexterous hand manipulation\nmotion alongside 3D object movement within a contextual home environment during\nnatural activities; (2) encompassing human interaction with multiple objects in\nvarious episodic scenarios with corresponding descriptions in texts; (3)\nincluding articulated objects with multiple parts expressed with parameterized\narticulations. Building upon our dataset, we introduce new research tasks aimed\nat building a generative model for learning and synthesizing human-object\ninteractions in a real-world room setting.", "field": "Computer Science", "categories": "cs.CV"}]}