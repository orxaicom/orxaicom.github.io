{"embeddings": [[9.714495658874512, 12.161886215209961], [9.163915634155273, 11.378083229064941], [8.010232925415039, 12.095100402832031], [7.9119768142700195, 12.175292015075684], [8.097776412963867, 11.1211576461792], [7.927749156951904, 12.07539176940918], [8.653156280517578, 12.926012992858887], [7.9581427574157715, 11.688200950622559], [9.084515571594238, 10.00899887084961], [10.958927154541016, 11.003641128540039], [8.914190292358398, 9.704005241394043], [8.880841255187988, 13.250642776489258], [8.363127708435059, 9.01180362701416], [8.352492332458496, 13.494994163513184], [11.691271781921387, 12.34637451171875], [8.636649131774902, 13.779838562011719], [8.71017837524414, 11.855794906616211], [9.006081581115723, 12.434715270996094], [8.23603343963623, 10.767538070678711], [8.835875511169434, 11.836337089538574], [9.041496276855469, 8.439501762390137], [11.66405963897705, 10.852086067199707], [8.032726287841797, 13.12812614440918], [8.452930450439453, 9.425497055053711], [7.912848949432373, 12.836139678955078], [9.256132125854492, 13.461044311523438], [9.660957336425781, 9.44847583770752], [8.821891784667969, 11.987815856933594], [11.98043155670166, 12.243322372436523], [8.849626541137695, 11.953669548034668], [8.049612045288086, 9.448796272277832], [10.897759437561035, 10.704065322875977], [7.463962554931641, 10.895357131958008], [7.960573196411133, 11.290947914123535], [8.86403751373291, 8.46900463104248], [9.91565227508545, 13.803485870361328], [12.07463264465332, 10.026643753051758], [11.984564781188965, 11.453166961669922], [11.00892448425293, 10.78816032409668], [8.327665328979492, 12.473931312561035], [7.99336051940918, 12.370821952819824], [8.663252830505371, 11.561362266540527], [9.575878143310547, 10.881155014038086], [9.602090835571289, 12.8033447265625], [8.443313598632812, 13.346649169921875], [7.03267765045166, 10.328792572021484], [9.280291557312012, 10.128507614135742], [8.314985275268555, 12.51677417755127], [9.258066177368164, 12.847014427185059], [11.03549575805664, 12.430523872375488], [10.691394805908203, 10.29693603515625], [7.625996112823486, 12.748905181884766], [8.787873268127441, 13.646112442016602], [8.947341918945312, 11.586763381958008], [8.979432106018066, 13.345497131347656], [9.175061225891113, 13.609344482421875], [7.670838356018066, 8.082279205322266], [11.631586074829102, 12.978672981262207], [11.074287414550781, 11.961098670959473], [7.755017280578613, 12.265997886657715], [9.120251655578613, 10.12664794921875], [12.225198745727539, 11.512404441833496], [10.322454452514648, 10.336163520812988], [8.58769702911377, 9.358902931213379], [8.666863441467285, 8.277563095092773], [12.111411094665527, 11.426331520080566], [9.309587478637695, 11.205741882324219], [8.236968040466309, 8.441108703613281], [11.372859001159668, 11.719132423400879], [9.191819190979004, 11.441579818725586], [8.119562149047852, 9.091635704040527], [7.8465752601623535, 12.359888076782227], [11.49355697631836, 12.301408767700195], [8.125492095947266, 13.272647857666016], [10.617522239685059, 12.649748802185059], [8.701279640197754, 11.219274520874023], [7.503903865814209, 11.99656867980957], [9.277204513549805, 13.744012832641602], [7.4350409507751465, 11.351428031921387], [12.206778526306152, 12.341768264770508], [9.663700103759766, 11.334593772888184], [11.008978843688965, 11.238134384155273], [12.147745132446289, 11.622925758361816], [8.655838012695312, 12.60947322845459], [8.259862899780273, 8.944424629211426], [9.92405891418457, 13.872544288635254], [12.55691909790039, 12.489185333251953], [11.496798515319824, 11.712689399719238], [11.901503562927246, 12.513484954833984], [8.747735977172852, 11.105979919433594], [7.126614570617676, 9.655756950378418], [8.681707382202148, 11.297842025756836], [7.885615825653076, 12.432467460632324], [9.652616500854492, 14.03101921081543], [8.479989051818848, 12.638203620910645], [12.269981384277344, 12.25409984588623], [7.630095481872559, 8.014759063720703], [11.211344718933105, 12.201065063476562], [11.788694381713867, 11.409156799316406], [10.268087387084961, 12.943434715270996], [10.031901359558105, 8.853946685791016], [8.668279647827148, 8.950126647949219], [11.881471633911133, 11.72434139251709], [7.984479904174805, 8.784405708312988], [10.139202117919922, 12.017475128173828], [7.292220115661621, 9.138252258300781], [7.5104804039001465, 12.012310981750488], [9.167773246765137, 11.09386157989502], [8.642570495605469, 13.610170364379883], [11.609554290771484, 11.942427635192871], [11.02109146118164, 12.562250137329102], [12.159767150878906, 12.015541076660156], [9.661541938781738, 11.74710464477539], [8.898358345031738, 8.528992652893066], [9.676698684692383, 13.564886093139648], [10.725008964538574, 10.78707218170166], [9.067837715148926, 8.320974349975586], [9.17768669128418, 8.249755859375], [8.480201721191406, 12.356322288513184], [7.739950180053711, 8.0821533203125], [9.095457077026367, 8.362696647644043], [7.201366424560547, 10.825740814208984], [10.113722801208496, 13.14037036895752], [10.847467422485352, 12.278166770935059], [9.106354713439941, 8.41762638092041], [8.368067741394043, 12.560114860534668], [9.239267349243164, 10.52037239074707], [8.761885643005371, 9.502552032470703], [12.66344928741455, 11.85546588897705], [7.6825947761535645, 8.051283836364746], [9.792407989501953, 13.080893516540527], [9.047999382019043, 12.662217140197754], [7.354525089263916, 10.956296920776367], [7.77231502532959, 8.049671173095703], [9.364522933959961, 11.24779224395752], [9.663897514343262, 9.408215522766113], [9.29796028137207, 13.67609691619873], [7.595732688903809, 8.116172790527344], [8.673833847045898, 10.55673885345459], [12.0472993850708, 12.358149528503418], [7.21375036239624, 9.275575637817383], [7.874936103820801, 12.543971061706543], [10.169319152832031, 11.545181274414062], [7.779446601867676, 8.135562896728516], [8.521624565124512, 10.182268142700195], [8.033427238464355, 11.920153617858887], [12.217344284057617, 11.541982650756836], [10.134116172790527, 12.708151817321777], [12.285289764404297, 11.884880065917969], [9.939908981323242, 13.871530532836914], [9.633137702941895, 8.91771125793457], [10.243486404418945, 13.2572021484375], [8.009515762329102, 12.405046463012695], [9.759466171264648, 11.591007232666016], [10.78040885925293, 12.029214859008789], [8.24738883972168, 12.505934715270996], [8.977418899536133, 13.87013053894043], [8.297266006469727, 9.88729190826416], [12.086462020874023, 11.583272933959961], [6.636442184448242, 10.514636993408203], [9.745182037353516, 13.282856941223145], [10.212738037109375, 11.52364444732666], [7.005868911743164, 9.890952110290527], [7.584377288818359, 12.291810989379883], [6.5737433433532715, 10.551870346069336], [11.535758018493652, 10.909431457519531], [10.055807113647461, 9.109768867492676], [7.17579984664917, 10.369157791137695], [9.096155166625977, 11.591717720031738], [7.233452320098877, 10.426936149597168], [9.899415969848633, 9.193340301513672], [8.401151657104492, 11.586036682128906], [12.384214401245117, 12.534385681152344], [12.64157485961914, 12.488998413085938], [8.467724800109863, 13.377846717834473], [10.344344139099121, 13.037721633911133], [7.798727989196777, 12.627881050109863], [9.932881355285645, 13.571575164794922], [9.831330299377441, 10.355931282043457], [8.124627113342285, 10.179244995117188], [8.093043327331543, 11.889007568359375], [8.582686424255371, 9.220149993896484], [8.845261573791504, 11.25718879699707], [9.001840591430664, 12.830638885498047], [11.60017204284668, 12.99772834777832], [9.315547943115234, 10.765267372131348], [8.603049278259277, 10.94849967956543], [9.608637809753418, 13.646224975585938], [11.37639045715332, 10.752975463867188], [10.346715927124023, 12.717890739440918], [8.04306411743164, 12.979043006896973], [6.802118301391602, 10.21523666381836], [9.834622383117676, 12.747322082519531], [8.729348182678223, 12.322949409484863], [7.750617980957031, 11.649079322814941], [9.162165641784668, 8.527264595031738], [8.574767112731934, 9.64777660369873], [9.823822021484375, 13.286360740661621], [9.986478805541992, 13.328471183776855], [8.644411087036133, 9.009284973144531], [8.272454261779785, 10.02672290802002], [9.923158645629883, 13.185758590698242], [9.838794708251953, 13.878006935119629], [7.357424736022949, 9.22861385345459], [8.418536186218262, 11.903145790100098], [10.976404190063477, 12.393098831176758], [12.385247230529785, 12.671810150146484], [12.433015823364258, 10.446243286132812], [9.060052871704102, 8.537678718566895], [11.598873138427734, 12.88633918762207], [9.575761795043945, 11.318696975708008], [9.937174797058105, 13.510018348693848], [10.276598930358887, 10.384982109069824], [11.683219909667969, 11.93310260772705], [9.026721000671387, 13.503629684448242], [7.691558361053467, 8.13511848449707], [10.677118301391602, 11.217286109924316], [9.722519874572754, 9.206598281860352], [12.858757019042969, 11.753616333007812], [9.825531959533691, 10.924145698547363], [10.07633113861084, 11.141395568847656], [8.010104179382324, 8.389301300048828], [12.727643966674805, 12.439530372619629], [11.141489028930664, 12.745174407958984], [11.869094848632812, 11.73953628540039], [7.666078567504883, 8.03390121459961], [11.772544860839844, 11.569539070129395], [9.894972801208496, 13.063185691833496], [12.26548957824707, 10.190199851989746], [6.9987263679504395, 9.513100624084473], [10.38390827178955, 11.636797904968262], [8.322036743164062, 9.956339836120605], [12.380441665649414, 10.372203826904297], [9.096410751342773, 11.750009536743164], [8.685248374938965, 8.37497329711914], [9.566193580627441, 11.701312065124512], [10.608790397644043, 12.10520076751709], [9.506186485290527, 13.653765678405762], [10.565463066101074, 12.257132530212402], [9.515069961547852, 10.04207706451416], [9.632697105407715, 12.906816482543945], [10.370153427124023, 12.673798561096191], [10.5786714553833, 11.204654693603516], [9.579792022705078, 13.676734924316406], [9.525884628295898, 14.020995140075684], [9.493390083312988, 10.538630485534668], [11.630833625793457, 12.116806030273438], [9.409049987792969, 10.447259902954102], [7.47133731842041, 11.388335227966309], [9.179557800292969, 11.968119621276855], [8.706700325012207, 8.87497329711914], [12.304614067077637, 11.468509674072266], [9.159721374511719, 12.885579109191895], [10.032721519470215, 9.576457023620605], [12.586752891540527, 11.9442777633667], [8.233735084533691, 8.590888023376465], [12.74197006225586, 11.181139945983887], [12.646419525146484, 11.783283233642578], [7.248422145843506, 9.266237258911133], [12.783795356750488, 11.382737159729004], [8.683213233947754, 13.513391494750977], [10.153451919555664, 13.629426002502441], [10.470991134643555, 13.403449058532715], [9.628076553344727, 12.918585777282715], [10.184320449829102, 13.198758125305176], [12.633833885192871, 10.96773910522461], [8.3546724319458, 10.048160552978516], [12.67317008972168, 12.227201461791992], [8.805098533630371, 10.597264289855957], [8.088249206542969, 11.772638320922852], [10.063783645629883, 9.17900562286377], [9.463937759399414, 10.586292266845703], [9.030616760253906, 8.290910720825195], [12.350996017456055, 10.972949981689453], [8.855680465698242, 8.252829551696777], [8.351028442382812, 9.330775260925293], [8.901999473571777, 8.212864875793457], [12.173463821411133, 11.02587890625], [8.943087577819824, 8.352153778076172], [9.804920196533203, 10.397167205810547], [10.669036865234375, 13.042488098144531], [7.817187309265137, 11.266868591308594], [7.989985466003418, 9.500306129455566], [8.4314603805542, 10.556991577148438], [8.529461860656738, 10.630559921264648], [7.3325276374816895, 9.995333671569824], [11.923615455627441, 11.654779434204102], [7.122107028961182, 9.820489883422852], [9.25061321258545, 10.809778213500977], [8.313041687011719, 10.876825332641602], [11.189414024353027, 11.61291217803955], [8.080022811889648, 11.47622299194336], [10.407327651977539, 10.820745468139648], [9.186091423034668, 12.761530876159668], [12.065784454345703, 11.809224128723145], [7.8010029792785645, 9.987342834472656], [9.27649974822998, 12.37222671508789], [10.391400337219238, 9.531811714172363], [12.084596633911133, 10.728057861328125], [9.855057716369629, 8.952364921569824], [11.8472318649292, 11.819494247436523], [10.544925689697266, 10.947396278381348], [7.768346786499023, 9.622358322143555], [7.600914001464844, 9.895965576171875], [10.263365745544434, 13.506264686584473], [10.126431465148926, 13.52729320526123], [9.595681190490723, 10.419914245605469], [7.768246173858643, 12.85507869720459], [8.877147674560547, 12.031569480895996], [8.386614799499512, 10.098442077636719], [11.701971054077148, 12.596367835998535], [9.075739860534668, 11.908754348754883], [11.770414352416992, 12.850529670715332], [11.993626594543457, 9.975545883178711], [9.687667846679688, 13.636462211608887], [7.4746904373168945, 11.9278564453125], [11.92016315460205, 12.010838508605957], [9.726210594177246, 10.900602340698242], [10.548410415649414, 12.033210754394531], [11.99620246887207, 12.554165840148926], [12.704389572143555, 11.742243766784668], [9.747010231018066, 10.852689743041992], [11.853570938110352, 12.403690338134766], [9.053484916687012, 9.581671714782715], [9.614084243774414, 8.78299331665039], [8.291030883789062, 10.074531555175781], [8.048993110656738, 12.83243465423584], [9.3383150100708, 10.379807472229004], [8.416126251220703, 10.272923469543457], [10.442058563232422, 13.435956954956055], [10.6783447265625, 11.541275978088379], [12.656185150146484, 11.620107650756836], [10.725954055786133, 12.12387752532959], [8.524953842163086, 8.618293762207031], [12.132145881652832, 10.242315292358398], [9.487785339355469, 10.31844711303711], [7.746392250061035, 10.40886116027832], [10.912172317504883, 10.858362197875977], [9.837604522705078, 9.283854484558105], [8.011137962341309, 12.156349182128906], [9.300987243652344, 11.965137481689453], [8.77866268157959, 12.366555213928223], [10.278963088989258, 13.133716583251953], [12.228646278381348, 12.400506019592285], [9.444559097290039, 12.192768096923828], [11.67232894897461, 12.830228805541992], [12.134926795959473, 10.456372261047363], [12.601561546325684, 11.423579216003418], [8.379314422607422, 10.2346830368042], [10.682211875915527, 11.743674278259277], [9.912068367004395, 8.76300048828125], [12.174018859863281, 10.589208602905273], [12.766361236572266, 11.866643905639648], [12.472898483276367, 12.560059547424316], [10.171442031860352, 10.483792304992676], [12.059887886047363, 10.455078125], [9.057470321655273, 10.704082489013672], [12.517836570739746, 12.425863265991211], [9.383792877197266, 13.853347778320312], [10.263044357299805, 11.447932243347168], [7.626843452453613, 8.066886901855469], [7.9536237716674805, 8.828174591064453], [11.754457473754883, 11.999957084655762], [7.796782493591309, 11.230957984924316], [10.271724700927734, 11.82519245147705], [9.997920989990234, 9.867569923400879], [12.628933906555176, 12.529807090759277], [12.536297798156738, 12.43479061126709], [12.128866195678711, 12.681986808776855], [8.732831954956055, 13.006552696228027], [10.268206596374512, 11.013425827026367], [9.906779289245605, 10.788185119628906], [12.780491828918457, 11.626218795776367], [6.54531717300415, 10.645523071289062], [8.193562507629395, 12.695537567138672], [9.8958740234375, 10.746005058288574], [8.428214073181152, 9.042646408081055], [10.104872703552246, 10.642683982849121], [7.903981685638428, 8.320586204528809], [11.457115173339844, 12.040800094604492], [12.489704132080078, 12.126782417297363], [10.30377197265625, 10.321772575378418], [10.358628273010254, 10.383931159973145], [12.298725128173828, 12.780291557312012], [11.755414009094238, 10.415818214416504], [8.942499160766602, 8.667299270629883], [12.477123260498047, 11.036255836486816], [9.827988624572754, 8.643245697021484], [8.992955207824707, 8.999898910522461], [9.951077461242676, 8.783082962036133], [11.35798454284668, 11.274757385253906], [12.506458282470703, 12.537651062011719], [8.756025314331055, 8.975700378417969], [12.204134941101074, 10.968690872192383], [11.341347694396973, 12.636310577392578], [10.162984848022461, 10.29609203338623], [9.000436782836914, 13.523795127868652], [8.093725204467773, 7.988630294799805], [9.415022850036621, 11.26791763305664], [10.165827751159668, 9.164384841918945], [11.5611572265625, 11.595430374145508], [9.890299797058105, 13.65957260131836], [11.154145240783691, 12.189529418945312], [9.396332740783691, 13.939414978027344], [7.676506042480469, 7.964267730712891], [7.2842607498168945, 11.395856857299805], [10.289082527160645, 12.527300834655762], [10.035612106323242, 8.949747085571289], [11.689910888671875, 12.432401657104492], [12.332975387573242, 10.294685363769531], [11.450183868408203, 11.483738899230957], [8.991232872009277, 10.558332443237305], [11.298192977905273, 13.225800514221191], [8.988683700561523, 12.74150562286377], [10.38650894165039, 10.514045715332031], [7.187458038330078, 11.2838134765625], [11.069509506225586, 11.2210054397583], [11.870353698730469, 12.2734375], [7.0903496742248535, 11.31905746459961], [8.178397178649902, 10.08371639251709], [9.365774154663086, 10.259666442871094], [9.62239933013916, 12.955063819885254], [8.723479270935059, 10.857481002807617], [9.654183387756348, 9.459299087524414], [7.176098346710205, 10.271317481994629], [9.775856018066406, 13.871707916259766], [7.260241985321045, 11.50525188446045], [7.592736721038818, 12.176039695739746], [7.829043388366699, 10.969644546508789], [8.510592460632324, 11.842361450195312], [7.022133827209473, 9.53771686553955], [9.13558292388916, 13.72062873840332], [8.95026969909668, 8.86544418334961], [11.480772018432617, 11.386124610900879], [7.894073486328125, 11.684026718139648], [7.914863109588623, 11.087933540344238], [10.107257843017578, 12.238525390625], [9.99951171875, 8.979389190673828], [8.139538764953613, 12.138432502746582], [6.713602066040039, 10.54559326171875], [6.358642101287842, 10.517619132995605], [6.550858497619629, 10.695747375488281], [7.528454303741455, 8.14975357055664], [6.4593424797058105, 10.415204048156738], [6.322234153747559, 10.48567008972168], [6.3306989669799805, 10.465104103088379], [6.3957905769348145, 10.557001113891602], [6.256415367126465, 10.45979118347168], [6.289472579956055, 10.41672420501709], [6.5305938720703125, 9.940715789794922], [9.794029235839844, 13.812928199768066], [12.735977172851562, 11.817517280578613], [12.81472396850586, 11.884323120117188], [8.175102233886719, 8.46114444732666], [7.7294745445251465, 8.055949211120605], [8.863019943237305, 13.862013816833496], [10.203703880310059, 11.463515281677246], [8.528359413146973, 11.154353141784668], [7.925845623016357, 8.302778244018555], [10.25881290435791, 9.066115379333496], [11.149847030639648, 13.074222564697266], [9.459829330444336, 14.041229248046875], [7.677310466766357, 11.179882049560547], [11.462017059326172, 11.723448753356934], [9.944385528564453, 8.834391593933105], [12.012919425964355, 11.847058296203613], [9.981176376342773, 9.020283699035645], [8.829740524291992, 11.411898612976074], [10.917153358459473, 10.479314804077148], [8.872419357299805, 8.3396577835083], [8.226637840270996, 10.062578201293945], [9.010087013244629, 10.795702934265137], [9.297223091125488, 12.962377548217773], [9.309308052062988, 13.864821434020996], [9.570576667785645, 11.524911880493164], [12.226347923278809, 10.232693672180176], [8.28292465209961, 12.433337211608887], [9.91599178314209, 11.94852352142334], [12.509879112243652, 10.605816841125488], [7.266724109649658, 9.899515151977539], [8.362618446350098, 11.95368480682373], [9.647784233093262, 11.43520736694336], [12.752936363220215, 11.512704849243164], [10.482519149780273, 11.65026569366455], [9.366948127746582, 13.191460609436035], [10.425649642944336, 10.40138053894043], [7.921521186828613, 9.047338485717773], [8.041501998901367, 12.006885528564453], [9.628787994384766, 10.95509147644043], [10.171570777893066, 10.965571403503418], [9.340435981750488, 11.066113471984863], [12.86723804473877, 11.550017356872559], [8.985495567321777, 9.122050285339355], [12.343770980834961, 10.39399528503418], [7.784657001495361, 8.519085884094238], [7.769862651824951, 8.014876365661621], [10.856501579284668, 11.992548942565918], [10.433098793029785, 10.745290756225586], [7.8435378074646, 8.022323608398438], [11.289159774780273, 13.10053539276123], [9.816581726074219, 8.726602554321289], [12.272184371948242, 10.156659126281738], [12.238319396972656, 10.178486824035645], [12.36716079711914, 11.604581832885742], [9.503443717956543, 10.006946563720703], [10.355622291564941, 10.805754661560059], [7.603845119476318, 12.105217933654785], [7.155907154083252, 10.714910507202148], [6.6584391593933105, 10.697354316711426], [10.953302383422852, 12.584864616394043], [8.92618179321289, 11.444294929504395], [9.954418182373047, 13.622488021850586], [9.542658805847168, 10.344473838806152], [9.876340866088867, 13.37063217163086], [8.015549659729004, 9.460545539855957], [8.940337181091309, 13.349559783935547], [11.793060302734375, 10.46753978729248], [9.838973045349121, 13.647234916687012], [8.428744316101074, 8.66466999053955], [9.665401458740234, 13.068193435668945], [10.144604682922363, 13.580170631408691], [9.400062561035156, 13.876976013183594], [7.472999572753906, 11.019353866577148], [7.0122175216674805, 9.996673583984375], [10.204977989196777, 13.66087818145752], [9.309908866882324, 11.113850593566895], [8.142059326171875, 8.308603286743164], [8.071005821228027, 10.552508354187012], [6.900388717651367, 10.483283996582031], [8.235014915466309, 10.415858268737793], [9.925431251525879, 9.174445152282715], [9.577896118164062, 14.045002937316895], [8.106770515441895, 10.990036964416504], [8.353707313537598, 10.410266876220703], [8.652206420898438, 13.774348258972168], [10.431888580322266, 11.403593063354492], [7.494263172149658, 10.39522647857666], [10.802825927734375, 10.668187141418457], [11.617627143859863, 11.018780708312988], [9.232744216918945, 9.980088233947754], [10.088018417358398, 8.914288520812988], [10.030038833618164, 12.96441650390625], [9.991390228271484, 8.99415397644043], [9.529135704040527, 10.786759376525879], [7.718451499938965, 9.308438301086426], [7.580644130706787, 11.4909029006958], [11.421401023864746, 11.411845207214355], [12.719970703125, 12.40319538116455], [11.903229713439941, 13.158254623413086], [7.200852394104004, 10.485897064208984], [8.682476043701172, 8.451587677001953], [8.000657081604004, 8.570147514343262], [12.319076538085938, 11.311944007873535], [10.872164726257324, 11.457420349121094], [10.157574653625488, 13.25136947631836], [11.62739372253418, 12.139209747314453], [10.24875259399414, 12.945523262023926], [8.683395385742188, 10.74688720703125], [9.761636734008789, 13.078445434570312], [9.645661354064941, 12.839844703674316], [9.22287368774414, 9.959596633911133], [8.634774208068848, 8.311942100524902], [10.357097625732422, 13.208630561828613], [12.363393783569336, 10.341232299804688], [8.112945556640625, 10.245379447937012], [12.046317100524902, 11.223278045654297], [10.957537651062012, 12.881903648376465], [11.613265037536621, 11.960197448730469], [6.60539436340332, 10.749926567077637], [8.580636024475098, 9.19736099243164], [10.745776176452637, 12.76679801940918], [12.546316146850586, 12.669102668762207]], "keys": ["2401.10893", "2401.10895", "2401.10896", "2401.10897", "2401.10898", "2401.10899", "2401.109", "2401.10901", "2401.10902", "2401.10904", "2401.10914", "2401.10917", "2401.10921", "2401.10926", "2401.10934", "2401.10935", "2401.10938", "2401.1094", "2401.10941", "2401.10942", "2401.10945", "2401.10946", "2401.10948", "2401.10949", "2401.10953", "2401.10956", "2401.10959", "2401.10961", "2401.10962", "2401.10963", "2401.10965", "2401.10967", "2401.10969", "2401.10973", "2401.1099", "2401.10995", "2401.10997", "2401.11002", "2401.11008", "2401.11012", "2401.11013", "2401.11016", "2401.11018", "2401.11021", "2401.11022", "2401.11029", "2401.1103", "2401.11032", "2401.11033", "2401.11035", "2401.11037", "2401.1104", "2401.11042", "2401.11044", "2401.11048", "2401.11052", "2401.11058", "2401.11061", "2401.11062", "2401.11063", "2401.11064", "2401.11067", "2401.11074", "2401.11076", "2401.11077", "2401.11078", "2401.11081", "2401.11084", "2401.11085", "2401.11089", "2401.1109", "2401.11092", "2401.11094", "2401.11095", "2401.11102", "2401.11103", "2401.11105", "2401.11107", "2401.11108", "2401.1111", "2401.11113", "2401.11114", "2401.11115", "2401.11116", "2401.11118", "2401.1112", "2401.11122", "2401.11123", "2401.11124", "2401.11126", "2401.11127", "2401.1113", "2401.11131", "2401.11132", "2401.11135", "2401.1114", "2401.11141", "2401.11143", "2401.11144", "2401.11145", "2401.11146", "2401.11148", "2401.1115", "2401.11155", "2401.11156", "2401.1116", "2401.11161", "2401.11162", "2401.11166", "2401.11167", "2401.1117", "2401.11174", "2401.11181", "2401.11183", "2401.11185", "2401.11188", "2401.11189", "2401.11191", "2401.11194", "2401.11195", "2401.11196", "2401.11197", "2401.11198", "2401.11199", "2401.112", "2401.11201", "2401.11202", "2401.11203", "2401.11204", "2401.11205", "2401.11206", "2401.11207", "2401.11212", "2401.11214", "2401.11215", "2401.11217", "2401.11218", "2401.11219", "2401.11225", "2401.11228", "2401.11231", "2401.11232", "2401.11235", "2401.11236", "2401.11237", "2401.11238", "2401.11239", "2401.1124", "2401.11243", "2401.11246", "2401.11247", "2401.11248", "2401.11249", "2401.1125", "2401.11252", "2401.11254", "2401.11255", "2401.11257", "2401.11261", "2401.11266", "2401.11268", "2401.11271", "2401.11274", "2401.11281", "2401.11282", "2401.11284", "2401.11286", "2401.11287", "2401.11288", "2401.1129", "2401.11295", "2401.11305", "2401.11311", "2401.11313", "2401.11314", "2401.11316", "2401.11317", "2401.11323", "2401.11324", "2401.11325", "2401.11326", "2401.11328", "2401.1133", "2401.11335", "2401.11337", "2401.11347", "2401.11353", "2401.11356", "2401.11358", "2401.1136", "2401.11361", "2401.11364", "2401.11365", "2401.11366", "2401.1137", "2401.11371", "2401.11372", "2401.11373", "2401.11374", "2401.11378", "2401.1138", "2401.11382", "2401.11389", "2401.1139", "2401.11391", "2401.11394", "2401.11395", "2401.11396", "2401.11398", "2401.11401", "2401.11402", "2401.11403", "2401.11404", "2401.11406", "2401.11408", "2401.11409", "2401.1141", "2401.11411", "2401.11414", "2401.11415", "2401.11418", "2401.11419", "2401.1142", "2401.11421", "2401.11425", "2401.11429", "2401.1143", "2401.11431", "2401.11432", "2401.11433", "2401.11436", "2401.11437", "2401.11439", "2401.11441", "2401.11445", "2401.11447", "2401.11448", "2401.11452", "2401.11453", "2401.11455", "2401.11458", "2401.11459", "2401.11462", "2401.11463", "2401.11467", "2401.11469", "2401.1147", "2401.11471", "2401.11472", "2401.11478", "2401.11483", "2401.11485", "2401.11487", "2401.11488", "2401.11489", "2401.1149", "2401.11491", "2401.11492", "2401.11496", "2401.11499", "2401.115", "2401.11504", "2401.11505", "2401.11506", "2401.11509", "2401.11511", "2401.11512", "2401.11519", "2401.1152", "2401.11524", "2401.11529", "2401.11531", "2401.11533", "2401.11535", "2401.11536", "2401.11538", "2401.11539", "2401.11541", "2401.11542", "2401.11543", "2401.11544", "2401.11547", "2401.11553", "2401.11563", "2401.11565", "2401.1158", "2401.11582", "2401.1159", "2401.11592", "2401.11596", "2401.11598", "2401.11599", "2401.116", "2401.11601", "2401.11605", "2401.11608", "2401.11609", "2401.11611", "2401.11614", "2401.11616", "2401.11617", "2401.11618", "2401.1162", "2401.11622", "2401.11624", "2401.11626", "2401.11627", "2401.11628", "2401.11629", "2401.1163", "2401.11631", "2401.11632", "2401.11633", "2401.11634", "2401.11641", "2401.11642", "2401.11644", "2401.11647", "2401.11648", "2401.11649", "2401.1165", "2401.11652", "2401.11654", "2401.11656", "2401.11658", "2401.1166", "2401.11663", "2401.11664", "2401.11666", "2401.11667", "2401.11669", "2401.11673", "2401.11674", "2401.11677", "2401.11681", "2401.11685", "2401.11686", "2401.11687", "2401.11694", "2401.11697", "2401.11698", "2401.11699", "2401.117", "2401.11704", "2401.11705", "2401.11708", "2401.11709", "2401.11711", "2401.11712", "2401.11713", "2401.11714", "2401.11715", "2401.11718", "2401.11719", "2401.1172", "2401.11721", "2401.11723", "2401.11724", "2401.11725", "2401.11726", "2401.1173", "2401.11731", "2401.11734", "2401.11735", "2401.11736", "2401.11737", "2401.11738", "2401.11739", "2401.1174", "2401.11742", "2401.11748", "2401.1175", "2401.11751", "2401.11752", "2401.11753", "2401.11755", "2401.11759", "2401.1176", "2401.11761", "2401.11764", "2401.11767", "2401.11768", "2401.11772", "2401.11775", "2401.11776", "2401.11779", "2401.11783", "2401.11786", "2401.11787", "2401.11788", "2401.1179", "2401.11791", "2401.11792", "2401.11795", "2401.11796", "2401.11798", "2401.118", "2401.11805", "2401.1181", "2401.11813", "2401.11814", "2401.11817", "2401.11818", "2401.11819", "2401.1182", "2401.11823", "2401.11824", "2401.11825", "2401.11831", "2401.11834", "2401.11835", "2401.11836", "2401.11838", "2401.11839", "2401.1184", "2401.11841", "2401.11844", "2401.11847", "2401.11848", "2401.11849", "2401.11851", "2401.11852", "2401.11854", "2401.1186", "2401.11861", "2401.11864", "2401.11865", "2401.11867", "2401.11868", "2401.1187", "2401.11872", "2401.11874", "2401.11876", "2401.11877", "2401.1188", "2401.11881", "2401.11888", "2401.1189", "2401.11892", "2401.11897", "2401.11898", "2401.119", "2401.11901", "2401.11903", "2401.11904", "2401.11905", "2401.11906", "2401.11908", "2401.11909", "2401.1191", "2401.11911", "2401.11913", "2401.11914", "2401.11915", "2401.11921", "2401.11923", "2401.11929", "2401.11932", "2401.11934", "2401.1194", "2401.11943", "2401.11944", "2401.11945", "2401.11946", "2401.11948", "2401.11949", "2401.11951", "2401.11954", "2401.1196", "2401.11961", "2401.11963", "2401.11968", "2401.11969", "2401.11972", "2401.11974", "2401.11977", "2401.11981", "2401.11983", "2401.11985", "2401.11991", "2401.11993", "2401.12", "2401.12001", "2401.12002", "2401.12005", "2401.12007", "2401.1201", "2401.12011", "2401.12012", "2401.12014", "2401.12018", "2401.12019", "2401.12023", "2401.12024", "2401.12025", "2401.12029", "2401.12032", "2401.12033", "2401.12036", "2401.12039", "2401.12043", "2401.12046", "2401.12048", "2401.12051", "2401.12055", "2401.12058", "2401.1206", "2401.12061", "2401.12067", "2401.12068", "2401.12069", "2401.1207", "2401.12071", "2401.12072", "2401.12073", "2401.12075", "2401.12076", "2401.12078", "2401.12079", "2401.12086", "2401.12087", "2401.12088", "2401.12093", "2401.12094", "2401.12097", "2401.12103", "2401.12107", "2401.12108", "2401.12111", "2401.12113", "2401.12114", "2401.12117", "2401.1212", "2401.12121", "2401.12125", "2401.12129", "2401.12131", "2401.12132", "2401.12133", "2401.12136", "2401.12138", "2401.12143", "2401.12147", "2401.12149", "2401.12151", "2401.12159", "2401.12161", "2401.12164", "2401.12168", "2401.1217", "2401.12172", "2401.12174", "2401.12175", "2401.12176", "2401.12178", "2401.12179", "2401.12181", "2401.12184", "2401.12187", "2401.12192", "2401.12193", "2401.12198", "2401.122", "2401.12202", "2401.12205", "2401.12207", "2401.12208", "2401.1221", "2401.12212", "2401.12214", "2401.12215", "2401.12217"], "additional_info": [{"arxiv_id": "2401.10893", "title": "Location Sensitive Embedding for Knowledge Graph Embedding", "abstract": "Knowledge graph embedding transforms knowledge graphs into a continuous,\nlow-dimensional space, facilitating inference and completion tasks. This field\nis mainly divided into translational distance models and semantic matching\nmodels. A key challenge in translational distance models is their inability to\neffectively differentiate between 'head' and 'tail' entities in graphs. To\naddress this, the novel location-sensitive embedding (LSE) method has been\ndeveloped. LSE innovatively modifies the head entity using relation-specific\nmappings, conceptualizing relations as linear transformations rather than mere\ntranslations. The theoretical foundations of LSE, including its\nrepresentational capabilities and its connections to existing models, have been\nthoroughly examined. A more streamlined variant, LSEd, employs a diagonal\nmatrix for transformations to enhance practical efficiency. In tests conducted\non four large-scale datasets for link prediction, LSEd either outperforms or is\ncompetitive with leading contemporary models.", "field": "Computer Science", "categories": "cs.IR,cs.CL"}, {"arxiv_id": "2401.10895", "title": "AI in Supply Chain Risk Assessment: A Systematic Literature Review and\n  Bibliometric Analysis", "abstract": "Supply chain risk assessment (SCRA) has witnessed a profound evolution\nthrough the integration of artificial intelligence (AI) and machine learning\n(ML) techniques, revolutionizing predictive capabilities and risk mitigation\nstrategies. The significance of this evolution stems from the critical role of\nrobust risk management strategies in ensuring operational resilience and\ncontinuity within modern supply chains. Previous reviews have outlined\nestablished methodologies but have overlooked emerging AI/ML techniques,\nleaving a notable research gap in understanding their practical implications\nwithin SCRA. This paper conducts a systematic literature review combined with a\ncomprehensive bibliometric analysis. We meticulously examined 1,717 papers and\nderived key insights from a select group of 48 articles published between 2014\nand 2023. The review fills this research gap by addressing pivotal research\nquestions, and exploring existing AI/ML techniques, methodologies, findings,\nand future trajectories, thereby providing a more encompassing view of the\nevolving landscape of SCRA. Our study unveils the transformative impact of\nAI/ML models, such as Random Forest, XGBoost, and hybrids, in substantially\nenhancing precision within SCRA. It underscores adaptable post-COVID\nstrategies, advocating for resilient contingency plans and aligning with\nevolving risk landscapes. Significantly, this review surpasses previous\nexaminations by accentuating emerging AI/ML techniques and their practical\nimplications within SCRA. Furthermore, it highlights the contributions through\na comprehensive bibliometric analysis, revealing publication trends,\ninfluential authors, and highly cited articles.", "field": "Computer Science", "categories": "cs.LG,cs.CE"}, {"arxiv_id": "2401.10896", "title": "Responsible AI Governance: A Systematic Literature Review", "abstract": "As artificial intelligence transforms a wide range of sectors and drives\ninnovation, it also introduces complex challenges concerning ethics,\ntransparency, bias, and fairness. The imperative for integrating Responsible AI\n(RAI) principles within governance frameworks is paramount to mitigate these\nemerging risks. While there are many solutions for AI governance, significant\nquestions remain about their effectiveness in practice. Addressing this\nknowledge gap, this paper aims to examine the existing literature on AI\nGovernance. The focus of this study is to analyse the literature to answer key\nquestions: WHO is accountable for AI systems' governance, WHAT elements are\nbeing governed, WHEN governance occurs within the AI development life cycle,\nand HOW it is executed through various mechanisms like frameworks, tools,\nstandards, policies, or models. Employing a systematic literature review\nmethodology, a rigorous search and selection process has been employed. This\neffort resulted in the identification of 61 relevant articles on the subject of\nAI Governance. Out of the 61 studies analysed, only 5 provided complete\nresponses to all questions. The findings from this review aid research in\nformulating more holistic and comprehensive Responsible AI (RAI) governance\nframeworks. This study highlights important role of AI governance on various\nlevels specially organisational in establishing effective and responsible AI\npractices. The findings of this study provides a foundational basis for future\nresearch and development of comprehensive governance models that align with RAI\nprinciples.", "field": "Computer Science", "categories": "cs.CY"}, {"arxiv_id": "2401.10897", "title": "Transformations in the Time of The Transformer", "abstract": "Foundation models offer a new opportunity to redesign existing systems and\nworkflows with a new AI first perspective. However, operationalizing this\nopportunity faces several challenges and tradeoffs. The goal of this article is\nto offer an organizational framework for making rational choices as enterprises\nstart their transformation journey towards an AI first organization. The\nchoices provided are holistic, intentional and informed while avoiding\ndistractions. The field may appear to be moving fast, but there are core\nfundamental factors that are relatively more slow moving. We focus on these\ninvariant factors to build the logic of the argument.", "field": "Computer Science", "categories": "cs.CY"}, {"arxiv_id": "2401.10898", "title": "Unified Pandemic Tracking System Based on Open Geospatial Consortium\n  SensorThings API", "abstract": "With the current nations struggling to track the pandemic's trajectories.\nThere has been a lack of transparency or real-live data streaming for pandemic\ncases and symptoms. This phenomenon has led to a rapid and uncontrolled spread\nof these deadly pandemics. One of the main issues in creating a global pandemic\ntracking system is the lack of standardization of communications protocols and\nthe deployment of Internet-of-Things (IoT) device sensors. The Open Geospatial\nConsortium (OGC) has developed several sensor web Enablement standards that\nallow the expeditious deployment of communications protocols within IoT devices\nand other sensor devices like the OGC SensorThings application programming\ninterface (API). In this paper, to address this issue, we outline the\ninteroperability challenge and provide a qualitative and quantitative study of\nthe OGC SensorThings API's deployment and its respective server. The OGC\nSensorThings API is developed to provide data exchange services between sensors\nand their observations. The OGC SensorThings API would play a primary and\nessential role in creating an automated pandemic tracking system. This API\nwould reduce the deployment of any set of sensors and provide real-time data\ntracking. Accordingly, global health organizations would react expeditiously\nand concentrate their efforts on high infection rates.", "field": "Computer Science", "categories": "cs.CY,cs.NI"}, {"arxiv_id": "2401.10899", "title": "Concrete Problems in AI Safety, Revisited", "abstract": "As AI systems proliferate in society, the AI community is increasingly\npreoccupied with the concept of AI Safety, namely the prevention of failures\ndue to accidents that arise from an unanticipated departure of a system's\nbehavior from designer intent in AI deployment. We demonstrate through an\nanalysis of real world cases of such incidents that although current vocabulary\ncaptures a range of the encountered issues of AI deployment, an expanded\nsocio-technical framing will be required for a more complete understanding of\nhow AI systems and implemented safety mechanisms fail and succeed in real life.", "field": "Computer Science", "categories": "cs.CY,cs.AI"}, {"arxiv_id": "2401.109", "title": "Towards building a monitoring platform for a challenge-oriented smart\n  specialisation with RIS3-MCAT", "abstract": "In the new research and innovation (R&I) paradigm, aimed at a transformation\ntowards more sustainable, inclusive and fair pathways to address societal and\nenvironmental challenges, and at generating new patterns of specialisation and\nnew trajectories for socioeconomic development, it is essential to provide\nmonitoring systems and tools to map and understand the contribution of R&I\npolicies and projects. To address this transformation, we present the RIS3-MCAT\nplatform, the result of a line of work aimed at exploring the potential of open\ndata, semantic analysis, and data visualisation, for monitoring\nchallenge-oriented smart specialisation in Catalonia. RIS3-MCAT is an\ninteractive platform that facilitates access to R&I project data in formats\nthat allow for sophisticated analyses of a large volume of texts, enabling the\ndetailed study of thematic specialisations and challenges beyond classical\nclassification systems. Its conceptualisation, development framework and use\nare presented in this paper.", "field": "Computer Science", "categories": "cs.CY,cs.CL,cs.HC"}, {"arxiv_id": "2401.10901", "title": "Enabling Technologies for Web 3.0: A Comprehensive Survey", "abstract": "Web 3.0 represents the next stage of Internet evolution, aiming to empower\nusers with increased autonomy, efficiency, quality, security, and privacy. This\nevolution can potentially democratize content access by utilizing the latest\ndevelopments in enabling technologies. In this paper, we conduct an in-depth\nsurvey of enabling technologies in the context of Web 3.0, such as blockchain,\nsemantic web, 3D interactive web, Metaverse, Virtual reality/Augmented reality,\nInternet of Things technology, and their roles in shaping Web 3.0. We commence\nby providing a comprehensive background of Web 3.0, including its concept,\nbasic architecture, potential applications, and industry adoption.\nSubsequently, we examine recent breakthroughs in IoT, 5G, and blockchain\ntechnologies that are pivotal to Web 3.0 development. Following that, other\nenabling technologies, including AI, semantic web, and 3D interactive web, are\ndiscussed. Utilizing these technologies can effectively address the critical\nchallenges in realizing Web 3.0, such as ensuring decentralized identity,\nplatform interoperability, data transparency, reducing latency, and enhancing\nthe system's scalability. Finally, we highlight significant challenges\nassociated with Web 3.0 implementation, emphasizing potential solutions and\nproviding insights into future research directions in this field.", "field": "Computer Science", "categories": "cs.CY"}, {"arxiv_id": "2401.10902", "title": "The lower energy consumption in cryptocurrency mining processes by\n  SHA-256 Quantum circuit design used in hybrid computing domains", "abstract": "Cryptocurrency mining processes always lead to a high energy consumption at\nconsiderably high production cost, which is nearly one-third of cryptocurrency\n(e.g. Bitcoin) price itself. As the core of mining process is based on SHA-256\ncryptographic hashing function, by using the alternative quantum computers,\nhybrid quantum computers or more larger quantum computing devices like quantum\nannealers, it would be possible to reduce the mining energy consumption with a\nquantum hardware's low-energy-operation characteristics. Within this work we\ndemonstrated the use of optimized quantum mining facilities which would replace\nthe classical SHA-256 and high energy consuming classical hardware in near\nfuture.", "field": "Computer Science", "categories": "cs.ET,cs.CR,quant-ph"}, {"arxiv_id": "2401.10904", "title": "A Review of Findings from Neuroscience and Cognitive Psychology as\n  Possible Inspiration for the Path to Artificial General Intelligence", "abstract": "This review aims to contribute to the quest for artificial general\nintelligence by examining neuroscience and cognitive psychology methods for\npotential inspiration. Despite the impressive advancements achieved by deep\nlearning models in various domains, they still have shortcomings in abstract\nreasoning and causal understanding. Such capabilities should be ultimately\nintegrated into artificial intelligence systems in order to surpass data-driven\nlimitations and support decision making in a way more similar to human\nintelligence. This work is a vertical review that attempts a wide-ranging\nexploration of brain function, spanning from lower-level biological neurons,\nspiking neural networks, and neuronal ensembles to higher-level concepts such\nas brain anatomy, vector symbolic architectures, cognitive and categorization\nmodels, and cognitive architectures. The hope is that these concepts may offer\ninsights for solutions in artificial general intelligence.", "field": "Computer Science", "categories": "cs.AI"}, {"arxiv_id": "2401.10914", "title": "Quantum Neural Network Software Testing, Analysis, and Code Optimization\n  for Advanced IoT Systems: Design, Implementation, and Visualization", "abstract": "This paper introduces a novel run-time testing, analysis, and code\noptimization (TACO) method for quantum neural network (QNN) software in\nadvanced Internet-of-Things (IoT) systems, which visually presents the learning\nperformance that is called a barren plateau. The run-time visual presentation\nof barren plateau situations is helpful for real-time quantum-based advanced\nIoT software testing because the software engineers can easily be aware of the\ntraining performances of QNN. Moreover, this tool is obviously useful for\nsoftware engineers because it can intuitively guide them in designing and\nimplementing high-accurate QNN-based advanced IoT software even if they are not\nfamiliar with quantum mechanics and quantum computing. Lastly, the proposed\nTACO is also capable of visual feedback because software engineers visually\nidentify the barren plateau situations using tensorboard. In turn, they are\nalso able to modify QNN structures based on the information.", "field": "Computer Science", "categories": "cs.SE"}, {"arxiv_id": "2401.10917", "title": "Artificial intelligence to automate the systematic review of scientific\n  literature", "abstract": "Artificial intelligence (AI) has acquired notorious relevance in modern\ncomputing as it effectively solves complex tasks traditionally done by humans.\nAI provides methods to represent and infer knowledge, efficiently manipulate\ntexts and learn from vast amount of data. These characteristics are applicable\nin many activities that human find laborious or repetitive, as is the case of\nthe analysis of scientific literature. Manually preparing and writing a\nsystematic literature review (SLR) takes considerable time and effort, since it\nrequires planning a strategy, conducting the literature search and analysis,\nand reporting the findings. Depending on the area under study, the number of\npapers retrieved can be of hundreds or thousands, meaning that filtering those\nrelevant ones and extracting the key information becomes a costly and\nerror-prone process. However, some of the involved tasks are repetitive and,\ntherefore, subject to automation by means of AI. In this paper, we present a\nsurvey of AI techniques proposed in the last 15 years to help researchers\nconduct systematic analyses of scientific literature. We describe the tasks\ncurrently supported, the types of algorithms applied, and available tools\nproposed in 34 primary studies. This survey also provides a historical\nperspective of the evolution of the field and the role that humans can play in\nan increasingly automated SLR process.", "field": "Computer Science", "categories": "cs.IR,cs.AI,68T01,I.2.m; A.1"}, {"arxiv_id": "2401.10921", "title": "Push- and Pull-based Effective Communication in Cyber-Physical Systems", "abstract": "In Cyber Physical Systems (CPSs), two groups of actors interact toward the\nmaximization of system performance: the sensors, observing and disseminating\nthe system state, and the actuators, performing physical decisions based on the\nreceived information. While it is generally assumed that sensors periodically\ntransmit updates, returning the feedback signal only when necessary, and\nconsequently adapting the physical decisions to the communication policy, can\nsignificantly improve the efficiency of the system. In particular, the choice\nbetween push-based communication, in which updates are initiated autonomously\nby the sensors, and pull-based communication, in which they are requested by\nthe actuators, is a key design step. In this work, we propose an analytical\nmodel for optimizing push- and pull-based communication in CPSs, observing that\nthe policy optimality coincides with Value of Information (VoI) maximization.\nOur results also highlight that, despite providing a better optimal solution,\nimplementable push-based communication strategies may underperform even in\nrelatively simple scenarios.", "field": "Computer Science", "categories": "eess.SY,cs.LG,cs.MA,cs.SY"}, {"arxiv_id": "2401.10926", "title": "A VR Serious Game to Increase Empathy towards Students with Phonological\n  Dyslexia", "abstract": "Dyslexia is a neurodevelopmental disorder that is estimated to affect about\n5-10% of the population. In particular, phonological dyslexia causes problems\nin connecting the sounds of words with their written forms. This results in\ndifficulties such as slow reading speed, inaccurate reading, and difficulty\ndecoding unfamiliar words. Moreover, dyslexia can also be a challenging and\nfrustrating experience for students as they may feel misunderstood or\nstigmatized by their peers or educators. For these reasons, the use of\ncompensatory tools and strategies is of crucial importance for dyslexic\nstudents to have the same opportunities as non-dyslexic ones. However,\ngenerally, people underestimate the problem and are not aware of the importance\nof support methodologies. In the light of this, the main purpose of this paper\nis to propose a virtual reality (VR) serious game through which teachers,\nstudents and, in general, non-dyslexic people could understand which are some\nof the issues of student with dyslexia and the fundamental utility of offering\nsupport to them. In the game, players must create a potion by following a\nrecipe written in an alphabet that is specifically designed to replicate the\nreading difficulties experienced by individuals with dyslexia. The task must be\nsolved first without any help and then by receiving supporting tools and\nstrategies with the idea that the player can put himself in the place of the\ndyslexic person and understand the real need for support methodologies.", "field": "Computer Science", "categories": "cs.HC,cs.CV,cs.GR"}, {"arxiv_id": "2401.10934", "title": "A New Creative Generation Pipeline for Click-Through Rate with Stable\n  Diffusion Model", "abstract": "In online advertising scenario, sellers often create multiple creatives to\nprovide comprehensive demonstrations, making it essential to present the most\nappealing design to maximize the Click-Through Rate (CTR). However, sellers\ngenerally struggle to consider users preferences for creative design, leading\nto the relatively lower aesthetics and quantities compared to Artificial\nIntelligence (AI)-based approaches. Traditional AI-based approaches still face\nthe same problem of not considering user information while having limited\naesthetic knowledge from designers. In fact that fusing the user information,\nthe generated creatives can be more attractive because different users may have\ndifferent preferences. To optimize the results, the generated creatives in\ntraditional methods are then ranked by another module named creative ranking\nmodel. The ranking model can predict the CTR score for each creative\nconsidering user features. However, the two above stages are regarded as two\ndifferent tasks and are optimized separately. In this paper, we proposed a new\nautomated Creative Generation pipeline for Click-Through Rate (CG4CTR) with the\ngoal of improving CTR during the creative generation stage. Our contributions\nhave 4 parts: 1) The inpainting mode in stable diffusion is firstly applied to\ncreative generation task in online advertising scene. A self-cyclic generation\npipeline is proposed to ensure the convergence of training. 2) Prompt model is\ndesigned to generate individualized creatives for different user groups, which\ncan further improve the diversity and quality. 3) Reward model comprehensively\nconsiders the multimodal features of image and text to improve the\neffectiveness of creative ranking task, and it is also critical in self-cyclic\npipeline. 4) The significant benefits obtained in online and offline\nexperiments verify the significance of our proposed method.", "field": "Computer Science", "categories": "cs.IR,cs.AI"}, {"arxiv_id": "2401.10935", "title": "SeeClick: Harnessing GUI Grounding for Advanced Visual GUI Agents", "abstract": "Graphical User Interface (GUI) agents are designed to automate complex tasks\non digital devices, such as smartphones and desktops. Most existing GUI agents\ninteract with the environment through extracted structured data, which can be\nnotably lengthy (e.g., HTML) and occasionally inaccessible (e.g., on desktops).\nTo alleviate this issue, we propose a visual GUI agent -- SeeClick, which only\nrelies on screenshots for task automation. In our preliminary study, we have\ndiscovered a key challenge in developing visual GUI agents: GUI grounding --\nthe capacity to accurately locate screen elements based on instructions. To\ntackle this challenge, we propose to enhance SeeClick with GUI grounding\npre-training and devise a method to automate the curation of GUI grounding\ndata. Along with the efforts above, we have also created ScreenSpot, the first\nrealistic GUI grounding dataset that encompasses mobile, desktop, and web\nenvironments. After pre-training, SeeClick demonstrates significant improvement\nin ScreenSpot over various baselines. Moreover, comprehensive evaluations on\nthree widely used benchmarks consistently support our finding that advancements\nin GUI grounding directly correlate with enhanced performance in downstream GUI\nagent tasks. The model, data and code are available at\nhttps://github.com/njucckevin/SeeClick.", "field": "Computer Science", "categories": "cs.HC,cs.AI"}, {"arxiv_id": "2401.10938", "title": "Even-if Explanations: Formal Foundations, Priorities and Complexity", "abstract": "EXplainable AI has received significant attention in recent years. Machine\nlearning models often operate as black boxes, lacking explainability and\ntransparency while supporting decision-making processes. Local post-hoc\nexplainability queries attempt to answer why individual inputs are classified\nin a certain way by a given model. While there has been important work on\ncounterfactual explanations, less attention has been devoted to semifactual\nones. In this paper, we focus on local post-hoc explainability queries within\nthe semifactual `even-if' thinking and their computational complexity among\ndifferent classes of models, and show that both linear and tree-based models\nare strictly more interpretable than neural networks. After this, we introduce\na preference-based framework that enables users to personalize explanations\nbased on their preferences, both in the case of semifactuals and\ncounterfactuals, enhancing interpretability and user-centricity. Finally, we\nexplore the complexity of several interpretability problems in the proposed\npreference-based framework and provide algorithms for polynomial cases.", "field": "Computer Science", "categories": "cs.AI,cs.LG"}, {"arxiv_id": "2401.1094", "title": "RELIANCE: Reliable Ensemble Learning for Information and News\n  Credibility Evaluation", "abstract": "In the era of information proliferation, discerning the credibility of news\ncontent poses an ever-growing challenge. This paper introduces RELIANCE, a\npioneering ensemble learning system designed for robust information and fake\nnews credibility evaluation. Comprising five diverse base models, including\nSupport Vector Machine (SVM), naive Bayes, logistic regression, random forest,\nand Bidirectional Long Short Term Memory Networks (BiLSTMs), RELIANCE employs\nan innovative approach to integrate their strengths, harnessing the collective\nintelligence of the ensemble for enhanced accuracy. Experiments demonstrate the\nsuperiority of RELIANCE over individual models, indicating its efficacy in\ndistinguishing between credible and non-credible information sources. RELIANCE,\nalso surpasses baseline models in information and news credibility assessment,\nestablishing itself as an effective solution for evaluating the reliability of\ninformation sources.", "field": "Computer Science", "categories": "cs.IR,cs.CL,cs.LG,cs.SI"}, {"arxiv_id": "2401.10941", "title": "Crowd-PrefRL: Preference-Based Reward Learning from Crowds", "abstract": "Preference-based reinforcement learning (RL) provides a framework to train\nagents using human feedback through pairwise preferences over pairs of\nbehaviors, enabling agents to learn desired behaviors when it is difficult to\nspecify a numerical reward function. While this paradigm leverages human\nfeedback, it currently treats the feedback as given by a single human user.\nMeanwhile, incorporating preference feedback from crowds (i.e. ensembles of\nusers) in a robust manner remains a challenge, and the problem of training RL\nagents using feedback from multiple human users remains understudied. In this\nwork, we introduce Crowd-PrefRL, a framework for performing preference-based RL\nleveraging feedback from crowds. This work demonstrates the viability of\nlearning reward functions from preference feedback provided by crowds of\nunknown expertise and reliability. Crowd-PrefRL not only robustly aggregates\nthe crowd preference feedback, but also estimates the reliability of each user\nwithin the crowd using only the (noisy) crowdsourced preference comparisons.\nMost importantly, we show that agents trained with Crowd-PrefRL outperform\nagents trained with majority-vote preferences or preferences from any\nindividual user in most cases, especially when the spread of user error rates\namong the crowd is large. Results further suggest that our method can identify\nminority viewpoints within the crowd.", "field": "Computer Science", "categories": "cs.HC,cs.LG,cs.SI"}, {"arxiv_id": "2401.10942", "title": "Machine Unlearning for Recommendation Systems: An Insight", "abstract": "This review explores machine unlearning (MUL) in recommendation systems,\naddressing adaptability, personalization, privacy, and bias challenges. Unlike\ntraditional models, MUL dynamically adjusts system knowledge based on shifts in\nuser preferences and ethical considerations. The paper critically examines\nMUL's basics, real-world applications, and challenges like algorithmic\ntransparency. It sifts through literature, offering insights into how MUL could\ntransform recommendations, discussing user trust, and suggesting paths for\nfuture research in responsible and user-focused artificial intelligence (AI).\nThe document guides researchers through challenges involving the trade-off\nbetween personalization and privacy, encouraging contributions to meet\npractical demands for targeted data removal. Emphasizing MUL's role in secure\nand adaptive machine learning, the paper proposes ways to push its boundaries.\nThe novelty of this paper lies in its exploration of the limitations of the\nmethods, which highlights exciting prospects for advancing the field.", "field": "Computer Science", "categories": "cs.IR,cs.AI,cs.LG"}, {"arxiv_id": "2401.10945", "title": "Automatic dimensionality reduction of Twin-in-the-Loop Observers", "abstract": "State-of-the-art vehicle dynamics estimation techniques usually share one\ncommon drawback: each variable to estimate is computed with an independent,\nsimplified filtering module. These modules run in parallel and need to be\ncalibrated separately. To solve this issue, a unified Twin-in-the-Loop (TiL)\nObserver architecture has recently been proposed: the classical simplified\ncontrol-oriented vehicle model in the estimators is replaced by a full-fledged\nvehicle simulator, or digital twin (DT). The states of the DT are corrected in\nreal time with a linear time invariant output error law. Since the simulator is\na black-box, no explicit analytical formulation is available, hence classical\nfilter tuning techniques cannot be used. Due to this reason, Bayesian\nOptimization will be used to solve a data-driven optimization problem to tune\nthe filter. Due to the complexity of the DT, the optimization problem is\nhigh-dimensional. This paper aims to find a procedure to tune the\nhigh-complexity observer by lowering its dimensionality. In particular, in this\nwork we will analyze both a supervised and an unsupervised learning approach.\nThe strategies have been validated for speed and yaw-rate estimation on\nreal-world data.", "field": "Computer Science", "categories": "cs.SY,cs.LG,eess.SY"}, {"arxiv_id": "2401.10946", "title": "Self context-aware emotion perception on human-robot interaction", "abstract": "Emotion recognition plays a crucial role in various domains of human-robot\ninteraction. In long-term interactions with humans, robots need to respond\ncontinuously and accurately, however, the mainstream emotion recognition\nmethods mostly focus on short-term emotion recognition, disregarding the\ncontext in which emotions are perceived. Humans consider that contextual\ninformation and different contexts can lead to completely different emotional\nexpressions. In this paper, we introduce self context-aware model (SCAM) that\nemploys a two-dimensional emotion coordinate system for anchoring and\nre-labeling distinct emotions. Simultaneously, it incorporates its distinctive\ninformation retention structure and contextual loss. This approach has yielded\nsignificant improvements across audio, video, and multimodal. In the auditory\nmodality, there has been a notable enhancement in accuracy, rising from 63.10%\nto 72.46%. Similarly, the visual modality has demonstrated improved accuracy,\nincreasing from 77.03% to 80.82%. In the multimodal, accuracy has experienced\nan elevation from 77.48% to 78.93%. In the future, we will validate the\nreliability and usability of SCAM on robots through psychology experiments.", "field": "Computer Science", "categories": "cs.HC,cs.AI"}, {"arxiv_id": "2401.10948", "title": "Design Principles & Issues for Gaze and Pinch Interaction", "abstract": "With the imminent release of the Apple Vision Pro, a wave of innovative\ntechnology will be going to get into people's hands. The \"eyes and hands\"\ninterface mixes up interaction design, indicating a need for principles,\nframeworks, and standards. This article highlights 5 design principles and 5\nissues for designing eyes & hands interfaces, drawing insights from both my\npersonal experience and scientific articles in the area of human-computer\ninteraction. Whether you're interested in design, tech, or research in this\nevolving space, the article provides valuable perspectives to enhance your\nunderstanding.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.10949", "title": "The Synergy Between Optimal Transport Theory and Multi-Agent\n  Reinforcement Learning", "abstract": "This paper explores the integration of optimal transport (OT) theory with\nmulti-agent reinforcement learning (MARL). This integration uses OT to handle\ndistributions and transportation problems to enhance the efficiency,\ncoordination, and adaptability of MARL. There are five key areas where OT can\nimpact MARL: (1) policy alignment, where OT's Wasserstein metric is used to\nalign divergent agent strategies towards unified goals; (2) distributed\nresource management, employing OT to optimize resource allocation among agents;\n(3) addressing non-stationarity, using OT to adapt to dynamic environmental\nshifts; (4) scalable multi-agent learning, harnessing OT for decomposing\nlarge-scale learning objectives into manageable tasks; and (5) enhancing energy\nefficiency, applying OT principles to develop sustainable MARL systems. This\npaper articulates how the synergy between OT and MARL can address scalability\nissues, optimize resource distribution, align agent policies in cooperative\nenvironments, and ensure adaptability in dynamically changing conditions.", "field": "Computer Science", "categories": "cs.MA,cs.LG,cs.SY,eess.SY"}, {"arxiv_id": "2401.10953", "title": "How customers' satisfaction change with the use of AR shopping\n  application: A conceptuall model", "abstract": "The paper proposes a conceptual model of how different perceived levels of\nexperiential AR application features have effects on customer experience, and\nin turn their satisfaction and purchase behavior. In addition, it put forward\nthe mediation role of immersion between perceived levels of experiential AR\napplication features and customers experience.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.10956", "title": "AI Revolution on Chat Bot: Evidence from a Randomized Controlled\n  Experiment", "abstract": "In recent years, generative AI has undergone major advancements,\ndemonstrating significant promise in augmenting human productivity. Notably,\nlarge language models (LLM), with ChatGPT-4 as an example, have drawn\nconsiderable attention. Numerous articles have examined the impact of LLM-based\ntools on human productivity in lab settings and designed tasks or in\nobservational studies. Despite recent advances, field experiments applying\nLLM-based tools in realistic settings are limited. This paper presents the\nfindings of a field randomized controlled trial assessing the effectiveness of\nLLM-based tools in providing unmonitored support services for information\nretrieval.", "field": "Computer Science", "categories": "cs.HC,cs.AI,cs.IR"}, {"arxiv_id": "2401.10959", "title": "Machine learning classification of power converter control mode", "abstract": "To ensure the proper functioning of the current and future electrical grid,\nit is necessary for Transmission System Operators (TSOs) to verify that energy\nproviders comply with the grid code and specifications provided by TSOs. A lot\nof energy production are conntected to the grid through a power electronic\ninverter. Grid Forming (GFM) and Grid Following (GFL) are the two types of\noperating modes used to control power electronic converters. The choice of\ncontrol mode by TSOs to avoid impacting the stability of the grid is crucial,\nas is the commitment to these choices by energy suppliers. This article\nproposes a comparison between commonplace machine learning algorithms for\nconverter control mode classification: GFL or GFM. The classification is based\non frequency-domain admittance obtained by external measurement methods. Most\nalgorithms are able to classify accurately when the control structure belongs\nto the training data, but they fail to classify modified control structures\nwith the exception of the random forest algorithm.", "field": "Computer Science", "categories": "eess.SY,cs.SY"}, {"arxiv_id": "2401.10961", "title": "Positive unlabeled learning for building recommender systems in a\n  parliamentary setting", "abstract": "Our goal is to learn about the political interests and preferences of the\nMembers of Parliament by mining their parliamentary activity, in order to\ndevelop a recommendation/filtering system that, given a stream of documents to\nbe distributed among them, is able to decide which documents should receive\neach Member of Parliament. We propose to use positive unlabeled learning to\ntackle this problem, because we only have information about relevant documents\n(the own interventions of each Member of Parliament in the debates) but not\nabout irrelevant documents, so that we cannot use standard binary classifiers\ntrained with positive and negative examples. We have also developed a new\nalgorithm of this type, which compares favourably with: a) the baseline\napproach assuming that all the interventions of other Members of Parliament are\nirrelevant, b) another well-known positive unlabeled learning method and c) an\napproach based on information retrieval methods that matches documents and\nlegislators' representations. The experiments have been carried out with data\nfrom the regional Andalusian Parliament at Spain.", "field": "Computer Science", "categories": "cs.IR"}, {"arxiv_id": "2401.10962", "title": "One Step Learning, One Step Review", "abstract": "Visual fine-tuning has garnered significant attention with the rise of\npre-trained vision models. The current prevailing method, full fine-tuning,\nsuffers from the issue of knowledge forgetting as it focuses solely on fitting\nthe downstream training set. In this paper, we propose a novel weight\nrollback-based fine-tuning method called OLOR (One step Learning, One step\nReview). OLOR combines fine-tuning with optimizers, incorporating a weight\nrollback term into the weight update term at each step. This ensures\nconsistency in the weight range of upstream and downstream models, effectively\nmitigating knowledge forgetting and enhancing fine-tuning performance. In\naddition, a layer-wise penalty is presented to employ penalty decay and the\ndiversified decay rate to adjust the weight rollback levels of layers for\nadapting varying downstream tasks. Through extensive experiments on various\ntasks such as image classification, object detection, semantic segmentation,\nand instance segmentation, we demonstrate the general applicability and\nstate-of-the-art performance of our proposed OLOR. Code is available at\nhttps://github.com/rainbow-xiao/OLOR-AAAI-2024.", "field": "Computer Science", "categories": "cs.CV,cs.LG"}, {"arxiv_id": "2401.10963", "title": "On the selection of the correct number of terms for profile\n  construction: theoretical and empirical analysis", "abstract": "In this paper, we examine the problem of building a user profile from a set\nof documents. This profile will consist of a subset of the most representative\nterms in the documents that best represent user preferences or interests.\nInspired by the discrete concentration theory we have conducted an axiomatic\nstudy of seven properties that a selection function should fulfill: the minimum\nand maximum uncertainty principle, invariant to adding zeros, invariant to\nscale transformations, principle of nominal increase, transfer principle and\nthe richest get richer inequality. We also present a novel selection function\nbased on the use of similarity metrics, and more specifically the cosine\nmeasure which is commonly used in information retrieval, and demonstrate that\nthis verifies six of the properties in addition to a weaker variant of the\ntransfer principle, thereby representing a good selection approach. The\ntheoretical study was complemented with an empirical study to compare the\nperformance of different selection criteria (weight- and unweight-based) using\nreal data in a parliamentary setting. In this study, we analyze the performance\nof the different functions focusing on the two main factors affecting the\nselection process: profile size (number of terms) and weight distribution.\nThese profiles are then used in a document filtering task to show that our\nsimilarity-based approach performs well in terms not only of recommendation\naccuracy but also efficiency (we obtain smaller profiles and consequently\nfaster recommendations).", "field": "Computer Science", "categories": "cs.IR"}, {"arxiv_id": "2401.10965", "title": "Decentralizing Coordination in Open Vehicle Fleets for Scalable and\n  Dynamic Task Allocation", "abstract": "One of the major challenges in the coordination of large, open,\ncollaborative, and commercial vehicle fleets is dynamic task allocation.\nSelf-concerned individually rational vehicle drivers have both local and global\nobjectives, which require coordination using some fair and efficient task\nallocation method. In this paper, we review the literature on scalable and\ndynamic task allocation focusing on deterministic and dynamic two-dimensional\nlinear assignment problems. We focus on multiagent system representation of\nopen vehicle fleets where dynamically appearing vehicles are represented by\nsoftware agents that should be allocated to a set of dynamically appearing\ntasks. We give a comparison and critical analysis of recent research results\nfocusing on centralized, distributed, and decentralized solution approaches.\nMoreover, we propose mathematical models for dynamic versions of the following\nassignment problems well known in combinatorial optimization: the assignment\nproblem, bottleneck assignment problem, fair matching problem, dynamic minimum\ndeviation assignment problem, $\\sum_{k}$-assignment problem, the semiassignment\nproblem, the assignment problem with side constraints, and the assignment\nproblem while recognizing agent qualification; all while considering the main\naspect of open vehicle fleets: random arrival of tasks and vehicles (agents)\nthat may become available after assisting previous tasks or by participating in\nthe fleet at times based on individual interest.", "field": "Computer Science", "categories": "cs.MA,cs.AI,I.2.0"}, {"arxiv_id": "2401.10967", "title": "HOSC: A Periodic Activation Function for Preserving Sharp Features in\n  Implicit Neural Representations", "abstract": "Recently proposed methods for implicitly representing signals such as images,\nscenes, or geometries using coordinate-based neural network architectures often\ndo not leverage the choice of activation functions, or do so only to a limited\nextent. In this paper, we introduce the Hyperbolic Oscillation function (HOSC),\na novel activation function with a controllable sharpness parameter. Unlike any\nprevious activations, HOSC has been specifically designed to better capture\nsudden changes in the input signal, and hence sharp or acute features of the\nunderlying data, as well as smooth low-frequency transitions. Due to its\nsimplicity and modularity, HOSC offers a plug-and-play functionality that can\nbe easily incorporated into any existing method employing a neural network as a\nway of implicitly representing a signal. We benchmark HOSC against other\npopular activations in an array of general tasks, empirically showing an\nimprovement in the quality of obtained representations, provide the\nmathematical motivation behind the efficacy of HOSC, and discuss its\nlimitations.", "field": "Computer Science", "categories": "cs.NE,cs.CV,cs.GR,cs.LG,I.2.10; I.4.10; I.3"}, {"arxiv_id": "2401.10969", "title": "MacroSwarm: A Field-based Compositional Framework for Swarm Programming", "abstract": "Swarm behaviour engineering is an area of research that seeks to investigate\nmethods and techniques for coordinating computation and action within groups of\nsimple agents to achieve complex global goals like pattern formation,\ncollective movement, clustering, and distributed sensing. Despite recent\nprogress in the analysis and engineering of swarms (of drones, robots,\nvehicles), there is still a need for general design and implementation methods\nand tools that can be used to define complex swarm behaviour in a principled\nway. To contribute to this quest, this article proposes a new field-based\ncoordination approach, called MacroSwarm, to design and program swarm behaviour\nin terms of reusable and fully composable functional blocks embedding\ncollective computation and coordination. Based on the macroprogramming paradigm\nof aggregate computing, MacroSwarm builds on the idea of expressing each swarm\nbehaviour block as a pure function mapping sensing fields into actuation goal\nfields, e.g. including movement vectors. In order to demonstrate the\nexpressiveness, compositionality, and practicality of MacroSwarm as a framework\nfor collective intelligence, we perform a variety of simulations covering\ncommon patterns of flocking, morphogenesis, and collective decision-making.", "field": "Computer Science", "categories": "cs.AI,cs.LO,cs.SE"}, {"arxiv_id": "2401.10973", "title": "T2MAC: Targeted and Trusted Multi-Agent Communication through Selective\n  Engagement and Evidence-Driven Integration", "abstract": "Communication stands as a potent mechanism to harmonize the behaviors of\nmultiple agents. However, existing works primarily concentrate on broadcast\ncommunication, which not only lacks practicality, but also leads to information\nredundancy. This surplus, one-fits-all information could adversely impact the\ncommunication efficiency. Furthermore, existing works often resort to basic\nmechanisms to integrate observed and received information, impairing the\nlearning process. To tackle these difficulties, we propose Targeted and Trusted\nMulti-Agent Communication (T2MAC), a straightforward yet effective method that\nenables agents to learn selective engagement and evidence-driven integration.\nWith T2MAC, agents have the capability to craft individualized messages,\npinpoint ideal communication windows, and engage with reliable partners,\nthereby refining communication efficiency. Following the reception of messages,\nthe agents integrate information observed and received from different sources\nat an evidence level. This process enables agents to collectively use evidence\ngarnered from multiple perspectives, fostering trusted and cooperative\nbehaviors. We evaluate our method on a diverse set of cooperative multi-agent\ntasks, with varying difficulties, involving different scales and ranging from\nHallway, MPE to SMAC. The experiments indicate that the proposed model not only\nsurpasses the state-of-the-art methods in terms of cooperative performance and\ncommunication efficiency, but also exhibits impressive generalization.", "field": "Computer Science", "categories": "cs.MA,cs.LG"}, {"arxiv_id": "2401.1099", "title": "A Nonlinear Observer Design for the Discrete-time Systems: Exploiting\n  Matrix-Multiplier-based LMI Approach", "abstract": "This letter focuses on the $\\mathcal{H}_\\infty$ observer design for a class\nof nonlinear discrete systems under the presence of measurement noise or\nexternal disturbances. A novel Linear Matrix Inequality (LMI) condition is\ndeveloped in this method through the utilisation of the reformulated Lipschitz\nproperty, a new variant of Young inequality and the well-known Linear Parameter\nVarying (LPV) approach. One of the key components of the proposed LMI is the\ngeneralised matrix multipliers. The deliberate use of these multipliers enables\nus to introduce more numbers of decision variables inside LMIs than the one\nillustrated in the literature. It aids in adding some extra degrees of freedom\nfrom a feasibility point of view, thus enhancing the LMI conditions. Thus, the\nproposed LMIs are less conservative than existing ones. Later on, the\neffectiveness of the developed LMIs and observer is highlighted through the\nnumerical example and an application of state of charge (SoC) estimation in the\nLi-ion battery model.", "field": "Computer Science", "categories": "eess.SY,cs.SY"}, {"arxiv_id": "2401.10995", "title": "The Radiation Oncology NLP Database", "abstract": "We present the Radiation Oncology NLP Database (ROND), the first dedicated\nNatural Language Processing (NLP) dataset for radiation oncology, an important\nmedical specialty that has received limited attention from the NLP community in\nthe past. With the advent of Artificial General Intelligence (AGI), there is an\nincreasing need for specialized datasets and benchmarks to facilitate research\nand development. ROND is specifically designed to address this gap in the\ndomain of radiation oncology, a field that offers many opportunities for NLP\nexploration. It encompasses various NLP tasks including Logic Reasoning, Text\nClassification, Named Entity Recognition (NER), Question Answering (QA), Text\nSummarization, and Patient-Clinician Conversations, each with a distinct focus\non radiation oncology concepts and application cases. In addition, we have\ndeveloped an instruction-tuning dataset consisting of over 20k instruction\npairs (based on ROND) and trained a large language model, CancerChat. This\nserves to demonstrate the potential of instruction-tuning large language models\nwithin a highly-specialized medical domain. The evaluation results in this\nstudy could serve as baseline results for future research. ROND aims to\nstimulate advancements in radiation oncology and clinical NLP by offering a\nplatform for testing and improving algorithms and models in a domain-specific\ncontext. The ROND dataset is a joint effort of multiple U.S. health\ninstitutions. The data is available at\nhttps://github.com/zl-liu/Radiation-Oncology-NLP-Database.", "field": "Computer Science", "categories": "cs.CL,physics.med-ph"}, {"arxiv_id": "2401.10997", "title": "A Novel and Accurate BiLSTM Configuration Controller for Modular Soft\n  Robots with Module Number Adaptability", "abstract": "Modular soft robots have shown higher potential in sophisticated tasks than\nsingle-module robots. However, the modular structure incurs the complexity of\naccurate control and necessitates a control strategy specifically for modular\nrobots. In this paper, we introduce a data collection strategy and a novel and\naccurate bidirectional LSTM configuration controller for modular soft robots\nwith module number adaptability. Such a controller can control module\nconfigurations in robots with different module numbers. Simulation cable-driven\nrobots and real pneumatic robots have been included in experiments to validate\nthe proposed approaches, and we have proven that our controller can be\nleveraged even with the increase or decrease of module number. This is the\nfirst paper that gets inspiration from the physical structure of modular robots\nand utilizes bidirectional LSTM for module number adaptability. Future work may\ninclude a planning method that bridges the task and configuration spaces and\nthe integration of an online controller.", "field": "Computer Science", "categories": "cs.RO"}, {"arxiv_id": "2401.11002", "title": "Fast Registration of Photorealistic Avatars for VR Facial Animation", "abstract": "Virtual Reality (VR) bares promise of social interactions that can feel more\nimmersive than other media. Key to this is the ability to accurately animate a\nphotorealistic avatar of one's likeness while wearing a VR headset. Although\nhigh quality registration of person-specific avatars to headset-mounted camera\n(HMC) images is possible in an offline setting, the performance of generic\nrealtime models are significantly degraded. Online registration is also\nchallenging due to oblique camera views and differences in modality. In this\nwork, we first show that the domain gap between the avatar and headset-camera\nimages is one of the primary sources of difficulty, where a transformer-based\narchitecture achieves high accuracy on domain-consistent data, but degrades\nwhen the domain-gap is re-introduced. Building on this finding, we develop a\nsystem design that decouples the problem into two parts: 1) an iterative\nrefinement module that takes in-domain inputs, and 2) a generic avatar-guided\nimage-to-image style transfer module that is conditioned on current estimation\nof expression and head pose. These two modules reinforce each other, as image\nstyle transfer becomes easier when close-to-ground-truth examples are shown,\nand better domain-gap removal helps registration. Our system produces\nhigh-quality results efficiently, obviating the need for costly offline\nregistration to generate personalized labels. We validate the accuracy and\nefficiency of our approach through extensive experiments on a commodity\nheadset, demonstrating significant improvements over direct regression methods\nas well as offline registration.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.11008", "title": "Helmholtz-Decomposition and Optical Flow: A new method to characterize\n  GCamP recordings", "abstract": "During deep sleep and under anaesthesia spontaneous patterns of cortical\nactivation frequently take the form of slow travelling waves. Slow wave sleep\nis an important cognitive state especially because of its relevance for memory\nconsolidation. However, despite extensive research the exact mechanisms are\nstill ill-understood. Novel methods such as high speed widefield imaging of\nGCamP activity offer new potentials. Here we show how data recorded from\ntransgenic mice under anesthesia can be processed to analyze sources, sinks and\npatterns of flow. To make the best possible use of the data novel means of data\nprocessing are necessary. Therefore, we (1) give a an brief account on\nprocesses that play a role in generating slow waves and demonstrate (2) a novel\napproach to characterize its patterns in GCamP recordings. While slow waves are\nhighly variable, it shows that some are surprisingly similar. To enable\nquantitative means of analysis and examine the structure of such prototypical\nevents we propose a novel approach for the characterization of slow waves: The\nHelmholtz-Decomposition of gradient-based Dense Optical Flow of the pixeldense\nGCamP contrast (df/f). It allows to detect the sources and sinks of activation\nand discern them from global patterns of neural flow. Aggregated features can\nbe analyzed with variational autoencoders. The results unravel regularities\nbetween slow waves and shows how they relate to the experimental conditions.\nThe approach reveals a complex topology of different features in latent slow\nwave space and identifies prototypical examples for each stage.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11012", "title": "Warum wir es f\u00fcr eine gute Idee gehalten haben, eine\n  DACH-Spieledatenbank aufzubauen", "abstract": "We are in the process of creating a database of digital games from the DACH\nregion. This article provides an insight into the context in which it was\ncreated and the underlying methodological considerations behind the games\ndatabase. The database was compiled collaboratively and lists digital games\ndeveloped in Germany, Austria and Switzerland up to the year 2000. In this\nreport, we outline our initial considerations and the various stages of\nrealisation as well as the input data on which the database was built, the aims\nof the data model and the difficulties we faced during the creation process. We\nthen pin down the current status of the games database and give an outlook on\nthe project's future plans.\n  --\n  Unser Werkstattbericht gibt Einblick in den Entstehungskontext sowie die\nzugrundeliegenden methodischen \\\"Uberlegungen hinter der von den Autor*innen\npublizierten Spieledatenbank. Diese wurde kollaborativ erarbeitet und f\\\"uhrt\ndigitale Spiele, die in Deutschland, \\\"Osterreich und der Schweiz bis zum Jahr\n2000 entwickelt wurden. In diesem Bericht skizzieren wir neben unseren\nAusgangs\\\"uberlegungen und den verschiedenen Arbeitsschritten bei der\nRealisierung au{\\ss}erdem auch, auf welcher Datenbasis die Datenbank aufgebaut\nund gepr\\\"uft wurde, was die Ziele des Datenmodells sind und mit welchen\nSchwierigkeiten wir im Prozess der Erstellung konfrontiert waren. Hiernach\nordnen wir den aktuellen Stand der Spieledatenbank ein und geben einen Ausblick\nauf die weiteren Pl\\\"ane des Projekts.", "field": "Computer Science", "categories": "cs.HC,cs.CY"}, {"arxiv_id": "2401.11013", "title": "Custom Developer GPT for Ethical AI Solutions", "abstract": "The main goal of this project is to create a new software artefact: a custom\nGenerative Pre-trained Transformer (GPT) for developers to discuss and solve\nethical issues through AI engineering. This conversational agent will provide\ndevelopers with practical application on (1) how to comply with legal\nframeworks which regard AI systems (like the EU AI Act~\\cite{aiact} and\nGDPR~\\cite{gdpr}) and (2) present alternate ethical perspectives to allow\ndevelopers to understand and incorporate alternate moral positions. In this\npaper, we provide motivation for the need of such an agent, detail our idea and\ndemonstrate a use case. The use of such a tool can allow practitioners to\nengineer AI solutions which meet legal requirements and satisfy diverse ethical\nperspectives.", "field": "Computer Science", "categories": "cs.SE"}, {"arxiv_id": "2401.11016", "title": "Bounding Consideration Probabilities in Consider-Then-Choose Ranking\n  Models", "abstract": "A common theory of choice posits that individuals make choices in a two-step\nprocess, first selecting some subset of the alternatives to consider before\nmaking a selection from the resulting consideration set. However, inferring\nunobserved consideration sets (or item consideration probabilities) in this\n\"consider then choose\" setting poses significant challenges, because even\nsimple models of consideration with strong independence assumptions are not\nidentifiable, even if item utilities are known. We consider a natural extension\nof consider-then-choose models to a top-$k$ ranking setting, where we assume\nrankings are constructed according to a Plackett-Luce model after sampling a\nconsideration set. While item consideration probabilities remain non-identified\nin this setting, we prove that knowledge of item utilities allows us to infer\nbounds on the relative sizes of consideration probabilities. Additionally,\ngiven a condition on the expected consideration set size, we derive absolute\nupper and lower bounds on item consideration probabilities. We also provide\nalgorithms to tighten those bounds on consideration probabilities by\npropagating inferred constraints. Thus, we show that we can learn useful\ninformation about consideration probabilities despite not being able to\nidentify them precisely. We demonstrate our methods on a ranking dataset from a\npsychology experiment with two different ranking tasks (one with fixed\nconsideration sets and one with unknown consideration sets). This combination\nof data allows us to estimate utilities and then learn about unknown\nconsideration probabilities using our bounds.", "field": "Computer Science", "categories": "cs.LG,cs.MA,econ.EM"}, {"arxiv_id": "2401.11018", "title": "Communication Efficient and Provable Federated Unlearning", "abstract": "We study federated unlearning, a novel problem to eliminate the impact of\nspecific clients or data points on the global model learned via federated\nlearning (FL). This problem is driven by the right to be forgotten and the\nprivacy challenges in FL. We introduce a new framework for exact federated\nunlearning that meets two essential criteria: \\textit{communication efficiency}\nand \\textit{exact unlearning provability}. To our knowledge, this is the first\nwork to tackle both aspects coherently. We start by giving a rigorous\ndefinition of \\textit{exact} federated unlearning, which guarantees that the\nunlearned model is statistically indistinguishable from the one trained without\nthe deleted data. We then pinpoint the key property that enables fast exact\nfederated unlearning: total variation (TV) stability, which measures the\nsensitivity of the model parameters to slight changes in the dataset.\nLeveraging this insight, we develop a TV-stable FL algorithm called\n\\texttt{FATS}, which modifies the classical\n\\texttt{\\underline{F}ed\\underline{A}vg} algorithm for \\underline{T}V\n\\underline{S}tability and employs local SGD with periodic averaging to lower\nthe communication round. We also design efficient unlearning algorithms for\n\\texttt{FATS} under two settings: client-level and sample-level unlearning. We\nprovide theoretical guarantees for our learning and unlearning algorithms,\nproving that they achieve exact federated unlearning with reasonable\nconvergence rates for both the original and unlearned models. We empirically\nvalidate our framework on 6 benchmark datasets, and show its superiority over\nstate-of-the-art methods in terms of accuracy, communication cost, computation\ncost, and unlearning efficacy.", "field": "Computer Science", "categories": "cs.LG,cs.DC"}, {"arxiv_id": "2401.11021", "title": "Analysis and Detection of Multilingual Hate Speech Using Transformer\n  Based Deep Learning", "abstract": "Hate speech is harmful content that directly attacks or promotes hatred\nagainst members of groups or individuals based on actual or perceived aspects\nof identity, such as racism, religion, or sexual orientation. This can affect\nsocial life on social media platforms as hateful content shared through social\nmedia can harm both individuals and communities. As the prevalence of hate\nspeech increases online, the demand for automated detection as an NLP task is\nincreasing. In this work, the proposed method is using transformer-based model\nto detect hate speech in social media, like twitter, Facebook, WhatsApp,\nInstagram, etc. The proposed model is independent of languages and has been\ntested on Italian, English, German, Bengali. The Gold standard datasets were\ncollected from renowned researcher Zeerak Talat, Sara Tonelli, Melanie Siegel,\nand Rezaul Karim. The success rate of the proposed model for hate speech\ndetection is higher than the existing baseline and state-of-the-art models with\naccuracy in Bengali dataset is 89%, in English: 91%, in German dataset 91% and\nin Italian dataset it is 77%. The proposed algorithm shows substantial\nimprovement to the benchmark method.", "field": "Computer Science", "categories": "cs.CL,cs.AI"}, {"arxiv_id": "2401.11022", "title": "Formulating or Fixating: Effects of Examples on Problem Solving Vary as\n  a Function of Example Presentation Interface Design", "abstract": "Interactive systems that facilitate exposure to examples can augment problem\nsolving performance. However designers of such systems are often faced with\nmany practical design decisions about how users will interact with examples,\nwith little clear theoretical guidance. To understand how example interaction\ndesign choices affect whether/how people benefit from examples, we conducted an\nexperiment where 182 participants worked on a controlled analog to an\nexploratory creativity task, with access to examples of varying diversity and\npresentation interfaces. Task performance was worse when examples were\npresented in a list, compared to contextualized in the exploration space or\nshown in a dropdown list. Example lists were associated with more fixation,\nwhereas contextualized examples were associated with using examples to\nformulate a model of the problem space to guide exploration. We discuss\nimplications of these results for a theoretical framework that maps design\nchoices to fundamental psychological mechanisms of creative inspiration from\nexamples.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.11029", "title": "Optimization of the Context-Free Language Reachability Matrix-Based\n  Algorithm", "abstract": "Various static analysis problems are reformulated as instances of the\nContext-Free Language Reachability (CFL-r) problem. One promising way to make\nsolving CFL-r more practical for large-scale interprocedural graphs is to\nreduce CFL-r to linear algebra operations on sparse matrices, as they are\nefficiently executed on modern hardware. In this work, we present five\noptimizations for a matrix-based CFL-r algorithm that utilize the specific\nproperties of both the underlying semiring and the widely-used linear algebra\nlibrary SuiteSparse:GraphBlas. Our experimental results show that these\noptimizations result in orders of magnitude speedup, with the optimized\nmatrix-based CFL-r algorithm consistently outperforming state-of-the-art CFL-r\nsolvers across four considered static analyses.", "field": "Computer Science", "categories": "cs.PL"}, {"arxiv_id": "2401.1103", "title": "Exploring Highly Quantised Neural Networks for Intrusion Detection in\n  Automotive CAN", "abstract": "Vehicles today comprise intelligent systems like connected autonomous driving\nand advanced driving assistance systems (ADAS) to enhance the driving\nexperience, which is enabled through increased connectivity to infrastructure\nand fusion of information from different sensing modes. However, the rising\nconnectivity coupled with the legacy network architecture within vehicles can\nbe exploited for launching active and passive attacks on critical vehicle\nsystems and directly affecting the safety of passengers. Machine learning-based\nintrusion detection models have been shown to successfully detect multiple\ntargeted attack vectors in recent literature, whose deployments are enabled\nthrough quantised neural networks targeting low-power platforms. Multiple\nmodels are often required to simultaneously detect multiple attack vectors,\nincreasing the area, (resource) cost, and energy consumption. In this paper, we\npresent a case for utilising custom-quantised MLP's (CQMLP) as a multi-class\nclassification model, capable of detecting multiple attacks from the benign\nflow of controller area network (CAN) messages. The specific quantisation and\nneural architecture are determined through a joint design space exploration,\nresulting in our choice of the 2-bit precision and the n-layer MLP. Our 2-bit\nversion is trained using Brevitas and optimised as a dataflow hardware model\nthrough the FINN toolflow from AMD/Xilinx, targeting an XCZU7EV device. We show\nthat the 2-bit CQMLP model, when integrated as the IDS, can detect malicious\nattack messages (DoS, fuzzing, and spoofing attack) with a very high accuracy\nof 99.9%, on par with the state-of-the-art methods in the literature.\nFurthermore, the dataflow model can perform line rate detection at a latency of\n0.11 ms from message reception while consuming 0.23 mJ/inference, making it\nideally suited for integration with an ECU in critical CAN networks.", "field": "Computer Science", "categories": "cs.CR,cs.AR,cs.LG,cs.SY,eess.SY"}, {"arxiv_id": "2401.11032", "title": "PressProtect: Helping Journalists Navigate Social Media in the Face of\n  Online Harassment", "abstract": "Social media has become a critical tool for journalists to disseminate their\nwork, engage with their audience, and connect with sources. Unfortunately,\njournalists also regularly endure significant online harassment on social media\nplatforms, ranging from personal attacks to doxxing to threats of physical\nharm. In this paper, we seek to understand how we can make social media usable\nfor journalists who face constant digital harassment. To begin, we conduct a\nset of need-finding interviews to understand where existing platform tools and\nnewsroom resources fall short in adequately protecting journalists. We map\njournalists' unmet needs to concrete design goals, which we use to build\nPressProtect, an interface that provides journalists greater agency over\nengaging with readers on Twitter/X. Through user testing with eight\njournalists, we evaluate PressProtect and find that participants felt it\neffectively protected them against harassment and could also generalize to\nserve other visible and vulnerable groups. We conclude with a discussion of our\nfindings and recommendations for social platforms hoping to build defensive\ndefaults for journalists facing online harassment.", "field": "Computer Science", "categories": "cs.CY,cs.HC"}, {"arxiv_id": "2401.11033", "title": "FAIR Enough: How Can We Develop and Assess a FAIR-Compliant Dataset for\n  Large Language Models' Training?", "abstract": "Advancements in Large Language Models (LLMs) highlight the need for ethical\npractices and data integrity. We introduce a framework that embeds FAIR\n(Findable, Accessible, Interoperable, Reusable) data principles into LLM\ntraining. This approach marks a shift towards practices compliant with FAIR\nstandards. Our framework presents guidelines for integrating FAIR data\nprinciples into LLM training. This initiative includes a checklist for\nresearchers and developers. We also demonstrate its practical application\nthrough a case study focused on bias identification and mitigation in our\nFAIR-compliant dataset. This work is a significant contribution to AI ethics\nand data science, advocating for balanced and ethical training methods in LLMs.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.11035", "title": "Image Safeguarding: Reasoning with Conditional Vision Language Model and\n  Obfuscating Unsafe Content Counterfactually", "abstract": "Social media platforms are being increasingly used by malicious actors to\nshare unsafe content, such as images depicting sexual activity, cyberbullying,\nand self-harm. Consequently, major platforms use artificial intelligence (AI)\nand human moderation to obfuscate such images to make them safer. Two critical\nneeds for obfuscating unsafe images is that an accurate rationale for\nobfuscating image regions must be provided, and the sensitive regions should be\nobfuscated (\\textit{e.g.} blurring) for users' safety. This process involves\naddressing two key problems: (1) the reason for obfuscating unsafe images\ndemands the platform to provide an accurate rationale that must be grounded in\nunsafe image-specific attributes, and (2) the unsafe regions in the image must\nbe minimally obfuscated while still depicting the safe regions. In this work,\nwe address these key issues by first performing visual reasoning by designing a\nvisual reasoning model (VLM) conditioned on pre-trained unsafe image\nclassifiers to provide an accurate rationale grounded in unsafe image\nattributes, and then proposing a counterfactual explanation algorithm that\nminimally identifies and obfuscates unsafe regions for safe viewing, by first\nutilizing an unsafe image classifier attribution matrix to guide segmentation\nfor a more optimal subregion segmentation followed by an informed greedy search\nto determine the minimum number of subregions required to modify the\nclassifier's output based on attribution score. Extensive experiments on\nuncurated data from social networks emphasize the efficacy of our proposed\nmethod. We make our code available at:\nhttps://github.com/SecureAIAutonomyLab/ConditionalVLM", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11037", "title": "Equivariant Graph Neural Operator for Modeling 3D Dynamics", "abstract": "Modeling the complex three-dimensional (3D) dynamics of relational systems is\nan important problem in the natural sciences, with applications ranging from\nmolecular simulations to particle mechanics. Machine learning methods have\nachieved good success by learning graph neural networks to model spatial\ninteractions. However, these approaches do not faithfully capture temporal\ncorrelations since they only model next-step predictions. In this work, we\npropose Equivariant Graph Neural Operator (EGNO), a novel and principled method\nthat directly models dynamics as trajectories instead of just next-step\nprediction. Different from existing methods, EGNO explicitly learns the\ntemporal evolution of 3D dynamics where we formulate the dynamics as a function\nover time and learn neural operators to approximate it. To capture the temporal\ncorrelations while keeping the intrinsic SE(3)-equivariance, we develop\nequivariant temporal convolutions parameterized in the Fourier space and build\nEGNO by stacking the Fourier layers over equivariant networks. EGNO is the\nfirst operator learning framework that is capable of modeling solution dynamics\nfunctions over time while retaining 3D equivariance. Comprehensive experiments\nin multiple domains, including particle simulations, human motion capture, and\nmolecular dynamics, demonstrate the significantly superior performance of EGNO\nagainst existing methods, thanks to the equivariant temporal modeling.", "field": "Computer Science", "categories": "cs.LG,cs.NA,math.NA,q-bio.QM"}, {"arxiv_id": "2401.1104", "title": "Design Frameworks for Spatial Zone Agents in XRI Metaverse Smart\n  Environments", "abstract": "The spatial XR-IoT (XRI) Zone Agents concept combines Extended Reality (XR),\nthe Internet of Things (IoT), and spatial computing concepts to create\nhyper-connected spaces for metaverse applications; envisioning space as zones\nthat are social, smart, scalable, expressive, and agent-based. These zone\nagents serve as applications and agents (partners, assistants, or guides) for\nusers co-living and co-operating together in a shared spatial context. The zone\nagent concept is toward reducing the gap between the physical environment\n(space) and the classical two-dimensional user interface, through space-based\ninteractions for future metaverse applications. This integration aims to enrich\nuser engagement with their environments through intuitive and immersive\nexperiences and pave the way for innovative human-machine interaction in smart\nspaces. Contributions include: i) a theoretical framework for creating XRI\nzone/space-agents using Mixed-Reality Agents (MiRAs) and XRI theory, ii) agent\nand scene design for spatial zone agents, and iii) prototype and user\ninteraction design scenario concepts for human-to-space agent relationships in\nan early immersive smart-space application.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.11042", "title": "Does Using ChatGPT Result in Human Cognitive Augmentation?", "abstract": "Human cognitive performance is enhanced by the use of tools. For example, a\nhuman can produce a much greater, and more accurate, volume of mathematical\ncalculation in a unit of time using a calculator or a spreadsheet application\non a computer. Such tools have taken over the burden of lower level cognitive\ngrunt work but the human still serves the role of the expert performing higher\nlevel thinking and reasoning. Recently, however, unsupervised, deep, machine\nlearning has produced cognitive systems able to outperform humans in several\ndomains. When humans use these tools in a human cog ensemble, the cognitive\nability of the human is augmented. In some cases, even non experts can achieve,\nand even exceed, the performance of experts in a particular domain, synthetic\nexpertise. A new cognitive system, ChatGPT, has burst onto the scene during the\npast year. This paper investigates human cognitive augmentation due to using\nChatGPT by presenting the results of two experiments comparing responses\ncreated using ChatGPT with results created not using ChatGPT. We find using\nChatGPT does not always result in cognitive augmentation and does not yet\nreplace human judgement, discernment, and evaluation in certain types of tasks.\nIn fact, ChatGPT was observed to result in misleading users resulting in\nnegative cognitive augmentation.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.11044", "title": "The Significance of Data Abstraction Methods in Machine Learning\n  Classification Processes for Critical Decision-Making", "abstract": "The applicability of widely adopted machine learning (ML) methods to\nclassification is circumscribed by the imperatives of explicability and\nuncertainty, particularly evident in domains such as healthcare, behavioural\nsciences, and finances, wherein accountability assumes priority. Recently,\nSmall and Incomplete Dataset Analyser (SaNDA) has been proposed to enhance the\nability to perform classification in such domains, by developing a data\nabstraction protocol using a ROC curve-based method. This paper focuses on\ncolumn-wise data transformations called abstractions, which are crucial for\nSaNDA's classification process and explores alternative abstractions protocols,\nsuch as constant binning and quantiles. The best-performing methods have been\ncompared against Random Forest as a baseline for explainable methods. The\nresults suggests that SaNDA can be a viable substitute for Random Forest when\ndata is incomplete, even with minimal missing values. It consistently maintains\nhigh accuracy even when half of the dataset is missing, unlike Random Forest\nwhich experiences a significant decline in accuracy under similar conditions.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.11048", "title": "PubTator 3.0: an AI-powered Literature Resource for Unlocking Biomedical\n  Knowledge", "abstract": "PubTator 3.0 (https://www.ncbi.nlm.nih.gov/research/pubtator3/) is a\nbiomedical literature resource using state-of-the-art AI techniques to offer\nsemantic and relation searches for key concepts like proteins, genetic\nvariants, diseases, and chemicals. It currently provides over one billion\nentity and relation annotations across approximately 36 million PubMed\nabstracts and 6 million full-text articles from the PMC open access subset,\nupdated weekly. PubTator 3.0's online interface and API utilize these\nprecomputed entity relations and synonyms to provide advanced search\ncapabilities and enable large-scale analyses, streamlining many complex\ninformation needs. We showcase the retrieval quality of PubTator 3.0 using a\nseries of entity pair queries, demonstrating that PubTator 3.0 retrieves a\ngreater number of articles than either PubMed or Google Scholar, with higher\nprecision in the top 20 results. We further show that integrating ChatGPT\n(GPT-4) with PubTator APIs dramatically improves the factuality and\nverifiability of its responses. In summary, PubTator 3.0 offers a comprehensive\nset of features and tools that allow researchers to navigate the ever-expanding\nwealth of biomedical literature, expediting research and unlocking valuable\ninsights for scientific discovery.", "field": "Computer Science", "categories": "cs.CL,q-bio.QM"}, {"arxiv_id": "2401.11052", "title": "Mining experimental data from Materials Science literature with Large\n  Language Models", "abstract": "This study is dedicated to evaluating the capabilities of advanced large\nlanguage models (LLMs) such as GPT-3.5-Turbo, GPT-4, and GPT-4-Turbo in the\nextraction of structured information from scientific documents within the field\nof materials science. We introduce a novel methodology for the comparative\nanalysis of intricate material expressions, emphasising the standardisation of\nchemical formulas to tackle the complexities inherent in materials science\ninformation assessment. To this end, we primarily focus on two critical tasks\nof information extraction: (i) a named entity recognition (NER) of studied\nmaterials and physical properties and (ii) a relation extraction (RE) between\nthese entities. The performance of LLMs in executing these tasks is benchmarked\nagainst traditional models based on the BERT architecture and rule-based\napproaches. For NER, LLMs fail to outperform the baseline with zero-shot\nprompting and exhibit only limited improvement with few-shot prompting.\nHowever, for RE, a GPT-3.5-Turbo fine-tuned with the appropriate strategy\noutperforms all models, including the baseline. Without any fine-tuning, GPT-4\nand GPT-4-Turbo display remarkable reasoning and relationship extraction\ncapabilities after being provided with merely a couple of examples, surpassing\nthe baseline. Overall, the results suggest that although LLMs demonstrate\nrelevant reasoning skills in connecting concepts, for tasks requiring\nextracting complex domain-specific entities like materials, specialised models\nare currently a better choice.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.11058", "title": "Low Complexity Turbo SIC-MMSE Detection for Orthogonal Time Frequency\n  Space Modulation", "abstract": "Recently, orthogonal time frequency space (OTFS) modulation has garnered\nconsiderable attention due to its robustness against doubly-selective wireless\nchannels. In this paper, we propose a low-complexity iterative successive\ninterference cancellation based minimum mean squared error (SIC-MMSE) detection\nalgorithm for zero-padded OTFS (ZP-OTFS) modulation. In the proposed algorithm,\nsignals are detected based on layers processed by multiple SIC-MMSE linear\nfilters for each sub-channel, with interference on the targeted signal layer\nbeing successively canceled either by hard or soft information. To reduce the\ncomplexity of computing individual layer filter coefficients, we also propose a\nnovel filter coefficients recycling approach in place of generating the exact\nform of MMSE filter weights. Moreover, we design a joint detection and decoding\nalgorithm for ZP-OTFS to enhance error performance. Compared to the\nconventional SIC-MMSE detection, our proposed algorithms outperform other\nlinear detectors, e.g., maximal ratio combining (MRC), for ZP-OTFS with up to 3\ndB gain while maintaining comparable computation complexity.", "field": "Computer Science", "categories": "cs.IT,eess.SP,math.IT"}, {"arxiv_id": "2401.11061", "title": "PhotoBot: Reference-Guided Interactive Photography via Natural Language", "abstract": "We introduce PhotoBot, a framework for automated photo acquisition based on\nan interplay between high-level human language guidance and a robot\nphotographer. We propose to communicate photography suggestions to the user via\na reference picture that is retrieved from a curated gallery. We exploit a\nvisual language model (VLM) and an object detector to characterize reference\npictures via textual descriptions and use a large language model (LLM) to\nretrieve relevant reference pictures based on a user's language query through\ntext-based reasoning. To correspond the reference picture and the observed\nscene, we exploit pre-trained features from a vision transformer capable of\ncapturing semantic similarity across significantly varying images. Using these\nfeatures, we compute pose adjustments for an RGB-D camera by solving a\nPerspective-n-Point (PnP) problem. We demonstrate our approach on a real-world\nmanipulator equipped with a wrist camera. Our user studies show that photos\ntaken by PhotoBot are often more aesthetically pleasing than those taken by\nusers themselves, as measured by human feedback.", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.RO"}, {"arxiv_id": "2401.11062", "title": "Learned Image resizing with efficient training (LRET) facilitates\n  improved performance of large-scale digital histopathology image\n  classification models", "abstract": "Histologic examination plays a crucial role in oncology research and\ndiagnostics. The adoption of digital scanning of whole slide images (WSI) has\ncreated an opportunity to leverage deep learning-based image classification\nmethods to enhance diagnosis and risk stratification. Technical limitations of\ncurrent approaches to training deep convolutional neural networks (DCNN) result\nin suboptimal model performance and make training and deployment of\ncomprehensive classification models unobtainable. In this study, we introduce a\nnovel approach that addresses the main limitations of traditional\nhistopathology classification model training. Our method, termed Learned\nResizing with Efficient Training (LRET), couples efficient training techniques\nwith image resizing to facilitate seamless integration of larger histology\nimage patches into state-of-the-art classification models while preserving\nimportant structural information.\n  We used the LRET method coupled with two distinct resizing techniques to\ntrain three diverse histology image datasets using multiple diverse DCNN\narchitectures. Our findings demonstrate a significant enhancement in\nclassification performance and training efficiency. Across the spectrum of\nexperiments, LRET consistently outperforms existing methods, yielding a\nsubstantial improvement of 15-28% in accuracy for a large-scale, multiclass\ntumor classification task consisting of 74 distinct brain tumor types. LRET not\nonly elevates classification accuracy but also substantially reduces training\ntimes, unlocking the potential for faster model development and iteration. The\nimplications of this work extend to broader applications within medical imaging\nand beyond, where efficient integration of high-resolution images into deep\nlearning pipelines is paramount for driving advancements in research and\nclinical practice.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11063", "title": "The Best Ends for the Best Means: Ethical Concerns in App Reviews", "abstract": "This work analyzes ethical concerns found in users' app store reviews. We\nperformed this study because ethical concerns in mobile applications (apps) are\nwidespread, pose severe threats to end users and society, and lack systematic\nanalysis and methods for detection and classification. In addition, app store\nreviews allow practitioners to collect users' perspectives, crucial for\nidentifying software flaws, from a geographically distributed and large-scale\naudience. For our analysis, we collected five million user reviews, developed a\nset of ethical concerns representative of user preferences, and manually\nlabeled a sample of these reviews. We found that (1) users highly report\nethical concerns about censorship, identity theft, and safety (2) user reviews\nwith ethical concerns are longer, more popular, and lowly rated, and (3) there\nis high automation potential for the classification and filtering of these\nreviews. Our results highlight the relevance of using app store reviews for the\nsystematic consideration of ethical concerns during software evolution.", "field": "Computer Science", "categories": "cs.SE,cs.HC"}, {"arxiv_id": "2401.11064", "title": "Low-Complexity Integer Divider Architecture for Homomorphic Encryption", "abstract": "Homomorphic encryption (HE) allows computations to be directly carried out on\nciphertexts and enables privacy-preserving cloud computing. The computations on\nthe coefficients of the polynomials involved in HE are always followed by\nmodular reduction, and the overall complexity of ciphertext multiplication can\nbe reduced by utilizing the quotient. Our previous design considers the cases\nthat the dividend is an integer multiple of the modulus and the modulus is in\nthe format of $2^w-2^u\\pm1$, where $u<w/2$. In this paper, the division is\ngeneralized for larger $u$ and dividend not an integer multiple of the modulus.\nAn algorithm is proposed to compute the quotient and vigorous mathematical\nproofs are provided. Moreover, efficient hardware architecture is developed for\nimplementing the proposed algorithm. Compared to alternative division\napproaches that utilize the inverse of the divisor, for $w=32$, the proposed\ndesign achieves at least 9% shorter latency and 79\\% area reduction for 75%\npossible values of $u$.", "field": "Computer Science", "categories": "cs.CR,cs.AR"}, {"arxiv_id": "2401.11067", "title": "Make-A-Shape: a Ten-Million-scale 3D Shape Model", "abstract": "Significant progress has been made in training large generative models for\nnatural language and images. Yet, the advancement of 3D generative models is\nhindered by their substantial resource demands for training, along with\ninefficient, non-compact, and less expressive representations. This paper\nintroduces Make-A-Shape, a new 3D generative model designed for efficient\ntraining on a vast scale, capable of utilizing 10 millions publicly-available\nshapes. Technical-wise, we first innovate a wavelet-tree representation to\ncompactly encode shapes by formulating the subband coefficient filtering scheme\nto efficiently exploit coefficient relations. We then make the representation\ngeneratable by a diffusion model by devising the subband coefficients packing\nscheme to layout the representation in a low-resolution grid. Further, we\nderive the subband adaptive training strategy to train our model to effectively\nlearn to generate coarse and detail wavelet coefficients. Last, we extend our\nframework to be controlled by additional input conditions to enable it to\ngenerate shapes from assorted modalities, e.g., single/multi-view images, point\nclouds, and low-resolution voxels. In our extensive set of experiments, we\ndemonstrate various applications, such as unconditional generation, shape\ncompletion, and conditional generation on a wide range of modalities. Our\napproach not only surpasses the state of the art in delivering high-quality\nresults but also efficiently generates shapes within a few seconds, often\nachieving this in just 2 seconds for most conditions.", "field": "Computer Science", "categories": "cs.CV,cs.GR"}, {"arxiv_id": "2401.11074", "title": "On The Temporal Domain of Differential Equation Inspired Graph Neural\n  Networks", "abstract": "Graph Neural Networks (GNNs) have demonstrated remarkable success in modeling\ncomplex relationships in graph-structured data. A recent innovation in this\nfield is the family of Differential Equation-Inspired Graph Neural Networks\n(DE-GNNs), which leverage principles from continuous dynamical systems to model\ninformation flow on graphs with built-in properties such as feature smoothing\nor preservation. However, existing DE-GNNs rely on first or second-order\ntemporal dependencies. In this paper, we propose a neural extension to those\npre-defined temporal dependencies. We show that our model, called TDE-GNN, can\ncapture a wide range of temporal dynamics that go beyond typical first or\nsecond-order methods, and provide use cases where existing temporal models are\nchallenged. We demonstrate the benefit of learning the temporal dependencies\nusing our method rather than using pre-defined temporal dynamics on several\ngraph benchmarks.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.11076", "title": "Optimal Control of Malware Propagation in IoT Networks", "abstract": "The rapid proliferation of Internet of Things (IoT) devices in recent years\nhas resulted in a significant surge in the number of cyber-attacks targeting\nthese devices. Recent data indicates that the number of such attacks has\nincreased by over 100 percent, highlighting the urgent need for robust\ncybersecurity measures to mitigate these threats. In addition, a cyber-attack\nwill begin to spread malware across the network once it has successfully\ncompromised an IoT network. However, to mitigate this attack, a new patch must\nbe applied immediately. In reality, the time required to prepare and apply the\nnew patch can vary significantly depending on the nature of the cyber-attack.\nIn this paper, we address the issue of how to mitigate cyber-attacks before the\nnew patch is applied by formulating an optimal control strategy that reduces\nthe impact of malware propagation and minimise the number of infected devices\nacross IoT networks in the smart home. A novel node-based epidemiological model\nsusceptible, infected high, infected low, recover first, and recover\ncomplete(SI_HI_LR_FR_C) is established with immediate response state for the\nrestricted environment. After that, the impact of malware on IoT devices using\nboth high and low infected rates will be analyzed. Finally, to illustrate the\nmain results, several numerical analyses are carried out in addition to\nsimulate the real-world scenario of IoT networks in the smart home, we built a\ndataset to be used in the experiments.", "field": "Computer Science", "categories": "cs.CR"}, {"arxiv_id": "2401.11077", "title": "Chance-Constrained, Drift-Safe Guidance for Spacecraft Rendezvous", "abstract": "A robust drift-safe rendezvous trajectory optimization tool is developed in\nthis work, with applications to orbital rendezvous and proximity operations.\nThe method is based on direct collocation and utilizes a sequential convex\nprogramming framework, and is extended from previous work to include passive\nsafety constraints. The tool is then paired with a dispersion analysis\nframework to allow trajectories to be optimized subject to plant, navigation,\nand actuator uncertainties. The timing, direction, and magnitude of orbital\nmaneuvers are optimized subject to the expected propellant usage, for a given\nnavigation system performance. Representative trajectories are presented for\nthe LEO flight regime, but the approach can also be applied to GEO and NRHO\nwith minimal modification.", "field": "Computer Science", "categories": "eess.SY,cs.SY"}, {"arxiv_id": "2401.11078", "title": "UltrAvatar: A Realistic Animatable 3D Avatar Diffusion Model with\n  Authenticity Guided Textures", "abstract": "Recent advances in 3D avatar generation have gained significant attentions.\nThese breakthroughs aim to produce more realistic animatable avatars, narrowing\nthe gap between virtual and real-world experiences. Most of existing works\nemploy Score Distillation Sampling (SDS) loss, combined with a differentiable\nrenderer and text condition, to guide a diffusion model in generating 3D\navatars. However, SDS often generates oversmoothed results with few facial\ndetails, thereby lacking the diversity compared with ancestral sampling. On the\nother hand, other works generate 3D avatar from a single image, where the\nchallenges of unwanted lighting effects, perspective views, and inferior image\nquality make them difficult to reliably reconstruct the 3D face meshes with the\naligned complete textures. In this paper, we propose a novel 3D avatar\ngeneration approach termed UltrAvatar with enhanced fidelity of geometry, and\nsuperior quality of physically based rendering (PBR) textures without unwanted\nlighting. To this end, the proposed approach presents a diffuse color\nextraction model and an authenticity guided texture diffusion model. The former\nremoves the unwanted lighting effects to reveal true diffuse colors so that the\ngenerated avatars can be rendered under various lighting conditions. The latter\nfollows two gradient-based guidances for generating PBR textures to render\ndiverse face-identity features and details better aligning with 3D mesh\ngeometry. We demonstrate the effectiveness and robustness of the proposed\nmethod, outperforming the state-of-the-art methods by a large margin in the\nexperiments.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11081", "title": "Learning from Aggregate responses: Instance Level versus Bag Level Loss\n  Functions", "abstract": "Due to the rise of privacy concerns, in many practical applications the\ntraining data is aggregated before being shared with the learner, in order to\nprotect privacy of users' sensitive responses. In an aggregate learning\nframework, the dataset is grouped into bags of samples, where each bag is\navailable only with an aggregate response, providing a summary of individuals'\nresponses in that bag. In this paper, we study two natural loss functions for\nlearning from aggregate responses: bag-level loss and the instance-level loss.\nIn the former, the model is learnt by minimizing a loss between aggregate\nresponses and aggregate model predictions, while in the latter the model aims\nto fit individual predictions to the aggregate responses. In this work, we show\nthat the instance-level loss can be perceived as a regularized form of the\nbag-level loss. This observation lets us compare the two approaches with\nrespect to bias and variance of the resulting estimators, and introduce a novel\ninterpolating estimator which combines the two approaches. For linear\nregression tasks, we provide a precise characterization of the risk of the\ninterpolating estimator in an asymptotic regime where the size of the training\nset grows in proportion to the features dimension. Our analysis allows us to\ntheoretically understand the effect of different factors, such as bag size on\nthe model prediction risk. In addition, we propose a mechanism for\ndifferentially private learning from aggregate responses and derive the optimal\nbag size in terms of prediction risk-privacy trade-off. We also carry out\nthorough experiments to corroborate our theory and show the efficacy of the\ninterpolating estimator.", "field": "Computer Science", "categories": "cs.LG,cs.AI,math.ST,stat.ML,stat.TH"}, {"arxiv_id": "2401.11084", "title": "Interference-Aware Queuing Analysis for Distributed Transmission Control\n  in UAV Networks", "abstract": "In this paper, we investigate the problem of distributed transmission control\nfor unmanned aerial vehicles (UAVs) operating in unlicensed spectrum bands. We\ndevelop a rigorous interference-aware queuing analysis framework that jointly\nconsiders two inter-dependent factors: (i) limited-size queues with\ndelay-constrained packet arrival, and (ii) in-band interference introduced by\nother ground/aerial users. We aim to optimize the expected throughput by\njointly analyzing these factors. In the queuing analysis, we explore two packet\nloss probabilities including, buffer overflow model and time threshold model.\nFor interference analysis, we investigate the outage probability and packet\nlosses due to low signal-to-interference-plus-noise ratio (SINR). We introduce\ntwo algorithms namely, Interference-Aware Transmission Control (IA-TC), and\nInterference-Aware Distributed Transmission Control (IA-DTC). These algorithms\nmaximize the expected throughput by adjusting transmission policies to balance\nthe trade-offs between packet drop from queues vs. transmission errors due to\nlow SINRs. We implement the proposed algorithms and demonstrate that the\noptimal transmission policy under various scenarios is found.", "field": "Computer Science", "categories": "cs.IT,math.IT"}, {"arxiv_id": "2401.11085", "title": "Adaptive Global-Local Representation Learning and Selection for\n  Cross-Domain Facial Expression Recognition", "abstract": "Domain shift poses a significant challenge in Cross-Domain Facial Expression\nRecognition (CD-FER) due to the distribution variation across different\ndomains. Current works mainly focus on learning domain-invariant features\nthrough global feature adaptation, while neglecting the transferability of\nlocal features. Additionally, these methods lack discriminative supervision\nduring training on target datasets, resulting in deteriorated feature\nrepresentation in target domain. To address these limitations, we propose an\nAdaptive Global-Local Representation Learning and Selection (AGLRLS) framework.\nThe framework incorporates global-local adversarial adaptation and\nsemantic-aware pseudo label generation to enhance the learning of\ndomain-invariant and discriminative feature during training. Meanwhile, a\nglobal-local prediction consistency learning is introduced to improve\nclassification results during inference. Specifically, the framework consists\nof separate global-local adversarial learning modules that learn\ndomain-invariant global and local features independently. We also design a\nsemantic-aware pseudo label generation module, which computes semantic labels\nbased on global and local features. Moreover, a novel dynamic threshold\nstrategy is employed to learn the optimal thresholds by leveraging independent\nprediction of global and local features, ensuring filtering out the unreliable\npseudo labels while retaining reliable ones. These labels are utilized for\nmodel optimization through the adversarial learning process in an end-to-end\nmanner. During inference, a global-local prediction consistency module is\ndeveloped to automatically learn an optimal result from multiple predictions.\nWe conduct comprehensive experiments and analysis based on a fair evaluation\nbenchmark. The results demonstrate that the proposed framework outperforms the\ncurrent competing methods by a substantial margin.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.11089", "title": "FedRKG: A Privacy-preserving Federated Recommendation Framework via\n  Knowledge Graph Enhancement", "abstract": "Federated Learning (FL) has emerged as a promising approach for preserving\ndata privacy in recommendation systems by training models locally. Recently,\nGraph Neural Networks (GNN) have gained popularity in recommendation tasks due\nto their ability to capture high-order interactions between users and items.\nHowever, privacy concerns prevent the global sharing of the entire user-item\ngraph. To address this limitation, some methods create pseudo-interacted items\nor users in the graph to compensate for missing information for each client.\nUnfortunately, these methods introduce random noise and raise privacy concerns.\nIn this paper, we propose FedRKG, a novel federated recommendation system,\nwhere a global knowledge graph (KG) is constructed and maintained on the server\nusing publicly available item information, enabling higher-order user-item\ninteractions. On the client side, a relation-aware GNN model leverages diverse\nKG relationships. To protect local interaction items and obscure gradients, we\nemploy pseudo-labeling and Local Differential Privacy (LDP). Extensive\nexperiments conducted on three real-world datasets demonstrate the competitive\nperformance of our approach compared to centralized algorithms while ensuring\nprivacy preservation. Moreover, FedRKG achieves an average accuracy improvement\nof 4% compared to existing federated learning baselines.", "field": "Computer Science", "categories": "cs.CR,cs.AI,cs.DC,cs.IR"}, {"arxiv_id": "2401.1109", "title": "Sharing Energy in Wide Area: A Two-Layer Energy Sharing Scheme for\n  Massive Prosumers", "abstract": "The popularization of distributed energy resources transforms end-users from\nconsumers into prosumers. Inspired by the sharing economy principle, energy\nsharing markets for prosumers are proposed to facilitate the utilization of\nrenewable energy. This paper proposes a novel two-layer energy sharing market\nfor massive prosumers, which can promote social efficiency by wider-area\nsharing. In this market, there is an upper-level wide-area market (WAM) in the\ndistribution system and numerous lower-level local-area markets (LAMs) in\ncommunities. Prosumers in the same community share energy with each other in\nthe LAM, which can be uncleared. The energy surplus and shortage of LAMs are\ncleared in the WAM. Thanks to the wide-area two-layer structure, the market\noutcome is near-social-optimal in large-scale systems. However, the proposed\nmarket forms a complex mathematical program with equilibrium constraints\n(MPEC). To solve the problem, we propose an efficient and hierarchically\ndistributed bidding algorithm. The proposed two-layer market and bidding\nalgorithm are verified on the IEEE 123-bus system with 11250 prosumers, which\ndemonstrates the practicality and efficiency for large-scale markets.", "field": "Computer Science", "categories": "cs.GT,cs.SY,eess.SY,math.OC"}, {"arxiv_id": "2401.11092", "title": "Boidae: Your Personal Mining Platform", "abstract": "Mining software repositories is a useful technique for researchers and\npractitioners to see what software developers actually do when developing\nsoftware. Tools like Boa provide users with the ability to easily mine these\nopen-source software repositories at a very large scale, with datasets\ncontaining hundreds of thousands of projects. The trade-off is that users must\nuse the provided infrastructure, query language, runtime, and datasets and this\nmight not fit all analysis needs. In this work, we present Boidae: a family of\nBoa installations controlled and customized by users. Boidae uses automation\ntools such as Ansible and Docker to facilitate the deployment of a customized\nBoa installation. In particular, Boidae allows the creation of custom datasets\ngenerated from any set of Git repositories, with helper scripts to aid in\nfinding and cloning repositories from GitHub and SourceForge. In this paper, we\nbriefly describe the architecture of Boidae and how researchers can utilize the\ninfrastructure to generate custom datasets. Boidae's scripts and all\ninfrastructure it builds upon are open-sourced. A video demonstration of\nBoidae's installation and extension is available at https://go.unl.edu/boidae.", "field": "Computer Science", "categories": "cs.SE"}, {"arxiv_id": "2401.11094", "title": "TypeDance: Creating Semantic Typographic Logos from Image through\n  Personalized Generation", "abstract": "Semantic typographic logos harmoniously blend typeface and imagery to\nrepresent semantic concepts while maintaining legibility. Conventional methods\nusing spatial composition and shape substitution are hindered by the\nconflicting requirement for achieving seamless spatial fusion between\ngeometrically dissimilar typefaces and semantics. While recent advances made AI\ngeneration of semantic typography possible, the end-to-end approaches exclude\ndesigner involvement and disregard personalized design. This paper presents\nTypeDance, an AI-assisted tool incorporating design rationales with the\ngenerative model for personalized semantic typographic logo design. It\nleverages combinable design priors extracted from uploaded image exemplars and\nsupports type-imagery mapping at various structural granularity, achieving\ndiverse aesthetic designs with flexible control. Additionally, we instantiate a\ncomprehensive design workflow in TypeDance, including ideation, selection,\ngeneration, evaluation, and iteration. A two-task user evaluation, including\nimitation and creation, confirmed the usability of TypeDance in design across\ndifferent usage scenarios", "field": "Computer Science", "categories": "cs.AI"}, {"arxiv_id": "2401.11095", "title": "Sound Unblending: Exploring Sound Manipulations for Accessible\n  Mixed-Reality Awareness", "abstract": "Mixed-reality (MR) soundscapes blend real-world sound with virtual audio from\nhearing devices, presenting intricate auditory information that is hard to\ndiscern and differentiate. This is particularly challenging for blind or\nvisually impaired individuals, who rely on sounds and descriptions in their\neveryday lives. To understand how complex audio information is consumed, we\nanalyzed online forum posts within the blind community, identifying prevailing\nchallenges, needs, and desired solutions. We synthesized the results and\nproposed Sound Unblending for increasing MR sound awareness, which includes six\nsound manipulations: Ambience Builder, Feature Shifter, Earcon Generator,\nPrioritizer, Spatializer, and Stylizer. To evaluate the effectiveness of sound\nunblending, we conducted a user study with 18 blind participants across three\nsimulated MR scenarios, where participants identified specific sounds within\nintricate soundscapes. We found that sound unblending increased MR sound\nawareness and minimized cognitive load. Finally, we developed three real-world\nexample applications to demonstrate the practicality of sound unblending.", "field": "Computer Science", "categories": "cs.HC,cs.SD,eess.AS"}, {"arxiv_id": "2401.11102", "title": "ASM: Audio Spectrogram Mixer", "abstract": "Transformer structures have demonstrated outstanding skills in the deep\nlearning space recently, significantly increasing the accuracy of models across\na variety of domains. Researchers have started to question whether such a\nsophisticated network structure is actually necessary and whether equally\noutstanding results can be reached with reduced inference cost due to its\ncomplicated network topology and high inference cost. In order to prove the\nMixer's efficacy on three datasets Speech Commands, UrbanSound8k, and CASIA\nChinese Sentiment Corpus this paper applies amore condensed version of the\nMixer to an audio classification task and conducts comparative experiments with\nthe Transformer-based Audio Spectrogram Transformer (AST)model. In addition,\nthis paper conducts comparative experiments on the application of several\nactivation functions in Mixer, namely GeLU, Mish, Swish and Acon-C.\nFurther-more, the use of various activation functions in Mixer, including GeLU,\nMish, Swish, and Acon-C, is compared in this research through comparison\nexperiments. Additionally, some AST model flaws are highlighted, and the model\nsuggested in this study is improved as a result. In conclusion, a model called\nthe Audio Spectrogram Mixer, which is the first model for audio classification\nwith Mixer, is suggested in this study and the model's future directions for\nimprovement are examined.", "field": "Computer Science", "categories": "cs.SD,eess.AS"}, {"arxiv_id": "2401.11103", "title": "Efficient Data Shapley for Weighted Nearest Neighbor Algorithms", "abstract": "This work aims to address an open problem in data valuation literature\nconcerning the efficient computation of Data Shapley for weighted $K$ nearest\nneighbor algorithm (WKNN-Shapley). By considering the accuracy of hard-label\nKNN with discretized weights as the utility function, we reframe the\ncomputation of WKNN-Shapley into a counting problem and introduce a\nquadratic-time algorithm, presenting a notable improvement from $O(N^K)$, the\nbest result from existing literature. We develop a deterministic approximation\nalgorithm that further improves computational efficiency while maintaining the\nkey fairness properties of the Shapley value. Through extensive experiments, we\ndemonstrate WKNN-Shapley's computational efficiency and its superior\nperformance in discerning data quality compared to its unweighted counterpart.", "field": "Computer Science", "categories": "cs.DS,cs.LG,stat.ML"}, {"arxiv_id": "2401.11105", "title": "Are Latent Vulnerabilities Hidden Gems for Software Vulnerability\n  Prediction? An Empirical Study", "abstract": "Collecting relevant and high-quality data is integral to the development of\neffective Software Vulnerability (SV) prediction models. Most of the current SV\ndatasets rely on SV-fixing commits to extract vulnerable functions and lines.\nHowever, none of these datasets have considered latent SVs existing between the\nintroduction and fix of the collected SVs. There is also little known about the\nusefulness of these latent SVs for SV prediction. To bridge these gaps, we\nconduct a large-scale study on the latent vulnerable functions in two commonly\nused SV datasets and their utilization for function-level and line-level SV\npredictions. Leveraging the state-of-the-art SZZ algorithm, we identify more\nthan 100k latent vulnerable functions in the studied datasets. We find that\nthese latent functions can increase the number of SVs by 4x on average and\ncorrect up to 5k mislabeled functions, yet they have a noise level of around\n6%. Despite the noise, we show that the state-of-the-art SV prediction model\ncan significantly benefit from such latent SVs. The improvements are up to\n24.5% in the performance (F1-Score) of function-level SV predictions and up to\n67% in the effectiveness of localizing vulnerable lines. Overall, our study\npresents the first promising step toward the use of latent SVs to improve the\nquality of SV datasets and enhance the performance of SV prediction tasks.", "field": "Computer Science", "categories": "cs.SE,cs.CR,cs.LG"}, {"arxiv_id": "2401.11107", "title": "Exploiting Duality in Open Information Extraction with Predicate Prompt", "abstract": "Open information extraction (OpenIE) aims to extract the schema-free triplets\nin the form of (\\emph{subject}, \\emph{predicate}, \\emph{object}) from a given\nsentence. Compared with general information extraction (IE), OpenIE poses more\nchallenges for the IE models, {especially when multiple complicated triplets\nexist in a sentence. To extract these complicated triplets more effectively, in\nthis paper we propose a novel generative OpenIE model, namely \\emph{DualOIE},\nwhich achieves a dual task at the same time as extracting some triplets from\nthe sentence, i.e., converting the triplets into the sentence.} Such dual task\nencourages the model to correctly recognize the structure of the given sentence\nand thus is helpful to extract all potential triplets from the sentence.\nSpecifically, DualOIE extracts the triplets in two steps: 1) first extracting a\nsequence of all potential predicates, 2) then using the predicate sequence as a\nprompt to induce the generation of triplets. Our experiments on two benchmarks\nand our dataset constructed from Meituan demonstrate that DualOIE achieves the\nbest performance among the state-of-the-art baselines. Furthermore, the online\nA/B test on Meituan platform shows that 0.93\\% improvement of QV-CTR and 0.56\\%\nimprovement of UV-CTR have been obtained when the triplets extracted by DualOIE\nwere leveraged in Meituan's search system.", "field": "Computer Science", "categories": "cs.CL,cs.IR"}, {"arxiv_id": "2401.11108", "title": "LLM4Fuzz: Guided Fuzzing of Smart Contracts with Large Language Models", "abstract": "As blockchain platforms grow exponentially, millions of lines of smart\ncontract code are being deployed to manage extensive digital assets. However,\nvulnerabilities in this mission-critical code have led to significant\nexploitations and asset losses. Thorough automated security analysis of smart\ncontracts is thus imperative. This paper introduces LLM4Fuzz to optimize\nautomated smart contract security analysis by leveraging large language models\n(LLMs) to intelligently guide and prioritize fuzzing campaigns. While\ntraditional fuzzing suffers from low efficiency in exploring the vast state\nspace, LLM4Fuzz employs LLMs to direct fuzzers towards high-value code regions\nand input sequences more likely to trigger vulnerabilities. Additionally,\nLLM4Fuzz can leverage LLMs to guide fuzzers based on user-defined invariants,\nreducing blind exploration overhead. Evaluations of LLM4Fuzz on real-world DeFi\nprojects show substantial gains in efficiency, coverage, and vulnerability\ndetection compared to baseline fuzzing. LLM4Fuzz also uncovered five critical\nvulnerabilities that can lead to a loss of more than $247k.", "field": "Computer Science", "categories": "cs.CR,cs.SE"}, {"arxiv_id": "2401.1111", "title": "VONet: Unsupervised Video Object Learning With Parallel U-Net Attention\n  and Object-wise Sequential VAE", "abstract": "Unsupervised video object learning seeks to decompose video scenes into\nstructural object representations without any supervision from depth, optical\nflow, or segmentation. We present VONet, an innovative approach that is\ninspired by MONet. While utilizing a U-Net architecture, VONet employs an\nefficient and effective parallel attention inference process, generating\nattention masks for all slots simultaneously. Additionally, to enhance the\ntemporal consistency of each mask across consecutive video frames, VONet\ndevelops an object-wise sequential VAE framework. The integration of these\ninnovative encoder-side techniques, in conjunction with an expressive\ntransformer-based decoder, establishes VONet as the leading unsupervised method\nfor object learning across five MOVI datasets, encompassing videos of diverse\ncomplexities. Code is available at https://github.com/hnyu/vonet.", "field": "Computer Science", "categories": "cs.CV,cs.LG"}, {"arxiv_id": "2401.11113", "title": "SPAND: Sleep Prediction Architecture using Network Dynamics", "abstract": "Sleep behavior significantly impacts health and acts as an indicator of\nphysical and mental well-being. Monitoring and predicting sleep behavior with\nubiquitous sensors may therefore assist in both sleep management and tracking\nof related health conditions. While sleep behavior depends on, and is reflected\nin the physiology of a person, it is also impacted by external factors such as\ndigital media usage, social network contagion, and the surrounding weather. In\nthis work, we propose SPAND (Sleep Prediction Architecture using Network\nDynamics), a system that exploits social contagion in sleep behavior through\ngraph networks and integrates it with physiological and phone data extracted\nfrom ubiquitous mobile and wearable devices for predicting next-day sleep\nlabels about sleep duration. Our architecture overcomes the limitations of\nlarge-scale graphs containing connections irrelevant to sleep behavior by\ndevising an attention mechanism. The extensive experimental evaluation\nhighlights the improvement provided by incorporating social networks in the\nmodel. Additionally, we conduct robustness analysis to demonstrate the system's\nperformance in real-life conditions. The outcomes affirm the stability of SPAND\nagainst perturbations in input data. Further analyses emphasize the\nsignificance of network topology in prediction performance revealing that users\nwith higher eigenvalue centrality are more vulnerable to data perturbations.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.SI,eess.SP"}, {"arxiv_id": "2401.11114", "title": "DengueNet: Dengue Prediction using Spatiotemporal Satellite Imagery for\n  Resource-Limited Countries", "abstract": "Dengue fever presents a substantial challenge in developing countries where\nsanitation infrastructure is inadequate. The absence of comprehensive\nhealthcare systems exacerbates the severity of dengue infections, potentially\nleading to life-threatening circumstances. Rapid response to dengue outbreaks\nis also challenging due to limited information exchange and integration. While\ntimely dengue outbreak forecasts have the potential to prevent such outbreaks,\nthe majority of dengue prediction studies have predominantly relied on data\nthat impose significant burdens on individual countries for collection. In this\nstudy, our aim is to improve health equity in resource-constrained countries by\nexploring the effectiveness of high-resolution satellite imagery as a\nnontraditional and readily accessible data source. By leveraging the wealth of\npublicly available and easily obtainable satellite imagery, we present a\nscalable satellite extraction framework based on Sentinel Hub, a cloud-based\ncomputing platform. Furthermore, we introduce DengueNet, an innovative\narchitecture that combines Vision Transformer, Radiomics, and Long Short-term\nMemory to extract and integrate spatiotemporal features from satellite images.\nThis enables dengue predictions on an epi-week basis. To evaluate the\neffectiveness of our proposed method, we conducted experiments on five\nmunicipalities in Colombia. We utilized a dataset comprising 780\nhigh-resolution Sentinel-2 satellite images for training and evaluation. The\nperformance of DengueNet was assessed using the mean absolute error (MAE)\nmetric. Across the five municipalities, DengueNet achieved an average MAE of\n43.92. Our findings strongly support the efficacy of satellite imagery as a\nvaluable resource for dengue prediction, particularly in informing public\nhealth policies within countries where manually collected data is scarce and\ndengue virus prevalence is severe.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11115", "title": "MotionMix: Weakly-Supervised Diffusion for Controllable Motion\n  Generation", "abstract": "Controllable generation of 3D human motions becomes an important topic as the\nworld embraces digital transformation. Existing works, though making promising\nprogress with the advent of diffusion models, heavily rely on meticulously\ncaptured and annotated (e.g., text) high-quality motion corpus, a\nresource-intensive endeavor in the real world. This motivates our proposed\nMotionMix, a simple yet effective weakly-supervised diffusion model that\nleverages both noisy and unannotated motion sequences. Specifically, we\nseparate the denoising objectives of a diffusion model into two stages:\nobtaining conditional rough motion approximations in the initial $T-T^*$ steps\nby learning the noisy annotated motions, followed by the unconditional\nrefinement of these preliminary motions during the last $T^*$ steps using\nunannotated motions. Notably, though learning from two sources of imperfect\ndata, our model does not compromise motion generation quality compared to fully\nsupervised approaches that access gold data. Extensive experiments on several\nbenchmarks demonstrate that our MotionMix, as a versatile framework,\nconsistently achieves state-of-the-art performances on text-to-motion,\naction-to-motion, and music-to-dance tasks.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11116", "title": "Promotion of Scientific Publications on ArXiv and X Is on the Rise and\n  Impacts Citations", "abstract": "In the evolving landscape of scientific publishing, it is important to\nunderstand the drivers of high-impact research, to equip scientists with\nactionable strategies to enhance the reach of their work, and to understand\ntrends in the use modern scientific publishing tools to inform their further\ndevelopment. Here, based on a large dataset of computer science publications,\nwe study trends in the use of early preprint publications and revisions on\nArXiv and the use of X (formerly Twitter) for promotion of such papers in the\nlast 10 years. We find that early submission to ArXiv and promotion on X have\nsoared in recent years. Estimating the effect that the use of each of these\nmodern affordances has on the number of citations of scientific publications,\nwe find that in the first 5 years from an initial publication peer-reviewed\nconference papers submitted early to ArXiv gain on average $21.1 \\pm 17.4$ more\ncitations, revised on ArXiv gain $18.4 \\pm 17.6$ more citations, and promoted\non X gain $44.4 \\pm 8$ more citations. Our results show that promoting one's\nwork on ArXiv or X has a large impact on the number of citations, as well as\nthe number of influential citations computed by Semantic Scholar, and thereby\non the career of researchers. We discuss the far-reaching implications of these\nfindings for future scientific publishing systems and measures of scientific\nimpact.", "field": "Computer Science", "categories": "cs.DL,cs.CY,cs.SI"}, {"arxiv_id": "2401.11118", "title": "Meta Reinforcement Learning for Strategic IoT Deployments Coverage in\n  Disaster-Response UAV Swarms", "abstract": "In the past decade, Unmanned Aerial Vehicles (UAVs) have grabbed the\nattention of researchers in academia and industry for their potential use in\ncritical emergency applications, such as providing wireless services to ground\nusers and collecting data from areas affected by disasters, due to their\nadvantages in terms of maneuverability and movement flexibility. The UAVs'\nlimited resources, energy budget, and strict mission completion time have posed\nchallenges in adopting UAVs for these applications. Our system model considers\na UAV swarm that navigates an area collecting data from ground IoT devices\nfocusing on providing better service for strategic locations and allowing UAVs\nto join and leave the swarm (e.g., for recharging) in a dynamic way. In this\nwork, we introduce an optimization model with the aim of minimizing the total\nenergy consumption and provide the optimal path planning of UAVs under the\nconstraints of minimum completion time and transmit power. The formulated\noptimization is NP-hard making it not applicable for real-time decision making.\nTherefore, we introduce a light-weight meta-reinforcement learning solution\nthat can also cope with sudden changes in the environment through fast\nconvergence. We conduct extensive simulations and compare our approach to three\nstate-of-the-art learning models. Our simulation results prove that our\nintroduced approach is better than the three state-of-the-art algorithms in\nproviding coverage to strategic locations with fast convergence.", "field": "Computer Science", "categories": "cs.LG,cs.RO"}, {"arxiv_id": "2401.1112", "title": "Enhancing Large Language Models for Clinical Decision Support by\n  Incorporating Clinical Practice Guidelines", "abstract": "Background Large Language Models (LLMs), enhanced with Clinical Practice\nGuidelines (CPGs), can significantly improve Clinical Decision Support (CDS).\nHowever, methods for incorporating CPGs into LLMs are not well studied. Methods\nWe develop three distinct methods for incorporating CPGs into LLMs: Binary\nDecision Tree (BDT), Program-Aided Graph Construction (PAGC), and\nChain-of-Thought-Few-Shot Prompting (CoT-FSP). To evaluate the effectiveness of\nthe proposed methods, we create a set of synthetic patient descriptions and\nconduct both automatic and human evaluation of the responses generated by four\nLLMs: GPT-4, GPT-3.5 Turbo, LLaMA, and PaLM 2. Zero-Shot Prompting (ZSP) was\nused as the baseline method. We focus on CDS for COVID-19 outpatient treatment\nas the case study. Results All four LLMs exhibit improved performance when\nenhanced with CPGs compared to the baseline ZSP. BDT outperformed both CoT-FSP\nand PAGC in automatic evaluation. All of the proposed methods demonstrated high\nperformance in human evaluation. Conclusion LLMs enhanced with CPGs demonstrate\nsuperior performance, as compared to plain LLMs with ZSP, in providing accurate\nrecommendations for COVID-19 outpatient treatment, which also highlights the\npotential for broader applications beyond the case study.", "field": "Computer Science", "categories": "cs.CL,cs.AI"}, {"arxiv_id": "2401.11122", "title": "Spatial Structure Constraints for Weakly Supervised Semantic\n  Segmentation", "abstract": "The image-level label has prevailed in weakly supervised semantic\nsegmentation tasks due to its easy availability. Since image-level labels can\nonly indicate the existence or absence of specific categories of objects,\nvisualization-based techniques have been widely adopted to provide object\nlocation clues. Considering class activation maps (CAMs) can only locate the\nmost discriminative part of objects, recent approaches usually adopt an\nexpansion strategy to enlarge the activation area for more integral object\nlocalization. However, without proper constraints, the expanded activation will\neasily intrude into the background region. In this paper, we propose spatial\nstructure constraints (SSC) for weakly supervised semantic segmentation to\nalleviate the unwanted object over-activation of attention expansion.\nSpecifically, we propose a CAM-driven reconstruction module to directly\nreconstruct the input image from deep CAM features, which constrains the\ndiffusion of last-layer object attention by preserving the coarse spatial\nstructure of the image content. Moreover, we propose an activation\nself-modulation module to refine CAMs with finer spatial structure details by\nenhancing regional consistency. Without external saliency models to provide\nbackground clues, our approach achieves 72.7\\% and 47.0\\% mIoU on the PASCAL\nVOC 2012 and COCO datasets, respectively, demonstrating the superiority of our\nproposed approach.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11123", "title": "Uncertainty-aware Bridge based Mobile-Former Network for Event-based\n  Pattern Recognition", "abstract": "The mainstream human activity recognition (HAR) algorithms are developed\nbased on RGB cameras, which are easily influenced by low-quality images (e.g.,\nlow illumination, motion blur). Meanwhile, the privacy protection issue caused\nby ultra-high definition (HD) RGB cameras aroused more and more people's\nattention. Inspired by the success of event cameras which perform better on\nhigh dynamic range, no motion blur, and low energy consumption, we propose to\nrecognize human actions based on the event stream. We propose a lightweight\nuncertainty-aware information propagation based Mobile-Former network for\nefficient pattern recognition, which aggregates the MobileNet and Transformer\nnetwork effectively. Specifically, we first embed the event images using a stem\nnetwork into feature representations, then, feed them into uncertainty-aware\nMobile-Former blocks for local and global feature learning and fusion. Finally,\nthe features from MobileNet and Transformer branches are concatenated for\npattern recognition. Extensive experiments on multiple event-based recognition\ndatasets fully validated the effectiveness of our model. The source code of\nthis work will be released at\nhttps://github.com/Event-AHU/Uncertainty_aware_MobileFormer.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11124", "title": "EMA-Net: Efficient Multitask Affinity Learning for Dense Scene\n  Predictions", "abstract": "Multitask learning (MTL) has gained prominence for its ability to jointly\npredict multiple tasks, achieving better per-task performance while using fewer\nper-task model parameters than single-task learning. More recently,\ndecoder-focused architectures have considerably improved multitask performance\nby refining task predictions using the features of other related tasks.\nHowever, most of these refinement methods fail to simultaneously capture local\nand global task-specific representations, as well as cross-task patterns in a\nparameter-efficient manner. In this paper, we introduce the Efficient Multitask\nAffinity Learning Network (EMA-Net), which is a lightweight framework that\nenhances the task refinement capabilities of multitask networks. EMA-Net\nadeptly captures local, global, and cross-task interactions using our novel\nCross-Task Affinity Learning (CTAL) module. The key innovation of CTAL lies in\nits ability to manipulate task affinity matrices in a manner that is optimally\nsuited to apply parameter-efficient grouped convolutions without worrying about\ninformation loss. Our results show that we achieve state-of-the-art MTL\nperformance for CNN-based decoder-focused models while using substantially\nfewer model parameters. Our code is publicly available at\nhttps://github.com/Armanfard-Lab/EMA-Net.", "field": "Computer Science", "categories": "cs.CV,cs.LG"}, {"arxiv_id": "2401.11126", "title": "CARE: Ensemble Adversarial Robustness Evaluation Against Adaptive\n  Attackers for Security Applications", "abstract": "Ensemble defenses, are widely employed in various security-related\napplications to enhance model performance and robustness. The widespread\nadoption of these techniques also raises many questions: Are general ensembles\ndefenses guaranteed to be more robust than individuals? Will stronger adaptive\nattacks defeat existing ensemble defense strategies as the cybersecurity arms\nrace progresses? Can ensemble defenses achieve adversarial robustness to\ndifferent types of attacks simultaneously and resist the continually adjusted\nadaptive attacks? Unfortunately, these critical questions remain unresolved as\nthere are no platforms for comprehensive evaluation of ensemble adversarial\nattacks and defenses in the cybersecurity domain. In this paper, we propose a\ngeneral Cybersecurity Adversarial Robustness Evaluation (CARE) platform aiming\nto bridge this gap.", "field": "Computer Science", "categories": "cs.CR,cs.LG"}, {"arxiv_id": "2401.11127", "title": "The Bit Complexity of Dynamic Algebraic Formulas and their Determinants", "abstract": "Many iterative algorithms in optimization, computational geometry, computer\nalgebra, and other areas of computer science require repeated computation of\nsome algebraic expression whose input changes slightly from one iteration to\nthe next. Although efficient data structures have been proposed for maintaining\nthe solution of such algebraic expressions under low-rank updates, most of\nthese results are only analyzed under exact arithmetic (real-RAM model and\nfinite fields) which may not accurately reflect the complexity guarantees of\nreal computers. In this paper, we analyze the stability and bit complexity of\nsuch data structures for expressions that involve the inversion,\nmultiplication, addition, and subtraction of matrices under the word-RAM model.\nWe show that the bit complexity only increases linearly in the number of matrix\noperations in the expression. In addition, we consider the bit complexity of\nmaintaining the determinant of a matrix expression. We show that the required\nbit complexity depends on the logarithm of the condition number of matrices\ninstead of the logarithm of their determinant. We also discuss rank maintenance\nand its connections to determinant maintenance. Our results have wide\napplications ranging from computational geometry (e.g., computing the volume of\na polytope) to optimization (e.g., solving linear programs using the simplex\nalgorithm).", "field": "Computer Science", "categories": "cs.CC,F.1.2; F.2.1; G.1.3"}, {"arxiv_id": "2401.1113", "title": "Identification and Estimation of Conditional Average Partial Causal\n  Effects via Instrumental Variable", "abstract": "There has been considerable recent interest in estimating heterogeneous\ncausal effects. In this paper, we introduce conditional average partial causal\neffects (CAPCE) to reveal the heterogeneity of causal effects with continuous\ntreatment. We provide conditions for identifying CAPCE in an instrumental\nvariable setting. We develop three families of CAPCE estimators: sieve,\nparametric, and reproducing kernel Hilbert space (RKHS)-based, and analyze\ntheir statistical properties. We illustrate the proposed CAPCE estimators on\nsynthetic and real-world data.", "field": "Computer Science", "categories": "cs.LG,stat.ML"}, {"arxiv_id": "2401.11131", "title": "Towards a Non-Ideal Methodological Framework for Responsible ML", "abstract": "Though ML practitioners increasingly employ various Responsible ML (RML)\nstrategies, their methodological approach in practice is still unclear. In\nparticular, the constraints, assumptions, and choices of practitioners with\ntechnical duties -- such as developers, engineers, and data scientists -- are\noften implicit, subtle, and under-scrutinized in HCI and related fields. We\ninterviewed 22 technically oriented ML practitioners across seven domains to\nunderstand the characteristics of their methodological approaches to RML\nthrough the lens of ideal and non-ideal theorizing of fairness. We find that\npractitioners' methodological approaches fall along a spectrum of idealization.\nWhile they structured their approaches through ideal theorizing, such as by\nabstracting RML workflow from the inquiry of applicability of ML, they did not\npay deliberate attention and systematically documented their non-ideal\napproaches, such as diagnosing imperfect conditions. We end our paper with a\ndiscussion of a new methodological approach, inspired by elements of non-ideal\ntheory, to structure technical practitioners' RML process and facilitate\ncollaboration with other stakeholders.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.11132", "title": "ConceptThread: Visualizing Threaded Concepts in MOOC Videos", "abstract": "Massive Open Online Courses (MOOCs) platforms are becoming increasingly\npopular in recent years. Online learners need to watch the whole course video\non MOOC platforms to learn the underlying new knowledge, which is often tedious\nand time-consuming due to the lack of a quick overview of the covered knowledge\nand their structures. In this paper, we propose ConceptThread, a visual\nanalytics approach to effectively show the concepts and the relations among\nthem to facilitate effective online learning. Specifically, given that the\nmajority of MOOC videos contain slides, we first leverage video processing and\nspeech analysis techniques, including shot recognition, speech recognition and\ntopic modeling, to extract core knowledge concepts and construct the\nhierarchical and temporal relations among them. Then, by using a metaphor of\nthread, we present a novel visualization to intuitively display the concepts\nbased on video sequential flow, and enable learners to perform interactive\nvisual exploration of concepts. We conducted a quantitative study, two case\nstudies, and a user study to extensively evaluate ConceptThread. The results\ndemonstrate the effectiveness and usability of ConceptThread in providing\nonline learners with a quick understanding of the knowledge content of MOOC\nvideos.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.11135", "title": "COVID-19 as Reflected in University President Bulk Email", "abstract": "E-mail ``Messages From the President'' to university students, staff, and\nfaculty have long been used to keep campus communities aware of the latest\npolicies, events, and news. But during the COVID-19 pandemic, as universities\nquickly closed facilities, sent students home, and canceled travel, these\nmessages took on even greater importance. We report on a content analysis of\nbulk emails from different universities' presidents to their students and\nemployees before and in three stages of the pandemic. We find that these\nmessages change as universities move towards and through closure. During the\npandemic, 1) presidential bulk emails tend to be more informative, positive,\nclearer than before; 2) they tend to use more personal and collective language;\n3) university presidents tend to mention more local political leaders and fewer\nother university leaders. Our results can inform research on digital crisis\ncommunication and may be useful for researchers interested in automatically\nidentifying crisis situations from communication streams.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.1114", "title": "Stability Plasticity Decoupled Fine-tuning For Few-shot end-to-end\n  Object Detection", "abstract": "Few-shot object detection(FSOD) aims to design methods to adapt object\ndetectors efficiently with only few annotated samples. Fine-tuning has been\nshown to be an effective and practical approach. However, previous works often\ntake the classical base-novel two stage fine-tuning procedure but ignore the\nimplicit stability-plasticity contradiction among different modules.\nSpecifically, the random re-initialized classifiers need more plasticity to\nadapt to novel samples. The other modules inheriting pre-trained weights demand\nmore stability to reserve their class-agnostic knowledge. Regular fine-tuning\nwhich couples the optimization of these two parts hurts the model\ngeneralization in FSOD scenarios. In this paper, we find that this problem is\nprominent in the end-to-end object detector Sparse R-CNN for its\nmulti-classifier cascaded architecture. We propose to mitigate this\ncontradiction by a new three-stage fine-tuning procedure by introducing an\naddtional plasticity classifier fine-tuning(PCF) stage. We further design the\nmulti-source ensemble(ME) technique to enhance the generalization of the model\nin the final fine-tuning stage. Extensive experiments verify that our method is\neffective in regularizing Sparse R-CNN, outperforming previous methods in the\nFSOD benchmark.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.11141", "title": "Wideband Beamforming for RIS Assisted Near-Field Communications", "abstract": "A near-field wideband beamforming scheme is investigated for reconfigurable\nintelligent surface (RIS) assisted multiple-input multiple-output (MIMO)\nsystems, in which a deep learning-based end-to-end (E2E) optimization framework\nis proposed to maximize the system spectral efficiency. To deal with the\nnear-field double beam split effect, the base station is equipped with\nfrequency-dependent hybrid precoding architecture by introducing sub-connected\ntrue time delay (TTD) units, while two specific RIS architectures, namely true\ntime delay-based RIS (TTD-RIS) and virtual subarray-based RIS (SA-RIS), are\nexploited to realize the frequency-dependent passive beamforming at the RIS.\nFurthermore, the efficient E2E beamforming models without explicit channel\nstate information are proposed, which jointly exploits the uplink channel\ntraining module and the downlink wideband beamforming module. In the proposed\nnetwork architecture of the E2E models, the classical communication signal\nprocessing methods, i.e., polarized filtering and sparsity transform, are\nleveraged to develop a signal-guided beamforming network. Numerical results\nshow that the proposed E2E models have superior beamforming performance and\nrobustness to conventional beamforming benchmarks. Furthermore, the tradeoff\nbetween the beamforming gain and the hardware complexity is investigated for\ndifferent frequency-dependent RIS architectures, in which the TTD-RIS can\nachieve better spectral efficiency than the SA-RIS while requiring additional\nenergy consumption and hardware cost.", "field": "Computer Science", "categories": "cs.IT,eess.SP,math.IT"}, {"arxiv_id": "2401.11143", "title": "Gaussian Adaptive Attention is All You Need: Robust Contextual\n  Representations Across Multiple Modalities", "abstract": "We propose the Multi-Head Gaussian Adaptive Attention Mechanism (GAAM), a\nnovel probabilistic attention framework, and the Gaussian Adaptive Transformer\n(GAT), designed to enhance information aggregation across multiple modalities,\nincluding Speech, Text and Vision. GAAM integrates learnable mean and variance\ninto its attention mechanism, implemented in a Multi-Headed framework enabling\nit to collectively model any Probability Distribution for dynamic recalibration\nof feature significance. This method demonstrates significant improvements,\nespecially with highly non-stationary data, surpassing the state-of-the-art\nattention techniques in model performance (up to approximately +20% in\naccuracy) by identifying key elements within the feature space. GAAM's\ncompatibility with dot-product-based attention models and relatively low number\nof parameters showcases its adaptability and potential to boost existing\nattention frameworks. Empirically, GAAM exhibits superior adaptability and\nefficacy across a diverse range of tasks, including emotion recognition in\nspeech, image classification, and text classification, thereby establishing its\nrobustness and versatility in handling multi-modal data. Furthermore, we\nintroduce the Importance Factor (IF), a new learning-based metric that enhances\nthe explainability of models trained with GAAM-based methods. Overall, GAAM\nrepresents an advancement towards development of better performing and more\nexplainable attention models across multiple modalities.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.CL,cs.CV,cs.SD,eess.AS,eess.SP"}, {"arxiv_id": "2401.11144", "title": "Towards Open-World Gesture Recognition", "abstract": "Static machine learning methods in gesture recognition assume that training\nand test data come from the same underlying distribution. However, in\nreal-world applications involving gesture recognition on wrist-worn devices,\ndata distribution may change over time. We formulate this problem of adapting\nrecognition models to new tasks, where new data patterns emerge, as open-world\ngesture recognition (OWGR). We propose leveraging continual learning to make\nmachine learning models adaptive to new tasks without degrading performance on\npreviously learned tasks. However, the exploration of parameters for questions\naround when and how to train and deploy recognition models requires\ntime-consuming user studies and is sometimes impractical. To address this\nchallenge, we propose a design engineering approach that enables offline\nanalysis on a collected large-scale dataset with various parameters and\ncompares different continual learning methods. Finally, design guidelines are\nprovided to enhance the development of an open-world wrist-worn gesture\nrecognition process.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11145", "title": "Document Set Expansion with Positive-Unlabeled Learning: A Density\n  Estimation-based Approach", "abstract": "Document set expansion aims to identify relevant documents from a large\ncollection based on a small set of documents that are on a fine-grained topic.\nPrevious work shows that PU learning is a promising method for this task.\nHowever, some serious issues remain unresolved, i.e. typical challenges that PU\nmethods suffer such as unknown class prior and imbalanced data, and the need\nfor transductive experimental settings. In this paper, we propose a novel PU\nlearning framework based on density estimation, called puDE, that can handle\nthe above issues. The advantage of puDE is that it neither constrained to the\nSCAR assumption and nor require any class prior knowledge. We demonstrate the\neffectiveness of the proposed method using a series of real-world datasets and\nconclude that our method is a better alternative for the DSE task.", "field": "Computer Science", "categories": "cs.LG,cs.IR"}, {"arxiv_id": "2401.11146", "title": "Generalized Optimal AMG Convergence Theory for Nonsymmetric and\n  Indefinite Problems", "abstract": "Algebraic multigrid (AMG) is known to be an effective solver for many sparse\nsymmetric positive definite (SPD) linear systems. For SPD systems, the\nconvergence theory of AMG is well-understood in terms of the $A$-norm but in a\nnonsymmetric setting such an energy norm is non-existent. For this reason,\nconvergence of AMG for nonsymmetric systems of equations remains an open area\nof research. Existing nonsymmetric AMG algorithms in this setting mostly rely\non heuristics motivated by SPD convergence theory. In the SPD setting, the\nclassical form of optimal AMG interpolation provides a useful insight in\ndetermining the two grid convergence rate of the method. In this work, we\ndiscuss a generalization of the optimal AMG convergence theory targeting\nnonsymmetric problems by constructing a $2\\times 2$ block symmetric indefinite\nsystem so that the Petrov-Galerkin AMG process for the nonsymmetric matrix $A$\ncan be recast as a Galerkin AMG process for a symmetric indefinite system. We\nshow that using this generalization of the optimal interpolation theory, one\ncan obtain the same identity for the two-grid convergence rate as that derived\nin the SPD setting for optimal interpolation. We also provide supporting\nnumerical results for the convergence result and nonsymmetric\nadvection-diffusion problems.", "field": "Computer Science", "categories": "math.NA,cs.NA"}, {"arxiv_id": "2401.11148", "title": "Enhancing System-Level Safety in Mixed-Autonomy Platoon via Safe\n  Reinforcement Learning", "abstract": "Connected and automated vehicles (CAVs) have recently gained prominence in\ntraffic research, thanks to the advancements in communication technology and\nautonomous driving. A variety of longitudinal control strategies for CAVs have\nbeen developed to enhance traffic efficiency, stability, and safety in\nmixed-autonomy scenarios. Deep reinforcement learning (DRL) is one promising\nstrategy for mixed-autonomy platoon control since it can tackle complex\nscenarios in real-time. However, there are three research gaps for DRL-based\nmixed-autonomy platoon control. First, incorporating safety considerations into\nDRL typically relies on designing collision avoidance-based reward functions,\nwhich lack collision-free guarantees. Second, current DRL-based-control\napproaches for mixed traffic only consider the safety of CAVs, with little\nattention paid to the surrounding HDVs. To address the research gaps, we\nintroduce a differentiable safety layer that converts DRL actions into safe\nactions with collision-free guarantees. This process relies on solving a\ndifferentiable quadratic programming problem that incorporates control barrier\nfunction-based (CBF) safety constraints for both CAV and its following HDVs to\nachieve system-level safety. Moreover, constructing CBF constraints needs\nsystem dynamics for the following HDVs, and thus we employ an online system\nidentification module to estimate the car-following dynamics of the surrounding\nHDVs. The proposed safe reinforcement learning approach explicitly integrates\nsystem-level safety constraints into the training process and enables our\nmethod to adapt to varying safety-critical scenarios. Simulation results\ndemonstrate that our proposed method effectively ensures CAV safety and\nimproves HDV safety in mixed platoon environments while simultaneously\nenhancing traffic capacity and string stability.", "field": "Computer Science", "categories": "eess.SY,cs.SY"}, {"arxiv_id": "2401.1115", "title": "Simultaneous Gesture Classification and Localization with an Automatic\n  Gesture Annotation Model", "abstract": "Training a real-time gesture recognition model heavily relies on annotated\ndata. However, manual data annotation is costly and demands substantial human\neffort. In order to address this challenge, we propose a novel annotation model\nthat can automatically annotate gesture classes and identify their temporal\nranges. Our ablation study demonstrates that our annotation model design\nsurpasses the baseline in terms of both gesture classification accuracy (3-4\\%\nimprovement) and localization accuracy (71-75\\% improvement). We believe that\nthis annotation model has immense potential to improve the training of\ndownstream gesture recognition models using unlabeled datasets.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11155", "title": "Deep Learning-Based Adaptive Joint Source-Channel Coding using\n  Hypernetworks", "abstract": "Deep learning-based joint source-channel coding (DJSCC) is expected to be a\nkey technique for {the} next-generation wireless networks. However, the\nexisting DJSCC schemes still face the challenge of channel adaptability as they\nare typically trained under specific channel conditions. In this paper, we\npropose a generic framework for channel-adaptive DJSCC by utilizing\nhypernetworks. To tailor the hypernetwork-based framework for communication\nsystems, we propose a memory-efficient hypernetwork parameterization and then\ndevelop a channel-adaptive DJSCC network, named Hyper-AJSCC. Compared with\nexisting adaptive DJSCC based on the attention mechanism, Hyper-AJSCC\nintroduces much fewer parameters and can be seamlessly combined with various\nexisting DJSCC networks without any substantial modifications to their neural\nnetwork architecture. Extensive experiments demonstrate the better adaptability\nto channel conditions and higher memory efficiency of Hyper-AJSCC compared with\nstate-of-the-art baselines.", "field": "Computer Science", "categories": "cs.IT,math.IT"}, {"arxiv_id": "2401.11156", "title": "Generalizing Speaker Verification for Spoof Awareness in the Embedding\n  Space", "abstract": "It is now well-known that automatic speaker verification (ASV) systems can be\nspoofed using various types of adversaries. The usual approach to counteract\nASV systems against such attacks is to develop a separate spoofing\ncountermeasure (CM) module to classify speech input either as a bonafide, or a\nspoofed utterance. Nevertheless, such a design requires additional computation\nand utilization efforts at the authentication stage. An alternative strategy\ninvolves a single monolithic ASV system designed to handle both zero-effort\nimposter (non-targets) and spoofing attacks. Such spoof-aware ASV systems have\nthe potential to provide stronger protections and more economic computations.\nTo this end, we propose to generalize the standalone ASV (G-SASV) against\nspoofing attacks, where we leverage limited training data from CM to enhance a\nsimple backend in the embedding space, without the involvement of a separate CM\nmodule during the test (authentication) phase. We propose a novel yet simple\nbackend classifier based on deep neural networks and conduct the study via\ndomain adaptation and multi-task integration of spoof embeddings at the\ntraining stage. Experiments are conducted on the ASVspoof 2019 logical access\ndataset, where we improve the performance of statistical ASV backends on the\njoint (bonafide and spoofed) and spoofed conditions by a maximum of 36.2% and\n49.8% in terms of equal error rates, respectively.", "field": "Computer Science", "categories": "cs.CR,cs.AI,cs.SD,eess.AS"}, {"arxiv_id": "2401.1116", "title": "New Perfect and Distance-Optimal Sum-Rank Codes", "abstract": "Constructions of infinite families of distance-optimal codes in the Hamming\nmetric and the sum-rank metric are challenging problems and have attracted many\nattentions. In this paper, we give the following three results.\n  1) If $\\lambda|q^{sm}-1$ and $\\lambda\n<\\sqrt{\\frac{(q^s-1)}{2(q-1)^2(1+\\epsilon)}}$, an infinite family of\ndistance-optimal $q$-ary cyclic sum-rank codes with the block length\n$t=\\frac{q^{sm}-1}{\\lambda}$, the matrix size $s \\times s$, the cardinality\n$q^{s^2t-s(2m+3)}$ and the minimum sum-rank distance four is constructed.\n  2) Block length $q^4-1$ and the matrix size $2 \\times 2$ distance-optimal\nsum-rank codes with the minimum sum-rank distance four and the Singleton defect\nfour are constructed. These sum-rank codes are close to the sphere packing\nbound , the Singleton-like bound and have much larger block length\n$q^4-1>>q-1$.\n  3) For given positive integers $n$ and $m$ satisfying $m<n$, an infinite\nfamily of perfect sum-rank codes with the matrix size $m \\times n$, and the\nminimum sum-rank distance three is also constructed.\n  The construction of perfect sum-rank codes of the matrix size $m \\times n$,\n$1<m<n$, answers the open problem proposed by U. Mart\\'{\\i}nez-Pe\\~{n}as in\n2019 positively.", "field": "Computer Science", "categories": "cs.IT,math.IT"}, {"arxiv_id": "2401.11161", "title": "BinaryAI: Binary Software Composition Analysis via Intelligent Binary\n  Source Code Matching", "abstract": "While third-party libraries are extensively reused to enhance productivity\nduring software development, they can also introduce potential security risks\nsuch as vulnerability propagation. Software composition analysis, proposed to\nidentify reused TPLs for reducing such risks, has become an essential procedure\nwithin modern DevSecOps. As one of the mainstream SCA techniques,\nbinary-to-source SCA identifies the third-party source projects contained in\nbinary files via binary source code matching, which is a major challenge in\nreverse engineering since binary and source code exhibit substantial\ndisparities after compilation. The existing binary-to-source SCA techniques\nleverage basic syntactic features that suffer from redundancy and lack\nrobustness in the large-scale TPL dataset, leading to inevitable false\npositives and compromised recall. To mitigate these limitations, we introduce\nBinaryAI, a novel binary-to-source SCA technique with two-phase binary source\ncode matching to capture both syntactic and semantic code features. First,\nBinaryAI trains a transformer-based model to produce function-level embeddings\nand obtain similar source functions for each binary function accordingly. Then\nby applying the link-time locality to facilitate function matching, BinaryAI\ndetects the reused TPLs based on the ratio of matched source functions. Our\nexperimental results demonstrate the superior performance of BinaryAI in terms\nof binary source code matching and the downstream SCA task. Specifically, our\nembedding model outperforms the state-of-the-art model CodeCMR, i.e., achieving\n22.54% recall@1 and 0.34 MRR compared with 10.75% and 0.17 respectively.\nAdditionally, BinaryAI outperforms all existing binary-to-source SCA tools in\nTPL detection, increasing the precision from 73.36% to 85.84% and recall from\n59.81% to 64.98% compared with the well-recognized commercial SCA product Black\nDuck.", "field": "Computer Science", "categories": "cs.SE"}, {"arxiv_id": "2401.11162", "title": "Extending Polaris to Support Transactions", "abstract": "In Polaris, we introduced a cloud-native distributed query processor to\nperform analytics at scale. In this paper, we extend the underlying Polaris\ndistributed computation framework, which can be thought of as a read-only\ntransaction engine, to execute general transactions (including updates,\ndeletes, inserts and bulk loads, in addition to queries) for Tier 1 warehousing\nworkloads in a highly performant and predictable manner. We take advantage of\nthe immutability of data files in log-structured data stores and build on SQL\nServer transaction management to deliver full transactional support with\nSnapshot Isolation semantics, including multi-table and multi-statement\ntransactions. With the enhancements described in this paper, Polaris supports\nboth query processing and transactions for T-SQL in Microsoft Fabric.", "field": "Computer Science", "categories": "cs.DB"}, {"arxiv_id": "2401.11166", "title": "ChatGPT in the classroom. Exploring its potential and limitations in a\n  Functional Programming course", "abstract": "In November 2022, OpenAI has introduced ChatGPT, a chatbot based on\nsupervised and reinforcement learning. Not only can it answer questions\nemulating human-like responses, but it can also generate code from scratch or\ncomplete coding templates provided by the user. ChatGPT can generate unique\nresponses which render any traditional anti-plagiarism tool useless. Its\nrelease has ignited a heated debate about its usage in academia, especially by\nstudents. We have found, to our surprise, that our students at POLITEHNICA\nUniversity of Bucharest (UPB) have been using generative AI tools (ChatGPT and\nits predecessors) for solving homework, for at least 6 months. We therefore set\nout to explore the capabilities of ChatGPT and assess its value for educational\npurposes. We solved all our coding assignments for the semester from our UPB\nFunctional Programming course. We discovered that, although ChatGPT provides\ncorrect answers in 68% of the cases, only around half of those are legible\nsolutions which can benefit students in some form. On the other hand, ChatGPT\nhas a very good ability to perform code review on student programming homework.\nBased on these findings, we discuss the pros and cons of ChatGPT in education.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.11167", "title": "Coevolving Artistic Images Using OMNIREP", "abstract": "We have recently developed OMNIREP, a coevolutionary algorithm to discover\nboth a representation and an interpreter that solve a particular problem of\ninterest. Herein, we demonstrate that the OMNIREP framework can be successfully\napplied within the field of evolutionary art. Specifically, we coevolve\nrepresentations that encode image position, alongside interpreters that\ntransform these positions into one of three pre-defined shapes (chunks,\npolygons, or circles) of varying size, shape, and color. We showcase a sampling\nof the unique image variations produced by this approach.", "field": "Computer Science", "categories": "cs.NE"}, {"arxiv_id": "2401.1117", "title": "Inducing High Energy-Latency of Large Vision-Language Models with\n  Verbose Images", "abstract": "Large vision-language models (VLMs) such as GPT-4 have achieved exceptional\nperformance across various multi-modal tasks. However, the deployment of VLMs\nnecessitates substantial energy consumption and computational resources. Once\nattackers maliciously induce high energy consumption and latency time\n(energy-latency cost) during inference of VLMs, it will exhaust computational\nresources. In this paper, we explore this attack surface about availability of\nVLMs and aim to induce high energy-latency cost during inference of VLMs. We\nfind that high energy-latency cost during inference of VLMs can be manipulated\nby maximizing the length of generated sequences. To this end, we propose\nverbose images, with the goal of crafting an imperceptible perturbation to\ninduce VLMs to generate long sentences during inference. Concretely, we design\nthree loss objectives. First, a loss is proposed to delay the occurrence of\nend-of-sequence (EOS) token, where EOS token is a signal for VLMs to stop\ngenerating further tokens. Moreover, an uncertainty loss and a token diversity\nloss are proposed to increase the uncertainty over each generated token and the\ndiversity among all tokens of the whole generated sequence, respectively, which\ncan break output dependency at token-level and sequence-level. Furthermore, a\ntemporal weight adjustment algorithm is proposed, which can effectively balance\nthese losses. Extensive experiments demonstrate that our verbose images can\nincrease the length of generated sequences by 7.87 times and 8.56 times\ncompared to original images on MS-COCO and ImageNet datasets, which presents\npotential challenges for various applications. Our code is available at\nhttps://github.com/KuofengGao/Verbose_Images.", "field": "Computer Science", "categories": "cs.CV,cs.CR"}, {"arxiv_id": "2401.11174", "title": "Pixel-Wise Recognition for Holistic Surgical Scene Understanding", "abstract": "This paper presents the Holistic and Multi-Granular Surgical Scene\nUnderstanding of Prostatectomies (GraSP) dataset, a curated benchmark that\nmodels surgical scene understanding as a hierarchy of complementary tasks with\nvarying levels of granularity. Our approach enables a multi-level comprehension\nof surgical activities, encompassing long-term tasks such as surgical phases\nand steps recognition and short-term tasks including surgical instrument\nsegmentation and atomic visual actions detection. To exploit our proposed\nbenchmark, we introduce the Transformers for Actions, Phases, Steps, and\nInstrument Segmentation (TAPIS) model, a general architecture that combines a\nglobal video feature extractor with localized region proposals from an\ninstrument segmentation model to tackle the multi-granularity of our benchmark.\nThrough extensive experimentation, we demonstrate the impact of including\nsegmentation annotations in short-term recognition tasks, highlight the varying\ngranularity requirements of each task, and establish TAPIS's superiority over\npreviously proposed baselines and conventional CNN-based models. Additionally,\nwe validate the robustness of our method across multiple public benchmarks,\nconfirming the reliability and applicability of our dataset. This work\nrepresents a significant step forward in Endoscopic Vision, offering a novel\nand comprehensive framework for future research towards a holistic\nunderstanding of surgical procedures.", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.LG"}, {"arxiv_id": "2401.11181", "title": "Inference without Interference: Disaggregate LLM Inference for Mixed\n  Downstream Workloads", "abstract": "Transformer-based large language model (LLM) inference serving is now the\nbackbone of many cloud services. LLM inference consists of a prefill phase and\na decode phase. However, existing LLM deployment practices often overlook the\ndistinct characteristics of these phases, leading to significant interference.\nTo mitigate interference, our insight is to carefully schedule and group\ninference requests based on their characteristics. We realize this idea in\nTetriInfer through three pillars. First, it partitions prompts into fixed-size\nchunks so that the accelerator always runs close to its computationsaturated\nlimit. Second, it disaggregates prefill and decode instances so each can run\nindependently. Finally, it uses a smart two-level scheduling algorithm\naugmented with predicted resource usage to avoid decode scheduling hotspots.\nResults show that TetriInfer improves time-to-first-token (TTFT), job\ncompletion time (JCT), and inference efficiency in turns of performance per\ndollar by a large margin, e.g., it uses 38% less resources all the while\nlowering average TTFT and average JCT by 97% and 47%, respectively.", "field": "Computer Science", "categories": "cs.DC"}, {"arxiv_id": "2401.11183", "title": "Predictive stability filters for nonlinear dynamical systems affected by\n  disturbances", "abstract": "Predictive safety filters provide a way of projecting potentially unsafe\ninputs onto the set of inputs that guarantee recursive state and input\nconstraint satisfaction. Unsafe inputs, proposed, e.g. by a human or\nlearning-based controller, can thereby be filtered by leveraging model\npredictive control techniques. In this paper, we extend this framework such\nthat in addition, robust asymptotic stability of the closed-loop system can be\nguaranteed by enforcing a decrease of an implicit Lyapunov function which is\nconstructed using a predicted system trajectory. Differently from previous\nresults, we show robust asymptotic stability on an extended state consisting of\nthe system state and a warmstart input sequence and establish robust asymptotic\nstability for the augmented dynamics with respect to a predefined disturbance.\nThe proposed strategy is applied to an automotive lane keeping example in\nsimulation.", "field": "Computer Science", "categories": "eess.SY,cs.SY,math.OC"}, {"arxiv_id": "2401.11185", "title": "How the Advent of Ubiquitous Large Language Models both Stymie and\n  Turbocharge Dynamic Adversarial Question Generation", "abstract": "Dynamic adversarial question generation, where humans write examples to stump\na model, aims to create examples that are realistic and informative. However,\nthe advent of large language models (LLMs) has been a double-edged sword for\nhuman authors: more people are interested in seeing and pushing the limits of\nthese models, but because the models are so much stronger an opponent, they are\nharder to defeat. To understand how these models impact adversarial question\nwriting process, we enrich the writing guidance with LLMs and retrieval models\nfor the authors to reason why their questions are not adversarial. While\nauthors could create interesting, challenging adversarial questions, they\nsometimes resort to tricks that result in poor questions that are ambiguous,\nsubjective, or confusing not just to a computer but also to humans. To address\nthese issues, we propose new metrics and incentives for eliciting good,\nchallenging questions and present a new dataset of adversarially authored\nquestions.", "field": "Computer Science", "categories": "cs.CL,cs.HC"}, {"arxiv_id": "2401.11188", "title": "Fast and Exact Enumeration of Deep Networks Partitions Regions", "abstract": "One fruitful formulation of Deep Networks (DNs) enabling their theoretical\nstudy and providing practical guidelines to practitioners relies on Piecewise\nAffine Splines. In that realm, a DN's input-mapping is expressed as per-region\naffine mapping where those regions are implicitly determined by the model's\narchitecture and form a partition of their input space. That partition -- which\nis involved in all the results spanned from this line of research -- has so far\nonly been computed on $2/3$-dimensional slices of the DN's input space or\nestimated by random sampling. In this paper, we provide the first parallel\nalgorithm that does exact enumeration of the DN's partition regions. The\nproposed algorithm enables one to finally assess the closeness of the commonly\nemployed approximations methods, e.g. based on random sampling of the DN input\nspace. One of our key finding is that if one is only interested in regions with\n``large'' volume, then uniform sampling of the space is highly efficient, but\nthat if one is also interested in discovering the ``small'' regions of the\npartition, then uniform sampling is exponentially costly with the DN's input\nspace dimension. On the other hand, our proposed method has complexity scaling\nlinearly with input dimension and the number of regions.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.11189", "title": "Globally exponentially convergent observer for systems evolving on\n  matrix Lie groups", "abstract": "We propose a globally exponentially convergent observer for the dynamical\nsystem evolving on matrix Lie groups with bounded velocity with unknown bound.\nWe design the observer in the ambient Euclidean space and show exponential\nconvergence of the observer to the state of the system. We show the convergence\nwith an example of a rigid body rotation and translation system on the special\nEuclidean group. We compare the proposed observer with an observer present in\nthe literature.", "field": "Computer Science", "categories": "eess.SY,cs.SY"}, {"arxiv_id": "2401.11191", "title": "Angular velocity and linear acceleration measurement bias estimators for\n  the rigid body system with global exponential convergence", "abstract": "Rigid body systems usually consider measurements of the pose of the body\nusing onboard cameras/LiDAR systems, that of linear acceleration using an\naccelerometer and of angular velocity using an IMU. However, the measurements\nof the linear acceleration and angular velocity are usually biased with an\nunknown constant or slowly varying bias. We propose a measurement bias\nestimator for such systems under assumption of boundedness of angular velocity.\nWe also provide continuous estimates to the state of the system, i.e. the pose,\nlinear velocity, and position of the body. These estimates are globally\nexponentially convergent to the state of the rigid body system. We propose two\nbias estimators designed with the estimate of the pose in the ambient Euclidean\nspace of the Special Euclidean group and show global exponential convergence of\nthe proposed observers to the state of the system. The first observer assumes\nknowledge of bounds of the angular velocity, while the second observer uses a\nRiccati observer to overcome this limitation. We show the convergence with an\nexample of a rigid body rotation and translation system on the special\nEuclidean group. We show that the observer is able to estimate the bias using\ndata collected from an Intel Realsense camera.", "field": "Computer Science", "categories": "eess.SY,cs.SY"}, {"arxiv_id": "2401.11194", "title": "Mapping the Field of Algorithm Auditing: A Systematic Literature Review\n  Identifying Research Trends, Linguistic and Geographical Disparities", "abstract": "The increasing reliance on complex algorithmic systems by online platforms\nhas sparked a growing need for algorithm auditing, a research methodology\nevaluating these systems' functionality and societal impact. In this paper, we\nsystematically review algorithm auditing studies and identify trends in their\nmethodological approaches, the geographic distribution of authors, and the\nselection of platforms, languages, geographies, and group-based attributes in\nthe focus of auditing research. We present evidence of a significant skew of\nresearch focus toward Western contexts, particularly the US, and a\ndisproportionate reliance on English language data. Additionally, our analysis\nindicates a tendency in algorithm auditing studies to focus on a narrow set of\ngroup-based attributes, often operationalized in simplified ways, which might\nobscure more nuanced aspects of algorithmic bias and discrimination. By\nconducting this review, we aim to provide a clearer understanding of the\ncurrent state of the algorithm auditing field and identify gaps that need to be\naddressed for a more inclusive and representative research landscape.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.11195", "title": "Triple-Refined Hybrid-Field Beam Training for mmWave Extremely\n  Large-Scale MIMO", "abstract": "This paper investigates beam training for extremely large-scale\nmultiple-input multiple-output systems. By considering both the near field and\nfar field, a triple-refined hybrid-field beam training scheme is proposed,\nwhere high-accuracy estimates of channel parameters are obtained through three\nsteps of progressive beam refinement. First, the hybrid-field beam gain\n(HFBG)-based first refinement method is developed. Based on the analysis of the\nHFBG, the first-refinement codebook is designed and the beam training is\nperformed accordingly to narrow down the potential region of the channel path.\nThen, the maximum likelihood (ML)-based and principle of stationary phase\n(PSP)-based second refinement methods are developed. By exploiting the\nmeasurements of the beam training, the ML is used to estimate the channel\nparameters. To avoid the high computational complexity of ML, closed-form\nestimates of the channel parameters are derived according to the PSP. Moreover,\nthe Gaussian approximation (GA)-based third refinement method is developed. The\nhybrid-field neighboring search is first performed to identify the potential\nregion of the main lobe of the channel steering vector. Afterwards, by applying\nthe GA, a least-squares estimator is developed to obtain the high-accuracy\nchannel parameter estimation. Simulation results verify the effectiveness of\nthe proposed scheme.", "field": "Computer Science", "categories": "cs.IT,eess.SP,math.IT"}, {"arxiv_id": "2401.11196", "title": "Machine learning based state observer for discrete time systems evolving\n  on Lie groups", "abstract": "In this paper, a machine learning based observer for systems evolving on\nmanifolds is designed such that the state of the observer is restricted to the\nLie group on which the system evolves. Conventional techniques involving\nmachine learning based observers on systems evolving on Lie groups involve\ndesigning charts for the Lie group, training a machine learning based observer\nfor each chart, and switching between the trained models based on the state of\nthe system. We propose a novel deep learning based technique whose predictions\nare restricted to a measure 0 subset of Euclidean space without using charts.\nUsing this network, we design an observer ensuring that the state of the\nobserver is restricted to the Lie group, and predicting the state using only\none trained algorithm. The deep learning network predicts an ``error term'' on\nthe Lie algebra of the Lie group, uses the map from the Lie algebra to the\ngroup, and uses the group action and the present state to estimate the state at\nthe next epoch. This model being purely data driven does not require the model\nof the system. The proposed algorithm provides a novel framework for\nconstraining the output of machine learning networks to a measure 0 subset of a\nEuclidean space without chart specific training and without requiring\nswitching. We show the validity of this method using Monte Carlo simulations\nperformed of the rigid body rotation and translation system.", "field": "Computer Science", "categories": "eess.SY,cs.LG,cs.SY"}, {"arxiv_id": "2401.11197", "title": "Introducing TOAST: Safe Asynchronous Mixed-Choice For Timed Interactions", "abstract": "Mixed-choice has long been barred from models of asynchronous communication\nsince it compromises the decidability of key properties of communicating\nfinite-state machines. Session types inherit this restriction, which precludes\nthem from fully modelling timeouts -- a core property of web and cloud\nservices. To address this deficiency, we present (binary) Timeout Asynchronous\nSession Types ({TOAST}) as an extension to (binary) asynchronous timed session\ntypes, that permits mixed-choice. {TOAST} deploys timing constraints to\nregulate the use of mixed-choice so as to preserve communication safety. We\nprovide a new behavioural semantics for {TOAST} which guarantees progress in\nthe presence of mixed-choice. Building upon {TOAST}, we provide a calculus\nfeaturing process timers which is capable of modelling timeouts using a\n$\\mathtt{receive\\text{-}after}$ pattern, much like Erlang, and capture the\ncorrespondence with TOAST specifications via a type system for which we prove\nsubject reduction.", "field": "Computer Science", "categories": "cs.LO"}, {"arxiv_id": "2401.11198", "title": "A Deep Learning Approach for Selective Relevance Feedback", "abstract": "Pseudo-relevance feedback (PRF) can enhance average retrieval effectiveness\nover a sufficiently large number of queries. However, PRF often introduces a\ndrift into the original information need, thus hurting the retrieval\neffectiveness of several queries. While a selective application of PRF can\npotentially alleviate this issue, previous approaches have largely relied on\nunsupervised or feature-based learning to determine whether a query should be\nexpanded. In contrast, we revisit the problem of selective PRF from a deep\nlearning perspective, presenting a model that is entirely data-driven and\ntrained in an end-to-end manner. The proposed model leverages a\ntransformer-based bi-encoder architecture. Additionally, to further improve\nretrieval effectiveness with this selective PRF approach, we make use of the\nmodel's confidence estimates to combine the information from the original and\nexpanded queries. In our experiments, we apply this selective feedback on a\nnumber of different combinations of ranking and feedback models, and show that\nour proposed approach consistently improves retrieval effectiveness for both\nsparse and dense ranking models, with the feedback models being either sparse,\ndense or generative.", "field": "Computer Science", "categories": "cs.IR"}, {"arxiv_id": "2401.11199", "title": "Projected Belief Networks With Discriminative Alignment for Acoustic\n  Event Classification: Rivaling State of the Art CNNs", "abstract": "The projected belief network (PBN) is a generative stochastic network with\ntractable likelihood function based on a feed-forward neural network (FFNN).\nThe generative function operates by \"backing up\" through the FFNN. The PBN is\ntwo networks in one, a FFNN that operates in the forward direction, and a\ngenerative network that operates in the backward direction. Both networks\nco-exist based on the same parameter set, have their own cost functions, and\ncan be separately or jointly trained. The PBN therefore has the potential to\npossess the best qualities of both discriminative and generative classifiers.\nTo realize this potential, a separate PBN is trained on each class, maximizing\nthe generative likelihood function for the given class, while minimizing the\ndiscriminative cost for the FFNN against \"all other classes\". This technique,\ncalled discriminative alignment (PBN-DA), aligns the contours of the likelihood\nfunction to the decision boundaries and attains vastly improved classification\nperformance, rivaling that of state of the art discriminative networks. The\nmethod may be further improved using a hidden Markov model (HMM) as a component\nof the PBN, called PBN-DA-HMM. This paper provides a comprehensive treatment of\nPBN, PBN-DA, and PBN-DA-HMM. In addition, the results of two new classification\nexperiments are provided. The first experiment uses air-acoustic events, and\nthe second uses underwater acoustic data consisting of marine mammal calls. In\nboth experiments, PBN-DA-HMM attains comparable or better performance as a\nstate of the art CNN, and attain a factor of two error reduction when combined\nwith the CNN.", "field": "Computer Science", "categories": "cs.LG,cs.SD,eess.AS,G.3; I.2"}, {"arxiv_id": "2401.112", "title": "Transversally exponentially stable Euclidean space extension technique\n  for discrete time systems", "abstract": "We propose a modification technique for discrete time systems for\nexponentially fast convergence to compact sets. The extension technique allows\nus to use tools defined on Euclidean spaces to systems evolving on manifolds by\nmodifying the dynamics of the system such that the manifold is an attractor\nset. We show the stability properties of this technique using the simulation of\nthe rigid body rotation system on the unit sphere $S^3$. We also show the\nimprovement afforded due to this technique on a Luenberger like observer\ndesigned for the rigid body rotation system on $S^3$.", "field": "Computer Science", "categories": "eess.SY,cs.SY"}, {"arxiv_id": "2401.11201", "title": "Navigating the Thin Line: Examining User Behavior in Search to Detect\n  Engagement and Backfire Effects", "abstract": "Opinionated users often seek information that aligns with their preexisting\nbeliefs while dismissing contradictory evidence due to confirmation bias. This\nconduct hinders their ability to consider alternative stances when searching\nthe web. Despite this, few studies have analyzed how the diversification of\nsearch results on disputed topics influences the search behavior of highly\nopinionated users. To this end, we present a preregistered user study (n = 257)\ninvestigating whether different levels (low and high) of bias metrics and\nsearch results presentation (with or without AI-predicted stances labels) can\naffect the stance diversity consumption and search behavior of opinionated\nusers on three debated topics (i.e., atheism, intellectual property rights, and\nschool uniforms). Our results show that exposing participants to\n(counter-attitudinally) biased search results increases their consumption of\nattitude-opposing content, but we also found that bias was associated with a\ntrend toward overall fewer interactions within the search page. We also found\nthat 19% of users interacted with queries and search pages but did not select\nany search results. When we removed these participants in a post-hoc analysis,\nwe found that stance labels increased the diversity of stances consumed by\nusers, particularly when the search results were biased. Our findings highlight\nthe need for future research to explore distinct search scenario settings to\ngain insight into opinionated users' behavior.", "field": "Computer Science", "categories": "cs.IR,cs.AI"}, {"arxiv_id": "2401.11202", "title": "PartIR: Composing SPMD Partitioning Strategies for Machine Learning", "abstract": "Training of modern large neural networks (NN) requires a combination of\nparallelization strategies encompassing data, model, or optimizer sharding.\nWhen strategies increase in complexity, it becomes necessary for partitioning\ntools to be 1) expressive, allowing the composition of simpler strategies, and\n2) predictable to estimate performance analytically. We present PartIR, our\ndesign for a NN partitioning system. PartIR is focused on an incremental\napproach to rewriting and is hardware-and-runtime agnostic. We present a simple\nbut powerful API for composing sharding strategies and a simulator to validate\nthem. The process is driven by high-level programmer-issued partitioning\ntactics, which can be both manual and automatic. Importantly, the tactics are\nspecified separately from the model code, making them easy to change. We\nevaluate PartIR on several different models to demonstrate its predictability,\nexpressibility, and ability to reach peak performance..", "field": "Computer Science", "categories": "cs.LG,cs.DC,cs.PL"}, {"arxiv_id": "2401.11203", "title": "Obstacle-Aware Navigation of Soft Growing Robots via Deep Reinforcement\n  Learning", "abstract": "Soft growing robots, are a type of robots that are designed to move and adapt\nto their environment in a similar way to how plants grow and move with\npotential applications where they could be used to navigate through tight\nspaces, dangerous terrain, and hard-to-reach areas. This research explores the\napplication of deep reinforcement Q-learning algorithm for facilitating the\nnavigation of the soft growing robots in cluttered environments. The proposed\nalgorithm utilizes the flexibility of the soft robot to adapt and incorporate\nthe interaction between the robot and the environment into the decision-making\nprocess. Results from simulations show that the proposed algorithm improves the\nsoft robot's ability to navigate effectively and efficiently in confined\nspaces. This study presents a promising approach to addressing the challenges\nfaced by growing robots in particular and soft robots general in planning\nobstacle-aware paths in real-world scenarios.", "field": "Computer Science", "categories": "cs.RO"}, {"arxiv_id": "2401.11204", "title": "Towards Category Unification of 3D Single Object Tracking on Point\n  Clouds", "abstract": "Category-specific models are provenly valuable methods in 3D single object\ntracking (SOT) regardless of Siamese or motion-centric paradigms. However, such\nover-specialized model designs incur redundant parameters, thus limiting the\nbroader applicability of 3D SOT task. This paper first introduces unified\nmodels that can simultaneously track objects across all categories using a\nsingle network with shared model parameters. Specifically, we propose to\nexplicitly encode distinct attributes associated to different object\ncategories, enabling the model to adapt to cross-category data. We find that\nthe attribute variances of point cloud objects primarily occur from the varying\nsize and shape (e.g., large and square vehicles v.s. small and slender humans).\nBased on this observation, we design a novel point set representation learning\nnetwork inheriting transformer architecture, termed AdaFormer, which adaptively\nencodes the dynamically varying shape and size information from cross-category\ndata in a unified manner. We further incorporate the size and shape prior\nderived from the known template targets into the model's inputs and learning\nobjective, facilitating the learning of unified representation. Equipped with\nsuch designs, we construct two category-unified models SiamCUT and\nMoCUT.Extensive experiments demonstrate that SiamCUT and MoCUT exhibit strong\ngeneralization and training stability. Furthermore, our category-unified models\noutperform the category-specific counterparts by a significant margin (e.g., on\nKITTI dataset, 12% and 3% performance gains on the Siamese and motion\nparadigms). Our code will be available.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11205", "title": "Joint Beamforming Optimization and Mode Selection for RDARS-aided MIMO\n  Systems", "abstract": "Considering the appealing distribution gains of distributed antenna systems\n(DAS) and passive gains of reconfigurable intelligent surface (RIS), a flexible\nreconfigurable architecture called reconfigurable distributed antenna and\nreflecting surface (RDARS) is proposed. RDARS encompasses DAS and RIS as two\nspecial cases and maintains the advantages of distributed antennas while\nreducing the hardware cost by replacing some active antennas with low-cost\npassive reflecting surfaces. In this paper, we present a RDARS-aided uplink\nmulti-user communication system and investigate the system transmission\nreliability with the newly proposed architecture. Specifically, in addition to\nthe distribution gain and the reflection gain provided by the connection and\nreflection modes, respectively, we also consider the dynamic mode switching of\neach element which introduces an additional degree of freedom (DoF) and thus\nresults in a selection gain. As such, we aim to minimize the total sum\nmean-square-error (MSE) of all data streams by jointly optimizing the receive\nbeamforming matrix, the reflection phase shifts and the channel-aware placement\nof elements in the connection mode. To tackle this nonconvex problem with\nintractable binary and cardinality constraints, we propose an inexact block\ncoordinate descent (BCD) based penalty dual decomposition (PDD) algorithm with\nthe guaranteed convergence. Since the PDD algorithm usually suffers from high\ncomputational complexity, a low-complexity greedy-search-based alternating\noptimization (AO) algorithm is developed to yield a semi-closed-form solution\nwith acceptable performance. Numerical results demonstrate the superiority of\nthe proposed architecture compared to the conventional fully passive RIS or\nDAS. Furthermore, some insights about the practical implementation of RDARS are\nprovided.", "field": "Computer Science", "categories": "cs.IT,eess.SP,math.IT"}, {"arxiv_id": "2401.11206", "title": "InferAligner: Inference-Time Alignment for Harmlessness through\n  Cross-Model Guidance", "abstract": "With the rapid development of large language models (LLMs), they are not only\nused as general-purpose AI assistants but are also customized through further\nfine-tuning to meet the requirements of different applications. A pivotal\nfactor in the success of current LLMs is the alignment process. Current\nalignment methods, such as supervised fine-tuning (SFT) and reinforcement\nlearning from human feedback (RLHF), focus on training-time alignment and are\noften complex and cumbersome to implement. Therefore, we develop\n\\textbf{InferAligner}, a novel inference-time alignment method that utilizes\ncross-model guidance for harmlessness alignment. InferAligner utilizes safety\nsteering vectors extracted from safety-aligned model to modify the activations\nof the target model when responding to harmful inputs, thereby guiding the\ntarget model to provide harmless responses. Experimental results show that our\nmethod can be very effectively applied to domain-specific models in finance,\nmedicine, and mathematics, as well as to multimodal large language models\n(MLLMs) such as LLaVA. It significantly diminishes the Attack Success Rate\n(ASR) of both harmful instructions and jailbreak attacks, while maintaining\nalmost unchanged performance in downstream tasks.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.11207", "title": "Unfair TOS: An Automated Approach using Customized BERT", "abstract": "Terms of Service (ToS) form an integral part of any agreement as it defines\nthe legal relationship between a service provider and an end-user. Not only do\nthey establish and delineate reciprocal rights and responsibilities, but they\nalso provide users with information on essential aspects of contracts that\npertain to the use of digital spaces. These aspects include a wide range of\ntopics, including limitation of liability, data protection, etc. Users tend to\naccept the ToS without going through it before using any application or\nservice. Such ignorance puts them in a potentially weaker situation in case any\naction is required. Existing methodologies for the detection or classification\nof unfair clauses are however obsolete and show modest performance. In this\nresearch paper, we present SOTA(State of The Art) results on unfair clause\ndetection from ToS documents based on unprecedented Fine-tuning BERT in\nintegration with SVC(Support Vector Classifier). The study shows proficient\nperformance with a macro F1-score of 0.922 at unfair clause detection, and\nsuperior performance is also shown in the classification of unfair clauses by\neach tag. Further, a comparative analysis is performed by answering research\nquestions on the Transformer models utilized. In order to further research and\nexperimentation the code and results are made available on\nhttps://github.com/batking24/Unfair-TOS-An-Automated-Approach-based-on-Fine-tuning-BERT-in-conjunction-with-ML.", "field": "Computer Science", "categories": "cs.CL,cs.CY"}, {"arxiv_id": "2401.11212", "title": "Programming Distributed Collective Processes in the eXchange Calculus", "abstract": "Recent trends like the Internet of Things (IoT) suggest a vision of dense and\nmulti-scale deployments of computing devices in nearly all kinds of\nenvironments. A prominent engineering challenge revolves around programming the\ncollective adaptive behaviour of such computational ecosystems. This requires\nabstractions able to capture concepts like ensembles (dynamic groups of\ncooperating devices) and collective tasks (joint activities carried out by\nensembles). In this work, we consider collections of devices interacting with\nneighbours and that execute in nearly-synchronised sense-compute-interact\nrounds, where the computation is given by a single program mapping sensing\nvalues and incoming messages to output and outcoming messages. To support\nprogramming whole computational collectives, we propose the abstraction of a\ndistributed collective process, which can be used to define at once the\nensemble formation logic and its collective task. We formalise the abstraction\nin the eXchange Calculus (XC), a core functional language based on neighbouring\nvalues (maps from neighbours to values) where state and interaction is handled\nthrough a single primitive, exchange, and provide a corresponding\nimplementation in the FCPP language. Then, we exercise distributed collective\nprocesses using two case studies: multi-hop message propagation and distributed\nmonitoring of spatial properties. Finally, we discuss the features of the\nabstraction and its suitability for different kinds of distributed computing\napplications.", "field": "Computer Science", "categories": "cs.DC,cs.AI,cs.MA,cs.PL,D.1.3; F.1.1; F.4.3; I.2.11; J.7"}, {"arxiv_id": "2401.11214", "title": "3D Receiver for Molecular Communications in Internet of Organoids", "abstract": "Organoids have garnered attention due to their effectiveness in modeling the\n3D structure of organ interactions. However, the communication engineering\nperspective has received relatively little attention. One way to achieve\norganoids communication is molecular communication (MC). Molecular\ncommunication is a bio-inspired communication paradigm that uses molecules as\ninformation carriers. It is considered one of the most promising methods for\nenabling the Internet of Nano-Things (IoNT) and nanonetworks. BioFETs are\ncommonly used to implement practical MC receivers. However, most previous\nanalyses have focused on a planar device, neglecting considerations like the\nthreshold voltage and its potential 3D structure. This paper introduces the\nfirst FinFET-based MC receiver that covers both the top and side gates with\nreceptors. Both binding noise and flicker noise are considered in the analysis.\nThe performance, in terms of signal-to-noise ratio (SNR) and symbol error\nprobability (SEP), is compared with that of the 2D receiver.", "field": "Computer Science", "categories": "cs.ET,cs.SY,eess.SY"}, {"arxiv_id": "2401.11215", "title": "Selecting Walk Schemes for Database Embedding", "abstract": "Machinery for data analysis often requires a numeric representation of the\ninput. Towards that, a common practice is to embed components of structured\ndata into a high-dimensional vector space. We study the embedding of the tuples\nof a relational database, where existing techniques are often based on\noptimization tasks over a collection of random walks from the database. The\nfocus of this paper is on the recent FoRWaRD algorithm that is designed for\ndynamic databases, where walks are sampled by following foreign keys between\ntuples. Importantly, different walks have different schemas, or \"walk schemes\",\nthat are derived by listing the relations and attributes along the walk. Also\nimportantly, different walk schemes describe relationships of different natures\nin the database. We show that by focusing on a few informative walk schemes, we\ncan obtain tuple embedding significantly faster, while retaining the quality.\nWe define the problem of scheme selection for tuple embedding, devise several\napproaches and strategies for scheme selection, and conduct a thorough\nempirical study of the performance over a collection of downstream tasks. Our\nresults confirm that with effective strategies for scheme selection, we can\nobtain high-quality embeddings considerably (e.g., three times) faster,\npreserve the extensibility to newly inserted tuples, and even achieve an\nincrease in the precision of some tasks.", "field": "Computer Science", "categories": "cs.LG,cs.DB"}, {"arxiv_id": "2401.11217", "title": "A Hybrid Approach of Transfer Learning and Physics-Informed Modeling:\n  Improving Dissolved Oxygen Concentration Prediction in an Industrial\n  Wastewater Treatment Plant", "abstract": "Constructing first principles models is a challenging task for nonlinear and\ncomplex systems such as a wastewater treatment unit. In recent years,\ndata-driven models are widely used to overcome the complexity. However, they\noften suffer from issues such as missing, low quality or noisy data. Transfer\nlearning is a solution for this issue where knowledge from another task is\ntransferred to target one to increase the prediction performance. In this work,\nthe objective is increasing the prediction performance of an industrial\nwastewater treatment plant by transferring the knowledge of (i) an open-source\nsimulation model that captures the underlying physics of the process, albeit\nwith dissimilarities to the target plant, (ii) another industrial plant\ncharacterized by noisy and limited data but located in the same refinery, and\n(iii) the model in (ii) and making the objective function of the training\nproblem physics informed where the physics information derived from the\nopen-source model in (ii). The results have shown that test and validation\nperformance are improved up to 27% and 59%, respectively.", "field": "Computer Science", "categories": "cs.LG,cs.AI,math.DS"}, {"arxiv_id": "2401.11218", "title": "End-to-End Argument Mining over Varying Rhetorical Structures", "abstract": "Rhetorical Structure Theory implies no single discourse interpretation of a\ntext, and the limitations of RST parsers further exacerbate inconsistent\nparsing of similar structures. Therefore, it is important to take into account\nthat the same argumentative structure can be found in semantically similar\ntexts with varying rhetorical structures. In this work, the differences between\nparaphrases within the same argument scheme are evaluated from a rhetorical\nperspective. The study proposes a deep dependency parsing model to assess the\nconnection between rhetorical and argument structures. The model utilizes\nrhetorical relations; RST structures of paraphrases serve as training data\naugmentations. The method allows for end-to-end argumentation analysis using a\nrhetorical tree instead of a word sequence. It is evaluated on the bilingual\nMicrotexts corpus, and the first results on fully-fledged argument parsing for\nthe Russian version of the corpus are reported. The results suggest that\nargument mining can benefit from multiple variants of discourse structure.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.11219", "title": "On the Information Leakage Performance of Secure Finite Blocklength\n  Transmissions over Rayleigh Fading Channels", "abstract": "This paper presents a secrecy performance study of a wiretap communication\nsystem with finite blocklength (FBL) transmissions over Rayleigh fading\nchannels, based on the definition of an average information leakage (AIL)\nmetric. We evaluate the exact and closed-form approximate AIL performance,\nassuming that only statistical channel state information (CSI) of the\neavesdropping link is available. Then, we reveal an inherent statistical\nrelationship between the AIL metric in the FBL regime and the commonly-used\nsecrecy outage probability in conventional infinite blocklength communications.\nAiming to improve the secure communication performance of the considered\nsystem, we formulate a blocklength optimization problem and solve it via a\nlow-complexity approach. Next, we present numerical results to verify our\nanalytical findings and provide various important insights into the impacts of\nsystem parameters on the AIL. Specifically, our results indicate that i)\ncompromising a small amount of AIL can lead to significant reliability\nimprovements, and ii) the AIL experiences a secrecy floor in the high\nsignal-to-noise ratio regime.", "field": "Computer Science", "categories": "cs.IT,math.IT"}, {"arxiv_id": "2401.11225", "title": "Protecting Personalized Trajectory with Differential Privacy under\n  Temporal Correlations", "abstract": "Location-based services (LBSs) in vehicular ad hoc networks (VANETs) offer\nusers numerous conveniences. However, the extensive use of LBSs raises concerns\nabout the privacy of users' trajectories, as adversaries can exploit temporal\ncorrelations between different locations to extract personal information.\nAdditionally, users have varying privacy requirements depending on the time and\nlocation. To address these issues, this paper proposes a personalized\ntrajectory privacy protection mechanism (PTPPM). This mechanism first uses the\ntemporal correlation between trajectory locations to determine the possible\nlocation set for each time instant. We identify a protection location set (PLS)\nfor each location by employing the Hilbert curve-based minimum distance search\nalgorithm. This approach incorporates the complementary features of\ngeo-indistinguishability and distortion privacy. We put forth a novel\nPermute-and-Flip mechanism for location perturbation, which maps its initial\napplication in data publishing privacy protection to a location perturbation\nmechanism. This mechanism generates fake locations with smaller perturbation\ndistances while improving the balance between privacy and quality of service\n(QoS). Simulation results show that our mechanism outperforms the benchmark by\nproviding enhanced privacy protection while meeting user's QoS requirements.", "field": "Computer Science", "categories": "cs.CR"}, {"arxiv_id": "2401.11228", "title": "Unifying Visual and Vision-Language Tracking via Contrastive Learning", "abstract": "Single object tracking aims to locate the target object in a video sequence\naccording to the state specified by different modal references, including the\ninitial bounding box (BBOX), natural language (NL), or both (NL+BBOX). Due to\nthe gap between different modalities, most existing trackers are designed for\nsingle or partial of these reference settings and overspecialize on the\nspecific modality. Differently, we present a unified tracker called UVLTrack,\nwhich can simultaneously handle all three reference settings (BBOX, NL,\nNL+BBOX) with the same parameters. The proposed UVLTrack enjoys several merits.\nFirst, we design a modality-unified feature extractor for joint visual and\nlanguage feature learning and propose a multi-modal contrastive loss to align\nthe visual and language features into a unified semantic space. Second, a\nmodality-adaptive box head is proposed, which makes full use of the target\nreference to mine ever-changing scenario features dynamically from video\ncontexts and distinguish the target in a contrastive way, enabling robust\nperformance in different reference settings. Extensive experimental results\ndemonstrate that UVLTrack achieves promising performance on seven visual\ntracking datasets, three vision-language tracking datasets, and three visual\ngrounding datasets. Codes and models will be open-sourced at\nhttps://github.com/OpenSpaceAI/UVLTrack.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11231", "title": "Two-Insertion/Deletion/Substitution Correcting Codes", "abstract": "In recent years, the emergence of DNA storage systems has led to a widespread\nfocus on the research of codes correcting insertions, deletions, and classic\nsubstitutions. During the initial investigation, Levenshtein discovered the VT\ncodes are precisely capable of correcting single insertion/deletion and then\nextended the VT construction to single-insertion/deletion/substitution\n($1$-ins/del/sub) correcting codes. Inspired by this, we generalize the recent\nfindings of $1$-del $1$-sub correcting codes with redundancy $6\\log_{2}n+O(1)$\nto more general $2$-ins/del/sub correcting codes without increasing the\nredundancy. Our key technique is to apply higher-order VT syndromes to distinct\nobjects and accomplish a systematic classification of all error patterns.", "field": "Computer Science", "categories": "cs.IT,math.IT"}, {"arxiv_id": "2401.11232", "title": "Collaborative consumption for low and high trust requiring business\n  models: from fare sharing to supporting the elderly and people with\n  disability", "abstract": "This paper offers an overview of collaborative consumption (CC), the related\nbusiness models (BM), the value added (VA) from the consumer's perspective and\nthe role of trust. CC is expanding but it is unclear what opportunities it\noffers and what the challenges will be. This research evaluates the current CC\nBMs and identifies 13 ways they add value from the consumer's perspective. This\nresearch further explores whether CC BMs fall into two categories in terms of\nwhat the consumer values. In the first category, the CC BMs require a low level\nof trust while in the second category of CC BMs a higher level of trust is\nnecessary. It was found that 13 VA by CC BMs could be grouped into personal\ninterest, communal interest and trust building. It is important for\norganisations to acknowledge how their CC BM relates to these dimensions.", "field": "Computer Science", "categories": "cs.HC,cs.CY,H.0; A.0; K.7"}, {"arxiv_id": "2401.11235", "title": "TreeMIL: A Multi-instance Learning Framework for Time Series Anomaly\n  Detection with Inexact Supervision", "abstract": "Time series anomaly detection (TSAD) plays a vital role in various domains\nsuch as healthcare, networks, and industry. Considering labels are crucial for\ndetection but difficult to obtain, we turn to TSAD with inexact supervision:\nonly series-level labels are provided during the training phase, while\npoint-level anomalies are predicted during the testing phase. Previous works\nfollow a traditional multi-instance learning (MIL) approach, which focuses on\nencouraging high anomaly scores at individual time steps. However, time series\nanomalies are not only limited to individual point anomalies, they can also be\ncollective anomalies, typically exhibiting abnormal patterns over subsequences.\nTo address the challenge of collective anomalies, in this paper, we propose a\ntree-based MIL framework (TreeMIL). We first adopt an N-ary tree structure to\ndivide the entire series into multiple nodes, where nodes at different levels\nrepresent subsequences with different lengths. Then, the subsequence features\nare extracted to determine the presence of collective anomalies. Finally, we\ncalculate point-level anomaly scores by aggregating features from nodes at\ndifferent levels. Experiments conducted on seven public datasets and eight\nbaselines demonstrate that TreeMIL achieves an average 32.3% improvement in F1-\nscore compared to previous state-of-the-art methods. The code is available at\nhttps://github.com/fly-orange/TreeMIL.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.11236", "title": "Hierarchical Cell-Free Massive MIMO for High Capacity with Simple\n  Implementation", "abstract": "Cell-free massive multi-input multi-output (MIMO) has recently gained much\nattention for its potential in shaping the landscape of sixth-generation (6G)\nwireless systems. This paper proposes a hierarchical network architecture\ntailored for cell-free massive MIMO, seamlessly integrating co-located and\ndistributed antennas. A central base station (CBS), equipped with an antenna\narray, positions itself near the center of the coverage area, complemented by\ndistributed access points spanning the periphery. The proposed architecture\nremarkably outperforms conventional cell-free networks, demonstrating superior\nsum throughput while maintaining a comparable worst-case per-user spectral\nefficiency. Meanwhile, the implementation cost associated with the fronthaul\nnetwork is substantially diminished.", "field": "Computer Science", "categories": "cs.IT,eess.SP,math.IT"}, {"arxiv_id": "2401.11237", "title": "Closing the Gap between TD Learning and Supervised Learning -- A\n  Generalisation Point of View", "abstract": "Some reinforcement learning (RL) algorithms can stitch pieces of experience\nto solve a task never seen before during training. This oft-sought property is\none of the few ways in which RL methods based on dynamic-programming differ\nfrom RL methods based on supervised-learning (SL). Yet, certain RL methods\nbased on off-the-shelf SL algorithms achieve excellent results without an\nexplicit mechanism for stitching; it remains unclear whether those methods\nforgo this important stitching property. This paper studies this question for\nthe problems of achieving a target goal state and achieving a target return\nvalue. Our main result is to show that the stitching property corresponds to a\nform of combinatorial generalization: after training on a distribution of\n(state, goal) pairs, one would like to evaluate on (state, goal) pairs not seen\ntogether in the training data. Our analysis shows that this sort of\ngeneralization is different from i.i.d. generalization. This connection between\nstitching and generalisation reveals why we should not expect SL-based RL\nmethods to perform stitching, even in the limit of large datasets and models.\nBased on this analysis, we construct new datasets to explicitly test for this\nproperty, revealing that SL-based methods lack this stitching property and\nhence fail to perform combinatorial generalization. Nonetheless, the connection\nbetween stitching and combinatorial generalisation also suggests a simple\nremedy for improving generalisation in SL: data augmentation. We propose a\ntemporal data augmentation and demonstrate that adding it to SL-based methods\nenables them to successfully complete tasks not seen together during training.\nOn a high level, this connection illustrates the importance of combinatorial\ngeneralization for data efficiency in time-series data beyond tasks beyond RL,\nlike audio, video, or text.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.11238", "title": "Can global, extended and repeated ransomware attacks overcome the users\n  status quo bias and cause a switch of system", "abstract": "Ransomware attack effectiveness has increased causing far reaching\nconsequences that are not fully understood. The ability to disrupt core\nservices, the global reach, extended duration, and the repetition has increased\ntheir ability to harm organizations. One aspect that needs to be understood\nbetter is the effect on the user. The user in the current environment is\nexposed to new technologies that might be adopted, but there are also habits of\nusing existing systems. The habits have developed over time with trust\nincreasing in the organization in contact directly and the institutions\nsupporting it. This research explores whether the global, extended, and\nrepeated RW attacks reduce the trust and inertia sufficiently to change\nlong-held habits in using information systems. The model tested measures the\neffect of the RW attack on the e-commerce status quo to evaluate if it is\nsignificant enough to overcome the users resistance to change.", "field": "Computer Science", "categories": "cs.CR,cs.CY,H.0; K.6; A.0; D.0"}, {"arxiv_id": "2401.11239", "title": "Product-Level Try-on: Characteristics-preserving Try-on with Realistic\n  Clothes Shading and Wrinkles", "abstract": "Image-based virtual try-on systems,which fit new garments onto human\nportraits,are gaining research attention.An ideal pipeline should preserve the\nstatic features of clothes(like textures and logos)while also generating\ndynamic elements(e.g.shadows,folds)that adapt to the model's pose and\nenvironment.Previous works fail specifically in generating dynamic features,as\nthey preserve the warped in-shop clothes trivially with predicted an alpha mask\nby composition.To break the dilemma of over-preserving and textures losses,we\npropose a novel diffusion-based Product-level virtual try-on pipeline,\\ie\nPLTON, which can preserve the fine details of logos and embroideries while\nproducing realistic clothes shading and wrinkles.The main insights are in three\nfolds:1)Adaptive Dynamic Rendering:We take a pre-trained diffusion model as a\ngenerative prior and tame it with image features,training a dynamic extractor\nfrom scratch to generate dynamic tokens that preserve high-fidelity semantic\ninformation. Due to the strong generative power of the diffusion prior,we can\ngenerate realistic clothes shadows and wrinkles.2)Static Characteristics\nTransformation: High-frequency Map(HF-Map)is our fundamental insight for static\nrepresentation.PLTON first warps in-shop clothes to the target model pose by a\ntraditional warping network,and uses a high-pass filter to extract an HF-Map\nfor preserving static cloth features.The HF-Map is used to generate modulation\nmaps through our static extractor,which are injected into a fixed U-net to\nsynthesize the final result.To enhance retention,a Two-stage Blended Denoising\nmethod is proposed to guide the diffusion process for correct spatial layout\nand color.PLTON is finetuned only with our collected small-size try-on\ndataset.Extensive quantitative and qualitative experiments on 1024 768 datasets\ndemonstrate the superiority of our framework in mimicking real clothes\ndynamics.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.1124", "title": "CaraServe: CPU-Assisted and Rank-Aware LoRA Serving for Generative LLM\n  Inference", "abstract": "Pre-trained large language models (LLMs) often need specialization for\ndomain-specific tasks. Low-Rank Adaptation (LoRA) is a popular approach that\nadapts a base model to multiple tasks by adding lightweight trainable adapters.\nIn this paper, we present CaraServe, a system that efficiently serves many LoRA\nadapters derived from a common base model. CaraServe maintains the base model\non GPUs and dynamically loads activated LoRA adapters from main memory. As GPU\nloading results in a cold-start that substantially delays token generation,\nCaraServe employs a CPU-assisted approach. It early starts the activated\nadapters on CPUs for prefilling as they are being loaded onto GPUs; after\nloading completes, it then switches to the GPUs for generative LoRA inference.\nCaraServe develops a highly optimized synchronization mechanism to efficiently\ncoordinate LoRA computation on the CPU and GPU. Moreover, CaraServe employs a\nrank-aware scheduling algorithm to optimally schedule heterogeneous LoRA\nrequests for maximum service-level objective (SLO) attainment. We have\nimplemented CaraServe and evaluated it against state-of-the-art LoRA serving\nsystems. Our results demonstrate that CaraServe can speed up the average\nrequest serving latency by up to 1.4$\\times$ and achieve an SLO attainment of\nup to 99%.", "field": "Computer Science", "categories": "cs.DC"}, {"arxiv_id": "2401.11243", "title": "LRP-QViT: Mixed-Precision Vision Transformer Quantization via Layer-wise\n  Relevance Propagation", "abstract": "Vision transformers (ViTs) have demonstrated remarkable performance across\nvarious visual tasks. However, ViT models suffer from substantial computational\nand memory requirements, making it challenging to deploy them on\nresource-constrained platforms. Quantization is a popular approach for reducing\nmodel size, but most studies mainly focus on equal bit-width quantization for\nthe entire network, resulting in sub-optimal solutions. While there are few\nworks on mixed precision quantization (MPQ) for ViTs, they typically rely on\nsearch space-based methods or employ mixed precision arbitrarily. In this\npaper, we introduce LRP-QViT, an explainability-based method for assigning\nmixed-precision bit allocations to different layers based on their importance\nduring classification. Specifically, to measure the contribution score of each\nlayer in predicting the target class, we employ the Layer-wise Relevance\nPropagation (LRP) method. LRP assigns local relevance at the output layer and\npropagates it through all layers, distributing the relevance until it reaches\nthe input layers. These relevance scores serve as indicators for computing the\nlayer contribution score. Additionally, we have introduced a clipped\nchannel-wise quantization aimed at eliminating outliers from post-LayerNorm\nactivations to alleviate severe inter-channel variations. To validate and\nassess our approach, we employ LRP-QViT across ViT, DeiT, and Swin transformer\nmodels on various datasets. Our experimental findings demonstrate that both our\nfixed-bit and mixed-bit post-training quantization methods surpass existing\nmodels in the context of 4-bit and 6-bit quantization.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11246", "title": "Prompt-RAG: Pioneering Vector Embedding-Free Retrieval-Augmented\n  Generation in Niche Domains, Exemplified by Korean Medicine", "abstract": "We propose a natural language prompt-based retrieval augmented generation\n(Prompt-RAG), a novel approach to enhance the performance of generative large\nlanguage models (LLMs) in niche domains. Conventional RAG methods mostly\nrequire vector embeddings, yet the suitability of generic LLM-based embedding\nrepresentations for specialized domains remains uncertain. To explore and\nexemplify this point, we compared vector embeddings from Korean Medicine (KM)\nand Conventional Medicine (CM) documents, finding that KM document embeddings\ncorrelated more with token overlaps and less with human-assessed document\nrelatedness, in contrast to CM embeddings. Prompt-RAG, distinct from\nconventional RAG models, operates without the need for embedding vectors. Its\nperformance was assessed through a Question-Answering (QA) chatbot application,\nwhere responses were evaluated for relevance, readability, and informativeness.\nThe results showed that Prompt-RAG outperformed existing models, including\nChatGPT and conventional vector embedding-based RAGs, in terms of relevance and\ninformativeness. Despite challenges like content structuring and response\nlatency, the advancements in LLMs are expected to encourage the use of\nPrompt-RAG, making it a promising tool for other domains in need of RAG\nmethods.", "field": "Computer Science", "categories": "cs.CL,cs.IR,I.2.7; H.3.3; J.3"}, {"arxiv_id": "2401.11247", "title": "Applying stiff integrators for ODEs and DDEs to problems with\n  distributed delays", "abstract": "There exist excellent codes for an efficient numerical treatment of stiff and\ndifferential-algebraic problems. Let us mention {\\sc Radau5} which is based on\nthe $3$-stage Radau IIA collocation method, and its extension to problems with\ndiscrete delays {\\sc Radar5}. The aim of the present work is to present a\ntechnique that permits a direct application of these codes to problems having a\nright-hand side with an additional distributed delay term (which is a special\ncase of an integro-differential equation). Models with distributed delays are\nof increasing importance in pharmacodynamics and pharmacokinetics for the study\nof the interaction between drugs and the body.\n  The main idea is to approximate the distribution kernel of the integral term\nby a sum of exponential functions or by a quasi-polynomial expansion, and then\nto transform the distributed (integral) delay term into a set of ordinary\ndifferential equations. This set is typically stiff and, for some distribution\nkernels (e.g., Pareto distribution), it contains discrete delay terms with\nconstant delay. The original equations augmented by this set of ordinary\ndifferential equations can have a very large dimension, and a careful treatment\nof the solution of the arising linear systems is necessary.\n  The use of the codes {\\sc Radau5} and {\\sc Radar5} is illustrated at three\nexamples (two test equations and one problem taken from pharmacodynamics). The\ndriver programs for these examples are publicly available from the homepages of\nthe authors.", "field": "Computer Science", "categories": "math.NA,cs.NA,65L06, 45D05, 65F05"}, {"arxiv_id": "2401.11248", "title": "Drop your Decoder: Pre-training with Bag-of-Word Prediction for Dense\n  Passage Retrieval", "abstract": "Masked auto-encoder pre-training has emerged as a prevalent technique for\ninitializing and enhancing dense retrieval systems. It generally utilizes\nadditional Transformer decoder blocks to provide sustainable supervision\nsignals and compress contextual information into dense representations.\nHowever, the underlying reasons for the effectiveness of such a pre-training\ntechnique remain unclear. The usage of additional Transformer-based decoders\nalso incurs significant computational costs. In this study, we aim to shed\nlight on this issue by revealing that masked auto-encoder (MAE) pre-training\nwith enhanced decoding significantly improves the term coverage of input tokens\nin dense representations, compared to vanilla BERT checkpoints. Building upon\nthis observation, we propose a modification to the traditional MAE by replacing\nthe decoder of a masked auto-encoder with a completely simplified Bag-of-Word\nprediction task. This modification enables the efficient compression of lexical\nsignals into dense representations through unsupervised pre-training.\nRemarkably, our proposed method achieves state-of-the-art retrieval performance\non several large-scale retrieval benchmarks without requiring any additional\nparameters, which provides a 67% training speed-up compared to standard masked\nauto-encoder pre-training with enhanced decoding.", "field": "Computer Science", "categories": "cs.IR,cs.CL"}, {"arxiv_id": "2401.11249", "title": "Evaluating if trust and personal information privacy concerns are\n  barriers to using health insurance that explicitly utilizes AI", "abstract": "Trust and privacy have emerged as significant concerns in online\ntransactions. Sharing information on health is especially sensitive but it is\nnecessary for purchasing and utilizing health insurance. Evidence shows that\nconsumers are increasingly comfortable with technology in place of humans, but\nthe expanding use of AI potentially changes this. This research explores\nwhether trust and privacy concern are barriers to the adoption of AI in health\ninsurance. Two scenarios are compared: The first scenario has limited AI that\nis not in the interface and its presence is not explicitly revealed to the\nconsumer. In the second scenario there is an AI interface and AI evaluation,\nand this is explicitly revealed to the consumer. The two scenarios were modeled\nand compared using SEM PLS-MGA. The findings show that trust is significantly\nlower in the second scenario where AI is visible. Privacy concerns are higher\nwith AI but the difference is not statistically significant within the model.", "field": "Computer Science", "categories": "cs.CY,cs.AI,H.0; A.0; K.4; K.6"}, {"arxiv_id": "2401.1125", "title": "AFS-BM: Enhancing Model Performance through Adaptive Feature Selection\n  with Binary Masking", "abstract": "We study the problem of feature selection in general machine learning (ML)\ncontext, which is one of the most critical subjects in the field. Although,\nthere exist many feature selection methods, however, these methods face\nchallenges such as scalability, managing high-dimensional data, dealing with\ncorrelated features, adapting to variable feature importance, and integrating\ndomain knowledge. To this end, we introduce the ``Adaptive Feature Selection\nwith Binary Masking\" (AFS-BM) which remedies these problems. AFS-BM achieves\nthis by joint optimization for simultaneous feature selection and model\ntraining. In particular, we do the joint optimization and binary masking to\ncontinuously adapt the set of features and model parameters during the training\nprocess. This approach leads to significant improvements in model accuracy and\na reduction in computational requirements. We provide an extensive set of\nexperiments where we compare AFS-BM with the established feature selection\nmethods using well-known datasets from real-life competitions. Our results show\nthat AFS-BM makes significant improvement in terms of accuracy and requires\nsignificantly less computational complexity. This is due to AFS-BM's ability to\ndynamically adjust to the changing importance of features during the training\nprocess, which an important contribution to the field. We openly share our code\nfor the replicability of our results and to facilitate further research.", "field": "Computer Science", "categories": "cs.LG,eess.SP,stat.ML"}, {"arxiv_id": "2401.11252", "title": "Automated Fusion of Multimodal Electronic Health Records for Better\n  Medical Predictions", "abstract": "The widespread adoption of Electronic Health Record (EHR) systems in\nhealthcare institutes has generated vast amounts of medical data, offering\nsignificant opportunities for improving healthcare services through deep\nlearning techniques. However, the complex and diverse modalities and feature\nstructures in real-world EHR data pose great challenges for deep learning model\ndesign. To address the multi-modality challenge in EHR data, current approaches\nprimarily rely on hand-crafted model architectures based on intuition and\nempirical experiences, leading to sub-optimal model architectures and limited\nperformance. Therefore, to automate the process of model design for mining EHR\ndata, we propose a novel neural architecture search (NAS) framework named\nAutoFM, which can automatically search for the optimal model architectures for\nencoding diverse input modalities and fusion strategies. We conduct thorough\nexperiments on real-world multi-modal EHR data and prediction tasks, and the\nresults demonstrate that our framework not only achieves significant\nperformance improvement over existing state-of-the-art methods but also\ndiscovers meaningful network architectures effectively.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.11254", "title": "The Great Ban: Efficacy and Unintended Consequences of a Massive\n  Deplatforming Operation on Reddit", "abstract": "In the current landscape of online abuses and harms, effective content\nmoderation is necessary to cultivate safe and inclusive online spaces. Yet, the\neffectiveness of many moderation interventions is still unclear. Here, we\nassess the effectiveness of The Great Ban, a massive deplatforming operation\nthat affected nearly 2,000 communities on Reddit. By analyzing 16M comments\nposted by 17K users during 14 months, we provide nuanced results on the\neffects, both desired and otherwise, of the ban. Among our main findings is\nthat 15.6% of the affected users left Reddit and that those who remained\nreduced their toxicity by 6.6% on average. The ban also caused 5% users to\nincrease their toxicity by more than 70% of their pre-ban level. However, these\nresentful users likely had limited impact on Reddit due to low activity and\nlittle support by peers. Overall, our multifaceted results provide new insights\ninto the efficacy of deplatforming. Our findings can inform the development of\nfuture moderation interventions and the policing of online platforms.", "field": "Computer Science", "categories": "cs.SI,cs.CY"}, {"arxiv_id": "2401.11255", "title": "Visualization Generation with Large Language Models: An Evaluation", "abstract": "Analysts frequently need to create visualizations in the data analysis\nprocess to obtain and communicate insights. To reduce the burden of creating\nvisualizations, previous research has developed various approaches for analysts\nto create visualizations from natural language queries. Recent studies have\ndemonstrated the capabilities of large language models in natural language\nunderstanding and code generation tasks. The capabilities imply the potential\nof using large language models to generate visualization specifications from\nnatural language queries. In this paper, we evaluate the capability of a large\nlanguage model to generate visualization specifications on the task of natural\nlanguage to visualization (NL2VIS). More specifically, we have opted for\nGPT-3.5 and Vega-Lite to represent large language models and visualization\nspecifications, respectively. The evaluation is conducted on the nvBench\ndataset. In the evaluation, we utilize both zero-shot and few-shot prompt\nstrategies. The results demonstrate that GPT-3.5 surpasses previous NL2VIS\napproaches. Additionally, the performance of few-shot prompts is higher than\nthat of zero-shot prompts. We discuss the limitations of GPT-3.5 on NL2VIS,\nsuch as misunderstanding the data attributes and grammar errors in generated\nspecifications. We also summarized several directions, such as correcting the\nground truth and reducing the ambiguities in natural language queries, to\nimprove the NL2VIS benchmark.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.11257", "title": "Measuring Policy Distance for Multi-Agent Reinforcement Learning", "abstract": "Diversity plays a crucial role in improving the performance of multi-agent\nreinforcement learning (MARL). Currently, many diversity-based methods have\nbeen developed to overcome the drawbacks of excessive parameter sharing in\ntraditional MARL. However, there remains a lack of a general metric to quantify\npolicy differences among agents. Such a metric would not only facilitate the\nevaluation of the diversity evolution in multi-agent systems, but also provide\nguidance for the design of diversity-based MARL algorithms. In this paper, we\npropose the multi-agent policy distance (MAPD), a general tool for measuring\npolicy differences in MARL. By learning the conditional representations of\nagents' decisions, MAPD can computes the policy distance between any pair of\nagents. Furthermore, we extend MAPD to a customizable version, which can\nquantify differences among agent policies on specified aspects. Based on the\nonline deployment of MAPD, we design a multi-agent dynamic parameter sharing\n(MADPS) algorithm as an example of the MAPD's applications. Extensive\nexperiments demonstrate that our method is effective in measuring differences\nin agent policies and specific behavioral tendencies. Moreover, in comparison\nto other methods of parameter sharing, MADPS exhibits superior performance.", "field": "Computer Science", "categories": "cs.MA,cs.AI"}, {"arxiv_id": "2401.11261", "title": "Diffusion Model Conditioning on Gaussian Mixture Model and Negative\n  Gaussian Mixture Gradient", "abstract": "Diffusion models (DMs) are a type of generative model that has a huge impact\non image synthesis and beyond. They achieve state-of-the-art generation results\nin various generative tasks. A great diversity of conditioning inputs, such as\ntext or bounding boxes, are accessible to control the generation. In this work,\nwe propose a conditioning mechanism utilizing Gaussian mixture models (GMMs) as\nfeature conditioning to guide the denoising process. Based on set theory, we\nprovide a comprehensive theoretical analysis that shows that conditional latent\ndistribution based on features and classes is significantly different, so that\nconditional latent distribution on features produces fewer defect generations\nthan conditioning on classes. Two diffusion models conditioned on the Gaussian\nmixture model are trained separately for comparison. Experiments support our\nfindings. A novel gradient function called the negative Gaussian mixture\ngradient (NGMG) is proposed and applied in diffusion model training with an\nadditional classifier. Training stability has improved. We also theoretically\nprove that NGMG shares the same benefit as the Earth Mover distance\n(Wasserstein) as a more sensible cost function when learning distributions\nsupported by low-dimensional manifolds.", "field": "Computer Science", "categories": "cs.LG,cs.CV"}, {"arxiv_id": "2401.11266", "title": "Lower bounds for set-blocked clauses proofs", "abstract": "We study propositional proof systems with inference rules that formalize\nrestricted versions of the ability to make assumptions that hold without loss\nof generality, commonly used informally to shorten proofs. Each system we study\nis built on resolution. They are called BC${}^-$, RAT${}^-$, SBC${}^-$, and\nGER${}^-$, denoting respectively blocked clauses, resolution asymmetric\ntautologies, set-blocked clauses, and generalized extended resolution - all\n\"without new variables.\" They may be viewed as weak versions of extended\nresolution (ER) since they are defined by first generalizing the extension rule\nand then taking away the ability to introduce new variables. Except for\nSBC${}^-$, they are known to be strictly between resolution and extended\nresolution.\n  Several separations between these systems were proved earlier by exploiting\nthe fact that they effectively simulate ER. We answer the questions left open:\nWe prove exponential lower bounds for SBC${}^-$ proofs of a binary encoding of\nthe pigeonhole principle, which separates ER from SBC${}^-$. Using this new\nseparation, we prove that both RAT${}^-$ and GER${}^-$ are exponentially\nseparated from SBC${}^-$. This completes the picture of their relative\nstrengths.", "field": "Computer Science", "categories": "cs.LO,cs.CC"}, {"arxiv_id": "2401.11268", "title": "Word-Level ASR Quality Estimation for Efficient Corpus Sampling and\n  Post-Editing through Analyzing Attentions of a Reference-Free Metric", "abstract": "In the realm of automatic speech recognition (ASR), the quest for models that\nnot only perform with high accuracy but also offer transparency in their\ndecision-making processes is crucial. The potential of quality estimation (QE)\nmetrics is introduced and evaluated as a novel tool to enhance explainable\nartificial intelligence (XAI) in ASR systems. Through experiments and analyses,\nthe capabilities of the NoRefER (No Reference Error Rate) metric are explored\nin identifying word-level errors to aid post-editors in refining ASR\nhypotheses. The investigation also extends to the utility of NoRefER in the\ncorpus-building process, demonstrating its effectiveness in augmenting datasets\nwith insightful annotations. The diagnostic aspects of NoRefER are examined,\nrevealing its ability to provide valuable insights into model behaviors and\ndecision patterns. This has proven beneficial for prioritizing hypotheses in\npost-editing workflows and fine-tuning ASR models. The findings suggest that\nNoRefER is not merely a tool for error detection but also a comprehensive\nframework for enhancing ASR systems' transparency, efficiency, and\neffectiveness. To ensure the reproducibility of the results, all source codes\nof this study are made publicly available.", "field": "Computer Science", "categories": "cs.CL,cs.SD,eess.AS"}, {"arxiv_id": "2401.11271", "title": "DACR: Distribution-Augmented Contrastive Reconstruction for Time-Series\n  Anomaly Detection", "abstract": "Anomaly detection in time-series data is crucial for identifying faults,\nfailures, threats, and outliers across a range of applications. Recently, deep\nlearning techniques have been applied to this topic, but they often struggle in\nreal-world scenarios that are complex and highly dynamic, e.g., the normal data\nmay consist of multiple distributions, and various types of anomalies may\ndiffer from the normal data to different degrees. In this work, to tackle these\nchallenges, we propose Distribution-Augmented Contrastive Reconstruction\n(DACR). DACR generates extra data disjoint from the normal data distribution to\ncompress the normal data's representation space, and enhances the feature\nextractor through contrastive learning to better capture the intrinsic\nsemantics from time-series data. Furthermore, DACR employs an attention\nmechanism to model the semantic dependencies among multivariate time-series\nfeatures, thereby achieving more robust reconstruction for anomaly detection.\nExtensive experiments conducted on nine benchmark datasets in various anomaly\ndetection scenarios demonstrate the effectiveness of DACR in achieving new\nstate-of-the-art time-series anomaly detection.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.11274", "title": "Unambiguous parity-query complexity", "abstract": "We give a lower bound of $\\Omega(\\sqrt n)$ on the unambiguous randomised\nparity-query complexity of the approximate majority problem -- that is, on the\nlowest randomised parity-query complexity of any function over $\\{0,1\\}^n$\nwhose value is \"0\" if the Hamming weight of the input is at most n/3, is \"1\" if\nthe weight is at least 2n/3, and may be arbitrary otherwise.", "field": "Computer Science", "categories": "cs.CC"}, {"arxiv_id": "2401.11281", "title": "Sources of Underproduction in Open Source Software", "abstract": "Because open source software relies on individuals who select their own\ntasks, it is often underproduced -- a term used by software engineering\nresearchers to describe when a piece of software's relative quality is lower\nthan its relative importance. We examine the social and technical factors\nassociated with underproduction through a comparison of software packaged by\nthe Debian GNU/Linux community. We test a series of hypotheses developed from a\nreading of prior research in software engineering. Although we find that\nsoftware age and programming language age offer a partial explanation for\nvariation in underproduction, we were surprised to find that the association\nbetween underproduction and package age is weaker at high levels of programming\nlanguage age. With respect to maintenance efforts, we find that additional\nresources are not always tied to better outcomes. In particular, having higher\nnumbers of contributors is associated with higher underproduction risk. Also,\ncontrary to our expectations, maintainer turnover and maintenance by a declared\nteam are not associated with lower rates of underproduction. Finally, we find\nthat the people working on bugs in underproduced packages tend to be those who\nare more central to the community's collaboration network structure, although\ncontributors' betweenness centrality (often associated with brokerage in social\nnetworks) is not associated with underproduction.", "field": "Computer Science", "categories": "cs.SE,cs.CY,cs.HC"}, {"arxiv_id": "2401.11282", "title": "What Juris Hartmanis taught me about Reductions", "abstract": "I was a student of Juris Hartmanis at Cornell in the late 1970's. He believed\nthat there was great potential in studying restricted reductions. I describe\nhere some of his influences on me and, in particular, how his insights\nconcerning reductions helped me to prove that nondeterministic space is closed\nunder complementation.", "field": "Computer Science", "categories": "cs.CC"}, {"arxiv_id": "2401.11284", "title": "Evaluating Driver Readiness in Conditionally Automated Vehicles from\n  Eye-Tracking Data and Head Pose", "abstract": "As automated driving technology advances, the role of the driver to resume\ncontrol of the vehicle in conditionally automated vehicles becomes increasingly\ncritical. In the SAE Level 3 or partly automated vehicles, the driver needs to\nbe available and ready to intervene when necessary. This makes it essential to\nevaluate their readiness accurately. This article presents a comprehensive\nanalysis of driver readiness assessment by combining head pose features and\neye-tracking data. The study explores the effectiveness of predictive models in\nevaluating driver readiness, addressing the challenges of dataset limitations\nand limited ground truth labels. Machine learning techniques, including LSTM\narchitectures, are utilised to model driver readiness based on the\nSpatio-temporal status of the driver's head pose and eye gaze. The experiments\nin this article revealed that a Bidirectional LSTM architecture, combining both\nfeature sets, achieves a mean absolute error of 0.363 on the DMD dataset,\ndemonstrating superior performance in assessing driver readiness. The modular\narchitecture of the proposed model also allows the integration of additional\ndriver-specific features, such as steering wheel activity, enhancing its\nadaptability and real-world applicability.", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.NE"}, {"arxiv_id": "2401.11286", "title": "Data repairing and resolution enhancement using data-driven modal\n  decomposition and deep learning", "abstract": "This paper introduces a new series of methods which combine modal\ndecomposition algorithms, such as singular value decomposition and high-order\nsingular value decomposition, and deep learning architectures to repair,\nenhance, and increase the quality and precision of numerical and experimental\ndata. A combination of two- and three-dimensional, numerical and experimental\ndasasets are used to demonstrate the reconstruction capacity of the presented\nmethods, showing that these methods can be used to reconstruct any type of\ndataset, showing outstanding results when applied to highly complex data, which\nis noisy. The combination of benefits of these techniques results in a series\nof data-driven methods which are capable of repairing and/or enhancing the\nresolution of a dataset by identifying the underlying physics that define the\ndata, which is incomplete or under-resolved, filtering any existing noise.\nThese methods and the Python codes are included in the first release of\nModelFLOWs-app.", "field": "Computer Science", "categories": "cs.CE,physics.flu-dyn"}, {"arxiv_id": "2401.11287", "title": "On-The-Fly Algorithm for Reachability in Parametric Timed Games\n  (Extended Version)", "abstract": "Parametric Timed Games (PTG) are an extension of the model of Timed Automata.\nThey allow for the verification and synthesis of real-time systems, reactive to\ntheir environmeand depending on adjustable parameters. Given a PTG and a\nreachability objective, we synthesize the values of the parameters such that\nthe game is winning for the controller. We adapt and implement the On-The-Fly\nalgorithm for parameter synthesis for PTG. Several pruning heuristics are\nintroduced, to improve termination and speed of the algorithm. We evaluate the\nfeasibility of parameter synthesis for PTG on two large case studies. Finally,\nwe investigate the correctness guarantee of the algorithm: though the problem\nis undecidable, our semi-algorithm produces all correct parameter valuations\n``in the limit''.", "field": "Computer Science", "categories": "cs.FL"}, {"arxiv_id": "2401.11288", "title": "Long-Term Fair Decision Making through Deep Generative Models", "abstract": "This paper studies long-term fair machine learning which aims to mitigate\ngroup disparity over the long term in sequential decision-making systems. To\ndefine long-term fairness, we leverage the temporal causal graph and use the\n1-Wasserstein distance between the interventional distributions of different\ndemographic groups at a sufficiently large time step as the quantitative\nmetric. Then, we propose a three-phase learning framework where the decision\nmodel is trained on high-fidelity data generated by a deep generative model. We\nformulate the optimization problem as a performative risk minimization and\nadopt the repeated gradient descent algorithm for learning. The empirical\nevaluation shows the efficacy of the proposed method using both synthetic and\nsemi-synthetic datasets.", "field": "Computer Science", "categories": "cs.LG,cs.CY"}, {"arxiv_id": "2401.1129", "title": "On Dependent Variables in Reactive Synthesis", "abstract": "Given a Linear Temporal Logic (LTL) formula over input and output variables,\nreactive synthesis requires us to design a deterministic Mealy machine that\ngives the values of outputs at every time step for every sequence of inputs,\nsuch that the LTL formula is satisfied. In this paper, we investigate the\nnotion of dependent variables in the context of reactive synthesis. Inspired by\nsuccessful pre-processing steps in Boolean functional synthesis, we define\ndependent variables as output variables that are uniquely assigned, given an\nassignment, to all other variables and the history so far. We describe an\nautomata-based approach for finding a set of dependent variables. Using this,\nwe show that dependent variables are surprisingly common in reactive synthesis\nbenchmarks. Next, we develop a novel synthesis framework that exploits\ndependent variables to construct an overall synthesis solution. By implementing\nthis framework using the widely used library Spot, we show that reactive\nsynthesis using dependent variables can solve some problems beyond the reach of\nseveral existing techniques. Further, among benchmarks with dependent\nvariables, if the number of non-dependent variables is low (at most 3 in our\nexperiments), our method is able outperform all state-of-the-art tools for\nsynthesis.", "field": "Computer Science", "categories": "cs.LO,cs.FL"}, {"arxiv_id": "2401.11295", "title": "An exact solution to the Fourier Transform of band-limited periodic\n  functions with nonequispaced data and application to non-periodic functions", "abstract": "The need to Fourier transform data sets with irregular sampling is shared by\nvarious domains of science. This is the case for example in astronomy or\nsismology. Iterative methods have been developed that allow to reach\napproximate solutions. Here an exact solution to the problem for band-limited\nperiodic signals is presented. The exact spectrum can be deduced from the\nspectrum of the non-equispaced data through the inversion of a Toeplitz matrix.\nThe result applies to data of any dimension. This method also provides an\nexcellent approximation for non-periodic band-limit signals. The method allows\nto reach very high dynamic ranges ($10^{13}$ with double-float precision) which\ndepend on the regularity of the samples.", "field": "Computer Science", "categories": "math.NA,cs.NA,65T50"}, {"arxiv_id": "2401.11305", "title": "Progress in Privacy Protection: A Review of Privacy Preserving\n  Techniques in Recommender Systems, Edge Computing, and Cloud Computing", "abstract": "As digital technology evolves, the increasing use of connected devices brings\nboth challenges and opportunities in the areas of mobile crowdsourcing, edge\ncomputing, and recommender systems. This survey focuses on these dynamic\nfields, emphasizing the critical need for privacy protection in our\nincreasingly data-oriented world. It explores the latest trends in these\ninterconnected areas, with a special emphasis on privacy and data security. Our\nmethod involves an in-depth analysis of various academic works, which helps us\nto gain a comprehensive understanding of these sectors and their shifting focus\ntowards privacy concerns. We present new insights and marks a significant\nadvancement in addressing privacy issues within these technologies. The survey\nis a valuable resource for researchers, industry practitioners, and policy\nmakers, offering an extensive overview of these fields and their related\nprivacy challenges, catering to a wide audience in the modern digital era.", "field": "Computer Science", "categories": "cs.CR,cs.CL"}, {"arxiv_id": "2401.11311", "title": "A Novel Benchmark for Few-Shot Semantic Segmentation in the Era of\n  Foundation Models", "abstract": "In recent years, the rapid evolution of computer vision has seen the\nemergence of various vision foundation models, each tailored to specific data\ntypes and tasks. While large language models often share a common pretext task,\nthe diversity in vision foundation models arises from their varying training\nobjectives. In this study, we delve into the quest for identifying the most\neffective vision foundation models for few-shot semantic segmentation, a\ncritical task in computer vision. Specifically, we conduct a comprehensive\ncomparative analysis of four prominent foundation models: DINO V2, Segment\nAnything, CLIP, Masked AutoEncoders, and a straightforward ResNet50 pre-trained\non the COCO dataset. Our investigation focuses on their adaptability to new\nsemantic segmentation tasks, leveraging only a limited number of segmented\nimages. Our experimental findings reveal that DINO V2 consistently outperforms\nthe other considered foundation models across a diverse range of datasets and\nadaptation methods. This outcome underscores DINO V2's superior capability to\nadapt to semantic segmentation tasks compared to its counterparts. Furthermore,\nour observations indicate that various adapter methods exhibit similar\nperformance, emphasizing the paramount importance of selecting a robust feature\nextractor over the intricacies of the adaptation technique itself. This insight\nsheds light on the critical role of feature extraction in the context of\nfew-shot semantic segmentation. This research not only contributes valuable\ninsights into the comparative performance of vision foundation models in the\nrealm of few-shot semantic segmentation but also highlights the significance of\na robust feature extractor in this domain.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11313", "title": "Weakly-Supervised Semantic Segmentation of Circular-Scan,\n  Synthetic-Aperture-Sonar Imagery", "abstract": "We propose a weakly-supervised framework for the semantic segmentation of\ncircular-scan synthetic-aperture-sonar (CSAS) imagery. The first part of our\nframework is trained in a supervised manner, on image-level labels, to uncover\na set of semi-sparse, spatially-discriminative regions in each image. The\nclassification uncertainty of each region is then evaluated. Those areas with\nthe lowest uncertainties are then chosen to be weakly labeled segmentation\nseeds, at the pixel level, for the second part of the framework. Each of the\nseed extents are progressively resized according to an unsupervised,\ninformation-theoretic loss with structured-prediction regularizers. This\nreshaping process uses multi-scale, adaptively-weighted features to delineate\nclass-specific transitions in local image content. Content-addressable memories\nare inserted at various parts of our framework so that it can leverage features\nfrom previously seen images to improve segmentation performance for related\nimages.\n  We evaluate our weakly-supervised framework using real-world CSAS imagery\nthat contains over ten seafloor classes and ten target classes. We show that\nour framework performs comparably to nine fully-supervised deep networks. Our\nframework also outperforms eleven of the best weakly-supervised deep networks.\nWe achieve state-of-the-art performance when pre-training on natural imagery.\nThe average absolute performance gap to the next-best weakly-supervised network\nis well over ten percent for both natural imagery and sonar imagery. This gap\nis found to be statistically significant.", "field": "Computer Science", "categories": "cs.CV,cs.LG,eess.IV"}, {"arxiv_id": "2401.11314", "title": "CodeAid: Evaluating a Classroom Deployment of an LLM-based Programming\n  Assistant that Balances Student and Educator Needs", "abstract": "Timely, personalized feedback is essential for students learning programming,\nespecially as class sizes expand. LLM-based tools like ChatGPT offer instant\nsupport, but reveal direct answers with code, which may hinder deep conceptual\nengagement. We developed CodeAid, an LLM-based programming assistant delivering\nhelpful, technically correct responses, without revealing code solutions. For\nexample, CodeAid can answer conceptual questions, generate pseudo-code with\nline-by-line explanations, and annotate student's incorrect code with fix\nsuggestions. We deployed CodeAid in a programming class of 700 students for a\n12-week semester. A thematic analysis of 8,000 usages of CodeAid was performed,\nfurther enriched by weekly surveys, and 22 student interviews. We then\ninterviewed eight programming educators to gain further insights on CodeAid.\nFindings revealed students primarily used CodeAid for conceptual understanding\nand debugging, although a minority tried to obtain direct code. Educators\nappreciated CodeAid's educational approach, and expressed concerns about\noccasional incorrect feedback and students defaulting to ChatGPT.", "field": "Computer Science", "categories": "cs.HC,cs.AI"}, {"arxiv_id": "2401.11316", "title": "PRILoRA: Pruned and Rank-Increasing Low-Rank Adaptation", "abstract": "With the proliferation of large pre-trained language models (PLMs),\nfine-tuning all model parameters becomes increasingly inefficient, particularly\nwhen dealing with numerous downstream tasks that entail substantial training\nand storage costs. Several approaches aimed at achieving parameter-efficient\nfine-tuning (PEFT) have been proposed. Among them, Low-Rank Adaptation (LoRA)\nstands out as an archetypal method, incorporating trainable rank decomposition\nmatrices into each target module. Nevertheless, LoRA does not consider the\nvarying importance of each layer. To address these challenges, we introduce\nPRILoRA, which linearly allocates a different rank for each layer, in an\nincreasing manner, and performs pruning throughout the training process,\nconsidering both the temporary magnitude of weights and the accumulated\nstatistics of the input to any given layer. We validate the effectiveness of\nPRILoRA through extensive experiments on eight GLUE benchmarks, setting a new\nstate of the art.", "field": "Computer Science", "categories": "cs.CL,cs.AI"}, {"arxiv_id": "2401.11317", "title": "Third-Party Developers and Tool Development For Community Management on\n  Live Streaming Platform Twitch", "abstract": "Community management is critical for community stakeholders to\ncollaboratively build and maintain the community with socio-technical support.\nExisting work mainly focuses on the community members and the platform; little\nwork explores the developers who mediate the relationship between the platform\nand community members and build the tools to support their community\nmanagement. In this study, we focus on third-party developers (TPDs) for the\nlive streaming platform Twitch and explore their tool development practices. In\na mixed method with in-depth qualitative analysis, we found that TPDs maintain\ncomplex relationships with different stakeholders (streamers, viewers,\nplatform, professional developers), and the multi-layered policy restricts\ntheir agency regarding idea innovation and tool development. We argue that HCI\nresearch should redirect the attention from tool users to tool developers\nregarding community management and propose close collaboration with the\nplatform and professional developers and streamlining the development process\nwith unified took kits and policy documentation.", "field": "Computer Science", "categories": "cs.HC,cs.CY"}, {"arxiv_id": "2401.11323", "title": "Analyzing Task-Encoding Tokens in Large Language Models", "abstract": "In-context learning (ICL) has become an effective solution for few-shot\nlearning in natural language processing. Past work has found that, during this\nprocess, representations of the last prompt token are utilized to store task\nreasoning procedures, thereby explaining the working mechanism of in-context\nlearning. In this paper, we seek to locate and analyze other task-encoding\ntokens whose representations store task reasoning procedures. Supported by\nexperiments that ablate the representations of different token types, we find\nthat template and stopword tokens are the most prone to be task-encoding\ntokens. In addition, we demonstrate experimentally that lexical cues,\nrepetition, and text formats are the main distinguishing characteristics of\nthese tokens. Our work provides additional insights into how large language\nmodels (LLMs) leverage task reasoning procedures in ICL and suggests that\nfuture work may involve using task-encoding tokens to improve the computational\nefficiency of LLMs at inference time and their ability to handle long\nsequences.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.11324", "title": "BANG: Billion-Scale Approximate Nearest Neighbor Search using a Single\n  GPU", "abstract": "Approximate Nearest Neighbour Search (ANNS) is a subroutine in algorithms\nroutinely employed in information retrieval, pattern recognition, data mining,\nimage processing, and beyond. Recent works have established that graph-based\nANNS algorithms are practically more efficient than the other methods proposed\nin the literature, on large datasets. The growing volume and dimensionality of\ndata necessitates designing scalable techniques for ANNS. To this end, the\nprior art has explored parallelizing graph-based ANNS on GPU leveraging its\nhigh computational power and energy efficiency. The current state-of-the-art\nGPU-based ANNS algorithms either (i) require both the index-graph and the data\nto reside entirely in the GPU memory, or (ii) they partition the data into\nsmall independent shards, each of which can fit in GPU memory, and perform the\nsearch on these shards on the GPU. While the first approach fails to handle\nlarge datasets due to the limited memory available on the GPU, the latter\ndelivers poor performance on large datasets due to high data traffic over the\nlow-bandwidth PCIe bus. In this paper, we introduce BANG, a first-of-its-kind\nGPU-based ANNS method which works efficiently on billion-scale datasets that\ncannot entirely fit in the GPU memory. BANG stands out by harnessing compressed\ndata on the GPU to perform distance computations while maintaining the graph on\nthe CPU. BANG incorporates high-optimized GPU kernels and proceeds in stages\nthat run concurrently on the GPU and CPU, taking advantage of their\narchitectural specificities. We evaluate BANG using a single NVIDIA Ampere A100\nGPU on ten popular ANN benchmark datasets. BANG outperforms the\nstate-of-the-art in the majority of the cases. Notably, on the billion-size\ndatasets, we are significantly faster than our competitors, achieving\nthroughputs 40x-200x more than the competing methods for a high recall of 0.9.", "field": "Computer Science", "categories": "cs.DC"}, {"arxiv_id": "2401.11325", "title": "Detecting Hidden Triggers: Mapping Non-Markov Reward Functions to Markov", "abstract": "Many Reinforcement Learning algorithms assume a Markov reward function to\nguarantee optimality. However, not all reward functions are known to be Markov.\nIn this paper, we propose a framework for mapping non-Markov reward functions\ninto equivalent Markov ones by learning a Reward Machine - a specialized reward\nautomaton. Unlike the general practice of learning Reward Machines, we do not\nrequire a set of high-level propositional symbols from which to learn. Rather,\nwe learn \\emph{hidden triggers} directly from data that encode them. We\ndemonstrate the importance of learning Reward Machines versus their\nDeterministic Finite-State Automata counterparts, for this task, given their\nability to model reward dependencies in a single automaton. We formalize this\ndistinction in our learning objective. Our mapping process is constructed as an\nInteger Linear Programming problem. We prove that our mappings provide\nconsistent expectations for the underlying process. We empirically validate our\napproach by learning black-box non-Markov Reward functions in the Officeworld\nDomain. Additionally, we demonstrate the effectiveness of learning dependencies\nbetween rewards in a new domain, Breakfastworld.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.11326", "title": "Navigating Cybersecurity Training: A Comprehensive Review", "abstract": "In the dynamic realm of cybersecurity, awareness training is crucial for\nstrengthening defenses against cyber threats. This survey examines a spectrum\nof cybersecurity awareness training methods, analyzing traditional,\ntechnology-based, and innovative strategies. It evaluates the principles,\nefficacy, and constraints of each method, presenting a comparative analysis\nthat highlights their pros and cons. The study also investigates emerging\ntrends like artificial intelligence and extended reality, discussing their\nprospective influence on the future of cybersecurity training. Additionally, it\naddresses implementation challenges and proposes solutions, drawing on insights\nfrom real-world case studies. The goal is to bolster the understanding of\ncybersecurity awareness training's current landscape, offering valuable\nperspectives for both practitioners and scholars.", "field": "Computer Science", "categories": "cs.CR"}, {"arxiv_id": "2401.11328", "title": "A Hierarchical Decision-Based Maintenance for a Complex Modular System\n  Driven by the { MoMA} Algorithm", "abstract": "This paper presents a maintenance policy for a modular system formed by K\nindependent modules (n-subsystems) subjected to environmental conditions\n(shocks). For the modeling of this complex system, the use of the\nMatrix-Analytical Method (MAM) is proposed under a layered approach according\nto its hierarchical structure. Thus, the operational state of the system (top\nlayer) depends on the states of the modules (middle layer), which in turn\ndepend on the states of their components (bottom layer). This allows a detailed\ndescription of the system operation to plan maintenance actions appropriately\nand optimally. We propose a hierarchical decision-based maintenance strategy\nwith periodic inspections as follows: at the time of the inspection, the\ncondition of the system is first evaluated. If intervention is necessary, the\nmodules are then checked to make individual decisions based on their states,\nand so on. Replacement or repair will be carried out as appropriate. An\noptimization problem is formulated as a function of the length of the\ninspection period and the intervention cost incurred over the useful life of\nthe system. Our method shows the advantages, providing compact and\nimplementable expressions. The model is illustrated on a submarine Electrical\nControl Unit (ECU).", "field": "Computer Science", "categories": "eess.SY,cs.SY,stat.ME,62M05, 90B25,G.3.5; G.3.11"}, {"arxiv_id": "2401.1133", "title": "Source Detection in Networks using the Stationary Distribution of a\n  Markov Chain", "abstract": "Nowadays, the diffusion of information through social networks is a powerful\nphenomenon. One common way to model diffusions in social networks is the\nIndependent Cascade (IC) model. Given a set of infected nodes according to the\nIC model, a natural problem is the source detection problem, in which the goal\nis to identify the unique node that has started the diffusion. Maximum\nLikelihood Estimation (MLE) is a common approach for tackling the source\ndetection problem, but it is computationally hard.\n  In this work, we propose an efficient method for the source detection problem\nunder the MLE approach, which is based on computing the stationary distribution\nof a Markov chain. Using simulations, we demonstrate the effectiveness of our\nmethod compared to other state-of-the-art methods from the literature, both on\nrandom and real-world networks.", "field": "Computer Science", "categories": "cs.SI"}, {"arxiv_id": "2401.11335", "title": "Deception and Manipulation in Generative AI", "abstract": "Large language models now possess human-level linguistic abilities in many\ncontexts. This raises the concern that they can be used to deceive and\nmanipulate on unprecedented scales, for instance spreading political\nmisinformation on social media. In future, agentic AI systems might also\ndeceive and manipulate humans for their own ends. In this paper, first, I argue\nthat AI-generated content should be subject to stricter standards against\ndeception and manipulation than we ordinarily apply to humans. Second, I offer\nnew characterizations of AI deception and manipulation meant to support such\nstandards, according to which a statement is deceptive (manipulative) if it\nleads human addressees away from the beliefs (choices) they would endorse under\n``semi-ideal'' conditions. Third, I propose two measures to guard against AI\ndeception and manipulation, inspired by this characterization: \"extreme\ntransparency\" requirements for AI-generated content and defensive systems that,\namong other things, annotate AI-generated statements with contextualizing\ninformation. Finally, I consider to what extent these measures can protect\nagainst deceptive behavior in future, agentic AIs, and argue that non-agentic\ndefensive systems can provide an important layer of defense even against more\npowerful agentic systems.", "field": "Computer Science", "categories": "cs.CY"}, {"arxiv_id": "2401.11337", "title": "Prompting Large Vision-Language Models for Compositional Reasoning", "abstract": "Vision-language models such as CLIP have shown impressive capabilities in\nencoding texts and images into aligned embeddings, enabling the retrieval of\nmultimodal data in a shared embedding space. However, these embedding-based\nmodels still face challenges in effectively matching images and texts with\nsimilar visio-linguistic compositionality, as evidenced by their performance on\nthe recent Winoground dataset. In this paper, we argue that this limitation\nstems from two factors: the use of single vector representations for complex\nmultimodal data, and the absence of step-by-step reasoning in these\nembedding-based methods. To address this issue, we make an exploratory step\nusing a novel generative method that prompts large vision-language models\n(e.g., GPT-4) to depict images and perform compositional reasoning. Our method\noutperforms other embedding-based methods on the Winoground dataset, and\nobtains further improvement of up to 10% accuracy when enhanced with the\noptimal description.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.11347", "title": "Are Your Epochs Too Epic? Batch Free Can Be Harmful", "abstract": "Epoch based memory reclamation (EBR) is one of the most popular techniques\nfor reclaiming memory in lock-free and optimistic locking data structures, due\nto its ease of use and good performance in practice. However, EBR is known to\nbe sensitive to thread delays, which can result in performance degradation.\nMoreover, the exact mechanism for this performance degradation is not well\nunderstood. This paper illustrates this performance degradation in a popular\ndata structure benchmark, and does a deep dive to uncover its root cause-a\nsubtle interaction between EBR and state of the art memory allocators. In\nessence, modern allocators attempt to reduce the overhead of freeing by\nmaintaining bounded thread caches of objects for local reuse, actually freeing\nthem (a very high latency operation) only when thread caches become too large.\nEBR immediately bypasses these mechanisms whenever a particularly large batch\nof objects is freed, substantially increasing overheads and latencies. Beyond\nEBR, many memory reclamation algorithms, and data structures, that reclaim\nobjects in large batches suffer similar deleterious interactions with popular\nallocators. We propose a simple algorithmic fix for such algorithms to amortize\nthe freeing of large object batches over time, and apply this technique to ten\nexisting memory reclamation algorithms, observing performance improvements for\nnine out of ten, and over 50% improvement for six out of ten in experiments on\na high performance lock-free ABtree. We also present an extremely simple token\npassing variant of EBR and show that, with our fix, it performs 1.5-2.6x faster\nthan the fastest known memory reclamation algorithm, and 1.2-1.5x faster than\nnot reclaiming at all, on a 192 thread four socket Intel system.", "field": "Computer Science", "categories": "cs.DC"}, {"arxiv_id": "2401.11353", "title": "Distributionally Robust Policy Evaluation under General Covariate Shift\n  in Contextual Bandits", "abstract": "We introduce a distributionally robust approach that enhances the reliability\nof offline policy evaluation in contextual bandits under general covariate\nshifts. Our method aims to deliver robust policy evaluation results in the\npresence of discrepancies in both context and policy distribution between\nlogging and target data. Central to our methodology is the application of\nrobust regression, a distributionally robust technique tailored here to improve\nthe estimation of conditional reward distribution from logging data. Utilizing\nthe reward model obtained from robust regression, we develop a comprehensive\nsuite of policy value estimators, by integrating our reward model into\nestablished evaluation frameworks, namely direct methods and doubly robust\nmethods. Through theoretical analysis, we further establish that the proposed\npolicy value estimators offer a finite sample upper bound for the bias,\nproviding a clear advantage over traditional methods, especially when the shift\nis large. Finally, we designed an extensive range of policy evaluation\nscenarios, covering diverse magnitudes of shifts and a spectrum of logging and\ntarget policies. Our empirical results indicate that our approach significantly\noutperforms baseline methods, most notably in 90% of the cases under the policy\nshift-only settings and 72% of the scenarios under the general covariate shift\nsettings.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.11356", "title": "ProLex: A Benchmark for Language Proficiency-oriented Lexical\n  Substitution", "abstract": "Lexical Substitution discovers appropriate substitutes for a given target\nword in a context sentence. However, the task fails to consider substitutes\nthat are of equal or higher proficiency than the target, an aspect that could\nbe beneficial for language learners looking to improve their writing. To bridge\nthis gap, we propose a new task, language proficiency-oriented lexical\nsubstitution. We also introduce ProLex, a novel benchmark designed to assess\nsystems' ability to generate not only appropriate substitutes but also\nsubstitutes that demonstrate better language proficiency. Besides the\nbenchmark, we propose models that can automatically perform the new task. We\nshow that our best model, a Llama2-13B model fine-tuned with task-specific\nsynthetic data, outperforms ChatGPT by an average of 3.2% in F-score and\nachieves comparable results with GPT-4 on ProLex.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.11358", "title": "ANNA: A Deep Learning Based Dataset in Heterogeneous Traffic for\n  Autonomous Vehicles", "abstract": "Recent breakthroughs in artificial intelligence offer tremendous promise for\nthe development of self-driving applications. Deep Neural Networks, in\nparticular, are being utilized to support the operation of semi-autonomous cars\nthrough object identification and semantic segmentation. To assess the\ninadequacy of the current dataset in the context of autonomous and\nsemi-autonomous cars, we created a new dataset named ANNA. This study discusses\na custom-built dataset that includes some unidentified vehicles in the\nperspective of Bangladesh, which are not included in the existing dataset. A\ndataset validity check was performed by evaluating models using the\nIntersection Over Union (IOU) metric. The results demonstrated that the model\ntrained on our custom dataset was more precise and efficient than the models\ntrained on the KITTI or COCO dataset concerning Bangladeshi traffic. The\nresearch presented in this paper also emphasizes the importance of developing\naccurate and efficient object detection algorithms for the advancement of\nautonomous vehicles.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.1136", "title": "PepHarmony: A Multi-View Contrastive Learning Framework for Integrated\n  Sequence and Structure-Based Peptide Encoding", "abstract": "Recent advances in protein language models have catalyzed significant\nprogress in peptide sequence representation. Despite extensive exploration in\nthis field, pre-trained models tailored for peptide-specific needs remain\nlargely unaddressed due to the difficulty in capturing the complex and\nsometimes unstable structures of peptides. This study introduces a novel\nmulti-view contrastive learning framework PepHarmony for the sequence-based\npeptide encoding task. PepHarmony innovatively combines both sequence- and\nstructure-level information into a sequence-level encoding module through\ncontrastive learning. We carefully select datasets from the Protein Data Bank\n(PDB) and AlphaFold database to encompass a broad spectrum of peptide sequences\nand structures. The experimental data highlights PepHarmony's exceptional\ncapability in capturing the intricate relationship between peptide sequences\nand structures compared with the baseline and fine-tuned models. The robustness\nof our model is confirmed through extensive ablation studies, which emphasize\nthe crucial roles of contrastive loss and strategic data sorting in enhancing\npredictive performance. The proposed PepHarmony framework serves as a notable\ncontribution to peptide representations, and offers valuable insights for\nfuture applications in peptide drug discovery and peptide engineering. We have\nmade all the source code utilized in this study publicly accessible via GitHub\nat https://github.com/zhangruochi/PepHarmony or\nhttp://www.healthinformaticslab.org/supp/.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.CE,q-bio.BM"}, {"arxiv_id": "2401.11361", "title": "Revolutionizing API Documentation through Summarization", "abstract": "This study tackles the challenges associated with interpreting Application\nProgramming Interface (API) documentation, an integral aspect of software\ndevelopment. Official API documentation, while essential, can be lengthy and\nchallenging to navigate, prompting developers to seek unofficial sources such\nas Stack Overflow. Leveraging the vast user-generated content on Stack\nOverflow, including code snippets and discussions, we employ BERTopic and\nextractive summarization to automatically generate concise and informative API\nsummaries. These summaries encompass key insights like general usage, common\ndeveloper issues, and potential solutions, sourced from the wealth of knowledge\non Stack Overflow. Software developers evaluate these summaries for\nperformance, coherence, and interoperability, providing valuable feedback on\nthe practicality of our approach.", "field": "Computer Science", "categories": "cs.SE,cs.AI,cs.CL"}, {"arxiv_id": "2401.11364", "title": "Folding Custom Gates with Verifier Input", "abstract": "In the context of interactive proofs, a \"folding scheme\" (popularized by\nNova) is a way to combine multiple instances of a constraint system into a\nsingle instance, so the validity of the multiple instances can statistically be\nreduced to the validity of a single one. We show how Nova folding can be\ngeneralized to ``custom'' gates and extra rounds of verifier randomness. As an\napplication of this extension, we present Origami, the first (to our knowledge)\nknown example of a folding scheme for lookups.", "field": "Computer Science", "categories": "cs.CR,cs.LO,94A60"}, {"arxiv_id": "2401.11365", "title": "Confidence Preservation Property in Knowledge Distillation Abstractions", "abstract": "Social media platforms prevent malicious activities by detecting harmful\ncontent of posts and comments. To that end, they employ large-scale deep neural\nnetwork language models for sentiment analysis and content understanding. Some\nmodels, like BERT, are complex, and have numerous parameters, which makes them\nexpensive to operate and maintain. To overcome these deficiencies, industry\nexperts employ a knowledge distillation compression technique, where a\ndistilled model is trained to reproduce the classification behavior of the\noriginal model. The distillation processes terminates when the distillation\nloss function reaches the stopping criteria. This function is mainly designed\nto ensure that the original and the distilled models exhibit alike\nclassification behaviors. However, besides classification accuracy, there are\nadditional properties of the original model that the distilled model should\npreserve to be considered as an appropriate abstraction. In this work, we\nexplore whether distilled TinyBERT models preserve confidence values of the\noriginal BERT models, and investigate how this confidence preservation property\ncould guide tuning hyperparameters of the distillation process.", "field": "Computer Science", "categories": "cs.CL,cs.LG"}, {"arxiv_id": "2401.11366", "title": "A Multivocal Literature Review on the Benefits and Limitations of\n  Automated Machine Learning Tools", "abstract": "Context. Advancements in Machine Learning (ML) are revolutionizing every\napplication domain, driving unprecedented transformations and fostering\ninnovation. However, despite these advances, several organizations are\nexperiencing friction in the adoption of ML-based technologies, mainly due to\nthe shortage of ML professionals. In this context, Automated Machine Learning\n(AutoML) techniques have been presented as a promising solution to democratize\nML adoption. Objective. We aim to provide an overview of the evidence on the\nbenefits and limitations of using AutoML tools. Method. We conducted a\nmultivocal literature review, which allowed us to identify 54 sources from the\nacademic literature and 108 sources from the grey literature reporting on\nAutoML benefits and limitations. We extracted reported benefits and limitations\nfrom the papers and applied thematic analysis. Results. We identified 18\nbenefits and 25 limitations. Concerning the benefits, we highlight that AutoML\ntools can help streamline the core steps of ML workflows, namely data\npreparation, feature engineering, model construction, and hyperparameter\ntuning, with concrete benefits on model performance, efficiency, and\nscalability. In addition, AutoML empowers both novice and experienced data\nscientists, promoting ML accessibility. On the other hand, we highlight several\nlimitations that may represent obstacles to the widespread adoption of AutoML.\nFor instance, AutoML tools may introduce barriers to transparency and\ninteroperability, exhibit limited flexibility for complex scenarios, and offer\ninconsistent coverage of the ML workflow. Conclusions. The effectiveness of\nAutoML in facilitating the adoption of machine learning by users may vary\ndepending on the tool and the context in which it is used. As of today, AutoML\ntools are used to increase human expertise rather than replace it, and, as\nsuch, they require skilled users.", "field": "Computer Science", "categories": "cs.SE"}, {"arxiv_id": "2401.1137", "title": "Self-sustaining Software Systems (S4): Towards Improved Interpretability\n  and Adaptation", "abstract": "Software systems impact society at different levels as they pervasively solve\nreal-world problems. Modern software systems are often so sophisticated that\ntheir complexity exceeds the limits of human comprehension. These systems must\nrespond to changing goals, dynamic data, unexpected failures, and security\nthreats, among other variable factors in real-world environments. Systems'\ncomplexity challenges their interpretability and requires autonomous responses\nto dynamic changes. Two main research areas explore autonomous systems'\nresponses: evolutionary computing and autonomic computing. Evolutionary\ncomputing focuses on software improvement based on iterative modifications to\nthe source code. Autonomic computing focuses on optimising systems' performance\nby changing their structure, behaviour, or environment variables. Approaches\nfrom both areas rely on feedback loops that accumulate knowledge from the\nsystem interactions to inform autonomous decision-making. However, this\nknowledge is often limited, constraining the systems' interpretability and\nadaptability. This paper proposes a new concept for interpretable and adaptable\nsoftware systems: self-sustaining software systems (S4). S4 builds knowledge\nloops between all available knowledge sources that define modern software\nsystems to improve their interpretability and adaptability. This paper\nintroduces and discusses the S4 concept.", "field": "Computer Science", "categories": "cs.SE,cs.AI,cs.SY,eess.SY"}, {"arxiv_id": "2401.11371", "title": "Modeling Considerations for Developing Deep Space Autonomous Spacecraft\n  and Simulators", "abstract": "To extend the limited scope of autonomy used in prior missions for operation\nin distant and complex environments, there is a need to further develop and\nmature autonomy that jointly reasons over multiple subsystems, which we term\nsystem-level autonomy. System-level autonomy establishes situational awareness\nthat resolves conflicting information across subsystems, which may necessitate\nthe refinement and interconnection of the underlying spacecraft and environment\nonboard models. However, with a limited understanding of the assumptions and\ntradeoffs of modeling to arbitrary extents, designing onboard models to support\nsystem-level capabilities presents a significant challenge.\n  In this paper, we provide a detailed analysis of the increasing levels of\nmodel fidelity for several key spacecraft subsystems, with the goal of\ninforming future spacecraft functional- and system-level autonomy algorithms\nand the physics-based simulators on which they are validated. We do not argue\nfor the adoption of a particular fidelity class of models but, instead,\nhighlight the potential tradeoffs and opportunities associated with the use of\nmodels for onboard autonomy and in physics-based simulators at various fidelity\nlevels. We ground our analysis in the context of deep space exploration of\nsmall bodies, an emerging frontier for autonomous spacecraft operation in\nspace, where the choice of models employed onboard the spacecraft may determine\nmission success. We conduct our experiments in the Multi-Spacecraft Concept and\nAutonomy Tool (MuSCAT), a software suite for developing spacecraft autonomy\nalgorithms.", "field": "Computer Science", "categories": "cs.RO,cs.SY,eess.SY,I.2.8; I.2.9; I.6.1; I.6.3; I.6.4; I.6.6; J.2"}, {"arxiv_id": "2401.11372", "title": "Back-stepping Experience Replay with Application to Model-free\n  Reinforcement Learning for a Soft Snake Robot", "abstract": "In this paper, we propose a novel technique, Back-stepping Experience Replay\n(BER), that is compatible with arbitrary off-policy reinforcement learning (RL)\nalgorithms. BER aims to enhance learning efficiency in systems with approximate\nreversibility, reducing the need for complex reward shaping. The method\nconstructs reversed trajectories using back-stepping transitions to reach\nrandom or fixed targets. Interpretable as a bi-directional approach, BER\naddresses inaccuracies in back-stepping transitions through a distillation of\nthe replay experience during learning. Given the intricate nature of soft\nrobots and their complex interactions with environments, we present an\napplication of BER in a model-free RL approach for the locomotion and\nnavigation of a soft snake robot, which is capable of serpentine motion enabled\nby anisotropic friction between the body and ground. In addition, a dynamic\nsimulator is developed to assess the effectiveness and efficiency of the BER\nalgorithm, in which the robot demonstrates successful learning (reaching a 100%\nsuccess rate) and adeptly reaches random targets, achieving an average speed\n48% faster than that of the best baseline approach.", "field": "Computer Science", "categories": "cs.RO,cs.LG"}, {"arxiv_id": "2401.11373", "title": "Finding a Needle in the Adversarial Haystack: A Targeted Paraphrasing\n  Approach For Uncovering Edge Cases with Minimal Distribution Distortion", "abstract": "Adversarial attacks against NLP Deep Learning models are a significant\nconcern. In particular, adversarial samples exploit the model's sensitivity to\nsmall input changes. While these changes appear insignificant on the semantics\nof the input sample, they result in significant decay in model performance. In\nthis paper, we propose Targeted Paraphrasing via RL (TPRL), an approach to\nautomatically learn a policy to generate challenging samples that most likely\nimprove the model's performance. TPRL leverages FLAN T5, a language model, as a\ngenerator and employs a self learned policy using a proximal policy gradient to\ngenerate the adversarial examples automatically. TPRL's reward is based on the\nconfusion induced in the classifier, preserving the original text meaning\nthrough a Mutual Implication score. We demonstrate and evaluate TPRL's\neffectiveness in discovering natural adversarial attacks and improving model\nperformance through extensive experiments on four diverse NLP classification\ntasks via Automatic and Human evaluation. TPRL outperforms strong baselines,\nexhibits generalizability across classifiers and datasets, and combines the\nstrengths of language modeling and reinforcement learning to generate diverse\nand influential adversarial examples.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.11374", "title": "Language Models as Hierarchy Encoders", "abstract": "Interpreting hierarchical structures latent in language is a key limitation\nof current language models (LMs). While previous research has implicitly\nleveraged these hierarchies to enhance LMs, approaches for their explicit\nencoding are yet to be explored. To address this, we introduce a novel approach\nto re-train transformer encoder-based LMs as Hierarchy Transformer encoders\n(HiTs), harnessing the expansive nature of hyperbolic space. Our method\nsituates the output embedding space of pre-trained LMs within a Poincar\\'e ball\nwith a curvature that adapts to the embedding dimension, followed by\nre-training on hyperbolic cluster and centripetal losses. These losses are\ndesigned to effectively cluster related entities (input as texts) and organise\nthem hierarchically. We evaluate HiTs against pre-trained and fine-tuned LMs,\nfocusing on their capabilities in simulating transitive inference, predicting\nsubsumptions, and transferring knowledge across hierarchies. The results\ndemonstrate that HiTs consistently outperform both pre-trained and fine-tuned\nLMs in these tasks, underscoring the effectiveness and transferability of our\nre-trained hierarchy encoders.", "field": "Computer Science", "categories": "cs.CL,cs.AI,cs.LG"}, {"arxiv_id": "2401.11378", "title": "Multi-Agent Generative Adversarial Interactive Self-Imitation Learning\n  for AUV Formation Control and Obstacle Avoidance", "abstract": "Multiple autonomous underwater vehicles (multi-AUV) can cooperatively\naccomplish tasks that a single AUV cannot complete. Recently, multi-agent\nreinforcement learning has been introduced to control of multi-AUV. However,\ndesigning efficient reward functions for various tasks of multi-AUV control is\ndifficult or even impractical. Multi-agent generative adversarial imitation\nlearning (MAGAIL) allows multi-AUV to learn from expert demonstration instead\nof pre-defined reward functions, but suffers from the deficiency of requiring\noptimal demonstrations and not surpassing provided expert demonstrations. This\npaper builds upon the MAGAIL algorithm by proposing multi-agent generative\nadversarial interactive self-imitation learning (MAGAISIL), which can\nfacilitate AUVs to learn policies by gradually replacing the provided\nsub-optimal demonstrations with self-generated good trajectories selected by a\nhuman trainer. Our experimental results in a multi-AUV formation control and\nobstacle avoidance task on the Gazebo platform with AUV simulator of our lab\nshow that AUVs trained via MAGAISIL can surpass the provided sub-optimal expert\ndemonstrations and reach a performance close to or even better than MAGAIL with\noptimal demonstrations. Further results indicate that AUVs' policies trained\nvia MAGAISIL can adapt to complex and different tasks as well as MAGAIL\nlearning from optimal demonstrations.", "field": "Computer Science", "categories": "cs.RO,cs.LG"}, {"arxiv_id": "2401.1138", "title": "MoMA: Model-based Mirror Ascent for Offline Reinforcement Learning", "abstract": "Model-based offline reinforcement learning methods (RL) have achieved\nstate-of-the-art performance in many decision-making problems thanks to their\nsample efficiency and generalizability. Despite these advancements, existing\nmodel-based offline RL approaches either focus on theoretical studies without\ndeveloping practical algorithms or rely on a restricted parametric policy\nspace, thus not fully leveraging the advantages of an unrestricted policy space\ninherent to model-based methods. To address this limitation, we develop MoMA, a\nmodel-based mirror ascent algorithm with general function approximations under\npartial coverage of offline data. MoMA distinguishes itself from existing\nliterature by employing an unrestricted policy class. In each iteration, MoMA\nconservatively estimates the value function by a minimization procedure within\na confidence set of transition models in the policy evaluation step, then\nupdates the policy with general function approximations instead of\ncommonly-used parametric policy classes in the policy improvement step. Under\nsome mild assumptions, we establish theoretical guarantees of MoMA by proving\nan upper bound on the suboptimality of the returned policy. We also provide a\npractically implementable, approximate version of the algorithm. The\neffectiveness of MoMA is demonstrated via numerical studies.", "field": "Computer Science", "categories": "cs.LG,math.ST,stat.ME,stat.ML,stat.TH"}, {"arxiv_id": "2401.11382", "title": "Using Large Language Model for End-to-End Chinese ASR and NER", "abstract": "Mapping speech tokens to the same feature space as text tokens has become the\nparadigm for the integration of speech modality into decoder-only large\nlanguage models (LLMs). An alternative approach is to use an encoder-decoder\narchitecture that incorporates speech features through cross-attention. This\napproach, however, has received less attention in the literature. In this work,\nwe connect the Whisper encoder with ChatGLM3 and provide in-depth comparisons\nof these two approaches using Chinese automatic speech recognition (ASR) and\nname entity recognition (NER) tasks. We evaluate them not only by conventional\nmetrics like the F1 score but also by a novel fine-grained taxonomy of ASR-NER\nerrors. Our experiments reveal that encoder-decoder architecture outperforms\ndecoder-only architecture with a short context, while decoder-only architecture\nbenefits from a long context as it fully exploits all layers of the LLM. By\nusing LLM, we significantly reduced the entity omission errors and improved the\nentity ASR accuracy compared to the Conformer baseline. Additionally, we\nobtained a state-of-the-art (SOTA) F1 score of 0.805 on the AISHELL-NER test\nset by using chain-of-thought (CoT) NER which first infers long-form ASR\ntranscriptions and then predicts NER labels.", "field": "Computer Science", "categories": "cs.CL,cs.AI"}, {"arxiv_id": "2401.11389", "title": "MedLM: Exploring Language Models for Medical Question Answering Systems", "abstract": "In the face of rapidly expanding online medical literature, automated systems\nfor aggregating and summarizing information are becoming increasingly crucial\nfor healthcare professionals and patients. Large Language Models (LLMs), with\ntheir advanced generative capabilities, have shown promise in various NLP\ntasks, and their potential in the healthcare domain, particularly for\nClosed-Book Generative QnA, is significant. However, the performance of these\nmodels in domain-specific tasks such as medical Q&A remains largely unexplored.\nThis study aims to fill this gap by comparing the performance of general and\nmedical-specific distilled LMs for medical Q&A. We aim to evaluate the\neffectiveness of fine-tuning domain-specific LMs and compare the performance of\ndifferent families of Language Models. The study will address critical\nquestions about these models' reliability, comparative performance, and\neffectiveness in the context of medical Q&A. The findings will provide valuable\ninsights into the suitability of different LMs for specific applications in the\nmedical domain.", "field": "Computer Science", "categories": "cs.CL,cs.AI,cs.LG"}, {"arxiv_id": "2401.1139", "title": "A Transformation of Repairing Reed-Solomon Codes from Rack-Aware Storage\n  Model to Homogeneous Storage Model", "abstract": "In this paper, we address the node repair problem of Reed-Solomon (RS) coded\ndistributed storage systems. Specifically, to overcome the challenges of\nmultiple-node failures of RS codes under the rack-aware storage model, we\nemploy good polynomials to guide the placement of the conventional RS codes\ninto racks and then propose a novel repair framework for the resultant\nrack-aware RS codes, which can transform its repair to that under the\nhomogeneous storage model. As applications of our repair framework, firstly we\npresent the repair scheme of multiple-node failures for some existing\nconstructions, which can only repair a single-node failure before. Secondly, we\ndeduce several new constructions of rack-aware RS codes supporting the repair\nof multiple-node failures.", "field": "Computer Science", "categories": "cs.IT,math.IT"}, {"arxiv_id": "2401.11391", "title": "Interactive AI with Retrieval-Augmented Generation for Next Generation\n  Networking", "abstract": "With the advance of artificial intelligence (AI), the emergence of Google\nGemini and OpenAI Q* marks the direction towards artificial general\nintelligence (AGI). To implement AGI, the concept of interactive AI (IAI) has\nbeen introduced, which can interactively understand and respond not only to\nhuman user input but also to dynamic system and network conditions. In this\narticle, we explore an integration and enhancement of IAI in networking. We\nfirst comprehensively review recent developments and future perspectives of AI\nand then introduce the technology and components of IAI. We then explore the\nintegration of IAI into the next-generation networks, focusing on how implicit\nand explicit interactions can enhance network functionality, improve user\nexperience, and promote efficient network management. Subsequently, we propose\nan IAI-enabled network management and optimization framework, which consists of\nenvironment, perception, action, and brain units. We also design the pluggable\nlarge language model (LLM) module and retrieval augmented generation (RAG)\nmodule to build the knowledge base and contextual memory for decision-making in\nthe brain unit. We demonstrate the effectiveness of the framework through case\nstudies. Finally, we discuss potential research directions for IAI-based\nnetworks.", "field": "Computer Science", "categories": "cs.NI,cs.IT,math.IT"}, {"arxiv_id": "2401.11394", "title": "Causal Generative Explainers using Counterfactual Inference: A Case\n  Study on the Morpho-MNIST Dataset", "abstract": "In this paper, we propose leveraging causal generative learning as an\ninterpretable tool for explaining image classifiers. Specifically, we present a\ngenerative counterfactual inference approach to study the influence of visual\nfeatures (i.e., pixels) as well as causal factors through generative learning.\nTo this end, we first uncover the most influential pixels on a classifier's\ndecision by varying the value of a causal attribute via counterfactual\ninference and computing both Shapely and contrastive explanations for\ncounterfactual images with these different attribute values. We then establish\na Monte-Carlo mechanism using the generator of a causal generative model in\norder to adapt Shapley explainers to produce feature importances for the\nhuman-interpretable attributes of a causal dataset in the case where a\nclassifier has been trained exclusively on the images of the dataset. Finally,\nwe present optimization methods for creating counterfactual explanations of\nclassifiers by means of counterfactual inference, proposing straightforward\napproaches for both differentiable and arbitrary classifiers. We exploit the\nMorpho-MNIST causal dataset as a case study for exploring our proposed methods\nfor generating counterfacutl explantions. We employ visual explanation methods\nfrom OmnixAI open source toolkit to compare them with our proposed methods. By\nemploying quantitative metrics to measure the interpretability of\ncounterfactual explanations, we find that our proposed methods of\ncounterfactual explanation offer more interpretable explanations compared to\nthose generated from OmnixAI. This finding suggests that our methods are\nwell-suited for generating highly interpretable counterfactual explanations on\ncausal datasets.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.11395", "title": "UniM-OV3D: Uni-Modality Open-Vocabulary 3D Scene Understanding with\n  Fine-Grained Feature Representation", "abstract": "3D open-vocabulary scene understanding aims to recognize arbitrary novel\ncategories beyond the base label space. However, existing works not only fail\nto fully utilize all the available modal information in the 3D domain but also\nlack sufficient granularity in representing the features of each modality. In\nthis paper, we propose a unified multimodal 3D open-vocabulary scene\nunderstanding network, namely UniM-OV3D, which aligns point clouds with image,\nlanguage and depth. To better integrate global and local features of the point\nclouds, we design a hierarchical point cloud feature extraction module that\nlearns comprehensive fine-grained feature representations. Further, to\nfacilitate the learning of coarse-to-fine point-semantic representations from\ncaptions, we propose the utilization of hierarchical 3D caption pairs,\ncapitalizing on geometric constraints across various viewpoints of 3D scenes.\nExtensive experimental results demonstrate the effectiveness and superiority of\nour method in open-vocabulary semantic and instance segmentation, which\nachieves state-of-the-art performance on both indoor and outdoor benchmarks\nsuch as ScanNet, ScanNet200, S3IDS and nuScenes. Code is available at\nhttps://github.com/hithqd/UniM-OV3D.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11396", "title": "Visual Imitation Learning with Calibrated Contrastive Representation", "abstract": "Adversarial Imitation Learning (AIL) allows the agent to reproduce expert\nbehavior with low-dimensional states and actions. However, challenges arise in\nhandling visual states due to their less distinguishable representation\ncompared to low-dimensional proprioceptive features. While existing methods\nresort to adopt complex network architectures or separate the process of\nlearning representation and decision-making, they overlook valuable intra-agent\ninformation within demonstrations. To address this problem, this paper proposes\na simple and effective solution by incorporating calibrated contrastive\nrepresentative learning into visual AIL framework. Specifically, we present an\nimage encoder in visual AIL, utilizing a combination of unsupervised and\nsupervised contrastive learning to extract valuable features from visual\nstates. Based on the fact that the improved agent often produces demonstrations\nof varying quality, we propose to calibrate the contrastive loss by treating\neach agent demonstrations as a mixed sample. The incorporation of contrastive\nlearning can be jointly optimized with the AIL framework, without modifying the\narchitecture or incurring significant computational costs. Experimental results\non DMControl Suite demonstrate our proposed method is sample efficient and can\noutperform other compared methods from different aspects.", "field": "Computer Science", "categories": "cs.LG,cs.CV"}, {"arxiv_id": "2401.11398", "title": "Application of a Novel Model Reduction Technique to the Assessment of\n  Boundedness/Stability of Some Delay Time-Varying Vector Nonlinear Systems", "abstract": "This paper develops a new approach to the assessment of the\nboundedness/stability of some vector nonlinear systems with delays and variable\ncoefficients. The approach rests on the development of scalar counterparts to\nthe original vector systems. We show that the solutions to these scalar\nauxiliary nonlinear equations with delay and variable coefficients bound from\nthe above the norms of solutions to the original equations with the matched\nhistory functions. This prompts the assessment of the boundedness/stability\ntraits of the vector systems through the abridged evaluation of the dynamics of\ntheir scalar counterparts. The latter task is achieved in effortless\nsimulations or through the application of simplified analytical inferences.\nConsequently, we convey some novel boundedness/ stability criteria and estimate\nthe radiuses of the balls imbedded in the boundedness/stability regions.\nLastly, we authenticate our inferences in representative simulations that also\nmeasure their accuracy.", "field": "Computer Science", "categories": "eess.SY,cs.SY,math.DG"}, {"arxiv_id": "2401.11401", "title": "LLMRA: Multi-modal Large Language Model based Restoration Assistant", "abstract": "Multi-modal Large Language Models (MLLMs) have a significant impact on\nvarious tasks, due to their extensive knowledge and powerful perception and\ngeneration capabilities. However, it still remains an open research problem on\napplying MLLMs to low-level vision tasks. In this paper, we present a simple\nMLLM-based Image Restoration framework to address this gap, namely Multi-modal\nLarge Language Model based Restoration Assistant (LLMRA). We exploit the\nimpressive capabilities of MLLMs to obtain the degradation information for\nuniversal image restoration. By employing a pretrained multi-modal large\nlanguage model and a vision language model, we generate text descriptions and\nencode them as context embedding with degradation information for the degraded\nimage. Through the proposed Context Enhance Module (CEM) and Degradation\nContext based Transformer Network (DC-former), we integrate these context\nembedding into the restoration network, contributing to more accurate and\nadjustable image restoration. Based on the dialogue with the users, our method\nleverages image degradation priors from MLLMs, providing low-level attributes\ndescriptions of the input low-quality images and the restored high-quality\nimages simultaneously. Extensive experiments demonstrate the superior\nperformance of our LLMRA in universal image restoration tasks.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11402", "title": "Enabling clustering algorithms to detect clusters of varying densities\n  through scale-invariant data preprocessing", "abstract": "In this paper, we show that preprocessing data using a variant of rank\ntransformation called 'Average Rank over an Ensemble of Sub-samples (ARES)'\nmakes clustering algorithms robust to data representation and enable them to\ndetect varying density clusters. Our empirical results, obtained using three\nmost widely used clustering algorithms-namely KMeans, DBSCAN, and DP (Density\nPeak)-across a wide range of real-world datasets, show that clustering after\nARES transformation produces better and more consistent results.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.11403", "title": "MolTailor: Tailoring Chemical Molecular Representation to Specific Tasks\n  via Text Prompts", "abstract": "Deep learning is now widely used in drug discovery, providing significant\nacceleration and cost reduction. As the most fundamental building block,\nmolecular representation is essential for predicting molecular properties to\nenable various downstream applications. Most existing methods attempt to\nincorporate more information to learn better representations. However, not all\nfeatures are equally important for a specific task. Ignoring this would\npotentially compromise the training efficiency and predictive accuracy. To\naddress this issue, we propose a novel approach, which treats language models\nas an agent and molecular pretraining models as a knowledge base. The agent\naccentuates task-relevant features in the molecular representation by\nunderstanding the natural language description of the task, just as a tailor\ncustomizes clothes for clients. Thus, we call this approach MolTailor.\nEvaluations demonstrate MolTailor's superior performance over baselines,\nvalidating the efficacy of enhancing relevance for molecular representation\nlearning. This illustrates the potential of language model guided optimization\nto better exploit and unleash the capabilities of existing powerful molecular\nrepresentation methods. Our codes and appendix are available at\nhttps://github.com/SCIR-HI/MolTailor.", "field": "Computer Science", "categories": "cs.LG,cs.CL,q-bio.BM"}, {"arxiv_id": "2401.11404", "title": "PlasmoData.jl -- A Julia Framework for Modeling and Analyzing Complex\n  Data as Graphs", "abstract": "Datasets encountered in scientific and engineering applications appear in\ncomplex formats (e.g., images, multivariate time series, molecules, video, text\nstrings, networks). Graph theory provides a unifying framework to model such\ndatasets and enables the use of powerful tools that can help analyze,\nvisualize, and extract value from data. In this work, we present PlasmoData.jl,\nan open-source, Julia framework that uses concepts of graph theory to\nfacilitate the modeling and analysis of complex datasets. The core of our\nframework is a general data modeling abstraction, which we call a DataGraph. We\nshow how the abstraction and software implementation can be used to represent\ndiverse data objects as graphs and to enable the use of tools from topology,\ngraph theory, and machine learning (e.g., graph neural networks) to conduct a\nvariety of tasks. We illustrate the versatility of the framework by using real\ndatasets: i) an image classification problem using topological data analysis to\nextract features from the graph model to train machine learning models; ii) a\ndisease outbreak problem where we model multivariate time series as graphs to\ndetect abnormal events; and iii) a technology pathway analysis problem where we\nhighlight how we can use graphs to navigate connectivity. Our discussion also\nhighlights how PlasmoData.jl leverages native Julia capabilities to enable\ncompact syntax, scalable computations, and interfaces with diverse packages.", "field": "Computer Science", "categories": "cs.MS,cs.LG"}, {"arxiv_id": "2401.11406", "title": "Adversarial Augmentation Training Makes Action Recognition Models More\n  Robust to Realistic Video Distribution Shifts", "abstract": "Despite recent advances in video action recognition achieving strong\nperformance on existing benchmarks, these models often lack robustness when\nfaced with natural distribution shifts between training and test data. We\npropose two novel evaluation methods to assess model resilience to such\ndistribution disparity. One method uses two different datasets collected from\ndifferent sources and uses one for training and validation, and the other for\ntesting. More precisely, we created dataset splits of HMDB-51 or UCF-101 for\ntraining, and Kinetics-400 for testing, using the subset of the classes that\nare overlapping in both train and test datasets. The other proposed method\nextracts the feature mean of each class from the target evaluation dataset's\ntraining data (i.e. class prototype) and estimates test video prediction as a\ncosine similarity score between each sample to the class prototypes of each\ntarget class. This procedure does not alter model weights using the target\ndataset and it does not require aligning overlapping classes of two different\ndatasets, thus is a very efficient method to test the model robustness to\ndistribution shifts without prior knowledge of the target distribution. We\naddress the robustness problem by adversarial augmentation training -\ngenerating augmented views of videos that are \"hard\" for the classification\nmodel by applying gradient ascent on the augmentation parameters - as well as\n\"curriculum\" scheduling the strength of the video augmentations. We\nexperimentally demonstrate the superior performance of the proposed adversarial\naugmentation approach over baselines across three state-of-the-art action\nrecognition models - TSM, Video Swin Transformer, and Uniformer. The presented\nwork provides critical insight into model robustness to distribution shifts and\npresents effective techniques to enhance video action recognition performance\nin a real-world deployment.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11408", "title": "SEBERTNets: Sequence Enhanced BERT Networks for Event Entity Extraction\n  Tasks Oriented to the Finance Field", "abstract": "Event extraction lies at the cores of investment analysis and asset\nmanagement in the financial field, and thus has received much attention. The\n2019 China conference on knowledge graph and semantic computing (CCKS)\nchallenge sets up a evaluation competition for event entity extraction task\noriented to the finance field. In this task, we mainly focus on how to extract\nthe event entity accurately, and recall all the corresponding event entity\neffectively. In this paper, we propose a novel model, Sequence Enhanced BERT\nNetworks (SEBERTNets for short), which can inherit the advantages of the\nBERT,and while capturing sequence semantic information. In addition, motivated\nby recommendation system, we propose Hybrid Sequence Enhanced BERT Networks\n(HSEBERTNets for short), which uses a multi-channel recall method to recall all\nthe corresponding event entity. The experimental results show that, the F1\nscore of SEBERTNets is 0.905 in the first stage, and the F1 score of\nHSEBERTNets is 0.934 in the first stage, which demonstarate the effectiveness\nof our methods.", "field": "Computer Science", "categories": "cs.CL,cs.AI"}, {"arxiv_id": "2401.11409", "title": "Robust Beamforming for Downlink Multi-Cell Systems: A Bilevel\n  Optimization Perspective", "abstract": "Utilization of inter-base station cooperation for information processing has\nshown great potential in enhancing the overall quality of communication\nservices (QoS) in wireless communication networks. Nevertheless, such\ncooperations require the knowledge of channel state information (CSI) at base\nstations (BSs), which is assumed to be perfectly known. However, CSI errors are\ninevitable in practice which necessitates beamforming techniques that can\nachieve robust performance in the presence of channel estimation errors.\nExisting approaches relax the robust beamforming design problems into\nsemidefinite programming (SDP), which can only achieve a solution that is far\nfrom being optimal. To this end, this paper views robust beamforming design\nproblems from a bilevel optimization perspective. In particular, we focus on\nmaximizing the worst-case weighted sum-rate (WSR) in the downlink multi-cell\nmulti-user multiple-input single-output (MISO) system considering bounded CSI\nerrors. We first reformulate this problem into a bilevel optimization problem\nand then develop an efficient algorithm based on the cutting plane method. A\ndistributed optimization algorithm has also been developed to facilitate the\nparallel processing in practical settings. Numerical results are provided to\nconfirm the effectiveness of the proposed algorithm in terms of performance and\ncomplexity, particularly in the presence of CSI uncertainties.", "field": "Computer Science", "categories": "cs.IT,eess.SP,math.IT"}, {"arxiv_id": "2401.1141", "title": "Agricultural Recommendation System based on Deep Learning: A\n  Multivariate Weather Forecasting Approach", "abstract": "Bangladesh is predominantly an agricultural country, where the agrarian\nsector plays an essential role in accelerating economic growth and enabling the\nfood security of the people. The performance of this sector has an overwhelming\nimpact on the primary macroeconomic objectives like food security, employment\ngeneration, poverty alleviation, human resources development, and other\neconomic and social forces. Although Bangladesh's labor-intensive agriculture\nhas achieved steady increases in food grain production, it often suffered from\nunfavorable weather conditions such as heavy rainfall, low temperature, and\ndrought. Consequently, these factors hinder the production of food\nsubstantially, putting the country's overall food security in danger. In order\nto have a profitable, sustainable, and farmer-friendly agricultural practice,\nthis paper proposes a context-based crop recommendation system powered by a\nweather forecast model. With extensive evaluation, the multivariate Stacked\nBi-LSTM Network is employed as the weather forecasting model. The proposed\nweather model can forecast Rainfall, Temperature, Humidity, and Sunshine for\nany given location in Bangladesh with higher accuracy. These predictions guide\nour system to assist the farmers in making feasible decisions about planting,\nirrigation, harvesting, and so on. Additionally, our full-fledged system is\ncapable of alerting the farmers about extreme weather conditions so that\npreventive measures can be undertaken to protect the crops. Finally, the system\nis also adept at making knowledge-based crop suggestions for the flood and\ndrought-prone regions of Bangladesh.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.11411", "title": "The degree of ill-posedness for some composition governed by the Cesaro\n  operator", "abstract": "In this article, we consider the singular value asymptotics of compositions\nof compact linear operators mapping in the real Hilbert space of quadratically\nintegrable functions over the unit interval. Specifically, the composition is\ngiven by the compact simple integration operator followed by the non-compact\nCes`aro operator possessing a non-closed range. We show that the degree of\nill-posedness of that composition is two, which means that the Ces`aro operator\nincreases the degree of illposedness by the amount of one compared to the\nsimple integration operator.", "field": "Computer Science", "categories": "math.NA,cs.NA,math.FA,47A52 (Primary), 47B06, 65J20, 40G05 (Secondary)"}, {"arxiv_id": "2401.11414", "title": "S$^3$M-Net: Joint Learning of Semantic Segmentation and Stereo Matching\n  for Autonomous Driving", "abstract": "Semantic segmentation and stereo matching are two essential components of 3D\nenvironmental perception systems for autonomous driving. Nevertheless,\nconventional approaches often address these two problems independently,\nemploying separate models for each task. This approach poses practical\nlimitations in real-world scenarios, particularly when computational resources\nare scarce or real-time performance is imperative. Hence, in this article, we\nintroduce S$^3$M-Net, a novel joint learning framework developed to perform\nsemantic segmentation and stereo matching simultaneously. Specifically,\nS$^3$M-Net shares the features extracted from RGB images between both tasks,\nresulting in an improved overall scene understanding capability. This feature\nsharing process is realized using a feature fusion adaption (FFA) module, which\neffectively transforms the shared features into semantic space and subsequently\nfuses them with the encoded disparity features. The entire joint learning\nframework is trained by minimizing a novel semantic consistency-guided (SCG)\nloss, which places emphasis on the structural consistency in both tasks.\nExtensive experimental results conducted on the vKITTI2 and KITTI datasets\ndemonstrate the effectiveness of our proposed joint learning framework and its\nsuperior performance compared to other state-of-the-art single-task networks.\nOur project webpage is accessible at mias.group/S3M-Net.", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.RO"}, {"arxiv_id": "2401.11415", "title": "A Fast Parallel Approach for Neighborhood-based Link Prediction by\n  Disregarding Large Hubs", "abstract": "Link prediction can help rectify inaccuracies in community detection stemming\nfrom unaccounted-for or overlooked links within networks. Many existing works\nuse a baseline approach, which incurs unnecessary computational costs due to\nits high time complexity. Further, many studies focus on smaller graphs, which\ncan lead to misleading conclusions. The report introduces two parallel\napproaches, called IHub and LHub, which predict links using neighborhood-based\nsimilarity measures on large graphs. LHub is a heuristic approach, which\nadditionally disregards large hubs - based on the idea that low-degree nodes\ncontribute significant similarity among neighbors. On a server equipped with\ndual 16-core Intel Xeon Gold 6226R processors, LHub is on average 563x faster\nthan IHub, especially on web graphs and social networks, while having similar\nprediction accuracy. Notably, LHub achieves a link prediction rate of 38.1M\nedges/s and improves performance at a rate of 1.6x for every doubling of\nthreads.", "field": "Computer Science", "categories": "cs.SI,cs.DC,G.2.2; I.5.3"}, {"arxiv_id": "2401.11418", "title": "Double-Bounded Optimal Transport for Advanced Clustering and\n  Classification", "abstract": "Optimal transport (OT) is attracting increasing attention in machine\nlearning. It aims to transport a source distribution to a target one at minimal\ncost. In its vanilla form, the source and target distributions are\npredetermined, which contracts to the real-world case involving undetermined\ntargets. In this paper, we propose Doubly Bounded Optimal Transport (DB-OT),\nwhich assumes that the target distribution is restricted within two boundaries\ninstead of a fixed one, thus giving more freedom for the transport to find\nsolutions. Based on the entropic regularization of DB-OT, three scaling-based\nalgorithms are devised for calculating the optimal solution. We also show that\nour DB-OT is helpful for barycenter-based clustering, which can avoid the\nexcessive concentration of samples in a single cluster. Then we further develop\nDB-OT techniques for long-tailed classification which is an emerging and open\nproblem. We first propose a connection between OT and classification, that is,\nin the classification task, training involves optimizing the Inverse OT to\nlearn the representations, while testing involves optimizing the OT for\npredictions. With this OT perspective, we first apply DB-OT to improve the\nloss, and the Balanced Softmax is shown as a special case. Then we apply DB-OT\nfor inference in the testing process. Even with vanilla Softmax trained\nfeatures, our extensive experimental results show that our method can achieve\ngood results with our improved inference scheme in the testing stage.", "field": "Computer Science", "categories": "cs.LG,cs.AI,math.OC"}, {"arxiv_id": "2401.11419", "title": "Joint UAV Deployment and Resource Allocation in THz-Assisted MEC-Enabled\n  Integrated Space-Air-Ground Networks", "abstract": "Multi-access edge computing (MEC)-enabled integrated space-air-ground (SAG)\nnetworks have drawn much attention recently, as they can provide communication\nand computing services to wireless devices in areas that lack terrestrial base\nstations (TBSs). Leveraging the ample bandwidth in the terahertz (THz)\nspectrum, in this paper, we propose MEC-enabled integrated SAG networks with\ncollaboration among unmanned aerial vehicles (UAVs). We then formulate the\nproblem of minimizing the energy consumption of devices and UAVs in the\nproposed MEC-enabled integrated SAG networks by optimizing tasks offloading\ndecisions, THz sub-bands assignment, transmit power control, and UAVs\ndeployment. The formulated problem is a mixed-integer nonlinear programming\n(MILP) problem with a non-convex structure, which is challenging to solve. We\nthus propose a block coordinate descent (BCD) approach to decompose the problem\ninto four sub-problems: 1) device task offloading decision problem, 2) THz\nsub-band assignment and power control problem, 3) UAV deployment problem, and\n4) UAV task offloading decision problem. We then propose to use a matching\ngame, concave-convex procedure (CCP) method, successive convex approximation\n(SCA), and block successive upper-bound minimization (BSUM) approaches for\nsolving the individual subproblems. Finally, extensive simulations are\nperformed to demonstrate the effectiveness of our proposed algorithm.", "field": "Computer Science", "categories": "cs.NI,eess.SP"}, {"arxiv_id": "2401.1142", "title": "Embedded Hyperspectral Band Selection with Adaptive Optimization for\n  Image Semantic Segmentation", "abstract": "Hyperspectral band selection plays a pivotal role in remote sensing and image\nanalysis, aiming to identify the most informative spectral bands while\nminimizing computational overhead. In this paper, we introduce a pioneering\napproach for hyperspectral band selection that offers an embedded solution,\nmaking it well-suited for resource-constrained or real-time applications. Our\nproposed method, embedded Hyperspectral Band Selection (EHBS), excels in\nselecting the best bands without the need for prior processing, seamlessly\nintegrating with the downstream task model. This is achieved through the\nadaptation of the Stochastic Gates (STG) algorithm, originally designed for\nfeature selection, for hyperspectral band selection in the context of image\nsemantic segmentation and the integration of a dynamic optimizer, DoG, which\nremoves the need for the required tuning the learning rate. To assess the\nperformance of our method, we introduce a novel metric for evaluating band\nselection methods across different target numbers of selected bands quantified\nby the Area Under the Curve (AUC). We conduct experiments on two distinct\nsemantic-segmentation hyperspectral benchmark datasets, demonstrating its\nsuperiority in terms of its resulting accuracy and its ease of use compared to\nmany common and state-of-the-art methods. Furthermore, our contributions extend\nbeyond the realm of hyperspectral band selection. The adaptability of our\napproach to other tasks, especially those involving grouped features, opens up\npromising avenues for broader applications within the realm of deep learning,\nsuch as feature selection for feature groups. The demonstrated success on the\ntested datasets and the potential for application to a variety of tasks\nunderscore the value of our method as a substantial addition to the field of\ncomputer vision.", "field": "Computer Science", "categories": "cs.CV,I.4.6; I.4.7; I.4.2; I.4.8"}, {"arxiv_id": "2401.11421", "title": "Enhancing the vision-language foundation model with key semantic\n  knowledge-emphasized report refinement", "abstract": "Recently, vision-language representation learning has made remarkable\nadvancements in building up medical foundation models, holding immense\npotential for transforming the landscape of clinical research and medical care.\nThe underlying hypothesis is that the rich knowledge embedded in radiology\nreports can effectively assist and guide the learning process, reducing the\nneed for additional labels. However, these reports tend to be complex and\nsometimes even consist of redundant descriptions that make the representation\nlearning too challenging to capture the key semantic information. This paper\ndevelops a novel iterative vision-language representation learning framework by\nproposing a key semantic knowledge-emphasized report refinement method.\nParticularly, raw radiology reports are refined to highlight the key\ninformation according to a constructed clinical dictionary and two\nmodel-optimized knowledge-enhancement metrics. The iterative framework is\ndesigned to progressively learn, starting from gaining a general understanding\nof the patient's condition based on raw reports and gradually refines and\nextracts critical information essential to the fine-grained analysis tasks. The\neffectiveness of the proposed framework is validated on various downstream\nmedical image analysis tasks, including disease classification,\nregion-of-interest segmentation, and phrase grounding. Our framework surpasses\nseven state-of-the-art methods in both fine-tuning and zero-shot settings,\ndemonstrating its encouraging potential for different clinical applications.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11425", "title": "Grayscale Image Colorization with GAN and CycleGAN in Different Image\n  Domain", "abstract": "Automatic colorization of grayscale image has been a challenging task.\nPrevious research have applied supervised methods in conquering this problem [\n1]. In this paper, we reproduces a GAN-based coloring model, and experiments\none of its variant. We also proposed a CycleGAN based model and experiments\nthose methods on various datasets. The result shows that the proposed CycleGAN\nmodel does well in human-face coloring and comic coloring, but lack the ability\nto diverse colorization.", "field": "Computer Science", "categories": "cs.CV,cs.LG,I.4.3"}, {"arxiv_id": "2401.11429", "title": "Joint Downlink and Uplink Optimization for RIS-Aided FDD MIMO\n  Communication Systems", "abstract": "This paper investigates reconfigurable intelligent surface (RIS)-aided\nfrequency division duplexing (FDD) communication systems. Since the downlink\nand uplink signals are simultaneously transmitted in FDD, the phase shifts at\nthe RIS should be designed to support both transmissions. Considering a\nsingle-user multiple-input multiple-output system, we formulate a weighted\nsum-rate maximization problem to jointly maximize the downlink and uplink\nsystem performance. To tackle the non-convex optimization problem, we adopt an\nalternating optimization (AO) algorithm, in which two phase shift optimization\ntechniques are developed to handle the unit-modulus constraints induced by the\nreflection coefficients at the RIS. The first technique exploits the manifold\noptimization-based algorithm, while the second uses a lower-complexity AO\napproach. Numerical results verify that the proposed techniques rapidly\nconverge to local optima and significantly improve the overall system\nperformance compared to existing benchmark schemes.", "field": "Computer Science", "categories": "cs.IT,eess.SP,math.IT"}, {"arxiv_id": "2401.1143", "title": "Exploring Diffusion Time-steps for Unsupervised Representation Learning", "abstract": "Representation learning is all about discovering the hidden modular\nattributes that generate the data faithfully. We explore the potential of\nDenoising Diffusion Probabilistic Model (DM) in unsupervised learning of the\nmodular attributes. We build a theoretical framework that connects the\ndiffusion time-steps and the hidden attributes, which serves as an effective\ninductive bias for unsupervised learning. Specifically, the forward diffusion\nprocess incrementally adds Gaussian noise to samples at each time-step, which\nessentially collapses different samples into similar ones by losing attributes,\ne.g., fine-grained attributes such as texture are lost with less noise added\n(i.e., early time-steps), while coarse-grained ones such as shape are lost by\nadding more noise (i.e., late time-steps). To disentangle the modular\nattributes, at each time-step t, we learn a t-specific feature to compensate\nfor the newly lost attribute, and the set of all 1,...,t-specific features,\ncorresponding to the cumulative set of lost attributes, are trained to make up\nfor the reconstruction error of a pre-trained DM at time-step t. On CelebA,\nFFHQ, and Bedroom datasets, the learned feature significantly improves\nattribute classification and enables faithful counterfactual generation, e.g.,\ninterpolating only one specified attribute between two images, validating the\ndisentanglement quality. Codes are in https://github.com/yue-zhongqi/diti.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11431", "title": "Majority or Minority: Data Imbalance Learning Method for Named Entity\n  Recognition", "abstract": "Data imbalance presents a significant challenge in various machine learning\n(ML) tasks, particularly named entity recognition (NER) within natural language\nprocessing (NLP). NER exhibits a data imbalance with a long-tail distribution,\nfeaturing numerous minority classes (i.e., entity classes) and a single\nmajority class (i.e., O-class). The imbalance leads to the misclassifications\nof the entity classes as the O-class. To tackle the imbalance, we propose a\nsimple and effective learning method, named majority or minority (MoM)\nlearning. MoM learning incorporates the loss computed only for samples whose\nground truth is the majority class (i.e., the O-class) into the loss of the\nconventional ML model. Evaluation experiments on four NER datasets (Japanese\nand English) showed that MoM learning improves prediction performance of the\nminority classes, without sacrificing the performance of the majority class and\nis more effective than widely known and state-of-the-art methods. We also\nevaluated MoM learning using frameworks as sequential labeling and machine\nreading comprehension, which are commonly used in NER. Furthermore, MoM\nlearning has achieved consistent performance improvements regardless of\nlanguage, model, or framework.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.11432", "title": "Bimanual Deformable Bag Manipulation Using a Structure-of-Interest Based\n  Latent Dynamics Model", "abstract": "The manipulation of deformable objects by robotic systems presents a\nsignificant challenge due to their complex and infinite-dimensional\nconfiguration spaces. This paper introduces a novel approach to Deformable\nObject Manipulation (DOM) by emphasizing the identification and manipulation of\nStructures of Interest (SOIs) in deformable fabric bags. We propose a bimanual\nmanipulation framework that leverages a Graph Neural Network (GNN)-based latent\ndynamics model to succinctly represent and predict the behavior of these SOIs.\nOur approach involves constructing a graph representation from partial point\ncloud data of the object and learning the latent dynamics model that\neffectively captures the essential deformations of the fabric bag within a\nreduced computational space. By integrating this latent dynamics model with\nModel Predictive Control (MPC), we empower robotic manipulators to perform\nprecise and stable manipulation tasks focused on the SOIs. We have validated\nour framework through various empirical experiments demonstrating its efficacy\nin bimanual manipulation of fabric bags. Our contributions not only address the\ncomplexities inherent in DOM but also provide new perspectives and\nmethodologies for enhancing robotic interactions with deformable objects by\nconcentrating on their critical structural elements. Experimental videos can be\nobtained from https://sites.google.com/view/bagbot.", "field": "Computer Science", "categories": "cs.RO"}, {"arxiv_id": "2401.11433", "title": "Error-Correcting Codes on Projective Bundles over Deligne-Lusztig\n  varieties", "abstract": "The aim of this article is to give lower bounds on the parameters of\nalgebraic geometric error-correcting codes constructed from projective bundles\nover Deligne--Lusztig surfaces. The methods based on an intensive use of the\nintersection theory allow us to extend the codes previously constructed from\nhigher-dimensional varieties, as well as those coming from curves. General\nbounds are obtained for the case of projective bundles of rank $2$ over\nstandard Deligne-Lusztig surfaces, and some explicit examples coming from\nsurfaces of type $A_{2}$ and ${}^{2}A_{4}$ are given.", "field": "Computer Science", "categories": "cs.IT,math.AG,math.IT,94B27, 14G50, 14C17, 14L35"}, {"arxiv_id": "2401.11436", "title": "Geometric Prior Guided Feature Representation Learning for Long-Tailed\n  Classification", "abstract": "Real-world data are long-tailed, the lack of tail samples leads to a\nsignificant limitation in the generalization ability of the model. Although\nnumerous approaches of class re-balancing perform well for moderate class\nimbalance problems, additional knowledge needs to be introduced to help the\ntail class recover the underlying true distribution when the observed\ndistribution from a few tail samples does not represent its true distribution\nproperly, thus allowing the model to learn valuable information outside the\nobserved domain. In this work, we propose to leverage the geometric information\nof the feature distribution of the well-represented head class to guide the\nmodel to learn the underlying distribution of the tail class. Specifically, we\nfirst systematically define the geometry of the feature distribution and the\nsimilarity measures between the geometries, and discover four phenomena\nregarding the relationship between the geometries of different feature\ndistributions. Then, based on four phenomena, feature uncertainty\nrepresentation is proposed to perturb the tail features by utilizing the\ngeometry of the head class feature distribution. It aims to make the perturbed\nfeatures cover the underlying distribution of the tail class as much as\npossible, thus improving the model's generalization performance in the test\ndomain. Finally, we design a three-stage training scheme enabling feature\nuncertainty modeling to be successfully applied. Experiments on\nCIFAR-10/100-LT, ImageNet-LT, and iNaturalist2018 show that our proposed\napproach outperforms other similar methods on most metrics. In addition, the\nexperimental phenomena we discovered are able to provide new perspectives and\ntheoretical foundations for subsequent studies.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11437", "title": "Open the Black Box: Step-based Policy Updates for Temporally-Correlated\n  Episodic Reinforcement Learning", "abstract": "Current advancements in reinforcement learning (RL) have predominantly\nfocused on learning step-based policies that generate actions for each\nperceived state. While these methods efficiently leverage step information from\nenvironmental interaction, they often ignore the temporal correlation between\nactions, resulting in inefficient exploration and unsmooth trajectories that\nare challenging to implement on real hardware. Episodic RL (ERL) seeks to\novercome these challenges by exploring in parameters space that capture the\ncorrelation of actions. However, these approaches typically compromise data\nefficiency, as they treat trajectories as opaque \\emph{black boxes}. In this\nwork, we introduce a novel ERL algorithm, Temporally-Correlated Episodic RL\n(TCE), which effectively utilizes step information in episodic policy updates,\nopening the 'black box' in existing ERL methods while retaining the smooth and\nconsistent exploration in parameter space. TCE synergistically combines the\nadvantages of step-based and episodic RL, achieving comparable performance to\nrecent ERL methods while maintaining data efficiency akin to state-of-the-art\n(SoTA) step-based RL.", "field": "Computer Science", "categories": "cs.LG,cs.RO"}, {"arxiv_id": "2401.11439", "title": "General Flow as Foundation Affordance for Scalable Robot Learning", "abstract": "We address the challenge of acquiring real-world manipulation skills with a\nscalable framework.Inspired by the success of large-scale auto-regressive\nprediction in Large Language Models (LLMs), we hold the belief that identifying\nan appropriate prediction target capable of leveraging large-scale datasets is\ncrucial for achieving efficient and universal learning. Therefore, we propose\nto utilize flow, which represents the future trajectories of 3D points on\nobjects of interest, as an ideal prediction target in robot learning. To\nexploit scalable data resources, we turn our attention to cross-embodiment\ndatasets. We develop, for the first time, a language-conditioned prediction\nmodel directly from large-scale RGBD human video datasets. Our predicted flow\noffers actionable geometric and physics guidance, thus facilitating stable\nzero-shot skill transfer in real-world scenarios.We deploy our method with a\npolicy based on closed-loop flow prediction. Remarkably, without any additional\ntraining, our method achieves an impressive 81% success rate in human-to-robot\nskill transfer, covering 18 tasks in 6 scenes. Our framework features the\nfollowing benefits: (1) scalability: leveraging cross-embodiment data\nresources; (2) universality: multiple object categories, including rigid,\narticulated, and soft bodies; (3) stable skill transfer: providing actionable\nguidance with a small inference domain-gap. These lead to a new pathway towards\nscalable general robot learning. Data, code, and model weights will be made\npublicly available.", "field": "Computer Science", "categories": "cs.RO,cs.AI,cs.CV"}, {"arxiv_id": "2401.11441", "title": "On-Device Recommender Systems: A Comprehensive Survey", "abstract": "Recommender systems have been widely deployed in various real-world\napplications to help users identify content of interest from massive amounts of\ninformation. Traditional recommender systems work by collecting user-item\ninteraction data in a cloud-based data center and training a centralized model\nto perform the recommendation service. However, such cloud-based recommender\nsystems (CloudRSs) inevitably suffer from excessive resource consumption,\nresponse latency, as well as privacy and security risks concerning both data\nand models. Recently, driven by the advances in storage, communication, and\ncomputation capabilities of edge devices, there has been a shift of focus from\nCloudRSs to on-device recommender systems (DeviceRSs), which leverage the\ncapabilities of edge devices to minimize centralized data storage requirements,\nreduce the response latency caused by communication overheads, and enhance user\nprivacy and security by localizing data processing and model training. Despite\nthe rapid rise of DeviceRSs, there is a clear absence of timely literature\nreviews that systematically introduce, categorize and contrast these methods.\nTo bridge this gap, we aim to provide a comprehensive survey of DeviceRSs,\ncovering three main aspects: (1) the deployment and inference of DeviceRSs (2)\nthe training and update of DeviceRSs (3) the security and privacy of DeviceRSs.\nFurthermore, we provide a fine-grained and systematic taxonomy of the methods\ninvolved in each aspect, followed by a discussion regarding challenges and\nfuture research directions. This is the first comprehensive survey on DeviceRSs\nthat covers a spectrum of tasks to fit various needs. We believe this survey\nwill help readers effectively grasp the current research status in this field,\nequip them with relevant technical foundations, and stimulate new research\nideas for developing DeviceRSs.", "field": "Computer Science", "categories": "cs.IR"}, {"arxiv_id": "2401.11445", "title": "Towards Non-Robocentric Dynamic Landing of Quadrotor UAVs", "abstract": "In this work, we propose a dynamic landing solution without the need for\nonboard exteroceptive sensors and an expensive computation unit, where all\nlocalization and control modules are carried out on the ground in a\nnon-inertial frame. Our system starts with a relative state estimator of the\naerial robot from the perspective of the landing platform, where the state\ntracking of the UAV is done through a set of onboard LED markers and an\non-ground camera; the state is expressed geometrically on manifold, and is\nreturned by Iterated Extended Kalman filter (IEKF) algorithm. Subsequently, a\nmotion planning module is developed to guide the landing process, formulating\nit as a minimum jerk trajectory by applying the differential flatness property.\nConsidering visibility and dynamic constraints, the problem is solved using\nquadratic programming, and the final motion primitive is expressed through\npiecewise polynomials. Through a series of experiments, the applicability of\nthis approach is validated by successfully landing 18 cm x 18 cm quadrotor on a\n43 cm x 43 cm platform, exhibiting performance comparable to conventional\nmethods. Finally, we provide comprehensive hardware and software details to the\nresearch community for future reference.", "field": "Computer Science", "categories": "cs.RO,cs.SY,eess.SY"}, {"arxiv_id": "2401.11447", "title": "Sequential Model for Predicting Patient Adherence in Subcutaneous\n  Immunotherapy for Allergic Rhinitis", "abstract": "Objective: Subcutaneous Immunotherapy (SCIT) is the long-lasting causal\ntreatment of allergic rhinitis. How to enhance the adherence of patients to\nmaximize the benefit of allergen immunotherapy (AIT) plays a crucial role in\nthe management of AIT. This study aims to leverage novel machine learning\nmodels to precisely predict the risk of non-adherence of patients and related\nsystematic symptom scores, to provide a novel approach in the management of\nlong-term AIT.\n  Methods: The research develops and analyzes two models, Sequential Latent\nActor-Critic (SLAC) and Long Short-Term Memory (LSTM), evaluating them based on\nscoring and adherence prediction capabilities.\n  Results: Excluding the biased samples at the first time step, the predictive\nadherence accuracy of the SLAC models is from $60\\,\\%$ to $72\\%$, and for LSTM\nmodels, it is $66\\,\\%$ to $84\\,\\%$, varying according to the time steps. The\nrange of Root Mean Square Error (RMSE) for SLAC models is between $0.93$ and\n$2.22$, while for LSTM models it is between $1.09$ and $1.77$. Notably, these\nRMSEs are significantly lower than the random prediction error of $4.55$.\n  Conclusion: We creatively apply sequential models in the long-term management\nof SCIT with promising accuracy in the prediction of SCIT nonadherence in\nAllergic Rhinitis (AR) patients. While LSTM outperforms SLAC in adherence\nprediction, SLAC excels in score prediction for patients undergoing SCIT for\nAR. The state-action-based SLAC adds flexibility, presenting a novel and\neffective approach for managing long-term AIT.", "field": "Computer Science", "categories": "cs.LG,q-bio.QM"}, {"arxiv_id": "2401.11448", "title": "Adaptive Betweenness Clustering for Semi-Supervised Domain Adaptation", "abstract": "Compared to unsupervised domain adaptation, semi-supervised domain adaptation\n(SSDA) aims to significantly improve the classification performance and\ngeneralization capability of the model by leveraging the presence of a small\namount of labeled data from the target domain. Several SSDA approaches have\nbeen developed to enable semantic-aligned feature confusion between labeled (or\npseudo labeled) samples across domains; nevertheless, owing to the scarcity of\nsemantic label information of the target domain, they were arduous to fully\nrealize their potential. In this study, we propose a novel SSDA approach named\nGraph-based Adaptive Betweenness Clustering (G-ABC) for achieving categorical\ndomain alignment, which enables cross-domain semantic alignment by mandating\nsemantic transfer from labeled data of both the source and target domains to\nunlabeled target samples. In particular, a heterogeneous graph is initially\nconstructed to reflect the pairwise relationships between labeled samples from\nboth domains and unlabeled ones of the target domain. Then, to degrade the\nnoisy connectivity in the graph, connectivity refinement is conducted by\nintroducing two strategies, namely Confidence Uncertainty based Node Removal\nand Prediction Dissimilarity based Edge Pruning. Once the graph has been\nrefined, Adaptive Betweenness Clustering is introduced to facilitate semantic\ntransfer by using across-domain betweenness clustering and within-domain\nbetweenness clustering, thereby propagating semantic label information from\nlabeled samples across domains to unlabeled target data. Extensive experiments\non three standard benchmark datasets, namely DomainNet, Office-Home, and\nOffice-31, indicated that our method outperforms previous state-of-the-art SSDA\napproaches, demonstrating the superiority of the proposed G-ABC algorithm.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11452", "title": "Towards Reliable and Factual Response Generation: Detecting Unanswerable\n  Questions in Information-Seeking Conversations", "abstract": "Generative AI models face the challenge of hallucinations that can undermine\nusers' trust in such systems. We approach the problem of conversational\ninformation seeking as a two-step process, where relevant passages in a corpus\nare identified first and then summarized into a final system response. This way\nwe can automatically assess if the answer to the user's question is present in\nthe corpus. Specifically, our proposed method employs a sentence-level\nclassifier to detect if the answer is present, then aggregates these\npredictions on the passage level, and eventually across the top-ranked passages\nto arrive at a final answerability estimate. For training and evaluation, we\ndevelop a dataset based on the TREC CAsT benchmark that includes answerability\nlabels on the sentence, passage, and ranking levels. We demonstrate that our\nproposed method represents a strong baseline and outperforms a state-of-the-art\nLLM on the answerability prediction task.", "field": "Computer Science", "categories": "cs.IR,cs.CL"}, {"arxiv_id": "2401.11453", "title": "Inter-Domain Mixup for Semi-Supervised Domain Adaptation", "abstract": "Semi-supervised domain adaptation (SSDA) aims to bridge source and target\ndomain distributions, with a small number of target labels available, achieving\nbetter classification performance than unsupervised domain adaptation (UDA).\nHowever, existing SSDA work fails to make full use of label information from\nboth source and target domains for feature alignment across domains, resulting\nin label mismatch in the label space during model testing. This paper presents\na novel SSDA approach, Inter-domain Mixup with Neighborhood Expansion (IDMNE),\nto tackle this issue. Firstly, we introduce a cross-domain feature alignment\nstrategy, Inter-domain Mixup, that incorporates label information into model\nadaptation. Specifically, we employ sample-level and manifold-level data mixing\nto generate compatible training samples. These newly established samples,\ncombined with reliable and actual label information, display diversity and\ncompatibility across domains, while such extra supervision thus facilitates\ncross-domain feature alignment and mitigates label mismatch. Additionally, we\nutilize Neighborhood Expansion to leverage high-confidence pseudo-labeled\nsamples in the target domain, diversifying the label information of the target\ndomain and thereby further increasing the performance of the adaptation model.\nAccordingly, the proposed approach outperforms existing state-of-the-art\nmethods, achieving significant accuracy improvements on popular SSDA\nbenchmarks, including DomainNet, Office-Home, and Office-31.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11455", "title": "Study on the Sorting Performance for Reactor Monte Carlo Neutron\n  Transport on Apple Unified Memory GPUs", "abstract": "In simulation of nuclear reactor physics using the Monte Carlo neutron\ntransport method on GPUs, the sorting of particles play a significant role in\nexecution performance. Traditionally, CPUs and GPUs are separated devices\nconnected with low data transfer rate and high data transfer latency. Emerging\ncomputing chips tend to integrate CPUs and GPUs. One example is the Apple\nsilicon chips with unified memory. Such a unified memory chips has opened doors\nfor new strategies of collaboration between CPUs and GPUs for Monte Carlo\nneutron transport. Sorting particle on CPU and transport on GPU is an example\nof such new strategy, which has been suffering the high CPU-GPU data transfer\nlatency on the traditional devices with separated CPU and GPU. The finding is\nthat for the Apple M2 max chip, sorting on CPU leads to better performance than\nsorting on GPU for the ExaSMR whole core benchmark problems, while for the\nHTR-10 high temperature gas reactor fuel pebble problem, sorting on GPU is more\nefficient. The features of partially sorted particle order have been identified\nto contribute to the higher performance with CPU sort than GPU for the ExaSMR\nproblem. The in-house code using both CPUs and GPUs achieves 7.5 times power\nefficiency that of OpenMC on CPUs for ExaSMR whole core and 50 times for HTR-10\nfuel pebble benchmark problems.", "field": "Computer Science", "categories": "cs.AR"}, {"arxiv_id": "2401.11458", "title": "Linear Alignment: A Closed-form Solution for Aligning Human Preferences\n  without Tuning and Feedback", "abstract": "The success of AI assistants based on Language Models (LLMs) hinges on\nReinforcement Learning from Human Feedback (RLHF) to comprehend and align with\nuser intentions. However, traditional alignment algorithms, such as PPO, are\nhampered by complex annotation and training requirements. This reliance limits\nthe applicability of RLHF and hinders the development of professional\nassistants tailored to diverse human preferences. In this work, we introduce\n\\textit{Linear Alignment}, a novel algorithm that aligns language models with\nhuman preferences in one single inference step, eliminating the reliance on\ndata annotation and model training. Linear alignment incorporates a new\nparameterization for policy optimization under divergence constraints, which\nenables the extraction of optimal policy in a closed-form manner and\nfacilitates the direct estimation of the aligned response. Extensive\nexperiments on both general and personalized preference datasets demonstrate\nthat linear alignment significantly enhances the performance and efficiency of\nLLM alignment across diverse scenarios. Our code and dataset will be published\non \\url{https://github.com/Wizardcoast/Linear_Alignment.git}.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.11459", "title": "AttentionLego: An Open-Source Building Block For Spatially-Scalable\n  Large Language Model Accelerator With Processing-In-Memory Technology", "abstract": "Large language models (LLMs) with Transformer architectures have become\nphenomenal in natural language processing, multimodal generative artificial\nintelligence, and agent-oriented artificial intelligence. The self-attention\nmodule is the most dominating sub-structure inside Transformer-based LLMs.\nComputation using general-purpose graphics processing units (GPUs) inflicts\nreckless demand for I/O bandwidth for transferring intermediate calculation\nresults between memories and processing units. To tackle this challenge, this\nwork develops a fully customized vanilla self-attention accelerator,\nAttentionLego, as the basic building block for constructing spatially\nexpandable LLM processors. AttentionLego provides basic implementation with\nfully-customized digital logic incorporating Processing-In-Memory (PIM)\ntechnology. It is based on PIM-based matrix-vector multiplication and look-up\ntable-based Softmax design. The open-source code is available online:\nhttps://bonany.cc/attentionleg.", "field": "Computer Science", "categories": "cs.AR,cs.AI,cs.LG"}, {"arxiv_id": "2401.11462", "title": "Frost Prediction Using Machine Learning Methods in Fars Province", "abstract": "One of the common hazards and issues in meteorology and agriculture is the\nproblem of frost, chilling or freezing. This event occurs when the minimum\nambient temperature falls below a certain value. This phenomenon causes a lot\nof damage to the country, especially Fars province. Solving this problem\nrequires that, in addition to predicting the minimum temperature, we can\nprovide enough time to implement the necessary measures. Empirical methods have\nbeen provided by the Food and Agriculture Organization (FAO), which can predict\nthe minimum temperature, but not in time. In addition to this, we can use\nmachine learning methods to model the minimum temperature. In this study, we\nhave used three methods Gated Recurrent Unit (GRU), Temporal Convolutional\nNetwork (TCN) as deep learning methods, and Gradient Boosting (XGBoost). A\ncustomized loss function designed for methods based on deep learning, which can\nbe effective in reducing prediction errors. With methods based on deep learning\nmodels, not only do we observe a reduction in RMSE error compared to empirical\nmethods but also have more time to predict minimum temperature. Thus, we can\nmodel the minimum temperature for the next 24 hours by having the current 24\nhours. With the gradient boosting model (XGBoost) we can keep the prediction\ntime as deep learning and RMSE error reduced. Finally, we experimentally\nconcluded that machine learning methods work better than empirical methods and\nXGBoost model can have better performance in this problem among other\nimplemented.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.11463", "title": "Estimating the Usefulness of Clarifying Questions and Answers for\n  Conversational Search", "abstract": "While the body of research directed towards constructing and generating\nclarifying questions in mixed-initiative conversational search systems is vast,\nresearch aimed at processing and comprehending users' answers to such questions\nis scarce. To this end, we present a simple yet effective method for processing\nanswers to clarifying questions, moving away from previous work that simply\nappends answers to the original query and thus potentially degrades retrieval\nperformance. Specifically, we propose a classifier for assessing usefulness of\nthe prompted clarifying question and an answer given by the user. Useful\nquestions or answers are further appended to the conversation history and\npassed to a transformer-based query rewriting module. Results demonstrate\nsignificant improvements over strong non-mixed-initiative baselines.\nFurthermore, the proposed approach mitigates the performance drops when non\nuseful questions and answers are utilized.", "field": "Computer Science", "categories": "cs.IR,cs.CL"}, {"arxiv_id": "2401.11467", "title": "Over-Reasoning and Redundant Calculation of Large Language Models", "abstract": "Large language models (LLMs) can solve problems step-by-step. While this\nchain-of-thought (CoT) reasoning boosts LLMs' performance, it is unclear if\nLLMs \\textit{know} when to use CoT and whether those CoT are always necessary\nto answer the question. This paper shows that LLMs tend to generate redundant\ncalculations and reasoning on a manually constructed math QA dataset,\nGSM8K-Zero. GSM8K-Zero is constructed such that the questions can be answered\nwithout any calculations, but LLMs, including Llama-2 models and Claude-2, tend\nto generate lengthy and unnecessary calculations to answer the questions. We\nalso conduct experiments to explain why LLMs generate redundant calculations\nand reasonings. GSM8K-Zero is publicly available at\nhttps://github.com/d223302/Over-Reasoning-of-LLMs and\nhttps://huggingface.co/datasets/dcml0714/GSM8K-Zero.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.11469", "title": "Accelerating Heterogeneous Tensor Parallelism via Flexible Workload\n  Control", "abstract": "Transformer-based models are becoming deeper and larger recently. For better\nscalability, an underlying training solution in industry is to split billions\nof parameters (tensors) into many tasks and then run them across homogeneous\naccelerators (e.g., GPUs). However, such dedicated compute cluster is\nprohibitively expensive in academia and moderate companies. An economic\nreplacement is to aggregate existing heterogeneous devices and share resources\namong multi-tenants. Nevertheless, static hardware configurations and dynamic\nresource contention definitely cause straggling tasks, which heavily slows down\nthe overall training efficiency. Existing works feature contributions mainly\ntailored for traditional data parallelism. They cannot work well for the new\ntensor parallelism due to strict communication and correctness constraints.\n  In this paper we first present ZERO-resizing, a novel dynamic workload\nbalancing technique without any data migration. We tune workloads in real-time\nby temporarily resizing matrices involved in core tensor-related computations.\nWe particularly design data imputation and priority selection policies to\nrespectively satisfy consistency constraint required by normal training and\nreduce the accuracy loss. We also give a lightweight data migration technique\nwithout loss of accuracy, to cope with heavy heterogeneity. Our final\nSEMI-migration solution is built on top of these two techniques and can\nadaptively distinguish their respective balancing missions, to achieve an\noverall success in efficiency and accuracy. Extensive experiments on the\nrepresentative Colossal-AI platform validate the effectiveness of our\nproposals.", "field": "Computer Science", "categories": "cs.DC"}, {"arxiv_id": "2401.1147", "title": "Exploring Missing Modality in Multimodal Egocentric Datasets", "abstract": "Multimodal video understanding is crucial for analyzing egocentric videos,\nwhere integrating multiple sensory signals significantly enhances action\nrecognition and moment localization. However, practical applications often\ngrapple with incomplete modalities due to factors like privacy concerns,\nefficiency demands, or hardware malfunctions. Addressing this, our study delves\ninto the impact of missing modalities on egocentric action recognition,\nparticularly within transformer-based models. We introduce a novel concept\n-Missing Modality Token (MMT)-to maintain performance even when modalities are\nabsent, a strategy that proves effective in the Ego4D, Epic-Kitchens, and\nEpic-Sounds datasets. Our method mitigates the performance loss, reducing it\nfrom its original $\\sim 30\\%$ drop to only $\\sim 10\\%$ when half of the test\nset is modal-incomplete. Through extensive experimentation, we demonstrate the\nadaptability of MMT to different training scenarios and its superiority in\nhandling missing modalities compared to current methods. Our research\ncontributes a comprehensive analysis and an innovative approach, opening\navenues for more resilient multimodal systems in real-world settings.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11471", "title": "LR-CNN: Lightweight Row-centric Convolutional Neural Network Training\n  for Memory Reduction", "abstract": "In the last decade, Convolutional Neural Network with a multi-layer\narchitecture has advanced rapidly. However, training its complex network is\nvery space-consuming, since a lot of intermediate data are preserved across\nlayers, especially when processing high-dimension inputs with a big batch size.\nThat poses great challenges to the limited memory capacity of current\naccelerators (e.g., GPUs). Existing efforts mitigate such bottleneck by\nexternal auxiliary solutions with additional hardware costs, and internal\nmodifications with potential accuracy penalty. Differently, our analysis\nreveals that computations intra- and inter-layers exhibit the spatial-temporal\nweak dependency and even complete independency features. That inspires us to\nbreak the traditional layer-by-layer (column) dataflow rule. Now operations are\nnovelly re-organized into rows throughout all convolution layers. This\nlightweight design allows a majority of intermediate data to be removed without\nany loss of accuracy. We particularly study the weak dependency between two\nconsecutive rows. For the resulting skewed memory consumption, we give two\nsolutions with different favorite scenarios. Evaluations on two representative\nnetworks confirm the effectiveness. We also validate that our middle dataflow\noptimization can be smoothly embraced by existing works for better memory\nreduction.", "field": "Computer Science", "categories": "cs.DC,cs.AI"}, {"arxiv_id": "2401.11472", "title": "Abstract Weighted Based Gradual Semantics in Argumentation Theory", "abstract": "Weighted gradual semantics provide an acceptability degree to each argument\nrepresenting the strength of the argument, computed based on factors including\nbackground evidence for the argument, and taking into account interactions\nbetween this argument and others. We introduce four important problems linking\ngradual semantics and acceptability degrees. First, we reexamine the inverse\nproblem, seeking to identify the argument weights of the argumentation\nframework which lead to a specific final acceptability degree. Second, we ask\nwhether the function mapping between argument weights and acceptability degrees\nis injective or a homeomorphism onto its image. Third, we ask whether argument\nweights can be found when preferences, rather than acceptability degrees for\narguments are considered. Fourth, we consider the topology of the space of\nvalid acceptability degrees, asking whether gaps exist in this space. While\ndifferent gradual semantics have been proposed in the literature, in this\npaper, we identify a large family of weighted gradual semantics, called\nabstract weighted based gradual semantics. These generalise many of the\nexisting semantics while maintaining desirable properties such as convergence\nto a unique fixed point. We also show that a sub-family of the weighted gradual\nsemantics, called abstract weighted (Lp,lambda,mu,A)-based gradual semantics\nand which include well-known semantics, solve all four of the aforementioned\nproblems.", "field": "Computer Science", "categories": "cs.AI"}, {"arxiv_id": "2401.11478", "title": "D2K: Turning Historical Data into Retrievable Knowledge for Recommender\n  Systems", "abstract": "A vast amount of user behavior data is constantly accumulating on today's\nlarge recommendation platforms, recording users' various interests and tastes.\nPreserving knowledge from the old data while new data continually arrives is a\nvital problem for recommender systems. Existing approaches generally seek to\nsave the knowledge implicitly in the model parameters. However, such a\nparameter-centric approach lacks scalability and flexibility -- the capacity is\nhard to scale, and the knowledge is inflexible to utilize. Hence, in this work,\nwe propose a framework that turns massive user behavior data to retrievable\nknowledge (D2K). It is a data-centric approach that is model-agnostic and easy\nto scale up. Different from only storing unary knowledge such as the user-side\nor item-side information, D2K propose to store ternary knowledge for\nrecommendation, which is determined by the complete recommendation factors --\nuser, item, and context. The knowledge retrieved by target samples can be\ndirectly used to enhance the performance of any recommendation algorithms.\nSpecifically, we introduce a Transformer-based knowledge encoder to transform\nthe old data into knowledge with the user-item-context cross features. A\npersonalized knowledge adaptation unit is devised to effectively exploit the\ninformation from the knowledge base by adapting the retrieved knowledge to the\ntarget samples. Extensive experiments on two public datasets show that D2K\nsignificantly outperforms existing baselines and is compatible with a major\ncollection of recommendation algorithms.", "field": "Computer Science", "categories": "cs.IR"}, {"arxiv_id": "2401.11483", "title": "Distributed Traffic Signal Control of Interconnected Intersections: A\n  Two-Lane Traffic Network Model", "abstract": "Practical and accurate traffic models play an important role in capturing\nreal traffic dynamics and then in achieving effective control performance. This\npaper studies traffic signal control in a traffic network with multiple\ninterconnected intersections, where the target is to balance the vehicle\ndensity on each lane by controlling the green times of each phase at every\nintersection. Different from traditional road-based modeling schemes, a\ntwo-lane intersection model is first proposed to model the flow propagation in\na more accurate way. A distributed model predictive control (MPC) method is\nthen presented to assign the green times. To enable the real-time feasibility\nof the proposed approach, the alternating direction method of multipliers\n(ADMM) is incorporated with the distributed MPC scheme for solving the problem.\nFinally, the simulation studies performed in VISSIM for a six-intersection\ntraffic network in Dalian, China, show the effectiveness and characteristics of\nthe proposed method.", "field": "Computer Science", "categories": "eess.SY,cs.SY,nlin.AO"}, {"arxiv_id": "2401.11485", "title": "ColorVideoVDP: A visual difference predictor for image, video and\n  display distortions", "abstract": "ColorVideoVDP is a video and image quality metric that models spatial and\ntemporal aspects of vision, for both luminance and color. The metric is built\non novel psychophysical models of chromatic spatiotemporal contrast sensitivity\nand cross-channel contrast masking. It accounts for the viewing conditions,\ngeometric, and photometric characteristics of the display. It was trained to\npredict common video streaming distortions (e.g. video compression, rescaling,\nand transmission errors), and also 8 new distortion types related to AR/VR\ndisplays (e.g. light source and waveguide non-uniformities). To address the\nlatter application, we collected our novel XR-Display-Artifact-Video quality\ndataset (XR-DAVID), comprised of 336 distorted videos. Extensive testing on\nXR-DAVID, as well as several datasets from the literature, indicate a\nsignificant gain in prediction performance compared to existing metrics.\nColorVideoVDP opens the doors to many novel applications which require the\njoint automated spatiotemporal assessment of luminance and color distortions,\nincluding video streaming, display specification and design, visual comparison\nof results, and perceptually-guided quality optimization.", "field": "Computer Science", "categories": "cs.CV,cs.GR,eess.IV"}, {"arxiv_id": "2401.11487", "title": "Towards Better Inclusivity: A Diverse Tweet Corpus of English Varieties", "abstract": "The prevalence of social media presents a growing opportunity to collect and\nanalyse examples of English varieties. Whilst usage of these varieties was -\nand, in many cases, still is - used only in spoken contexts or hard-to-access\nprivate messages, social media sites like Twitter provide a platform for users\nto communicate informally in a scrapeable format. Notably, Indian English\n(Hinglish), Singaporean English (Singlish), and African-American English (AAE)\ncan be commonly found online. These varieties pose a challenge to existing\nnatural language processing (NLP) tools as they often differ orthographically\nand syntactically from standard English for which the majority of these tools\nare built. NLP models trained on standard English texts produced biased\noutcomes for users of underrepresented varieties. Some research has aimed to\novercome the inherent biases caused by unrepresentative data through techniques\nlike data augmentation or adjusting training models.\n  We aim to address the issue of bias at its root - the data itself. We curate\na dataset of tweets from countries with high proportions of underserved English\nvariety speakers, and propose an annotation framework of six categorical\nclassifications along a pseudo-spectrum that measures the degree of standard\nEnglish and that thereby indirectly aims to surface the manifestations of\nEnglish varieties in these tweets. Following best annotation practices, our\ngrowing corpus features 170,800 tweets taken from 7 countries, labeled by\nannotators who are from those countries and can communicate in\nregionally-dominant varieties of English. Our corpus highlights the accuracy\ndiscrepancies in pre-trained language identifiers between western English and\nnon-western (i.e., less standard) English varieties. We hope to contribute to\nthe growing literature identifying and reducing the implicit demographic\ndiscrepancies in NLP.", "field": "Computer Science", "categories": "cs.CL,cs.CY"}, {"arxiv_id": "2401.11488", "title": "HARDCORE: H-field and power loss estimation for arbitrary waveforms with\n  residual, dilated convolutional neural networks in ferrite cores", "abstract": "The MagNet Challenge 2023 calls upon competitors to develop data-driven\nmodels for the material-specific, waveform-agnostic estimation of steady-state\npower losses in toroidal ferrite cores. The following HARDCORE (H-field and\npower loss estimation for Arbitrary waveforms with Residual, Dilated\nconvolutional neural networks in ferrite COREs) approach shows that a residual\nconvolutional neural network with physics-informed extensions can serve this\ntask efficiently when trained on observational data beforehand. One key\nsolution element is an intermediate model layer which first reconstructs the bh\ncurve and then estimates the power losses based on the curve's area rendering\nthe proposed topology physically interpretable. In addition, emphasis was\nplaced on expert-based feature engineering and information-rich inputs in order\nto enable a lean model architecture. A model is trained from scratch for each\nmaterial, while the topology remains the same. A Pareto-style trade-off between\nmodel size and estimation accuracy is demonstrated, which yields an optimum at\nas low as 1755 parameters and down to below 8\\,\\% for the 95-th percentile of\nthe relative error for the worst-case material with sufficient samples.", "field": "Computer Science", "categories": "eess.SY,cs.LG,cs.SY,physics.app-ph"}, {"arxiv_id": "2401.11489", "title": "MapChange: Enhancing Semantic Change Detection with Temporal-Invariant\n  Historical Maps Based on Deep Triplet Network", "abstract": "Semantic Change Detection (SCD) is recognized as both a crucial and\nchallenging task in the field of image analysis. Traditional methods for SCD\nhave predominantly relied on the comparison of image pairs. However, this\napproach is significantly hindered by substantial imaging differences, which\narise due to variations in shooting times, atmospheric conditions, and angles.\nSuch discrepancies lead to two primary issues: the under-detection of minor yet\nsignificant changes, and the generation of false alarms due to temporal\nvariances. These factors often result in unchanged objects appearing markedly\ndifferent in multi-temporal images. In response to these challenges, the\nMapChange framework has been developed. This framework introduces a novel\nparadigm that synergizes temporal-invariant historical map data with\ncontemporary high-resolution images. By employing this combination, the\ntemporal variance inherent in conventional image pair comparisons is\neffectively mitigated. The efficacy of the MapChange framework has been\nempirically validated through comprehensive testing on two public datasets.\nThese tests have demonstrated the framework's marked superiority over existing\nstate-of-the-art SCD methods.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.1149", "title": "Reliable Low-Delay Routing In Space with Routing-Oblivious LEO\n  Satellites", "abstract": "Large networks of Low Earth Orbit (LEO) satellites are being built using\ninter-satellite lasers. These networks promise to offer low-latency wide-area\nconnectivity, but reliably routing such traffic is difficult, as satellites are\nvery resource-constrained and paths change constantly.\n  We present STARGLIDER, a new routing system where path computation is\ndelegated to ground stations, while satellites are routing-oblivious and\nexchange no information at runtime. Yet, STARGLIDER satellites effectively\nsupport reliability primitives: they fast reroute packets over near-optimal\npaths when links fail, and validate that packets sent by potentially malicious\nground stations follow reasonable paths.", "field": "Computer Science", "categories": "cs.NI"}, {"arxiv_id": "2401.11491", "title": "BA-LINS: A Frame-to-Frame Bundle Adjustment for LiDAR-Inertial\n  Navigation", "abstract": "Bundle Adjustment (BA) has been proven to improve the accuracy of the LiDAR\nmapping. However, the BA method has not been properly employed in a\ndead-reckoning navigation system. In this paper, we present a frame-to-frame\n(F2F) BA for LiDAR-inertial navigation, named BA-LINS. Based on the direct F2F\npoint-cloud association, the same-plane points are associated among the LiDAR\nkeyframes. Hence, the plane-point BA measurement can be constructed using the\nsame-plane points. The LiDAR BA measurements and the inertial measurement unit\n(IMU)-preintegration measurements are tightly integrated under the framework of\nfactor graph optimization. An effective adaptive covariance estimation\nalgorithm for LiDAR BA measurements is proposed to further improve the accuracy\nof BA-LINS. We conduct exhaustive real-world experiments on public and private\ndatasets to examine the proposed BA-LINS. The results demonstrate that BA-LINS\nyields superior accuracy to state-of-the-art methods. Compared to the baseline\nsystem FF-LINS, the absolute translation accuracy and state-estimation\nefficiency of BA-LINS are improved by 29.5% and 28.7%, respectively, on the\nprivate dataset. Besides, the ablation experiment results exhibit that the\nproposed adaptive covariance estimation algorithm can notably improve the\naccuracy and robustness of BA-LINS.", "field": "Computer Science", "categories": "cs.RO"}, {"arxiv_id": "2401.11492", "title": "Edge-Enabled Real-time Railway Track Segmentation", "abstract": "Accurate and rapid railway track segmentation can assist automatic train\ndriving and is a key step in early warning to fixed or moving obstacles on the\nrailway track. However, certain existing algorithms tailored for track\nsegmentation often struggle to meet the requirements of real-time and\nefficiency on resource-constrained edge devices. Considering this challenge, we\npropose an edge-enabled real-time railway track segmentation algorithm, which\nis optimized to be suitable for edge applications by optimizing the network\nstructure and quantizing the model after training. Initially, Ghost convolution\nis introduced to reduce the complexity of the backbone, thereby achieving the\nextraction of key information of the interested region at a lower cost. To\nfurther reduce the model complexity and calculation, a new lightweight\ndetection head is proposed to achieve the best balance between accuracy and\nefficiency. Subsequently, we introduce quantization techniques to map the\nmodel's floating-point weights and activation values into lower bit-width\nfixed-point representations, reducing computational demands and memory\nfootprint, ultimately accelerating the model's inference. Finally, we draw\ninspiration from GPU parallel programming principles to expedite the\npre-processing and post-processing stages of the algorithm by doing parallel\nprocessing. The approach is evaluated with public and challenging dataset\nRailSem19 and tested on Jetson Nano. Experimental results demonstrate that our\nenhanced algorithm achieves an accuracy level of 83.3% while achieving a\nreal-time inference rate of 25 frames per second when the input size is\n480x480, thereby effectively meeting the requirements for real-time and\nhigh-efficiency operation.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11496", "title": "On a Group Under Which Symmetric Reed-Muller Codes are Invariant", "abstract": "The Reed-Muller codes are a family of error-correcting codes that have been\nwidely studied in coding theory. In 2020, Wei Yan and Sian-Jheng Lin introduced\na variant of Reed-Muller codes so called symmetric Reed-Muller codes. We\ninvestigate linear maps of the automorphism group of symmetric Reed-Muller\ncodes and show that the set of these linear maps forms a subgroup of the\ngeneral linear group, which is the automorphism group of punctured Reed-Muller\ncodes. We provide a method to determine all the automorphisms in this subgroup\nexplicitly for some special cases.", "field": "Computer Science", "categories": "cs.IT,math.IT,94B05, 11T71, 08A35, 11T06"}, {"arxiv_id": "2401.11499", "title": "Self-Supervised Bird's Eye View Motion Prediction with Cross-Modality\n  Signals", "abstract": "Learning the dense bird's eye view (BEV) motion flow in a self-supervised\nmanner is an emerging research for robotics and autonomous driving. Current\nself-supervised methods mainly rely on point correspondences between point\nclouds, which may introduce the problems of fake flow and inconsistency,\nhindering the model's ability to learn accurate and realistic motion. In this\npaper, we introduce a novel cross-modality self-supervised training framework\nthat effectively addresses these issues by leveraging multi-modality data to\nobtain supervision signals. We design three innovative supervision signals to\npreserve the inherent properties of scene motion, including the masked Chamfer\ndistance loss, the piecewise rigidity loss, and the temporal consistency loss.\nThrough extensive experiments, we demonstrate that our proposed self-supervised\nframework outperforms all previous self-supervision methods for the motion\nprediction task.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.115", "title": "Integration of Large Language Models in Control of EHD Pumps for Precise\n  Color Synthesis", "abstract": "This paper presents an innovative approach to integrating Large Language\nModels (LLMs) with Arduino-controlled Electrohydrodynamic (EHD) pumps for\nprecise color synthesis in automation systems. We propose a novel framework\nthat employs fine-tuned LLMs to interpret natural language commands and convert\nthem into specific operational instructions for EHD pump control. This approach\naims to enhance user interaction with complex hardware systems, making it more\nintuitive and efficient. The methodology involves four key steps: fine-tuning\nthe language model with a dataset of color specifications and corresponding\nArduino code, developing a natural language processing interface, translating\nuser inputs into executable Arduino code, and controlling EHD pumps for\naccurate color mixing. Conceptual experiment results, based on theoretical\nassumptions, indicate a high potential for accurate color synthesis, efficient\nlanguage model interpretation, and reliable EHD pump operation. This research\nextends the application of LLMs beyond text-based tasks, demonstrating their\npotential in industrial automation and control systems. While highlighting the\nlimitations and the need for real-world testing, this study opens new avenues\nfor AI applications in physical system control and sets a foundation for future\nadvancements in AI-driven automation technologies.", "field": "Computer Science", "categories": "cs.RO,cs.AI,cs.SY,eess.SY"}, {"arxiv_id": "2401.11504", "title": "With Greater Text Comes Greater Necessity: Inference-Time Training Helps\n  Long Text Generation", "abstract": "Long text generation, such as novel writing or discourse-level translation\nwith extremely long contexts, presents significant challenges to current\nlanguage models. Existing methods mainly focus on extending the model's context\nwindow through strategies like length extrapolation. However, these approaches\ndemand substantial hardware resources during the training and/or inference\nphases. Our proposed method, Temp-Lora, introduces an alternative concept.\nInstead of relying on the KV cache to store all context information, Temp-Lora\nembeds this information directly into the model's parameters. In the process of\nlong text generation, we use a temporary Lora module, progressively trained\nwith text generated previously. This approach not only efficiently preserves\ncontextual knowledge but also prevents any permanent alteration to the model's\nparameters given that the module is discarded post-generation. Extensive\nexperiments on the PG19 language modeling benchmark and the GuoFeng\ndiscourse-level translation benchmark validate the effectiveness of Temp-Lora.\nOur results show that: 1) Temp-Lora substantially enhances generation quality\nfor long texts, as indicated by a 13.2% decrease in perplexity on a subset of\nPG19, and a 29.6% decrease in perplexity along with a 53.2% increase in BLEU\nscore on GuoFeng, 2) Temp-Lora is compatible with and enhances most existing\nlong text generation methods, and 3) Temp-Lora can greatly reduce computational\ncosts by shortening the context window. While ensuring a slight improvement in\ngeneration quality (a decrease of 3.8% in PPL), it enables a reduction of 70.5%\nin the FLOPs required for inference and a 51.5% decrease in latency.", "field": "Computer Science", "categories": "cs.CL,cs.AI"}, {"arxiv_id": "2401.11505", "title": "CheX-GPT: Harnessing Large Language Models for Enhanced Chest X-ray\n  Report Labeling", "abstract": "Free-text radiology reports present a rich data source for various medical\ntasks, but effectively labeling these texts remains challenging. Traditional\nrule-based labeling methods fall short of capturing the nuances of diverse\nfree-text patterns. Moreover, models using expert-annotated data are limited by\ndata scarcity and pre-defined classes, impacting their performance, flexibility\nand scalability. To address these issues, our study offers three main\ncontributions: 1) We demonstrate the potential of GPT as an adept labeler using\ncarefully designed prompts. 2) Utilizing only the data labeled by GPT, we\ntrained a BERT-based labeler, CheX-GPT, which operates faster and more\nefficiently than its GPT counterpart. 3) To benchmark labeler performance, we\nintroduced a publicly available expert-annotated test set, MIMIC-500,\ncomprising 500 cases from the MIMIC validation set. Our findings demonstrate\nthat CheX-GPT not only excels in labeling accuracy over existing models, but\nalso showcases superior efficiency, flexibility, and scalability, supported by\nour introduction of the MIMIC-500 dataset for robust benchmarking. Code and\nmodels are available at https://github.com/kakaobrain/CheXGPT.", "field": "Computer Science", "categories": "cs.CL,cs.IR"}, {"arxiv_id": "2401.11506", "title": "Enhancing Recommendation Diversity by Re-ranking with Large Language\n  Models", "abstract": "It has long been recognized that it is not enough for a Recommender System\n(RS) to provide recommendations based only on their relevance to users. Among\nmany other criteria, the set of recommendations may need to be diverse in order\nto handle uncertainty and offer a meaningful choice. The literature reports\nmany ways of measuring diversity and ways of improving the diversity of a set\nof recommendations, most notably by re-ranking and selecting from a larger set\nof candidate recommendations. Driven by promising insights from the literature\non how to incorporate versatile Large Language Models (LLMs) into the RS\npipeline, in this paper, we show how LLMs can be used for diversity re-ranking.\n  We begin with an informal study that verifies that LLMs can be used for\nre-ranking tasks and do have some understanding of the concept of diversity.\nThen, we design a more rigorous methodology where LLMs are prompted to generate\na diverse ranking from a candidate ranking using various prompt templates with\ndifferent re-ranking instructions in a zero-shot fashion. We conduct\ncomprehensive experiments testing state-of-the-art conversational LLMs from the\nGPT and Llama families. We compare their re-ranking capabilities with random\nre-ranking and various traditional re-ranking methods from the literature (MMR,\nxQuAD and RxQuAD). We find that LLM-based re-ranking outperforms random\nre-ranking across all the metrics that we use but does not perform as well as\nthe traditional re-ranking methods. We gain insight into prompt design for this\ntask (e.g.\\ on the whole, it is better to prompt for diversity rather than a\nbalance of diversity and relevance). Given that no special knowledge\nengineering is needed, we conclude that LLM-based re-ranking is a promising\napproach, and we highlight directions for future research. We open-source the\ncode of our experiments for reproducibility.", "field": "Computer Science", "categories": "cs.IR,cs.LG"}, {"arxiv_id": "2401.11509", "title": "Simple Domain Adaptation for Sparse Retrievers", "abstract": "In Information Retrieval, and more generally in Natural Language Processing,\nadapting models to specific domains is conducted through fine-tuning. Despite\nthe successes achieved by this method and its versatility, the need for\nhuman-curated and labeled data makes it impractical to transfer to new tasks,\ndomains, and/or languages when training data doesn't exist. Using the model\nwithout training (zero-shot) is another option that however suffers an\neffectiveness cost, especially in the case of first-stage retrievers. Numerous\nresearch directions have emerged to tackle these issues, most of them in the\ncontext of adapting to a task or a language. However, the literature is scarcer\nfor domain (or topic) adaptation. In this paper, we address this issue of\ncross-topic discrepancy for a sparse first-stage retriever by transposing a\nmethod initially designed for language adaptation. By leveraging pre-training\non the target data to learn domain-specific knowledge, this technique\nalleviates the need for annotated data and expands the scope of domain\nadaptation. Despite their relatively good generalization ability, we show that\neven sparse retrievers can benefit from our simple domain adaptation method.", "field": "Computer Science", "categories": "cs.IR"}, {"arxiv_id": "2401.11511", "title": "MobileARLoc: On-device Robust Absolute Localisation for Pervasive\n  Markerless Mobile AR", "abstract": "Recent years have seen significant improvement in absolute camera pose\nestimation, paving the way for pervasive markerless Augmented Reality (AR).\nHowever, accurate absolute pose estimation techniques are computation- and\nstorage-heavy, requiring computation offloading. As such, AR systems rely on\nvisual-inertial odometry (VIO) to track the device's relative pose between\nrequests to the server. However, VIO suffers from drift, requiring frequent\nabsolute repositioning. This paper introduces MobileARLoc, a new framework for\non-device large-scale markerless mobile AR that combines an absolute pose\nregressor (APR) with a local VIO tracking system. Absolute pose regressors\n(APRs) provide fast on-device pose estimation at the cost of reduced accuracy.\nTo address APR accuracy and reduce VIO drift, MobileARLoc creates a feedback\nloop where VIO pose estimations refine the APR predictions. The VIO system\nidentifies reliable predictions of APR, which are then used to compensate for\nthe VIO drift. We comprehensively evaluate MobileARLoc through dataset\nsimulations. MobileARLoc halves the error compared to the underlying APR and\nachieve fast (80\\,ms) on-device inference speed.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11512", "title": "Information-Theoretic State Variable Selection for Reinforcement\n  Learning", "abstract": "Identifying the most suitable variables to represent the state is a\nfundamental challenge in Reinforcement Learning (RL). These variables must\nefficiently capture the information necessary for making optimal decisions. In\norder to address this problem, in this paper, we introduce the Transfer Entropy\nRedundancy Criterion (TERC), an information-theoretic criterion, which\ndetermines if there is \\textit{entropy transferred} from state variables to\nactions during training. We define an algorithm based on TERC that provably\nexcludes variables from the state that have no effect on the final performance\nof the agent, resulting in more sample efficient learning. Experimental results\nshow that this speed-up is present across three different algorithm classes\n(represented by tabular Q-learning, Actor-Critic, and Proximal Policy\nOptimization (PPO)) in a variety of environments. Furthermore, to highlight the\ndifferences between the proposed methodology and the current state-of-the-art\nfeature selection approaches, we present a series of controlled experiments on\nsynthetic data, before generalizing to real-world decision-making tasks. We\nalso introduce a representation of the problem that compactly captures the\ntransfer of information from state variables to actions as Bayesian networks.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.IT,math.IT"}, {"arxiv_id": "2401.11519", "title": "CaBuAr: California Burned Areas dataset for delineation", "abstract": "Forest wildfires represent one of the catastrophic events that, over the last\ndecades, caused huge environmental and humanitarian damages. In addition to a\nsignificant amount of carbon dioxide emission, they are a source of risk to\nsociety in both short-term (e.g., temporary city evacuation due to fire) and\nlong-term (e.g., higher risks of landslides) cases. Consequently, the\navailability of tools to support local authorities in automatically identifying\nburned areas plays an important role in the continuous monitoring requirement\nto alleviate the aftereffects of such catastrophic events. The great\navailability of satellite acquisitions coupled with computer vision techniques\nrepresents an important step in developing such tools. This paper introduces a\nnovel open dataset that tackles the burned area delineation problem, a binary\nsegmentation problem applied to satellite imagery. The presented resource\nconsists of pre- and post-fire Sentinel-2 L2A acquisitions of California forest\nfires that took place starting in 2015. Raster annotations were generated from\nthe data released by California's Department of Forestry and Fire Protection.\nMoreover, in conjunction with the dataset, we release three different baselines\nbased on spectral indexes analyses, SegFormer, and U-Net models.", "field": "Computer Science", "categories": "cs.CV,cs.LG,eess.IV"}, {"arxiv_id": "2401.1152", "title": "Is it a Real CD Mismatch in Interdomain Routing?", "abstract": "In inter-domain routing, a packet is not always forwarded along the\nAutonomous System (AS) level path determined by the BGP routing protocol. This\nis often called control-plane and data-plane (CD) mismatch, which allows for\nflexible traffic control, but also leads to operation and security issues. We\nsystematically analyze this phenomenon with path pairs collected from 128 pairs\nof vantage points over more than 5 years, and use multiple IP-to-AS mapping\nmethods to compare CD paths. What is interesting is that, working at such a\nlarge scale in turn helps us design a novel method to fairly evaluate the\naccuracy of various existing mapping methods, and further develop a new mapping\nmethod, i.e., LearnToCorrect, that can correct more than 70\\% mapping errors of\nthe state-of-the-art one. Then we devise to identify real mismatches with\nLearnToCorrect, and estimate that the real-mismatch ratio in the wild is\ntypically less than 6\\%. At last, we use our proposed methods to detect routing\nsecurity issues, which are previously difficult to accurately find out.", "field": "Computer Science", "categories": "cs.NI"}, {"arxiv_id": "2401.11524", "title": "Controlling the Misinformation Diffusion in Social Media by the Effect\n  of Different Classes of Agents", "abstract": "The rapid and widespread dissemination of misinformation through social\nnetworks is a growing concern in today's digital age. This study focused on\nmodeling fake news diffusion, discovering the spreading dynamics, and designing\ncontrol strategies. A common approach for modeling the misinformation dynamics\nis SIR-based models. Our approach is an extension of a model called 'SBFC'\nwhich is a SIR-based model. This model has three states, Susceptible, Believer,\nand Fact-Checker. The dynamics and transition between states are based on\nneighbors' beliefs, hoax credibility, spreading rate, probability of verifying\nthe news, and probability of forgetting the current state. Our contribution is\nto push this model to real social networks by considering different classes of\nagents with their characteristics. We proposed two main strategies for\nconfronting misinformation diffusion. First, we can educate a minor class, like\nscholars or influencers, to improve their ability to verify the news or\nremember their state longer. The second strategy is adding fact-checker bots to\nthe network to spread the facts and influence their neighbors' states. Our\nresult shows that both of these approaches can effectively control the\nmisinformation spread.", "field": "Computer Science", "categories": "cs.MA,cs.SI"}, {"arxiv_id": "2401.11529", "title": "Computational predictions of weld structural integrity in hydrogen\n  transport pipelines", "abstract": "We combine welding process modelling with deformation-diffusion-fracture\n(embrittlement) simulations to predict failures in hydrogen transport\npipelines. The focus is on the structural integrity of seam welds, as these are\noften the locations most susceptible to damage in gas transport infrastructure.\nFinite element analyses are conducted to showcase the ability of the model to\npredict cracking in pipeline steels exposed to hydrogen-containing\nenvironments. The validated model is then employed to quantify critical H$_2$\nfracture pressures. The coupled, phase field-based simulations conducted\nprovide insight into the role of existing defects, microstructural\nheterogeneity, and residual stresses. We find that under a combination of\ndeleterious yet realistic conditions, the critical pressure at which fracture\ntakes place can be as low as 15 MPa. These results bring new mechanistic\ninsight into the viability of using the existing natural gas pipeline network\nto transport hydrogen, and the computational framework presented enables\nmapping the conditions under which this can be achieved safely.", "field": "Computer Science", "categories": "cs.CE,cond-mat.mtrl-sci,physics.app-ph,physics.chem-ph"}, {"arxiv_id": "2401.11531", "title": "Tempo: Confidentiality Preservation in Cloud-Based Neural Network\n  Training", "abstract": "Cloud deep learning platforms provide cost-effective deep neural network\n(DNN) training for customers who lack computation resources. However, cloud\nsystems are often untrustworthy and vulnerable to attackers, leading to growing\nconcerns about model privacy. Recently, researchers have sought to protect data\nprivacy in deep learning by leveraging CPU trusted execution environments\n(TEEs), which minimize the use of cryptography, but existing works failed to\nsimultaneously utilize the computational resources of GPUs to assist in\ntraining and prevent model leakage. This paper presents Tempo, the first\ncloud-based deep learning system that cooperates with TEE and distributed GPUs\nfor efficient DNN training with model confidentiality preserved. To tackle the\nchallenge of preserving privacy while offloading linear algebraic operations\nfrom TEE to GPUs for efficient batch computation, we introduce a customized\npermutation-based obfuscation algorithm to blind both inputs and model\nparameters. An optimization mechanism that reduces encryption operations is\nproposed for faster weight updates during backpropagation to speed up training.\nWe implement Tempo and evaluate it with both training and inference for two\nprevalent DNNs. Empirical results indicate that Tempo outperforms baselines and\noffers sufficient privacy protection.", "field": "Computer Science", "categories": "cs.CR,cs.LG"}, {"arxiv_id": "2401.11533", "title": "Pulse Width Modulation Method Applied to Nonlinear Model Predictive\n  Control on an Under-actuated Small Satellite", "abstract": "Among various satellite actuators, magnetic torquers have been widely\nequipped for stabilization and attitude control of small satellites. Although\nmagnetorquers are generally used with other actuators, such as momentum wheels,\nthis paper explores a control method where only a magnetic actuation is\navailable. We applied a nonlinear optimal control method, Nonlinear Model\nPredictive Control (NMPC), to small satellites, employing the generalized\nminimal residual (GMRES) method, which generates continuous control inputs.\nOnboard magnetic actuation systems often find it challenging to produce smooth\nmagnetic moments as a control input; hence, we employ the Pulse Width\nModulation (PWM) method, which discretizes a control input and reduces the\nburden on actuators. In our case, the PWM approach discretizes control torques\ngenerated by the NMPC scheme. This study's main contributions are investigating\nthe NMPC and the GMRES method applied to small spacecraft and presenting the\nPWM control system's feasibility.", "field": "Computer Science", "categories": "eess.SY,cs.SY"}, {"arxiv_id": "2401.11535", "title": "Deformable Endoscopic Tissues Reconstruction with Gaussian Splatting", "abstract": "Surgical 3D reconstruction is a critical area of research in robotic surgery,\nwith recent works adopting variants of dynamic radiance fields to achieve\nsuccess in 3D reconstruction of deformable tissues from single-viewpoint\nvideos. However, these methods often suffer from time-consuming optimization or\ninferior quality, limiting their adoption in downstream tasks. Inspired by 3D\nGaussian Splatting, a recent trending 3D representation, we present EndoGS,\napplying Gaussian Splatting for deformable endoscopic tissue reconstruction.\nSpecifically, our approach incorporates deformation fields to handle dynamic\nscenes, depth-guided supervision to optimize 3D targets with a single\nviewpoint, and a spatial-temporal weight mask to mitigate tool occlusion. As a\nresult, EndoGS reconstructs and renders high-quality deformable endoscopic\ntissues from a single-viewpoint video, estimated depth maps, and labeled tool\nmasks. Experiments on DaVinci robotic surgery videos demonstrate that EndoGS\nachieves superior rendering quality. Code is available at\nhttps://github.com/HKU-MedAI/EndoGS.", "field": "Computer Science", "categories": "cs.CV,cs.RO"}, {"arxiv_id": "2401.11536", "title": "Nonlinear Model Predictive Detumbling of Small Satellites with a\n  Single-axis Magnetorquer", "abstract": "Various actuators are used in spacecraft to achieve attitude stabilization,\nincluding thrusters, momentum wheels, and control moment gyros. Small\nsatellites, however, have stringent size, weight, and cost constraints, which\nmakes many actuator choices prohibitive. Consequently, magnetic torquers have\ncommonly been applied to spacecraft to attenuate angular rates. Approaches for\ndealing with under-actuation due to magnetic control torque's dependency on the\nmagnetic field and required high magnetic flux densities have been previously\nconsidered. Generally speaking, control of a satellite that becomes\nunder-actuated as a result of on-board failures has been a recurrent theme in\nthe literature. Methods for controlling spacecraft with fewer actuators than\ndegrees of freedom are increasingly in demand due to the increased number of\nsmall satellite launches. Magnetic torquers have been extensively investigated\nfor momentum management of spacecraft with momentum wheels and for nutation\ndamping of spin satellites, momentum-biased, and dual-spin satellites.\nNonetheless, severely under-actuated small spacecraft that carry only a\nsingle-axis magnetic torquer have not been previously treated. This note\nconsiders the detumbling of a small spacecraft using only a single-axis\nmagnetic torquer. Even with a three-axis magnetic torquer, the spacecraft is\nunder-actuated, while, in the case of only a single axis magnetic torquer, the\nproblem is considerably more demanding. Our note examines the feasibility of\nspacecraft attitude control with a single-axis magnetic torquer and possible\ncontrol methods that can be used.", "field": "Computer Science", "categories": "eess.SY,cs.SY"}, {"arxiv_id": "2401.11538", "title": "Maintenance cost assessment for heterogeneous multi-component systems\n  incorporating perfect inspections and waiting time to maintenance", "abstract": "Most existing research about complex systems maintenance assumes they consist\nof the same type of components. However, systems can be assembled with\nheterogeneous components (for example degrading and non-degrading components)\nthat require different maintenance actions. Since industrial systems become\nmore and more complex, more research about the maintenance of systems with\nheterogeneous components is needed. For this reason, in this paper, a system\nconsisting of two groups of components: degrading and non-degrading components\nis analyzed. The main novelty of this paper is the evaluation of a maintenance\npolicy at system-level coordinating condition-based maintenance for the\ndegrading components, delay time to the maintenance and an inspection strategy\nfor this heterogeneous system. To that end, an analytic cost model is built\nusing the semi-regenerative processes theory. Furthermore, a safety constraint\nrelated to the reliability of the degrading components is imposed. To find the\noptimal maintenance strategy, meta-heuristic algorithms are used.", "field": "Computer Science", "categories": "cs.SY,math.PR"}, {"arxiv_id": "2401.11539", "title": "Model Predictive Approach for Detumbling an Underactuated Satellite", "abstract": "This research proposes an innovative approach to detumble satellites'\ntriple-axis angular velocities with only one single-axis magnetic torquer.\nSince magnetic torque is generated perpendicularly to magnetorquers, no\nintended control torque along the magnetorquer can be produced, which makes\nsystems underactuated. Our paper introduces a control method using Model\nPredictive Control (MPC) and compares it with B-dot control algorithm. By\napplying these control laws to Kyushu University Light Curve Inversion (Q-Li)\nDemonstration Satellite in numerical simulations, we describe the applicability\nof these control laws to underactuated systems.", "field": "Computer Science", "categories": "eess.SY,cs.SY"}, {"arxiv_id": "2401.11541", "title": "Multi-View Neural 3D Reconstruction of Micro-/Nanostructures with Atomic\n  Force Microscopy", "abstract": "Atomic Force Microscopy (AFM) is a widely employed tool for micro-/nanoscale\ntopographic imaging. However, conventional AFM scanning struggles to\nreconstruct complex 3D micro-/nanostructures precisely due to limitations such\nas incomplete sample topography capturing and tip-sample convolution artifacts.\nHere, we propose a multi-view neural-network-based framework with AFM\n(MVN-AFM), which accurately reconstructs surface models of intricate\nmicro-/nanostructures. Unlike previous works, MVN-AFM does not depend on any\nspecially shaped probes or costly modifications to the AFM system. To achieve\nthis, MVN-AFM uniquely employs an iterative method to align multi-view data and\neliminate AFM artifacts simultaneously. Furthermore, we pioneer the application\nof neural implicit surface reconstruction in nanotechnology and achieve\nmarkedly improved results. Extensive experiments show that MVN-AFM effectively\neliminates artifacts present in raw AFM images and reconstructs various\nmicro-/nanostructures including complex geometrical microstructures printed via\nTwo-photon Lithography and nanoparticles such as PMMA nanospheres and ZIF-67\nnanocrystals. This work presents a cost-effective tool for micro-/nanoscale 3D\nanalysis.", "field": "Computer Science", "categories": "cs.CV,cond-mat.mtrl-sci"}, {"arxiv_id": "2401.11542", "title": "Nigel -- Mechatronic Design and Robust Sim2Real Control of an\n  Over-Actuated Autonomous Vehicle", "abstract": "Simulation to reality (sim2real) transfer from a dynamics and controls\nperspective usually involves re-tuning or adapting the designed algorithms to\nsuit real-world operating conditions, which often violates the performance\nguarantees established originally. This work presents a generalizable framework\nfor achieving reliable sim2real transfer of autonomy-oriented control systems\nusing multi-model multi-objective robust optimal control synthesis, which lends\nwell to uncertainty handling and disturbance rejection with theoretical\nguarantees. Particularly, this work is centered around an actuation-redundant\nscaled autonomous vehicle called Nigel, with independent all-wheel drive and\nindependent all-wheel steering architecture, whose enhanced configuration space\nbodes well for robust control applications. To this end, we present a\nsystematic study on the complete mechatronic design, dynamics modeling,\nparameter identification, and robust stabilizing as well as steady-state\ntracking control of Nigel using the proposed framework, with experimental\nvalidation.", "field": "Computer Science", "categories": "cs.RO,cs.SY,eess.SY"}, {"arxiv_id": "2401.11543", "title": "How Robust Are Energy-Based Models Trained With Equilibrium Propagation?", "abstract": "Deep neural networks (DNNs) are easily fooled by adversarial perturbations\nthat are imperceptible to humans. Adversarial training, a process where\nadversarial examples are added to the training set, is the current\nstate-of-the-art defense against adversarial attacks, but it lowers the model's\naccuracy on clean inputs, is computationally expensive, and offers less\nrobustness to natural noise. In contrast, energy-based models (EBMs), which\nwere designed for efficient implementation in neuromorphic hardware and\nphysical systems, incorporate feedback connections from each layer to the\nprevious layer, yielding a recurrent, deep-attractor architecture which we\nhypothesize should make them naturally robust. Our work is the first to explore\nthe robustness of EBMs to both natural corruptions and adversarial attacks,\nwhich we do using the CIFAR-10 and CIFAR-100 datasets. We demonstrate that EBMs\nare more robust than transformers and display comparable robustness to\nadversarially-trained DNNs on gradient-based (white-box) attacks, query-based\n(black-box) attacks, and natural perturbations without sacrificing clean\naccuracy, and without the need for adversarial training or additional training\ntechniques.", "field": "Computer Science", "categories": "cs.LG,cs.CV"}, {"arxiv_id": "2401.11544", "title": "Hierarchical Prompts for Rehearsal-free Continual Learning", "abstract": "Continual learning endeavors to equip the model with the capability to\nintegrate current task knowledge while mitigating the forgetting of past task\nknowledge. Inspired by prompt tuning, prompt-based methods maintain a frozen\nbackbone and train with slight learnable prompts to minimize the catastrophic\nforgetting that arises due to updating a large number of backbone parameters.\nNonetheless, these learnable prompts tend to concentrate on the discriminatory\nknowledge of the current task while ignoring past task knowledge, leading to\nthat learnable prompts still suffering from catastrophic forgetting. This paper\nintroduces a novel rehearsal-free paradigm for continual learning termed\nHierarchical Prompts (H-Prompts), comprising three categories of prompts --\nclass prompt, task prompt, and general prompt. To effectively depict the\nknowledge of past classes, class prompt leverages Bayesian Distribution\nAlignment to model the distribution of classes in each task. To reduce the\nforgetting of past task knowledge, task prompt employs Cross-task Knowledge\nExcavation to amalgamate the knowledge encapsulated in the learned class\nprompts of past tasks and current task knowledge. Furthermore, general prompt\nutilizes Generalized Knowledge Exploration to deduce highly generalized\nknowledge in a self-supervised manner. Evaluations on two benchmarks\nsubstantiate the efficacy of the proposed H-Prompts, exemplified by an average\naccuracy of 87.8% in Split CIFAR-100 and 70.6% in Split ImageNet-R.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11547", "title": "Understanding the Security Risks of Decentralized Exchanges by\n  Uncovering Unfair Trades in the Wild", "abstract": "DEX, or decentralized exchange, is a prominent class of decentralized finance\n(DeFi) applications on blockchains, attracting a total locked value worth tens\nof billions of USD today.\n  This paper presents the first large-scale empirical study that uncovers\nunfair trades on popular DEX services on Ethereum and Binance Smart Chain\n(BSC). By joining and analyzing 60 million transactions, we find 671,400 unfair\ntrades on all six measured DEXes, including Uniswap, Balancer, and Curve. Out\nof these unfair trades, we attribute 55,000 instances, with high confidence, to\ntoken thefts that cause a value loss of more than 3.88 million USD.\nFurthermore, the measurement study uncovers previously unknown causes of\nextractable value and real-world adaptive strategies to these causes. Finally,\nwe propose countermeasures to redesign secure DEX protocols and to harden\ndeployed services against the discovered security risks.", "field": "Computer Science", "categories": "cs.CR"}, {"arxiv_id": "2401.11553", "title": "Taxi dispatching strategies with compensations", "abstract": "Urban mobility efficiency is of utmost importance in big cities. Taxi\nvehicles are key elements in daily traffic activity. The advance of ICT and\ngeo-positioning systems has given rise to new opportunities for improving the\nefficiency of taxi fleets in terms of waiting times of passengers, cost and\ntime for drivers, traffic density, CO2 emissions, etc., by using more informed,\nintelligent dispatching. Still, the explicit spatial and temporal components,\nas well as the scale and, in particular, the dynamicity of the problem of\npairing passengers and taxis in big towns, render traditional approaches for\nsolving standard assignment problem useless for this purpose, and call for\nintelligent approximation strategies based on domain-specific heuristics.\nFurthermore, taxi drivers are often autonomous actors and may not agree to\nparticipate in assignments that, though globally efficient, may not be\nsufficently beneficial for them individually. This paper presents a new\nheuristic algorithm for taxi assignment to customers that considers taxi\nreassignments if this may lead to globally better solutions. In addition, as\nsuch new assignments may reduce the expected revenues of individual drivers, we\npropose an economic compensation scheme to make individually rational drivers\nagree to proposed modifications in their assigned clients. We carried out a set\nof experiments, where several commonly used assignment strategies are compared\nto three different instantiations of our heuristic algorithm. The results\nindicate that our proposal has the potential to reduce customer waiting times\nin fleets of autonomous taxis, while being also beneficial from an economic\npoint of view.", "field": "Computer Science", "categories": "cs.AI,I.2.1"}, {"arxiv_id": "2401.11563", "title": "Distributed Multi-Task Learning for Stochastic Bandits with Context\n  Distribution and Stage-wise Constraints", "abstract": "We present the problem of conservative distributed multi-task learning in\nstochastic linear contextual bandits with heterogeneous agents. This extends\nconservative linear bandits to a distributed setting where M agents tackle\ndifferent but related tasks while adhering to stage-wise performance\nconstraints. The exact context is unknown, and only a context distribution is\navailable to the agents as in many practical applications that involve a\nprediction mechanism to infer context, such as stock market prediction and\nweather forecast. We propose a distributed upper confidence bound (UCB)\nalgorithm, DiSC-UCB. Our algorithm constructs a pruned action set during each\nround to ensure the constraints are met. Additionally, it includes synchronized\nsharing of estimates among agents via a central server using well-structured\nsynchronization steps. We prove the regret and communication bounds on the\nalgorithm. We extend the problem to a setting where the agents are unaware of\nthe baseline reward. For this setting, we provide a modified algorithm,\nDiSC-UCB2, and we show that the modified algorithm achieves the same regret and\ncommunication bounds. We empirically validated the performance of our algorithm\non synthetic data and real-world Movielens-100K data.", "field": "Computer Science", "categories": "cs.LG,cs.MA"}, {"arxiv_id": "2401.11565", "title": "Thompson Sampling for Stochastic Bandits with Noisy Contexts: An\n  Information-Theoretic Regret Analysis", "abstract": "We explore a stochastic contextual linear bandit problem where the agent\nobserves a noisy, corrupted version of the true context through a noise channel\nwith an unknown noise parameter. Our objective is to design an action policy\nthat can approximate\" that of an oracle, which has access to the reward model,\nthe channel parameter, and the predictive distribution of the true context from\nthe observed noisy context. In a Bayesian framework, we introduce a Thompson\nsampling algorithm for Gaussian bandits with Gaussian context noise. Adopting\nan information-theoretic analysis, we demonstrate the Bayesian regret of our\nalgorithm concerning the oracle's action policy. We also extend this problem to\na scenario where the agent observes the true context with some delay after\nreceiving the reward and show that delayed true contexts lead to lower Bayesian\nregret. Finally, we empirically demonstrate the performance of the proposed\nalgorithms against baselines.", "field": "Computer Science", "categories": "cs.LG,stat.ML"}, {"arxiv_id": "2401.1158", "title": "Age of Gossip in Random and Bipartite Networks", "abstract": "In this paper we study gossip networks where a source observing a process\nsends updates to an underlying graph. Nodes in the graph communicate to their\nneighbors by randomly sending updates. Our interest is studying the version age\nof information (vAoI) metric over various classes of networks. It is known that\nthe version age of $K_n$ is logarithmic, and the version age of\n$\\overline{K_n}$ is linear. We study the question `how does the vAoI evolve as\nwe interpolate between $K_n$ and $\\overline{K_n}$' by studying Erd\\H{o}s-Reyni\nrandom graphs, random $d$-regular graphs, and bipartite networks. Our main\nresults are proving the existence of a threshold in $G(n,p)$ from rational to\nlogarithmic average version age, and showing $G(n,d)$ almost surely has\nlogarithmic version age for constant $d$. We also characterize the version age\nof complete bipartite graphs $K_{L,R}$, when we let $L$ vary from $O(1)$ to\n$O(n)$.", "field": "Computer Science", "categories": "cs.IT,math.CO,math.IT"}, {"arxiv_id": "2401.11582", "title": "Thermal Image Calibration and Correction using Unpaired Cycle-Consistent\n  Adversarial Networks", "abstract": "Unmanned aerial vehicles (UAVs) offer a flexible and cost-effective solution\nfor wildfire monitoring. However, their widespread deployment during wildfires\nhas been hindered by a lack of operational guidelines and concerns about\npotential interference with aircraft systems. Consequently, the progress in\ndeveloping deep-learning models for wildfire detection and characterization\nusing aerial images is constrained by the limited availability, size, and\nquality of existing datasets. This paper introduces a solution aimed at\nenhancing the quality of current aerial wildfire datasets to align with\nadvancements in camera technology. The proposed approach offers a solution to\ncreate a comprehensive, standardized large-scale image dataset. This paper\npresents a pipeline based on CycleGAN to enhance wildfire datasets and a novel\nfusion method that integrates paired RGB images as attribute conditioning in\nthe generators of both directions, improving the accuracy of the generated\nimages.", "field": "Computer Science", "categories": "cs.CV,cs.LG,eess.IV"}, {"arxiv_id": "2401.1159", "title": "Small Even Covers, Locally Decodable Codes and Restricted Subgraphs of\n  Edge-Colored Kikuchi Graphs", "abstract": "Given a $k$-uniform hypergraph $H$ on $n$ vertices, an even cover in $H$ is a\ncollection of hyperedges that touch each vertex an even number of times. Even\ncovers are a generalization of cycles in graphs and are equivalent to linearly\ndependent subsets of a system of linear equations modulo $2$. As a result, they\narise naturally in the context of well-studied questions in coding theory and\nrefuting unsatisfiable $k$-SAT formulas. Analogous to the irregular Moore bound\nof Alon, Hoory, and Linial (2002), in 2008, Feige conjectured an extremal\ntrade-off between the number of hyperedges and the length of the smallest even\ncover in a $k$-uniform hypergraph. This conjecture was recently settled up to a\nmultiplicative logarithmic factor in the number of hyperedges (Guruswami,\nKothari, and 1Manohar 2022 and Hsieh, Kothari, and Mohanty 2023). These works\nintroduce the new technique that relates hypergraph even covers to cycles in\nthe associated \\emph{Kikuchi} graphs. Their analysis of these Kikuchi graphs,\nespecially for odd $k$, is rather involved and relies on matrix concentration\ninequalities.\n  In this work, we give a simple and purely combinatorial argument that\nrecovers the best-known bound for Feige's conjecture for even $k$. We also\nintroduce a novel variant of a Kikuchi graph which together with this argument\nimproves the logarithmic factor in the best-known bounds for odd $k$. As an\napplication of our ideas, we also give a purely combinatorial proof of the\nimproved lower bounds (Alrabiah, Guruswami, Kothari and Manohar, 2023) on\n3-query binary linear locally decodable codes.", "field": "Computer Science", "categories": "cs.CC,math.CO"}, {"arxiv_id": "2401.11592", "title": "Differential Privacy in Hierarchical Federated Learning: A Formal\n  Analysis and Evaluation", "abstract": "While federated learning (FL) eliminates the transmission of raw data over a\nnetwork, it is still vulnerable to privacy breaches from the communicated model\nparameters. In this work, we formalize Differentially Private Hierarchical\nFederated Learning (DP-HFL), a DP-enhanced FL methodology that seeks to improve\nthe privacy-utility tradeoff inherent in FL. Building upon recent proposals for\nHierarchical Differential Privacy (HDP), one of the key concepts of DP-HFL is\nadapting DP noise injection at different layers of an established FL hierarchy\n-- edge devices, edge servers, and cloud servers -- according to the trust\nmodels within particular subnetworks. We conduct a comprehensive analysis of\nthe convergence behavior of DP-HFL, revealing conditions on parameter tuning\nunder which the model training process converges sublinearly to a stationarity\ngap, with this gap depending on the network hierarchy, trust model, and target\nprivacy level. Subsequent numerical evaluations demonstrate that DP-HFL obtains\nsubstantial improvements in convergence speed over baselines for different\nprivacy budgets, and validate the impact of network configuration on training.", "field": "Computer Science", "categories": "cs.LG,cs.CR,cs.DC"}, {"arxiv_id": "2401.11596", "title": "Learning to Maximize Gains From Trade in Small Markets", "abstract": "We study the problem of designing a two-sided market (double auction) to\nmaximize the gains from trade (social welfare) under the constraints of\n(dominant-strategy) incentive compatibility and budget-balance. Our goal is to\ndo so for an unknown distribution from which we are given a polynomial number\nof samples. Our first result is a general impossibility for the case of\ncorrelated distributions of values even between just one seller and two buyers,\nin contrast to the case of one seller and one buyer (bilateral trade) where\nthis is possible. Our second result is an efficient learning algorithm for one\nseller and two buyers in the case of independent distributions which is based\non a novel algorithm for computing optimal mechanisms for finitely supported\nand explicitly given independent distributions. Both results rely heavily on\ncharacterizations of (dominant-strategy) incentive compatible mechanisms that\nare strongly budget-balanced.", "field": "Computer Science", "categories": "cs.GT,cs.AI,cs.LG,F.0; I.2; I.2.6; J.4"}, {"arxiv_id": "2401.11598", "title": "TetraLoss: Improving the Robustness of Face Recognition against Morphing\n  Attacks", "abstract": "Face recognition systems are widely deployed in high-security applications\nsuch as for biometric verification at border controls. Despite their high\naccuracy on pristine data, it is well-known that digital manipulations, such as\nface morphing, pose a security threat to face recognition systems. Malicious\nactors can exploit the facilities offered by the identity document issuance\nprocess to obtain identity documents containing morphed images. Thus, subjects\nwho contributed to the creation of the morphed image can with high probability\nuse the identity document to bypass automated face recognition systems. In\nrecent years, no-reference (i.e., single image) and differential morphing\nattack detectors have been proposed to tackle this risk. These systems are\ntypically evaluated in isolation from the face recognition system that they\nhave to operate jointly with and do not consider the face recognition process.\nContrary to most existing works, we present a novel method for adapting deep\nlearning-based face recognition systems to be more robust against face morphing\nattacks. To this end, we introduce TetraLoss, a novel loss function that learns\nto separate morphed face images from its contributing subjects in the embedding\nspace while still preserving high biometric verification performance. In a\ncomprehensive evaluation, we show that the proposed method can significantly\nenhance the original system while also significantly outperforming other tested\nbaseline methods.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11599", "title": "Reducing Usefulness of Stolen Credentials in SSO Contexts", "abstract": "Approximately 61% of cyber attacks involve adversaries in possession of valid\ncredentials. Attackers acquire credentials through various means, including\nphishing, dark web data drops, password reuse, etc. Multi-factor authentication\n(MFA) helps to thwart attacks that use valid credentials, but attackers still\ncommonly breach systems by tricking users into accepting MFA step up requests\nthrough techniques, such as ``MFA Bombing'', where multiple requests are sent\nto a user until they accept one. Currently, there are several solutions to this\nproblem, each with varying levels of security and increasing invasiveness on\nuser devices. This paper proposes a token-based enrollment architecture that is\nless invasive to user devices than mobile device management, but still offers\nstrong protection against use of stolen credentials and MFA attacks.", "field": "Computer Science", "categories": "cs.CR"}, {"arxiv_id": "2401.116", "title": "Understanding the Generalization Benefits of Late Learning Rate Decay", "abstract": "Why do neural networks trained with large learning rates for a longer time\noften lead to better generalization? In this paper, we delve into this question\nby examining the relation between training and testing loss in neural networks.\nThrough visualization of these losses, we note that the training trajectory\nwith a large learning rate navigates through the minima manifold of the\ntraining loss, finally nearing the neighborhood of the testing loss minimum.\nMotivated by these findings, we introduce a nonlinear model whose loss\nlandscapes mirror those observed for real neural networks. Upon investigating\nthe training process using SGD on our model, we demonstrate that an extended\nphase with a large learning rate steers our model towards the minimum norm\nsolution of the training loss, which may achieve near-optimal generalization,\nthereby affirming the empirically observed benefits of late learning rate\ndecay.", "field": "Computer Science", "categories": "cs.LG,stat.ML"}, {"arxiv_id": "2401.11601", "title": "Robust Evaluation Measures for Evaluating Social Biases in Masked\n  Language Models", "abstract": "Many evaluation measures are used to evaluate social biases in masked\nlanguage models (MLMs). However, we find that these previously proposed\nevaluation measures are lacking robustness in scenarios with limited datasets.\nThis is because these measures are obtained by comparing the\npseudo-log-likelihood (PLL) scores of the stereotypical and anti-stereotypical\nsamples using an indicator function. The disadvantage is the limited mining of\nthe PLL score sets without capturing its distributional information. In this\npaper, we represent a PLL score set as a Gaussian distribution and use Kullback\nLeibler (KL) divergence and Jensen Shannon (JS) divergence to construct\nevaluation measures for the distributions of stereotypical and\nanti-stereotypical PLL scores. Experimental results on the publicly available\ndatasets StereoSet (SS) and CrowS-Pairs (CP) show that our proposed measures\nare significantly more robust and interpretable than those proposed previously.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.11605", "title": "Scalable High-Resolution Pixel-Space Image Synthesis with Hourglass\n  Diffusion Transformers", "abstract": "We present the Hourglass Diffusion Transformer (HDiT), an image generative\nmodel that exhibits linear scaling with pixel count, supporting training at\nhigh-resolution (e.g. $1024 \\times 1024$) directly in pixel-space. Building on\nthe Transformer architecture, which is known to scale to billions of\nparameters, it bridges the gap between the efficiency of convolutional U-Nets\nand the scalability of Transformers. HDiT trains successfully without typical\nhigh-resolution training techniques such as multiscale architectures, latent\nautoencoders or self-conditioning. We demonstrate that HDiT performs\ncompetitively with existing models on ImageNet $256^2$, and sets a new\nstate-of-the-art for diffusion models on FFHQ-$1024^2$.", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.LG"}, {"arxiv_id": "2401.11608", "title": "$\\texttt{immrax}$: A Parallelizable and Differentiable Toolbox for\n  Interval Analysis and Mixed Monotone Reachability in JAX", "abstract": "We present an implementation of interval analysis and mixed monotone interval\nreachability analysis as function transforms in Python, fully composable with\nthe computational framework JAX. The resulting toolbox inherits several key\nfeatures from JAX, including computational efficiency through Just-In-Time\nCompilation, GPU acceleration for quick parallelized computations, and\nAutomatic Differentiability. We demonstrate the toolbox's performance on\nseveral case studies, including a reachability problem on a vehicle model\ncontrolled by a neural network, and a robust closed-loop optimal control\nproblem for a swinging pendulum.", "field": "Computer Science", "categories": "eess.SY,cs.LG,cs.SY,math.OC"}, {"arxiv_id": "2401.11609", "title": "Graph Edits for Counterfactual Explanations: A Unified GNN Approach", "abstract": "Counterfactuals have been established as a popular explainability technique\nwhich leverages a set of minimal edits to alter the prediction of a classifier.\nWhen considering conceptual counterfactuals, the edits requested should\ncorrespond to salient concepts present in the input data. At the same time,\nconceptual distances are defined by knowledge graphs, ensuring the optimality\nof conceptual edits. In this work, we extend previous endeavors on conceptual\ncounterfactuals by introducing \\textit{graph edits as counterfactual\nexplanations}: should we represent input data as graphs, which is the shortest\ngraph edit path that results in an alternative classification label as provided\nby a black-box classifier?", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.11611", "title": "Continuous Field Reconstruction from Sparse Observations with Implicit\n  Neural Networks", "abstract": "Reliably reconstructing physical fields from sparse sensor data is a\nchallenge that frequently arises in many scientific domains. In practice, the\nprocess generating the data often is not understood to sufficient accuracy.\nTherefore, there is a growing interest in using the deep neural network route\nto address the problem. This work presents a novel approach that learns a\ncontinuous representation of the physical field using implicit neural\nrepresentations (INRs). Specifically, after factorizing spatiotemporal\nvariability into spatial and temporal components using the separation of\nvariables technique, the method learns relevant basis functions from sparsely\nsampled irregular data points to develop a continuous representation of the\ndata. In experimental evaluations, the proposed model outperforms recent INR\nmethods, offering superior reconstruction quality on simulation data from a\nstate-of-the-art climate model and a second dataset that comprises ultra-high\nresolution satellite-based sea surface temperature fields.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.11614", "title": "Lightweight Self-Driven Deformable Organ Animations", "abstract": "The subject of simulating internal organs is a valuable and important topic\nof research to multiple fields from medical analysis to education and training.\nThis paper presents a solution that utilizes a graphical technique in\ncombination with a Stochastic method for tuning an active physics-based model.\nWe generate responsive interactive organ animations with regional properties\n(i.e., areas of the model oscillating with different harmonic frequencies) to\nreproduce and capture real-world characteristics. Our method builds upon\nbiological and physical discoveries to procedurally generate internally\ncontrolled rhythmic motions but also enable the solution to be interactive and\nadaptive. We briefly review deformation models for medical simulations and\ninvestigate the impediments to combining 'computergraphics' representations\nwith biomechanical models. Finally, we present a lightweight solution that is\nscalable and able to procedurally generate large organ animations. In\nparticular, simplified geometric representations of deformable structures that\nuse periodic coupled forces to drive themselves.", "field": "Computer Science", "categories": "cs.GR"}, {"arxiv_id": "2401.11616", "title": "Boundary element method for the Dirichlet problem for Laplace's equation\n  on a disk", "abstract": "The Boundary Element Method (BEM) is implemented using piecewise linear\nelements to solve the two-dimensional Dirichlet problem for Laplace's equation\nposed on a disk. A benefit of the BEM as opposed to many other numerical\nsolution techniques is that discretization only occurs on the boundary, i.e.,\nthe complete domain does not need to be discretized. This provides an advantage\nin terms of time and cost. The algorithm's performance is illustrated through\nsample test problems with known solutions. A comparison between the exact\nsolution and the BEM numerical solution is done, and error analysis is\nperformed on the results.", "field": "Computer Science", "categories": "math.NA,cs.NA"}, {"arxiv_id": "2401.11617", "title": "A Survey on African Computer Vision Datasets, Topics and Researchers", "abstract": "Computer vision encompasses a range of tasks such as object detection,\nsemantic segmentation, and 3D reconstruction. Despite its relevance to African\ncommunities, research in this field within Africa represents only 0.06% of\ntop-tier publications over the past decade. This study undertakes a thorough\nanalysis of 63,000 Scopus-indexed computer vision publications from Africa,\nspanning from 2012 to 2022. The aim is to provide a survey of African computer\nvision topics, datasets and researchers. A key aspect of our study is the\nidentification and categorization of African Computer Vision datasets using\nlarge language models that automatically parse abstracts of these publications.\nWe also provide a compilation of unofficial African Computer Vision datasets\ndistributed through challenges or data hosting platforms, and provide a full\ntaxonomy of dataset categories. Our survey also pinpoints computer vision\ntopics trends specific to different African regions, indicating their unique\nfocus areas. Additionally, we carried out an extensive survey to capture the\nviews of African researchers on the current state of computer vision research\nin the continent and the structural barriers they believe need urgent\nattention. In conclusion, this study catalogs and categorizes Computer Vision\ndatasets and topics contributed or initiated by African institutions and\nidentifies barriers to publishing in top-tier Computer Vision venues. This\nsurvey underscores the importance of encouraging African researchers and\ninstitutions in advancing computer vision research in the continent. It also\nstresses on the need for research topics to be more aligned with the needs of\nAfrican communities.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11618", "title": "Efficient local linearity regularization to overcome catastrophic\n  overfitting", "abstract": "Catastrophic overfitting (CO) in single-step adversarial training (AT)\nresults in abrupt drops in the adversarial test accuracy (even down to 0%). For\nmodels trained with multi-step AT, it has been observed that the loss function\nbehaves locally linearly with respect to the input, this is however lost in\nsingle-step AT. To address CO in single-step AT, several methods have been\nproposed to enforce local linearity of the loss via regularization. However,\nthese regularization terms considerably slow down training due to Double\nBackpropagation. Instead, in this work, we introduce a regularization term,\ncalled ELLE, to mitigate CO effectively and efficiently in classical AT\nevaluations, as well as some more difficult regimes, e.g., large adversarial\nperturbations and long training schedules. Our regularization term can be\ntheoretically linked to curvature of the loss function and is computationally\ncheaper than previous methods by avoiding Double Backpropagation. Our thorough\nexperimental validation demonstrates that our work does not suffer from CO,\neven in challenging settings where previous works suffer from it. We also\nnotice that adapting our regularization parameter during training (ELLE-A)\ngreatly improves the performance, specially in large $\\epsilon$ setups. Our\nimplementation is available in https://github.com/LIONS-EPFL/ELLE .", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.CR,stat.ML"}, {"arxiv_id": "2401.1162", "title": "Real-Time Systems Optimization with Black-box Constraints and Hybrid\n  Variables", "abstract": "When optimizing real-time systems, designers often face a challenging problem\nwhere the schedulability constraints are non-convex, non-continuous, or lack an\nanalytical form to understand their properties. Although the optimization\nframework NORTH proposed in previous work is general (it works with arbitrary\nschedulability analysis) and scalable, it can only handle problems with\ncontinuous variables, which limits its application. In this paper, we extend\nthe applications of the framework NORTH to problems with a hybrid of continuous\nand discrete variables. This is achieved in a coordinate-descent method, where\nthe continuous and discrete variables are optimized separately during\niterations. The new framework, NORTH+, improves around 20% solution quality\nthan NORTH in experiments.", "field": "Computer Science", "categories": "eess.SY,cs.SY"}, {"arxiv_id": "2401.11622", "title": "The Markov-Chain Polytope with Applications", "abstract": "This paper addresses the problem of finding a minimum-cost $m$-state Markov\nchain $(S_0,\\ldots,S_{m-1})$ in a large set of chains. The chains studied have\na reward associated with each state. The cost of a chain is its \"gain\", i.e.,\nits average reward under its stationary distribution.\n  Specifically, for each $k=0,\\ldots,m-1$ there is a known set ${\\mathbb S}_k$\nof type-$k$ states. A permissible Markov chain contains exactly one state of\neach type; the problem is to find a minimum-cost permissible chain.\n  The original motivation was to find a cheapest binary AIFV-$m$ lossless code\non a source alphabet of size $n$. Such a code is an $m$-tuple of trees, in\nwhich each tree can be viewed as a Markov Chain state. This formulation was\nthen used to address other problems in lossless compression. The known solution\ntechniques for finding minimum-cost Markov chains were iterative and ran in\nexponential time.\n  This paper shows how to map every possible type-$k$ state into a type-$k$\nhyperplane and then define a \"Markov Chain Polytope\" as the lower envelope of\nall such hyperplanes. Finding a minimum-cost Markov chain can then be shown to\nbe equivalent to finding a \"highest\" point on this polytope.\n  The local optimization procedures used in the previous iterative algorithms\nare shown to be separation oracles for this polytope. Since these were often\npolynomial time, an application of the Ellipsoid method immediately leads to\npolynomial time algorithms for these problems.", "field": "Computer Science", "categories": "cs.IT,math.IT,F.2.2; E.4"}, {"arxiv_id": "2401.11624", "title": "In-context Learning with Retrieved Demonstrations for Language Models: A\n  Survey", "abstract": "Language models, especially pre-trained large language models, have showcased\nremarkable abilities as few-shot in-context learners (ICL), adept at adapting\nto new tasks with just a few demonstrations in the input context. However, the\nmodel's ability to perform ICL is sensitive to the choice of the few-shot\ndemonstrations. Instead of using a fixed set of demonstrations, one recent\ndevelopment is to retrieve demonstrations tailored to each input query. The\nimplementation of demonstration retrieval is relatively straightforward,\nleveraging existing databases and retrieval systems. This not only improves the\nefficiency and scalability of the learning process but also has been shown to\nreduce biases inherent in manual example selection. In light of the encouraging\nresults and growing research in ICL with retrieved demonstrations, we conduct\nan extensive review of studies in this area. In this survey, we discuss and\ncompare different design choices for retrieval models, retrieval training\nprocedures, and inference algorithms.", "field": "Computer Science", "categories": "cs.CL,cs.AI,cs.IR"}, {"arxiv_id": "2401.11626", "title": "Freely Long-Thinking Transformer (FraiLT)", "abstract": "Freely Long-Thinking Transformer (FraiLT) is an improved transformer model\ndesigned to enhance processing capabilities without scaling up size. It\nutilizes a recursive approach, iterating over a subset of layers multiple\ntimes, and introduces iteration encodings to maintain awareness across these\ncycles. Iteration encoding allows FraiLT to achieve the interpretive depth of\nlarger models in a compact form. When evaluated on a synthetic story dataset,\nFraiLT outperformed larger models, showcasing its ability to deliver\nhigh-quality performance while reducing memory demands. This model represents a\nstep forward towards more efficient and accessible language models.", "field": "Computer Science", "categories": "cs.LG,cs.CL"}, {"arxiv_id": "2401.11627", "title": "Tight Verification of Probabilistic Robustness in Bayesian Neural\n  Networks", "abstract": "We introduce two algorithms for computing tight guarantees on the\nprobabilistic robustness of Bayesian Neural Networks (BNNs). Computing\nrobustness guarantees for BNNs is a significantly more challenging task than\nverifying the robustness of standard Neural Networks (NNs) because it requires\nsearching the parameters' space for safe weights. Moreover, tight and complete\napproaches for the verification of standard NNs, such as those based on\nMixed-Integer Linear Programming (MILP), cannot be directly used for the\nverification of BNNs because of the polynomial terms resulting from the\nconsecutive multiplication of variables encoding the weights. Our algorithms\nefficiently and effectively search the parameters' space for safe weights by\nusing iterative expansion and the network's gradient and can be used with any\nverification algorithm of choice for BNNs. In addition to proving that our\nalgorithms compute tighter bounds than the SoA, we also evaluate our algorithms\nagainst the SoA on standard benchmarks, such as MNIST and CIFAR10, showing that\nour algorithms compute bounds up to 40% tighter than the SoA.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.FL,cs.LO,68T27 (Primary) 68T45, 68T07, 68T01 (Secondary),I.2.0; I.2.4; F.3.1; D.2.4"}, {"arxiv_id": "2401.11628", "title": "Older Adults Imagining Future Technologies in Participatory Design\n  Workshops: Supporting Continuity in the Pursuit of Meaningful Activities", "abstract": "Recent innovations in digital technology offer significant opportunities for\nolder adults to engage in meaningful activities. To investigate older adults'\nperceptions of using existing and emerging technologies for meaningful\nactivities, we conducted three participatory design workshops and follow-up\ninterviews with adults aged over 65. The workshops encompassed discussions on\nexisting technologies for meaningful activities, demonstrations of emerging\ntechnologies such as VR, AR, and AI, and design activities including\nprototyping and storyboarding. Our findings show that while participants had\ndiverse interpretations of meaningful activities, they sought to use\ntechnologies to support continuity in the pursuit of these activities.\nSpecifically, participants highlighted the importance of safe aging at home,\nwhich provides a pathway for meaningful activities in later life. We further\ndiscuss participants' discerning attitudes when assessing the use of different\ntechnologies for meaningful activities and several values and attributes they\ndesire when envisioning future technologies, including simplicity, positivity,\nproactivity, and integration.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.11629", "title": "Jump off the Bandwagon? Characterizing Bandwagon Fans' Future Loyalty in\n  Online NBA Fan Communities", "abstract": "Online user dynamics has been actively studied in recent years and bandwagon\nbehavior is one of the most representative topics which can provide valuable\ninsights for user identity change. Many previous studies have characterized\nbandwagon users and leveraged such characteristics to tackle practical problems\nsuch as community loyalty prediction. However, very few of them have\ninvestigated bandwagon dynamics from a long-term perspective. In this work, we\nfocus on characterizing and predicting long-term bandwagon user behaviors in\nthe context of online fan loyalty. Using a dataset collected from NBA-related\ndiscussion forums on Reddit, we trace the long-term loyalty status of bandwagon\nfans to capture their latent behavioral characteristics and then propose a\ncomputational model to predict their next sport season loyalty status with\ntheir home teams. Our analyses reveal that bandwagoning for most fans is a\ntemporary switch and most of them will be back in the long term. In addition,\nonline fans with different loyalty levels to their home teams have demonstrated\ndifferent behaviors in various aspects, such as activity level, language usage\nand reply network properties. We then propose a model based on such behavioral\ncharacteristics to predict their next-season loyalty status. Its promising\nperformance demonstrates the effectiveness of our behavior characterization.", "field": "Computer Science", "categories": "cs.CY,cs.SI"}, {"arxiv_id": "2401.1163", "title": "Reframing Offline Reinforcement Learning as a Regression Problem", "abstract": "The study proposes the reformulation of offline reinforcement learning as a\nregression problem that can be solved with decision trees. Aiming to predict\nactions based on input states, return-to-go (RTG), and timestep information, we\nobserve that with gradient-boosted trees, the agent training and inference are\nvery fast, the former taking less than a minute. Despite the simplification\ninherent in this reformulated problem, our agent demonstrates performance that\nis at least on par with established methods. This assertion is validated by\ntesting it across standard datasets associated with D4RL Gym-MuJoCo tasks. We\nfurther discuss the agent's ability to generalize by testing it on two extreme\ncases, how it learns to model the return distributions effectively even with\nhighly skewed expert datasets, and how it exhibits robust performance in\nscenarios with sparse/delayed rewards.", "field": "Computer Science", "categories": "cs.LG,cs.SY,eess.SY"}, {"arxiv_id": "2401.11631", "title": "Text-to-Image Cross-Modal Generation: A Systematic Review", "abstract": "We review research on generating visual data from text from the angle of\n\"cross-modal generation.\" This point of view allows us to draw parallels\nbetween various methods geared towards working on input text and producing\nvisual output, without limiting the analysis to narrow sub-areas. It also\nresults in the identification of common templates in the field, which are then\ncompared and contrasted both within pools of similar methods and across lines\nof research. We provide a breakdown of text-to-image generation into various\nflavors of image-from-text methods, video-from-text methods, image editing,\nself-supervised and graph-based approaches. In this discussion, we focus on\nresearch papers published at 8 leading machine learning conferences in the\nyears 2016-2022, also incorporating a number of relevant papers not matching\nthe outlined search criteria. The conducted review suggests a significant\nincrease in the number of papers published in the area and highlights research\ngaps and potential lines of investigation. To our knowledge, this is the first\nreview to systematically look at text-to-image generation from the perspective\nof \"cross-modal generation.\"", "field": "Computer Science", "categories": "cs.CV,cs.CL,cs.LG"}, {"arxiv_id": "2401.11632", "title": "What Are We Optimizing For? A Human-centric Evaluation Of Deep\n  Learning-based Recommender Systems", "abstract": "Deep learning-based (DL) models in recommender systems (RecSys) have gained\nsignificant recognition for their remarkable accuracy in predicting user\npreferences. However, their performance often lacks a comprehensive evaluation\nfrom a human-centric perspective, which encompasses various dimensions beyond\nsimple interest matching. In this work, we have developed a robust\nhuman-centric evaluation framework that incorporates seven diverse metrics to\nassess the quality of recommendations generated by five recent open-sourced DL\nmodels. Our evaluation datasets consist of both offline benchmark data and\npersonalized online recommendation feedback collected from 445 real users. We\nfind that (1) different DL models have different pros and cons in the\nmulti-dimensional metrics that we test with; (2) users generally want a\ncombination of accuracy with at least one another human values in the\nrecommendation; (3) the degree of combination of different values needs to be\ncarefully experimented to user preferred level.", "field": "Computer Science", "categories": "cs.IR,cs.HC,cs.LG"}, {"arxiv_id": "2401.11633", "title": "Zoom-shot: Fast and Efficient Unsupervised Zero-Shot Transfer of CLIP to\n  Vision Encoders with Multimodal Loss", "abstract": "The fusion of vision and language has brought about a transformative shift in\ncomputer vision through the emergence of Vision-Language Models (VLMs).\nHowever, the resource-intensive nature of existing VLMs poses a significant\nchallenge. We need an accessible method for developing the next generation of\nVLMs. To address this issue, we propose Zoom-shot, a novel method for\ntransferring the zero-shot capabilities of CLIP to any pre-trained vision\nencoder. We do this by exploiting the multimodal information (i.e. text and\nimage) present in the CLIP latent space through the use of specifically\ndesigned multimodal loss functions. These loss functions are (1)\ncycle-consistency loss and (2) our novel prompt-guided knowledge distillation\nloss (PG-KD). PG-KD combines the concept of knowledge distillation with CLIP's\nzero-shot classification, to capture the interactions between text and image\nfeatures. With our multimodal losses, we train a $\\textbf{linear mapping}$\nbetween the CLIP latent space and the latent space of a pre-trained vision\nencoder, for only a $\\textbf{single epoch}$. Furthermore, Zoom-shot is entirely\nunsupervised and is trained using $\\textbf{unpaired}$ data. We test the\nzero-shot capabilities of a range of vision encoders augmented as new VLMs, on\ncoarse and fine-grained classification datasets, outperforming the previous\nstate-of-the-art in this problem domain. In our ablations, we find Zoom-shot\nallows for a trade-off between data and compute during training; and our\nstate-of-the-art results can be obtained by reducing training from 20% to 1% of\nthe ImageNet training data with 20 epochs. All code and models are available on\nGitHub.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.11634", "title": "MR.CAP: Multi-Robot Joint Control and Planning for Object Transport", "abstract": "With the recent influx in demand for multi-robot systems throughout industry\nand academia, there is an increasing need for faster, robust, and generalizable\npath planning algorithms. Similarly, given the inherent connection between\ncontrol algorithms and multi-robot path planners, there is in turn an increased\ndemand for fast, efficient, and robust controllers. We propose a scalable joint\npath planning and control algorithm for multi-robot systems with constrained\nbehaviours based on factor graph optimization. We demonstrate our algorithm on\na series of hardware and simulated experiments. Our algorithm is consistently\nable to recover from disturbances and avoid obstacles while outperforming\nstate-of-the-art methods in optimization time, path deviation, and inter-robot\nerrors. See the code and supplementary video for experiments.", "field": "Computer Science", "categories": "cs.RO"}, {"arxiv_id": "2401.11641", "title": "Revolutionizing Finance with LLMs: An Overview of Applications and\n  Insights", "abstract": "In recent years, Large Language Models (LLMs) like ChatGPT have seen\nconsiderable advancements and have been applied in diverse fields. Built on the\nTransformer architecture, these models are trained on extensive datasets,\nenabling them to understand and generate human language effectively. In the\nfinancial domain, the deployment of LLMs is gaining momentum. These models are\nbeing utilized for automating financial report generation, forecasting market\ntrends, analyzing investor sentiment, and offering personalized financial\nadvice. Leveraging their natural language processing capabilities, LLMs can\ndistill key insights from vast financial data, aiding institutions in making\ninformed investment choices and enhancing both operational efficiency and\ncustomer satisfaction. In this study, we provide a comprehensive overview of\nthe emerging integration of LLMs into various financial tasks. Additionally, we\nconducted holistic tests on multiple financial tasks through the combination of\nnatural language instructions. Our findings show that GPT-4 effectively follow\nprompt instructions across various financial tasks. This survey and evaluation\nof LLMs in the financial domain aim to deepen the understanding of LLMs'\ncurrent role in finance for both financial practitioners and LLM researchers,\nidentify new research and application prospects, and highlight how these\ntechnologies can be leveraged to solve practical challenges in the finance\nindustry.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.11642", "title": "SyzRetrospector: A Large-Scale Retrospective Study of Syzbot", "abstract": "Over the past 6 years, Syzbot has fuzzed the Linux kernel day and night to\nreport over 5570 bugs, of which 4604 have been patched [11]. While this is\nimpressive, we have found the average time to find a bug is over 405 days.\nMoreover, we have found that current metrics commonly used, such as\ntime-to-find and number of bugs found, are inaccurate in evaluating Syzbot\nsince bugs often spend the majority of their lives hidden from the fuzzer. In\nthis paper, we set out to better understand and quantify Syzbot's performance\nand improvement in finding bugs. Our tool, SyzRetrospector, takes a different\napproach to evaluating Syzbot by finding the earliest that Syzbot was capable\nof finding a bug, and why that bug was revealed. We use SyzRetrospector on a\nlarge scale to analyze 559 bugs and find that bugs are hidden for an average of\n331.17 days before Syzbot is even able to find them. We further present\nfindings on the behaviors of revealing factors, how some bugs are harder to\nreveal than others, the trends in delays over the past 6 years, and how bug\nlocation relates to delays. We also provide key takeaways for improving\nSyzbot's delays.", "field": "Computer Science", "categories": "cs.SE,cs.CR,cs.OS"}, {"arxiv_id": "2401.11644", "title": "Friends Across Time: Multi-Scale Action Segmentation Transformer for\n  Surgical Phase Recognition", "abstract": "Automatic surgical phase recognition is a core technology for modern\noperating rooms and online surgical video assessment platforms. Current\nstate-of-the-art methods use both spatial and temporal information to tackle\nthe surgical phase recognition task. Building on this idea, we propose the\nMulti-Scale Action Segmentation Transformer (MS-AST) for offline surgical phase\nrecognition and the Multi-Scale Action Segmentation Causal Transformer\n(MS-ASCT) for online surgical phase recognition. We use ResNet50 or\nEfficientNetV2-M for spatial feature extraction. Our MS-AST and MS-ASCT can\nmodel temporal information at different scales with multi-scale temporal\nself-attention and multi-scale temporal cross-attention, which enhances the\ncapture of temporal relationships between frames and segments. We demonstrate\nthat our method can achieve 95.26% and 96.15% accuracy on the Cholec80 dataset\nfor online and offline surgical phase recognition, respectively, which achieves\nnew state-of-the-art results. Our method can also achieve state-of-the-art\nresults on non-medical datasets in the video action segmentation domain.", "field": "Computer Science", "categories": "cs.CV,cs.RO"}, {"arxiv_id": "2401.11647", "title": "LW-FedSSL: Resource-efficient Layer-wise Federated Self-supervised\n  Learning", "abstract": "Many recent studies integrate federated learning (FL) with self-supervised\nlearning (SSL) to take advantage of raw training data distributed across edge\ndevices. However, edge devices often struggle with high computation and\ncommunication costs imposed by SSL and FL algorithms. To tackle this hindrance,\nwe propose LW-FedSSL, a layer-wise federated self-supervised learning approach\nthat allows edge devices to incrementally train one layer of the model at a\ntime. LW-FedSSL comprises server-side calibration and representation alignment\nmechanisms to maintain comparable performance with end-to-end FedSSL while\nsignificantly lowering clients' resource requirements. The server-side\ncalibration mechanism takes advantage of the resource-rich server in an FL\nenvironment to assist in global model training. Meanwhile, the representation\nalignment mechanism encourages closeness between representations of FL local\nmodels and those of the global model. Our experiments show that LW-FedSSL has a\n$3.3 \\times$ lower memory requirement and a $3.2 \\times$ cheaper communication\ncost than its end-to-end counterpart. We also explore a progressive training\nstrategy called Prog-FedSSL that outperforms end-to-end training with a similar\nmemory requirement and a $1.8 \\times$ cheaper communication cost.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.11648", "title": "Next Visit Diagnosis Prediction via Medical Code-Centric Multimodal\n  Contrastive EHR Modelling with Hierarchical Regularisation", "abstract": "Predicting next visit diagnosis using Electronic Health Records (EHR) is an\nessential task in healthcare, critical for devising proactive future plans for\nboth healthcare providers and patients. Nonetheless, many preceding studies\nhave not sufficiently addressed the heterogeneous and hierarchical\ncharacteristics inherent in EHR data, inevitably leading to sub-optimal\nperformance. To this end, we propose NECHO, a novel medical code-centric\nmultimodal contrastive EHR learning framework with hierarchical regularisation.\nFirst, we integrate multifaceted information encompassing medical codes,\ndemographics, and clinical notes using a tailored network design and a pair of\nbimodal contrastive losses, all of which pivot around a medical code\nrepresentation. We also regularise modality-specific encoders using a parental\nlevel information in medical ontology to learn hierarchical structure of EHR\ndata. A series of experiments on MIMIC-III data demonstrates effectiveness of\nour approach.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.IR"}, {"arxiv_id": "2401.11649", "title": "M2-CLIP: A Multimodal, Multi-task Adapting Framework for Video Action\n  Recognition", "abstract": "Recently, the rise of large-scale vision-language pretrained models like\nCLIP, coupled with the technology of Parameter-Efficient FineTuning (PEFT), has\ncaptured substantial attraction in video action recognition. Nevertheless,\nprevailing approaches tend to prioritize strong supervised performance at the\nexpense of compromising the models' generalization capabilities during\ntransfer. In this paper, we introduce a novel Multimodal, Multi-task CLIP\nadapting framework named \\name to address these challenges, preserving both\nhigh supervised performance and robust transferability. Firstly, to enhance the\nindividual modality architectures, we introduce multimodal adapters to both the\nvisual and text branches. Specifically, we design a novel visual TED-Adapter,\nthat performs global Temporal Enhancement and local temporal Difference\nmodeling to improve the temporal representation capabilities of the visual\nencoder. Moreover, we adopt text encoder adapters to strengthen the learning of\nsemantic label information. Secondly, we design a multi-task decoder with a\nrich set of supervisory signals to adeptly satisfy the need for strong\nsupervised performance and generalization within a multimodal framework.\nExperimental results validate the efficacy of our approach, demonstrating\nexceptional performance in supervised learning while maintaining strong\ngeneralization in zero-shot scenarios.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.1165", "title": "PointGL: A Simple Global-Local Framework for Efficient Point Cloud\n  Analysis", "abstract": "Efficient analysis of point clouds holds paramount significance in real-world\n3D applications. Currently, prevailing point-based models adhere to the\nPointNet++ methodology, which involves embedding and abstracting point features\nwithin a sequence of spatially overlapping local point sets, resulting in\nnoticeable computational redundancy. Drawing inspiration from the streamlined\nparadigm of pixel embedding followed by regional pooling in Convolutional\nNeural Networks (CNNs), we introduce a novel, uncomplicated yet potent\narchitecture known as PointGL, crafted to facilitate efficient point cloud\nanalysis. PointGL employs a hierarchical process of feature acquisition through\ntwo recursive steps. First, the Global Point Embedding leverages\nstraightforward residual Multilayer Perceptrons (MLPs) to effectuate feature\nembedding for each individual point. Second, the novel Local Graph Pooling\ntechnique characterizes point-to-point relationships and abstracts regional\nrepresentations through succinct local graphs. The harmonious fusion of\none-time point embedding and parameter-free graph pooling contributes to\nPointGL's defining attributes of minimized model complexity and heightened\nefficiency. Our PointGL attains state-of-the-art accuracy on the ScanObjectNN\ndataset while exhibiting a runtime that is more than 5 times faster and\nutilizing only approximately 4% of the FLOPs and 30% of the parameters compared\nto the recent PointMLP model. The code for PointGL is available at\nhttps://github.com/Roywangj/PointGL.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11652", "title": "OnDev-LCT: On-Device Lightweight Convolutional Transformers towards\n  federated learning", "abstract": "Federated learning (FL) has emerged as a promising approach to\ncollaboratively train machine learning models across multiple edge devices\nwhile preserving privacy. The success of FL hinges on the efficiency of\nparticipating models and their ability to handle the unique challenges of\ndistributed learning. While several variants of Vision Transformer (ViT) have\nshown great potential as alternatives to modern convolutional neural networks\n(CNNs) for centralized training, the unprecedented size and higher\ncomputational demands hinder their deployment on resource-constrained edge\ndevices, challenging their widespread application in FL. Since client devices\nin FL typically have limited computing resources and communication bandwidth,\nmodels intended for such devices must strike a balance between model size,\ncomputational efficiency, and the ability to adapt to the diverse and non-IID\ndata distributions encountered in FL. To address these challenges, we propose\nOnDev-LCT: Lightweight Convolutional Transformers for On-Device vision tasks\nwith limited training data and resources. Our models incorporate image-specific\ninductive biases through the LCT tokenizer by leveraging efficient depthwise\nseparable convolutions in residual linear bottleneck blocks to extract local\nfeatures, while the multi-head self-attention (MHSA) mechanism in the LCT\nencoder implicitly facilitates capturing global representations of images.\nExtensive experiments on benchmark image datasets indicate that our models\noutperform existing lightweight vision models while having fewer parameters and\nlower computational demands, making them suitable for FL scenarios with data\nheterogeneity and communication bottlenecks.", "field": "Computer Science", "categories": "cs.CV,cs.LG"}, {"arxiv_id": "2401.11654", "title": "ActionHub: A Large-scale Action Video Description Dataset for Zero-shot\n  Action Recognition", "abstract": "Zero-shot action recognition (ZSAR) aims to learn an alignment model between\nvideos and class descriptions of seen actions that is transferable to unseen\nactions. The text queries (class descriptions) used in existing ZSAR works,\nhowever, are often short action names that fail to capture the rich semantics\nin the videos, leading to misalignment. With the intuition that video content\ndescriptions (e.g., video captions) can provide rich contextual information of\nvisual concepts in videos, we propose to utilize human annotated video\ndescriptions to enrich the semantics of the class descriptions of each action.\nHowever, all existing action video description datasets are limited in terms of\nthe number of actions, the semantics of video descriptions, etc. To this end,\nwe collect a large-scale action video descriptions dataset named ActionHub,\nwhich covers a total of 1,211 common actions and provides 3.6 million action\nvideo descriptions. With the proposed ActionHub dataset, we further propose a\nnovel Cross-modality and Cross-action Modeling (CoCo) framework for ZSAR, which\nconsists of a Dual Cross-modality Alignment module and a Cross-action\nInvariance Mining module. Specifically, the Dual Cross-modality Alignment\nmodule utilizes both action labels and video descriptions from ActionHub to\nobtain rich class semantic features for feature alignment. The Cross-action\nInvariance Mining module exploits a cycle-reconstruction process between the\nclass semantic feature spaces of seen actions and unseen actions, aiming to\nguide the model to learn cross-action invariant representations. Extensive\nexperimental results demonstrate that our CoCo framework significantly\noutperforms the state-of-the-art on three popular ZSAR benchmarks (i.e.,\nKinetics-ZSAR, UCF101 and HMDB51) under two different learning protocols in\nZSAR. We will release our code, models, and the proposed ActionHub dataset.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11656", "title": "Agent-Based Modeling of C. Difficile Spread in Hospitals: Assessing\n  Contribution of High-Touch vs. Low-Touch Surfaces and Inoculations'\n  Containment Impact", "abstract": "Health issues and pandemics remain paramount concerns in the contemporary\nera. Clostridioides Difficile Infection (CDI) stands out as a critical\nhealthcare-associated infection with global implications. Effectively\nunderstanding the mechanisms of infection dissemination within healthcare units\nand hospitals is imperative to implement targeted containment measures. In this\nstudy, we address the limitations of prior research by Sulyok et al., where\nthey delineated two distinct categories of surfaces as high-touch and low-touch\nfomites, and subsequently evaluated the viral spread contribution of each\nsurface utilizing mathematical modeling and Ordinary Differential Equations\n(ODE). Acknowledging the indispensable role of spatial features and\nheterogeneity in the modeling of hospital and healthcare settings, we employ\nagent-based modeling to capture new insights. By incorporating spatial\nconsiderations and heterogeneous patients, we explore the impact of high-touch\nand low-touch surfaces on contamination transmission between patients.\nFurthermore, the study encompasses a comprehensive assessment of various\ncleaning protocols, with differing intervals and detergent cleaning efficacies,\nin order to identify the most optimal cleaning strategy and the most important\nfactor amidst the array of alternatives. Our results indicate that, among\nvarious factors, the frequency of cleaning intervals is the most critical\nelement for controlling the spread of CDI in a hospital environment.", "field": "Computer Science", "categories": "cs.MA"}, {"arxiv_id": "2401.11658", "title": "A Randomized Runge-Kutta Method for time-irregular delay differential\n  equations", "abstract": "In this paper we investigate the existence, uniqueness and approximation of\nsolutions of delay differential equations (DDEs) with the right-hand side\nfunctions $f=f(t,x,z)$ that are Lipschitz continuous with respect to $x$ but\nonly H\\\"older continuous with respect to $(t,z)$. We give a construction of the\nrandomized two-stage Runge-Kutta scheme for DDEs and investigate its upper\nerror bound in the $L^p(\\Omega)$-norm for $p\\in [2,+\\infty)$. Finally, we\nreport on results of numerical experiments.", "field": "Computer Science", "categories": "math.NA,cs.NA,math.PR"}, {"arxiv_id": "2401.1166", "title": "Differentiable Tree Search in Latent State Space", "abstract": "In decision-making problems with limited training data, policy functions\napproximated using deep neural networks often exhibit suboptimal performance.\nAn alternative approach involves learning a world model from the limited data\nand determining actions through online search. However, the performance is\nadversely affected by compounding errors arising from inaccuracies in the\nlearnt world model. While methods like TreeQN have attempted to address these\ninaccuracies by incorporating algorithmic structural biases into their\narchitectures, the biases they introduce are often weak and insufficient for\ncomplex decision-making tasks. In this work, we introduce Differentiable Tree\nSearch (DTS), a novel neural network architecture that significantly\nstrengthens the inductive bias by embedding the algorithmic structure of a\nbest-first online search algorithm. DTS employs a learnt world model to conduct\na fully differentiable online search in latent state space. The world model is\njointly optimised with the search algorithm, enabling the learning of a robust\nworld model and mitigating the effect of model inaccuracies. We address\npotential Q-function discontinuities arising from naive incorporation of\nbest-first search by adopting a stochastic tree expansion policy, formulating\nsearch tree expansion as a decision-making task, and introducing an effective\nvariance reduction technique for the gradient computation. We evaluate DTS in\nan offline-RL setting with a limited training data scenario on Procgen games\nand grid navigation task, and demonstrate that DTS outperforms popular\nmodel-free and model-based baselines.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.11663", "title": "\"I Got Flagged for Supposed Bullying, Even Though It Was in Response to\n  Someone Harassing Me About My Disability.\": A Study of Blind TikTokers'\n  Content Moderation Experiences", "abstract": "The Human-Computer Interaction (HCI) community has consistently focused on\nthe experiences of users moderated by social media platforms. Recently,\nscholars have noticed that moderation practices could perpetuate biases,\nresulting in the marginalization of user groups undergoing moderation. However,\nmost studies have primarily addressed marginalization related to issues such as\nracism or sexism, with little attention given to the experiences of people with\ndisabilities. In this paper, we present a study on the moderation experiences\nof blind users on TikTok, also known as \"BlindToker,\" to address this gap. We\nconducted semi-structured interviews with 20 BlindTokers and used thematic\nanalysis to analyze the data. Two main themes emerged: BlindTokers' situated\ncontent moderation experiences and their reactions to content moderation. We\nreported on the lack of accessibility on TikTok's platform, contributing to the\nmoderation and marginalization of BlindTokers. Additionally, we discovered\ninstances of harassment from trolls that prompted BlindTokers to respond with\nharsh language, triggering further moderation. We discussed these findings in\nthe context of the literature on moderation, marginalization, and\ntransformative justice, seeking solutions to address such issues.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.11664", "title": "Zero-Space Cost Fault Tolerance for Transformer-based Language Models on\n  ReRAM", "abstract": "Resistive Random Access Memory (ReRAM) has emerged as a promising platform\nfor deep neural networks (DNNs) due to its support for parallel in-situ\nmatrix-vector multiplication. However, hardware failures, such as\nstuck-at-fault defects, can result in significant prediction errors during\nmodel inference. While additional crossbars can be used to address these\nfailures, they come with storage overhead and are not efficient in terms of\nspace, energy, and cost. In this paper, we propose a fault protection mechanism\nthat incurs zero space cost. Our approach includes: 1) differentiable structure\npruning of rows and columns to reduce model redundancy, 2) weight duplication\nand voting for robust output, and 3) embedding duplicated most significant bits\n(MSBs) into the model weight. We evaluate our method on nine tasks of the GLUE\nbenchmark with the BERT model, and experimental results prove its\neffectiveness.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.AR"}, {"arxiv_id": "2401.11666", "title": "P2DT: Mitigating Forgetting in task-incremental Learning with\n  progressive prompt Decision Transformer", "abstract": "Catastrophic forgetting poses a substantial challenge for managing\nintelligent agents controlled by a large model, causing performance degradation\nwhen these agents face new tasks. In our work, we propose a novel solution -\nthe Progressive Prompt Decision Transformer (P2DT). This method enhances a\ntransformer-based model by dynamically appending decision tokens during new\ntask training, thus fostering task-specific policies. Our approach mitigates\nforgetting in continual and offline reinforcement learning scenarios. Moreover,\nP2DT leverages trajectories collected via traditional reinforcement learning\nfrom all tasks and generates new task-specific tokens during training, thereby\nretaining knowledge from previous studies. Preliminary results demonstrate that\nour model effectively alleviates catastrophic forgetting and scales well with\nincreasing task environments.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.11667", "title": "INCPrompt: Task-Aware incremental Prompting for Rehearsal-Free\n  Class-incremental Learning", "abstract": "This paper introduces INCPrompt, an innovative continual learning solution\nthat effectively addresses catastrophic forgetting. INCPrompt's key innovation\nlies in its use of adaptive key-learner and task-aware prompts that capture\ntask-relevant information. This unique combination encapsulates general\nknowledge across tasks and encodes task-specific knowledge. Our comprehensive\nevaluation across multiple continual learning benchmarks demonstrates\nINCPrompt's superiority over existing algorithms, showing its effectiveness in\nmitigating catastrophic forgetting while maintaining high performance. These\nresults highlight the significant impact of task-aware incremental prompting on\ncontinual learning performance.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.11669", "title": "An Improved Grey Wolf Optimization Algorithm for Heart Disease\n  Prediction", "abstract": "This paper presents a unique solution to challenges in medical image\nprocessing by incorporating an adaptive curve grey wolf optimization (ACGWO)\nalgorithm into neural network backpropagation. Neural networks show potential\nin medical data but suffer from issues like overfitting and lack of\ninterpretability due to imbalanced and scarce data. Traditional Gray Wolf\nOptimization (GWO) also has its drawbacks, such as a lack of population\ndiversity and premature convergence. This paper addresses these problems by\nintroducing an adaptive algorithm, enhancing the standard GWO with a sigmoid\nfunction. This algorithm was extensively compared to four leading algorithms\nusing six well-known test functions, outperforming them effectively. Moreover,\nby utilizing the ACGWO, we increase the robustness and generalization of the\nneural network, resulting in more interpretable predictions. Applied to the\npublicly accessible Cleveland Heart Disease dataset, our technique surpasses\nten other methods, achieving 86.8% accuracy, indicating its potential for\nefficient heart disease prediction in the clinical setting.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.NE"}, {"arxiv_id": "2401.11673", "title": "MVSFormer++: Revealing the Devil in Transformer's Details for Multi-View\n  Stereo", "abstract": "Recent advancements in learning-based Multi-View Stereo (MVS) methods have\nprominently featured transformer-based models with attention mechanisms.\nHowever, existing approaches have not thoroughly investigated the profound\ninfluence of transformers on different MVS modules, resulting in limited depth\nestimation capabilities. In this paper, we introduce MVSFormer++, a method that\nprudently maximizes the inherent characteristics of attention to enhance\nvarious components of the MVS pipeline. Formally, our approach involves\ninfusing cross-view information into the pre-trained DINOv2 model to facilitate\nMVS learning. Furthermore, we employ different attention mechanisms for the\nfeature encoder and cost volume regularization, focusing on feature and spatial\naggregations respectively. Additionally, we uncover that some design details\nwould substantially impact the performance of transformer modules in MVS,\nincluding normalized 3D positional encoding, adaptive attention scaling, and\nthe position of layer normalization. Comprehensive experiments on DTU,\nTanks-and-Temples, BlendedMVS, and ETH3D validate the effectiveness of the\nproposed method. Notably, MVSFormer++ achieves state-of-the-art performance on\nthe challenging DTU and Tanks-and-Temples benchmarks.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11674", "title": "Memory-Efficient Prompt Tuning for Incremental Histopathology\n  Classification", "abstract": "Recent studies have made remarkable progress in histopathology\nclassification. Based on current successes, contemporary works proposed to\nfurther upgrade the model towards a more generalizable and robust direction\nthrough incrementally learning from the sequentially delivered domains. Unlike\nprevious parameter isolation based approaches that usually demand massive\ncomputation resources during model updating, we present a memory-efficient\nprompt tuning framework to cultivate model generalization potential in\neconomical memory cost. For each incoming domain, we reuse the existing\nparameters of the initial classification model and attach lightweight trainable\nprompts into it for customized tuning. Considering the domain heterogeneity, we\nperform decoupled prompt tuning, where we adopt a domain-specific prompt for\neach domain to independently investigate its distinctive characteristics, and\none domain-invariant prompt shared across all domains to continually explore\nthe common content embedding throughout time. All domain-specific prompts will\nbe appended to the prompt bank and isolated from further changes to prevent\nforgetting the distinctive features of early-seen domains. While the\ndomain-invariant prompt will be passed on and iteratively evolve by\nstyle-augmented prompt refining to improve model generalization capability over\ntime. In specific, we construct a graph with existing prompts and build a\nstyle-augmented graph attention network to guide the domain-invariant prompt\nexploring the overlapped latent embedding among all delivered domains for more\ndomain generic representations. We have extensively evaluated our framework\nwith two histopathology tasks, i.e., breast cancer metastasis classification\nand epithelium-stroma tissue classification, where our approach yielded\nsuperior performance and memory efficiency over the competing methods.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.11677", "title": "Emulation-based Stabilization for Networked Control Systems with\n  Stochastic Channels", "abstract": "This paper studies the stabilization problem of networked control systems\n(NCSs) with random packet dropouts caused by stochastic channels. To describe\nthe effects of stochastic channels on the information transmission, the\ntransmission times are assumed to be deterministic, whereas the packet\ntransmission is assumed to be random. We first propose a stochastic scheduling\nprotocol to model random packet dropouts, and address the properties of the\nproposed stochastic scheduling protocol. The proposed scheduling protocol\nprovides a unified modelling framework for a general class of random packet\ndropouts due to different stochastic channels. Next, the proposed scheduling\nprotocol is embedded into the closed-loop system, which leads to a stochastic\nhybrid model for NCSs with random packet dropouts. Based on this stochastic\nhybrid model, we follow the emulation approach to establish sufficient\nconditions to guarantee uniform global asymptotical stability in probability.\nIn particular, an upper bound on the maximally allowable transmission interval\nis derived explicitly for all stochastic protocols satisfying Lyapunov\nconditions that guarantee uniform global asymptotic stability in probability.\nFinally, two numerical examples are presented to demonstrate the derived\nresults.", "field": "Computer Science", "categories": "eess.SY,cs.SY"}, {"arxiv_id": "2401.11681", "title": "Functional Eigen-Grasping Using Approach Heatmaps", "abstract": "This work presents a framework for a robot with a multi-fingered hand to\nfreely utilize daily tools, including functional parts like buttons and\ntriggers. An approach heatmap is generated by selecting a functional finger,\nindicating optimal palm positions on the object's surface that enable the\nfunctional finger to contact the tool's functional part. Once the palm position\nis identified through the heatmap, achieving the functional grasp becomes a\nstraightforward process where the fingers stably grasp the object with\nlow-dimensional inputs using the eigengrasp. As our approach does not need\nhuman demonstrations, it can easily adapt to various sizes and designs,\nextending its applicability to different objects. In our approach, we use\ndirectional manipulability to obtain the approach heatmap. In addition, we add\ntwo kinds of energy functions, i.e., palm energy and functional energy\nfunctions, to realize the eigengrasp. Using this method, each robotic gripper\ncan autonomously identify its optimal workspace for functional grasping,\nextending its applicability to non-anthropomorphic robotic hands. We show that\nseveral daily tools like spray, drill, and remotes can be efficiently used by\nnot only an anthropomorphic Shadow hand but also a non-anthropomorphic Barrett\nhand.", "field": "Computer Science", "categories": "cs.RO"}, {"arxiv_id": "2401.11685", "title": "Accelerating Seed Location Filtering in DNA Read Mapping Using a\n  Commercial Compute-in-SRAM Architecture", "abstract": "DNA sequence alignment is an important workload in computational genomics.\nReference-guided DNA assembly involves aligning many read sequences against\ncandidate locations in a long reference genome. To reduce the computational\nload of this alignment, candidate locations can be pre-filtered using simpler\nalignment algorithms like edit distance. Prior work has explored accelerating\nfiltering on simulated compute-in-DRAM, due to the massive parallelism of\ncompute-in-memory architectures. In this paper, we present work-in-progress on\naccelerating filtering using a commercial compute-in-SRAM accelerator. We\nleverage the recently released Gemini accelerator platform from GSI Technology,\nwhich is the first, to our knowledge, commercial-scale compute-in-SRAM system.\nWe accelerate the Myers' bit-parallel edit distance algorithm, producing\naverage speedups of 14.1x over single-core CPU performance. Individual\nquery/candidate alignments produce speedups of up to 24.1x. These early results\nsuggest this novel architecture is well-suited to accelerating the filtering\nstep of sequence-to-sequence DNA alignment.", "field": "Computer Science", "categories": "cs.AR,q-bio.GN"}, {"arxiv_id": "2401.11686", "title": "Evolutionary dynamics of any multiplayer game on regular graphs", "abstract": "Multiplayer games on graphs are at the heart of theoretical descriptions of\nkey evolutionary processes that govern vital social and natural systems.\nHowever, a comprehensive theoretical framework for solving multiplayer games\nwith an arbitrary number of strategies on graphs is still missing. Here, we\nsolve this by drawing an analogy with the Ball-and-Box problem, based on which\nwe show that the local configuration of multiplayer games on graphs is\nequivalent to distributing $k$ identical co-players among $n$ distinct\nstrategies. We use this to derive the replicator equation for any $n$-strategy\nmultiplayer game under weak selection, which can be solved in polynomial time.\nAs an example, we revisit the second-order free-riding problem, where costly\npunishment cannot truly resolve social dilemmas in a well-mixed population.\nYet, in structured populations, we derive an accurate threshold for the\npunishment strength, beyond which punishment can either lead to the extinction\nof defection or transform the system into a rock-paper-scissors-like cycle. The\nanalytical solution also qualitatively agrees with the phase diagrams that were\npreviously obtained for non-marginal selection strengths. Our framework thus\nallows an exploration of any multi-strategy multiplayer game on regular graphs.", "field": "Computer Science", "categories": "cs.GT,cond-mat.stat-mech,cs.CC,nlin.CG,q-bio.PE"}, {"arxiv_id": "2401.11687", "title": "TIM: An Efficient Temporal Interaction Module for Spiking Transformer", "abstract": "Spiking Neural Networks (SNNs), as the third generation of neural networks,\nhave gained prominence for their biological plausibility and computational\nefficiency, especially in processing diverse datasets. The integration of\nattention mechanisms, inspired by advancements in neural network architectures,\nhas led to the development of Spiking Transformers. These have shown promise in\nenhancing SNNs' capabilities, particularly in the realms of both static and\nneuromorphic datasets. Despite their progress, a discernible gap exists in\nthese systems, specifically in the Spiking Self Attention (SSA) mechanism's\neffectiveness in leveraging the temporal processing potential of SNNs. To\naddress this, we introduce the Temporal Interaction Module (TIM), a novel,\nconvolution-based enhancement designed to augment the temporal data processing\nabilities within SNN architectures. TIM's integration into existing SNN\nframeworks is seamless and efficient, requiring minimal additional parameters\nwhile significantly boosting their temporal information handling capabilities.\nThrough rigorous experimentation, TIM has demonstrated its effectiveness in\nexploiting temporal information, leading to state-of-the-art performance across\nvarious neuromorphic datasets.", "field": "Computer Science", "categories": "cs.NE,cs.CV,cs.LG"}, {"arxiv_id": "2401.11694", "title": "Parametric Matrix Models", "abstract": "We present a general class of machine learning algorithms called parametric\nmatrix models. Parametric matrix models are based on matrix equations, and the\ndesign is motivated by the efficiency of reduced basis methods for\napproximating solutions of parametric equations. The dependent variables can be\ndefined implicitly or explicitly, and the equations may use algebraic,\ndifferential, or integral relations. Parametric matrix models can be trained\nwith empirical data only, and no high-fidelity model calculations are needed.\nWhile originally designed for scientific computing, parametric matrix models\nare universal function approximators that can be applied to general machine\nlearning problems. After introducing the underlying theory, we apply parametric\nmatrix models to a series of different challenges that show their performance\nfor a wide range of problems. For all the challenges tested here, parametric\nmatrix models produce accurate results within a computational framework that\nallows for parameter extrapolation and interpretability.", "field": "Computer Science", "categories": "cs.LG,cond-mat.dis-nn,nucl-th,physics.comp-ph,quant-ph"}, {"arxiv_id": "2401.11697", "title": "A risk-based approach to assessing liability risk for AI-driven harms\n  considering EU liability directive", "abstract": "Artificial intelligence can cause inconvenience, harm, or other unintended\nconsequences in various ways, including those that arise from defects or\nmalfunctions in the AI system itself or those caused by its use or misuse.\nResponsibility for AI harms or unintended consequences must be addressed to\nhold accountable the people who caused such harms and ensure that victims\nreceive compensation for any damages or losses they may have sustained.\nHistorical instances of harm caused by AI have led to European Union\nestablishing an AI Liability Directive. The directive aims to lay down a\nuniform set of rules for access to information, delineate the duty and level of\ncare required for AI development and use, and clarify the burden of proof for\ndamages or harms caused by AI systems, establishing broader protection for\nvictims. The future ability of provider to contest a product liability claim\nwill depend on good practices adopted in designing, developing, and maintaining\nAI systems in the market. This paper provides a risk-based approach to\nexamining liability for AI-driven injuries. It also provides an overview of\nexisting liability approaches, insights into limitations and complexities in\nthese approaches, and a detailed self-assessment questionnaire to assess the\nrisk associated with liability for a specific AI system from a provider's\nperspective.", "field": "Computer Science", "categories": "cs.CY"}, {"arxiv_id": "2401.11698", "title": "Admission Prediction in Undergraduate Applications: an Interpretable\n  Deep Learning Approach", "abstract": "This article addresses the challenge of validating the admission committee's\ndecisions for undergraduate admissions. In recent years, the traditional review\nprocess has struggled to handle the overwhelmingly large amount of applicants'\ndata. Moreover, this traditional assessment often leads to human bias, which\nmight result in discrimination among applicants. Although classical machine\nlearning-based approaches exist that aim to verify the quantitative assessment\nmade by the application reviewers, these methods lack scalability and suffer\nfrom performance issues when a large volume of data is in place. In this\ncontext, we propose deep learning-based classifiers, namely Feed-Forward and\nInput Convex neural networks, which overcome the challenges faced by the\nexisting methods. Furthermore, we give additional insights into our model by\nincorporating an interpretability module, namely LIME. Our training and test\ndatasets comprise applicants' data with a wide range of variables and\ninformation. Our models achieve higher accuracy compared to the best-performing\ntraditional machine learning-based approach by a considerable margin of 3.03\\%.\nAdditionally, we show the sensitivity of different features and their relative\nimpacts on the overall admission decision using the LIME technique.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.11699", "title": "Dissecting Bias of ChatGPT in College Major Recommendations", "abstract": "I investigate bias in terms of ChatGPT's college major recommendations for\nstudents with various profiles, looking at demographic disparities in factors\nsuch as race, gender, and socioeconomic status, as well as educational\ndisparities such as score percentiles. By constructing prompts for the ChatGPT\nAPI, allowing the model to recommend majors based on high school student\nprofiles, I evaluate bias using various metrics, including the Jaccard\nCoefficient, Wasserstein Metric, and STEM Disparity Score. The results of this\nstudy reveal a significant disparity in the set of recommended college majors,\nirrespective of the bias metric applied.", "field": "Computer Science", "categories": "cs.CY,cs.AI"}, {"arxiv_id": "2401.117", "title": "Keep Decoding Parallel with Effective Knowledge Distillation from\n  Language Models to End-to-end Speech Recognisers", "abstract": "This study presents a novel approach for knowledge distillation (KD) from a\nBERT teacher model to an automatic speech recognition (ASR) model using\nintermediate layers. To distil the teacher's knowledge, we use an attention\ndecoder that learns from BERT's token probabilities. Our method shows that\nlanguage model (LM) information can be more effectively distilled into an ASR\nmodel using both the intermediate layers and the final layer. By using the\nintermediate layers as distillation target, we can more effectively distil LM\nknowledge into the lower network layers. Using our method, we achieve better\nrecognition accuracy than with shallow fusion of an external LM, allowing us to\nmaintain fast parallel decoding. Experiments on the LibriSpeech dataset\ndemonstrate the effectiveness of our approach in enhancing greedy decoding with\nconnectionist temporal classification (CTC).", "field": "Computer Science", "categories": "cs.CL,cs.SD,eess.AS"}, {"arxiv_id": "2401.11704", "title": "EK-Net:Real-time Scene Text Detection with Expand Kernel Distance", "abstract": "Recently, scene text detection has received significant attention due to its\nwide application. However, accurate detection in complex scenes of multiple\nscales, orientations, and curvature remains a challenge. Numerous detection\nmethods adopt the Vatti clipping (VC) algorithm for multiple-instance training\nto address the issue of arbitrary-shaped text. Yet we identify several bias\nresults from these approaches called the \"shrinked kernel\". Specifically, it\nrefers to a decrease in accuracy resulting from an output that overly favors\nthe text kernel. In this paper, we propose a new approach named Expand Kernel\nNetwork (EK-Net) with expand kernel distance to compensate for the previous\ndeficiency, which includes three-stages regression to complete instance\ndetection. Moreover, EK-Net not only realize the precise positioning of\narbitrary-shaped text, but also achieve a trade-off between performance and\nspeed. Evaluation results demonstrate that EK-Net achieves state-of-the-art or\ncompetitive performance compared to other advanced methods, e.g., F-measure of\n85.72% at 35.42 FPS on ICDAR 2015, F-measure of 85.75% at 40.13 FPS on CTW1500.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11705", "title": "Domain-Aware Cross-Attention for Cross-domain Recommendation", "abstract": "Cross-domain recommendation (CDR) is an important method to improve\nrecommender system performance, especially when observations in target domains\nare sparse. However, most existing cross-domain recommendations fail to fully\nutilize the target domain's special features and are hard to be generalized to\nnew domains. The designed network is complex and is not suitable for rapid\nindustrial deployment. Our method introduces a two-step domain-aware\ncross-attention, extracting transferable features of the source domain from\ndifferent granularity, which allows the efficient expression of both domain and\nuser interests. In addition, we simplify the training process, and our model\ncan be easily deployed on new domains. We conduct experiments on both public\ndatasets and industrial datasets, and the experimental results demonstrate the\neffectiveness of our method. We have also deployed the model in an online\nadvertising system and observed significant improvements in both\nClick-Through-Rate (CTR) and effective cost per mille (ECPM).", "field": "Computer Science", "categories": "cs.IR,cs.AI"}, {"arxiv_id": "2401.11708", "title": "Mastering Text-to-Image Diffusion: Recaptioning, Planning, and\n  Generating with Multimodal LLMs", "abstract": "Diffusion models have exhibit exceptional performance in text-to-image\ngeneration and editing. However, existing methods often face challenges when\nhandling complex text prompts that involve multiple objects with multiple\nattributes and relationships. In this paper, we propose a brand new\ntraining-free text-to-image generation/editing framework, namely Recaption,\nPlan and Generate (RPG), harnessing the powerful chain-of-thought reasoning\nability of multimodal LLMs to enhance the compositionality of text-to-image\ndiffusion models. Our approach employs the MLLM as a global planner to\ndecompose the process of generating complex images into multiple simpler\ngeneration tasks within subregions. We propose complementary regional diffusion\nto enable region-wise compositional generation. Furthermore, we integrate\ntext-guided image generation and editing within the proposed RPG in a\nclosed-loop fashion, thereby enhancing generalization ability. Extensive\nexperiments demonstrate our RPG outperforms state-of-the-art text-to-image\ndiffusion models, including DALL-E 3 and SDXL, particularly in multi-category\nobject composition and text-image semantic alignment. Notably, our RPG\nframework exhibits wide compatibility with various MLLM architectures (e.g.,\nMiniGPT-4) and diffusion backbones (e.g., ControlNet). Our code is available\nat: https://github.com/YangLing0818/RPG-DiffusionMaster", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11709", "title": "Haptic-Assisted Collaborative Robot Framework for Improved Situational\n  Awareness in Skull Base Surgery", "abstract": "Skull base surgery is a demanding field in which surgeons operate in and\naround the skull while avoiding critical anatomical structures including nerves\nand vasculature. While image-guided surgical navigation is the prevailing\nstandard, limitation still exists requiring personalized planning and\nrecognizing the irreplaceable role of a skilled surgeon. This paper presents a\ncollaboratively controlled robotic system tailored for assisted drilling in\nskull base surgery. Our central hypothesis posits that this collaborative\nsystem, enriched with haptic assistive modes to enforce virtual fixtures, holds\nthe potential to significantly enhance surgical safety, streamline efficiency,\nand alleviate the physical demands on the surgeon. The paper describes the\nintricate system development work required to enable these virtual fixtures\nthrough haptic assistive modes. To validate our system's performance and\neffectiveness, we conducted initial feasibility experiments involving a medical\nstudent and two experienced surgeons. The experiment focused on drilling around\ncritical structures following cortical mastoidectomy, utilizing dental stone\nphantom and cadaveric models. Our experimental results demonstrate that our\nproposed haptic feedback mechanism enhances the safety of drilling around\ncritical structures compared to systems lacking haptic assistance. With the aid\nof our system, surgeons were able to safely skeletonize the critical structures\nwithout breaching any critical structure even under obstructed view of the\nsurgical site.", "field": "Computer Science", "categories": "cs.RO,cs.SY,eess.SY"}, {"arxiv_id": "2401.11711", "title": "HG3-NeRF: Hierarchical Geometric, Semantic, and Photometric Guided\n  Neural Radiance Fields for Sparse View Inputs", "abstract": "Neural Radiance Fields (NeRF) have garnered considerable attention as a\nparadigm for novel view synthesis by learning scene representations from\ndiscrete observations. Nevertheless, NeRF exhibit pronounced performance\ndegradation when confronted with sparse view inputs, consequently curtailing\nits further applicability. In this work, we introduce Hierarchical Geometric,\nSemantic, and Photometric Guided NeRF (HG3-NeRF), a novel methodology that can\naddress the aforementioned limitation and enhance consistency of geometry,\nsemantic content, and appearance across different views. We propose\nHierarchical Geometric Guidance (HGG) to incorporate the attachment of\nStructure from Motion (SfM), namely sparse depth prior, into the scene\nrepresentations. Different from direct depth supervision, HGG samples volume\npoints from local-to-global geometric regions, mitigating the misalignment\ncaused by inherent bias in the depth prior. Furthermore, we draw inspiration\nfrom notable variations in semantic consistency observed across images of\ndifferent resolutions and propose Hierarchical Semantic Guidance (HSG) to learn\nthe coarse-to-fine semantic content, which corresponds to the coarse-to-fine\nscene representations. Experimental results demonstrate that HG3-NeRF can\noutperform other state-of-the-art methods on different standard benchmarks and\nachieve high-fidelity synthesis results for sparse view inputs.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11712", "title": "A First Step Towards Runtime Analysis of Evolutionary Neural\n  Architecture Search", "abstract": "Evolutionary neural architecture search (ENAS) employs evolutionary\nalgorithms to find high-performing neural architectures automatically, and has\nachieved great success. However, compared to the empirical success, its\nrigorous theoretical analysis has yet to be touched. This work goes preliminary\nsteps toward the mathematical runtime analysis of ENAS. In particular, we\ndefine a binary classification problem UNIFORM, and formulate an explicit\nfitness function to represent the relationship between neural architecture and\nclassification accuracy. Furthermore, we consider (1+1)-ENAS algorithm with\nmutation to optimize the neural architecture, and obtain the following runtime\nbounds: 1) the one-bit mutation finds the optimum in an expected runtime of\n$O(n)$ and $\\Omega(\\log n)$; 2) the multi-bit mutation finds the optimum in an\nexpected runtime of $\\Theta(n)$. These theoretical results show that one-bit\nand multi-bit mutations achieve nearly the same performance on UNIFORM. We\nprovide insight into the choices of mutation in the ENAS community: although\nmulti-bit mutation can change the step size to prevent a local trap, this may\nnot always improve runtime. Empirical results also verify the equivalence of\nthese two mutation operators. This work begins the runtime analysis of ENAS,\nlaying the foundation for further theoretical studies to guide the design of\nENAS.", "field": "Computer Science", "categories": "cs.NE"}, {"arxiv_id": "2401.11713", "title": "Medical Image Debiasing by Learning Adaptive Agreement from a Biased\n  Council", "abstract": "Deep learning could be prone to learning shortcuts raised by dataset bias and\nresult in inaccurate, unreliable, and unfair models, which impedes its adoption\nin real-world clinical applications. Despite its significance, there is a\ndearth of research in the medical image classification domain to address\ndataset bias. Furthermore, the bias labels are often agnostic, as identifying\nbiases can be laborious and depend on post-hoc interpretation. This paper\nproposes learning Adaptive Agreement from a Biased Council (Ada-ABC), a\ndebiasing framework that does not rely on explicit bias labels to tackle\ndataset bias in medical images. Ada-ABC develops a biased council consisting of\nmultiple classifiers optimized with generalized cross entropy loss to learn the\ndataset bias. A debiasing model is then simultaneously trained under the\nguidance of the biased council. Specifically, the debiasing model is required\nto learn adaptive agreement with the biased council by agreeing on the\ncorrectly predicted samples and disagreeing on the wrongly predicted samples by\nthe biased council. In this way, the debiasing model could learn the target\nattribute on the samples without spurious correlations while also avoiding\nignoring the rich information in samples with spurious correlations. We\ntheoretically demonstrated that the debiasing model could learn the target\nfeatures when the biased model successfully captures dataset bias. Moreover, to\nour best knowledge, we constructed the first medical debiasing benchmark from\nfour datasets containing seven different bias scenarios. Our extensive\nexperiments practically showed that our proposed Ada-ABC outperformed\ncompetitive approaches, verifying its effectiveness in mitigating dataset bias\nfor medical image classification. The codes and organized benchmark datasets\nwill be made publicly available.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.11714", "title": "Conjugate Direction Methods Under Inconsistent Systems", "abstract": "Since the development of the conjugate gradient (CG) method in 1952 by\nHestenes and Stiefel, CG, has become an indispensable tool in computational\nmathematics for solving positive definite linear systems. On the other hand,\nthe conjugate residual (CR) method, closely related CG and introduced by\nStiefel in 1955 for the same settings, remains relatively less known outside\nthe numerical linear algebra community. Since their inception, these methods --\nhenceforth collectively referred to as conjugate direction methods -- have been\nextended beyond positive definite to indefinite, albeit consistent, settings.\nGoing one step further, in this paper, we investigate theoretical and empirical\nproperties of these methods under inconsistent systems. Among other things, we\nshow that small modifications to the original algorithms allow for the\npseudo-inverse solution. Furthermore, we show that CR is essentially equivalent\nto the minimum residual method, proposed by Paige and Saunders in 1975, in such\ncontexts. Lastly, we conduct a series of numerical experiments to shed lights\non their numerical stability (or lack thereof) and their performance for\ninconsistent systems. Surprisingly, we will demonstrate that, unlike CR and\ncontrary to popular belief, CG can exhibit significant numerical instability,\nbordering on catastrophe in some instances.", "field": "Computer Science", "categories": "math.NA,cs.NA"}, {"arxiv_id": "2401.11715", "title": "Integrating 3D Slicer with a Dynamic Simulator for Situational Aware\n  Robotic Interventions", "abstract": "Image-guided robotic interventions represent a transformative frontier in\nsurgery, blending advanced imaging and robotics for improved precision and\noutcomes. This paper addresses the critical need for integrating open-source\nplatforms to enhance situational awareness in image-guided robotic research. We\npresent an open-source toolset that seamlessly combines a physics-based\nconstraint formulation framework, AMBF, with a state-of-the-art imaging\nplatform application, 3D Slicer. Our toolset facilitates the creation of highly\ncustomizable interactive digital twins, that incorporates processing and\nvisualization of medical imaging, robot kinematics, and scene dynamics for\nreal-time robot control. Through a feasibility study, we showcase real-time\nsynchronization of a physical robotic interventional environment in both 3D\nSlicer and AMBF, highlighting low-latency updates and improved visualization.", "field": "Computer Science", "categories": "cs.RO,cs.SY,eess.SY"}, {"arxiv_id": "2401.11718", "title": "MsSVT++: Mixed-scale Sparse Voxel Transformer with Center Voting for 3D\n  Object Detection", "abstract": "Accurate 3D object detection in large-scale outdoor scenes, characterized by\nconsiderable variations in object scales, necessitates features rich in both\nlong-range and fine-grained information. While recent detectors have utilized\nwindow-based transformers to model long-range dependencies, they tend to\noverlook fine-grained details. To bridge this gap, we propose MsSVT++, an\ninnovative Mixed-scale Sparse Voxel Transformer that simultaneously captures\nboth types of information through a divide-and-conquer approach. This approach\ninvolves explicitly dividing attention heads into multiple groups, each\nresponsible for attending to information within a specific range. The outputs\nof these groups are subsequently merged to obtain final mixed-scale features.\nTo mitigate the computational complexity associated with applying a\nwindow-based transformer in 3D voxel space, we introduce a novel Chessboard\nSampling strategy and implement voxel sampling and gathering operations\nsparsely using a hash map. Moreover, an important challenge stems from the\nobservation that non-empty voxels are primarily located on the surface of\nobjects, which impedes the accurate estimation of bounding boxes. To overcome\nthis challenge, we introduce a Center Voting module that integrates newly voted\nvoxels enriched with mixed-scale contextual information towards the centers of\nthe objects, thereby improving precise object localization. Extensive\nexperiments demonstrate that our single-stage detector, built upon the\nfoundation of MsSVT++, consistently delivers exceptional performance across\ndiverse datasets.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11719", "title": "SFC: Shared Feature Calibration in Weakly Supervised Semantic\n  Segmentation", "abstract": "Image-level weakly supervised semantic segmentation has received increasing\nattention due to its low annotation cost. Existing methods mainly rely on Class\nActivation Mapping (CAM) to obtain pseudo-labels for training semantic\nsegmentation models. In this work, we are the first to demonstrate that\nlong-tailed distribution in training data can cause the CAM calculated through\nclassifier weights over-activated for head classes and under-activated for tail\nclasses due to the shared features among head- and tail- classes. This degrades\npseudo-label quality and further influences final semantic segmentation\nperformance. To address this issue, we propose a Shared Feature Calibration\n(SFC) method for CAM generation. Specifically, we leverage the class prototypes\nthat carry positive shared features and propose a Multi-Scaled\nDistribution-Weighted (MSDW) consistency loss for narrowing the gap between the\nCAMs generated through classifier weights and class prototypes during training.\nThe MSDW loss counterbalances over-activation and under-activation by\ncalibrating the shared features in head-/tail-class classifier weights.\nExperimental results show that our SFC significantly improves CAM boundaries\nand achieves new state-of-the-art performances. The project is available at\nhttps://github.com/Barrett-python/SFC.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.1172", "title": "Graph Condensation: A Survey", "abstract": "The burgeoning volume of graph data poses significant challenges in storage,\ntransmission, and particularly the training of graph neural networks (GNNs). To\naddress these challenges, graph condensation (GC) has emerged as an innovative\nsolution. GC focuses on synthesizing a compact yet highly representative graph,\non which GNNs can achieve performance comparable to trained on the large\noriginal graph. The notable efficacy of GC and its broad prospects have\ngarnered significant attention and spurred extensive research. This survey\npaper provides an up-to-date and systematic overview of GC, organizing existing\nresearch into four categories aligned with critical GC evaluation criteria:\neffectiveness, generalization, fairness, and efficiency. To facilitate an\nin-depth and comprehensive understanding of GC, we examine various methods\nunder each category and thoroughly discuss two essential components within GC:\noptimization strategies and condensed graph generation. Additionally, we\nintroduce the applications of GC in a variety of fields, and highlight the\npresent challenges and novel insights in GC, promoting advancements in future\nresearch.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.11721", "title": "Beyond the Manual Touch: Situational-aware Force Control for Increased\n  Safety in Robot-assisted Skullbase Surgery", "abstract": "Purpose - Skullbase surgery demands exceptional precision when removing bone\nin the lateral skull base. Robotic assistance can alleviate the effect of human\nsensory-motor limitations. However, the stiffness and inertia of the robot can\nsignificantly impact the surgeon's perception and control of the tool-to-tissue\ninteraction forces. Methods - We present a situational-aware, force control\ntechnique aimed at regulating interaction forces during robot-assisted\nskullbase drilling. The contextual interaction information derived from the\ndigital twin environment is used to enhance sensory perception and suppress\nundesired high forces. Results - To validate our approach, we conducted initial\nfeasibility experiments involving a medical and two engineering students. The\nexperiment focused on further drilling around critical structures following\ncortical mastoidectomy. The experiment results demonstrate that robotic\nassistance coupled with our proposed control scheme effectively limited\nundesired interaction forces when compared to robotic assistance without the\nproposed force control. Conclusions - The proposed force control techniques\nshow promise in significantly reducing undesired interaction forces during\nrobot-assisted skullbase surgery. These findings contribute to the ongoing\nefforts to enhance surgical precision and safety in complex procedures\ninvolving the lateral skull base.", "field": "Computer Science", "categories": "cs.RO,cs.SY,eess.SY"}, {"arxiv_id": "2401.11723", "title": "Unraveling Attacks in Machine Learning-based IoT Ecosystems: A Survey\n  and the Open Libraries Behind Them", "abstract": "The advent of the Internet of Things (IoT) has brought forth an era of\nunprecedented connectivity, with an estimated 80 billion smart devices expected\nto be in operation by the end of 2025. These devices facilitate a multitude of\nsmart applications, enhancing the quality of life and efficiency across various\ndomains. Machine Learning (ML) serves as a crucial technology, not only for\nanalyzing IoT-generated data but also for diverse applications within the IoT\necosystem. For instance, ML finds utility in IoT device recognition, anomaly\ndetection, and even in uncovering malicious activities. This paper embarks on a\ncomprehensive exploration of the security threats arising from ML's integration\ninto various facets of IoT, spanning various attack types including membership\ninference, adversarial evasion, reconstruction, property inference, model\nextraction, and poisoning attacks. Unlike previous studies, our work offers a\nholistic perspective, categorizing threats based on criteria such as adversary\nmodels, attack targets, and key security attributes (confidentiality,\navailability, and integrity). We delve into the underlying techniques of ML\nattacks in IoT environment, providing a critical evaluation of their mechanisms\nand impacts. Furthermore, our research thoroughly assesses 65 libraries, both\nauthor-contributed and third-party, evaluating their role in safeguarding model\nand data privacy. We emphasize the availability and usability of these\nlibraries, aiming to arm the community with the necessary tools to bolster\ntheir defenses against the evolving threat landscape. Through our comprehensive\nreview and analysis, this paper seeks to contribute to the ongoing discourse on\nML-based IoT security, offering valuable insights and practical solutions to\nsecure ML models and data in the rapidly expanding field of artificial\nintelligence in IoT.", "field": "Computer Science", "categories": "cs.CR,cs.AI"}, {"arxiv_id": "2401.11724", "title": "Augmenting Prototype Network with TransMix for Few-shot Hyperspectral\n  Image Classification", "abstract": "Few-shot hyperspectral image classification aims to identify the classes of\neach pixel in the images by only marking few of these pixels. And in order to\nobtain the spatial-spectral joint features of each pixel, the fixed-size\npatches centering around each pixel are often used for classification. However,\nobserving the classification results of existing methods, we found that\nboundary patches corresponding to the pixels which are located at the boundary\nof the objects in the hyperspectral images, are hard to classify. These\nboundary patchs are mixed with multi-class spectral information. Inspired by\nthis, we propose to augment the prototype network with TransMix for few-shot\nhyperspectrial image classification(APNT). While taking the prototype network\nas the backbone, it adopts the transformer as feature extractor to learn the\npixel-to-pixel relation and pay different attentions to different pixels. At\nthe same time, instead of directly using the patches which are cut from the\nhyperspectral images for training, it randomly mixs up two patches to imitate\nthe boundary patches and uses the synthetic patches to train the model, with\nthe aim to enlarge the number of hard training samples and enhance their\ndiversity. And by following the data agumentation technique TransMix, the\nattention returned by the transformer is also used to mix up the labels of two\npatches to generate better labels for synthetic patches. Compared with existing\nmethods, the proposed method has demonstrated sate of the art performance and\nbetter robustness for few-shot hyperspectral image classification in our\nexperiments.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.11725", "title": "Speak It Out: Solving Symbol-Related Problems with Symbol-to-Language\n  Conversion for Language Models", "abstract": "Symbols (or more broadly, non-natural language textual representations) such\nas numerical sequences, molecular formulas, and table delimiters widely exist,\nplaying important roles in various tasks such as abstract reasoning, chemical\nproperty prediction, and table question answering. Despite the impressive\nnatural language comprehension capabilities of large language models (LLMs),\ntheir reasoning abilities for symbols remain inadequate, which could attributed\nto the difference between symbol representations and general natural languages.\nWe propose symbol-to-language (S2L), a tuning-free method that enables large\nlanguage models to solve symbol-related problems with information expressed in\nnatural language. Specifically, S2L first converts the symbols involved to\nlanguage-based representations, which can be implemented by prompting LLMs or\nleveraging external tools, then these language-based representations are\nintegrated into the original problem via direct substitution or concatenation,\nserving as useful input information for LLMs. We evaluate the S2L method using\nboth API-based (GPT-4, ChatGPT) and open-source (OpenChat) models over eight\nsymbol-related tasks, ranging from symbol-only abstract reasoning to sentiment\nanalysis in social media. Experimental results show that S2L consistently leads\nto superior performance. For example, by employing S2L for GPT-4, there can be\naverage significant improvements of +21.9% and +9.5% for subtasks in 1D-ARC and\nDyck language, respectively. Codes and data are available at\nhttps://github.com/THUNLP-MT/symbol2language.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.11726", "title": "Detecting Out-of-Distribution Samples via Conditional Distribution\n  Entropy with Optimal Transport", "abstract": "When deploying a trained machine learning model in the real world, it is\ninevitable to receive inputs from out-of-distribution (OOD) sources. For\ninstance, in continual learning settings, it is common to encounter OOD samples\ndue to the non-stationarity of a domain. More generally, when we have access to\na set of test inputs, the existing rich line of OOD detection solutions,\nespecially the recent promise of distance-based methods, falls short in\neffectively utilizing the distribution information from training samples and\ntest inputs. In this paper, we argue that empirical probability distributions\nthat incorporate geometric information from both training samples and test\ninputs can be highly beneficial for OOD detection in the presence of test\ninputs available. To address this, we propose to model OOD detection as a\ndiscrete optimal transport problem. Within the framework of optimal transport,\nwe propose a novel score function known as the \\emph{conditional distribution\nentropy} to quantify the uncertainty of a test input being an OOD sample. Our\nproposal inherits the merits of certain distance-based methods while\neliminating the reliance on distribution assumptions, a-prior knowledge, and\nspecific training mechanisms. Extensive experiments conducted on benchmark\ndatasets demonstrate that our method outperforms its competitors in OOD\ndetection.", "field": "Computer Science", "categories": "cs.LG,cs.CV"}, {"arxiv_id": "2401.1173", "title": "Massive Synchrony in Distributed Antenna Systems", "abstract": "Distributed antennas must be phase-calibrated (phase-synchronized) for\ncertain operations, such as reciprocity-based joint coherent downlink\nbeamforming, to work. We use rigorous signal processing tools to analyze the\naccuracy of calibration protocols that are based on over-the-air measurements\nbetween antennas, with a focus on scalability aspects for large systems. We\nshow that (i) for some who-measures-on-whom topologies, the errors in the\ncalibration process are unbounded when the network grows; and (ii) despite that\nconclusion, it is optimal -- irrespective of the topology -- to solve a single\ncalibration problem for the entire system and use the result everywhere to\nsupport the beamforming. The analyses are exemplified by investigating specific\ntopologies, including lines, rings, and two-dimensional surfaces.", "field": "Computer Science", "categories": "cs.IT,eess.SP,math.IT"}, {"arxiv_id": "2401.11731", "title": "Fast and Scalable Network Slicing by Integrating Deep Learning with\n  Lagrangian Methods", "abstract": "Network slicing is a key technique in 5G and beyond for efficiently\nsupporting diverse services. Many network slicing solutions rely on deep\nlearning to manage complex and high-dimensional resource allocation problems.\nHowever, deep learning models suffer limited generalization and adaptability to\ndynamic slicing configurations. In this paper, we propose a novel framework\nthat integrates constrained optimization methods and deep learning models,\nresulting in strong generalization and superior approximation capability. Based\non the proposed framework, we design a new neural-assisted algorithm to\nallocate radio resources to slices to maximize the network utility under\ninter-slice resource constraints. The algorithm exhibits high scalability,\naccommodating varying numbers of slices and slice configurations with ease. We\nimplement the proposed solution in a system-level network simulator and\nevaluate its performance extensively by comparing it to state-of-the-art\nsolutions including deep reinforcement learning approaches. The numerical\nresults show that our solution obtains near-optimal quality-of-service\nsatisfaction and promising generalization performance under different network\nslicing scenarios.", "field": "Computer Science", "categories": "cs.NI,cs.AI,cs.LG"}, {"arxiv_id": "2401.11734", "title": "Colorectal Polyp Segmentation in the Deep Learning Era: A Comprehensive\n  Survey", "abstract": "Colorectal polyp segmentation (CPS), an essential problem in medical image\nanalysis, has garnered growing research attention. Recently, the deep\nlearning-based model completely overwhelmed traditional methods in the field of\nCPS, and more and more deep CPS methods have emerged, bringing the CPS into the\ndeep learning era. To help the researchers quickly grasp the main techniques,\ndatasets, evaluation metrics, challenges, and trending of deep CPS, this paper\npresents a systematic and comprehensive review of deep-learning-based CPS\nmethods from 2014 to 2023, a total of 115 technical papers. In particular, we\nfirst provide a comprehensive review of the current deep CPS with a novel\ntaxonomy, including network architectures, level of supervision, and learning\nparadigm. More specifically, network architectures include eight subcategories,\nthe level of supervision comprises six subcategories, and the learning paradigm\nencompasses 12 subcategories, totaling 26 subcategories. Then, we provided a\ncomprehensive analysis the characteristics of each dataset, including the\nnumber of datasets, annotation types, image resolution, polyp size, contrast\nvalues, and polyp location. Following that, we summarized CPS's commonly used\nevaluation metrics and conducted a detailed analysis of 40 deep SOTA models,\nincluding out-of-distribution generalization and attribute-based performance\nanalysis. Finally, we discussed deep learning-based CPS methods' main\nchallenges and opportunities.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11735", "title": "zkLogin: Privacy-Preserving Blockchain Authentication with Existing\n  Credentials", "abstract": "For many users, a private key based wallet serves as the primary entry point\nto blockchains. Commonly recommended wallet authentication methods, such as\nmnemonics or hardware wallets, can be cumbersome. This difficulty in user\nonboarding has significantly hindered the adoption of blockchain-based\napplications.\n  We develop zkLogin, a novel technique that leverages identity tokens issued\nby popular platforms (any OpenID Connect enabled platform e.g. Google,\nFacebook, etc.) to authenticate transactions. At the heart of zkLogin lies a\nsignature scheme allowing the signer to \\textit{sign using their existing\nOpenID accounts} and nothing else. This improves the user experience\nsignificantly as users do not need to remember a new secret and can reuse their\nexisting accounts.\n  zkLogin provides strong security and privacy guarantees. By design, zkLogin\nbuilds on top of the underlying platform's authentication mechanisms, and\nderives its security from there. Unlike prior related works however, zkLogin\navoids the use of additional trusted parties (e.g., trusted hardware or\noracles) for its security guarantees. zkLogin leverages zero-knowledge proofs\n(ZKP) to ensure that the link between a user's off-chain and on-chain\nidentities is hidden, even from the platform itself.\n  We have implemented and deployed zkLogin on the Sui blockchain as an\nalternative to traditional digital signature-based addresses. Due to the ease\nof web3 on-boarding just with social login, without requiring mnemonics, many\nhundreds of thousands zkLogin accounts have already been generated in various\nindustries such as gaming, DeFi, direct payments, NFT collections, ride\nsharing, sports racing and many more.", "field": "Computer Science", "categories": "cs.CR"}, {"arxiv_id": "2401.11736", "title": "Attention on Personalized Clinical Decision Support System: Federated\n  Learning Approach", "abstract": "Health management has become a primary problem as new kinds of diseases and\ncomplex symptoms are introduced to a rapidly growing modern society. Building a\nbetter and smarter healthcare infrastructure is one of the ultimate goals of a\nsmart city. To the best of our knowledge, neural network models are already\nemployed to assist healthcare professionals in achieving this goal. Typically,\ntraining a neural network requires a rich amount of data but heterogeneous and\nvulnerable properties of clinical data introduce a challenge for the\ntraditional centralized network. Moreover, adding new inputs to a medical\ndatabase requires re-training an existing model from scratch. To tackle these\nchallenges, we proposed a deep learning-based clinical decision support system\ntrained and managed under a federated learning paradigm. We focused on a novel\nstrategy to guarantee the safety of patient privacy and overcome the risk of\ncyberattacks while enabling large-scale clinical data mining. As a result, we\ncan leverage rich clinical data for training each local neural network without\nthe need for exchanging the confidential data of patients. Moreover, we\nimplemented the proposed scheme as a sequence-to-sequence model architecture\nintegrating the attention mechanism. Thus, our objective is to provide a\npersonalized clinical decision support system with evolvable characteristics\nthat can deliver accurate solutions and assist healthcare professionals in\nmedical diagnosing.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.11737", "title": "Sphractal: Estimating the Fractal Dimension of Surfaces Computed from\n  Precise Atomic Coordinates via Box-Counting Algorithm", "abstract": "The fractal dimension of a surface allows its degree of roughness to be\ncharacterised quantitatively. However, limited effort has been attempted to\ncompute the fractal dimension of surfaces computed from precisely known atomic\ncoordinates from computational biomolecular and nanomaterial studies. This work\nproposes methods to estimate the fractal dimension of the surface of any\nthree-dimensional object composed of spheres, by representing it as either a\nvoxelised point cloud or a mathematically exact surface, and computing its\nbox-counting dimension. Sphractal is published as a Python package that\nprovides these functionalities, and its utility is demonstrated on a set of\nsimulated palladium nanoparticle data.", "field": "Computer Science", "categories": "cs.MS,physics.atom-ph,physics.comp-ph"}, {"arxiv_id": "2401.11738", "title": "MetaSeg: Content-Aware Meta-Net for Omni-Supervised Semantic\n  Segmentation", "abstract": "Noisy labels, inevitably existing in pseudo segmentation labels generated\nfrom weak object-level annotations, severely hampers model optimization for\nsemantic segmentation. Previous works often rely on massive hand-crafted losses\nand carefully-tuned hyper-parameters to resist noise, suffering poor\ngeneralization capability and high model complexity. Inspired by recent\nadvances in meta learning, we argue that rather than struggling to tolerate\nnoise hidden behind clean labels passively, a more feasible solution would be\nto find out the noisy regions actively, so as to simply ignore them during\nmodel optimization. With this in mind, this work presents a novel meta learning\nbased semantic segmentation method, MetaSeg, that comprises a primary\ncontent-aware meta-net (CAM-Net) to sever as a noise indicator for an arbitrary\nsegmentation model counterpart. Specifically, CAM-Net learns to generate\npixel-wise weights to suppress noisy regions with incorrect pseudo labels while\nhighlighting clean ones by exploiting hybrid strengthened features from image\ncontent, providing straightforward and reliable guidance for optimizing the\nsegmentation model. Moreover, to break the barrier of time-consuming training\nwhen applying meta learning to common large segmentation models, we further\npresent a new decoupled training strategy that optimizes different model layers\nin a divide-and-conquer manner. Extensive experiments on object, medical,\nremote sensing and human segmentation shows that our method achieves superior\nperformance, approaching that of fully supervised settings, which paves a new\npromising way for omni-supervised semantic segmentation.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11739", "title": "EmerDiff: Emerging Pixel-level Semantic Knowledge in Diffusion Models", "abstract": "Diffusion models have recently received increasing research attention for\ntheir remarkable transfer abilities in semantic segmentation tasks. However,\ngenerating fine-grained segmentation masks with diffusion models often requires\nadditional training on annotated datasets, leaving it unclear to what extent\npre-trained diffusion models alone understand the semantic relations of their\ngenerated images. To address this question, we leverage the semantic knowledge\nextracted from Stable Diffusion (SD) and aim to develop an image segmentor\ncapable of generating fine-grained segmentation maps without any additional\ntraining. The primary difficulty stems from the fact that semantically\nmeaningful feature maps typically exist only in the spatially lower-dimensional\nlayers, which poses a challenge in directly extracting pixel-level semantic\nrelations from these feature maps. To overcome this issue, our framework\nidentifies semantic correspondences between image pixels and spatial locations\nof low-dimensional feature maps by exploiting SD's generation process and\nutilizes them for constructing image-resolution segmentation maps. In extensive\nexperiments, the produced segmentation maps are demonstrated to be well\ndelineated and capture detailed parts of the images, indicating the existence\nof highly accurate pixel-level semantic knowledge in diffusion models.", "field": "Computer Science", "categories": "cs.CV,cs.LG"}, {"arxiv_id": "2401.1174", "title": "Multi-level Cross-modal Alignment for Image Clustering", "abstract": "Recently, the cross-modal pretraining model has been employed to produce\nmeaningful pseudo-labels to supervise the training of an image clustering\nmodel. However, numerous erroneous alignments in a cross-modal pre-training\nmodel could produce poor-quality pseudo-labels and degrade clustering\nperformance. To solve the aforementioned issue, we propose a novel\n\\textbf{Multi-level Cross-modal Alignment} method to improve the alignments in\na cross-modal pretraining model for downstream tasks, by building a smaller but\nbetter semantic space and aligning the images and texts in three levels, i.e.,\ninstance-level, prototype-level, and semantic-level. Theoretical results show\nthat our proposed method converges, and suggests effective means to reduce the\nexpected clustering risk of our method. Experimental results on five benchmark\ndatasets clearly show the superiority of our new method.", "field": "Computer Science", "categories": "cs.CV,cs.LG"}, {"arxiv_id": "2401.11742", "title": "Knowledge Navigation: Inferring the Interlocking Map of Knowledge from\n  Research Trajectories", "abstract": "\"If I have seen further, it is by standing on the shoulders of giants,\" Isaac\nNewton's renowned statement hints that new knowledge builds upon existing\nfoundations, which means there exists an interdependent relationship between\nknowledge, which, yet uncovered, is implied in the historical development of\nscientific systems for hundreds of years. By leveraging natural language\nprocessing techniques, this study introduces an innovative embedding scheme\ndesigned to infer the \"knowledge interlocking map.\" This map, derived from the\nresearch trajectories of millions of scholars, reveals the intricate\nconnections among knowledge. We validate that the inferred map effectively\ndelineates disciplinary boundaries and captures the intricate relationships\nbetween diverse concepts. The utility of the interlocking map is showcased\nthrough multiple applications. Firstly, we demonstrated the multi-step analogy\ninferences within the knowledge space and the functional connectivity between\nconcepts in different disciplines. Secondly, we trace the evolution of\nknowledge across domains, observing trends such as shifts from \"Theoretical\" to\n\"Applied\" or \"Chemistry\" to \"Biomedical\" along predefined functional\ndirections. Lastly, by analyzing the high-dimensional knowledge network\nstructure, we found that knowledge connects each other with shorter global\npathways, and the interdisciplinary knowledge plays a critical role in\naccessibility of the global knowledge network. Our framework offers a novel\napproach to mining knowledge inheritance pathways in extensive scientific\nliterature, which is of great significance for understanding scientific\ndevelopment patterns, tailoring scientific learning trajectories, and\naccelerating scientific progress.", "field": "Computer Science", "categories": "cs.IR,cs.DL,stat.AP"}, {"arxiv_id": "2401.11748", "title": "GI-PIP: Do We Require Impractical Auxiliary Dataset for Gradient\n  Inversion Attacks?", "abstract": "Deep gradient inversion attacks expose a serious threat to Federated Learning\n(FL) by accurately recovering private data from shared gradients. However, the\nstate-of-the-art heavily relies on impractical assumptions to access excessive\nauxiliary data, which violates the basic data partitioning principle of FL. In\nthis paper, a novel method, Gradient Inversion Attack using Practical Image\nPrior (GI-PIP), is proposed under a revised threat model. GI-PIP exploits\nanomaly detection models to capture the underlying distribution from fewer\ndata, while GAN-based methods consume significant more data to synthesize\nimages. The extracted distribution is then leveraged to regulate the attack\nprocess as Anomaly Score loss. Experimental results show that GI-PIP achieves a\n16.12 dB PSNR recovery using only 3.8\\% data of ImageNet, while GAN-based\nmethods necessitate over 70\\%. Moreover, GI-PIP exhibits superior capability on\ndistribution generalization compared to GAN-based methods. Our approach\nsignificantly alleviates the auxiliary data requirement on both amount and\ndistribution in gradient inversion attacks, hence posing more substantial\nthreat to real-world FL.", "field": "Computer Science", "categories": "cs.CR,cs.AI,cs.LG"}, {"arxiv_id": "2401.1175", "title": "AdaFGL: A New Paradigm for Federated Node Classification with Topology\n  Heterogeneity", "abstract": "Recently, Federated Graph Learning (FGL) has attracted significant attention\nas a distributed framework based on graph neural networks, primarily due to its\ncapability to break data silos. Existing FGL studies employ community split on\nthe homophilous global graph by default to simulate federated semi-supervised\nnode classification settings. Such a strategy assumes the consistency of\ntopology between the multi-client subgraphs and the global graph, where\nconnected nodes are highly likely to possess similar feature distributions and\nthe same label. However, in real-world implementations, the varying\nperspectives of local data engineering result in various subgraph topologies,\nposing unique heterogeneity challenges in FGL. Unlike the well-known label\nNon-independent identical distribution (Non-iid) problems in federated\nlearning, FGL heterogeneity essentially reveals the topological divergence\namong multiple clients, namely homophily or heterophily. To simulate and handle\nthis unique challenge, we introduce the concept of structure Non-iid split and\nthen present a new paradigm called \\underline{Ada}ptive \\underline{F}ederated\n\\underline{G}raph \\underline{L}earning (AdaFGL), a decoupled two-step\npersonalized approach. To begin with, AdaFGL employs standard multi-client\nfederated collaborative training to acquire the federated knowledge extractor\nby aggregating uploaded models in the final round at the server. Then, each\nclient conducts personalized training based on the local subgraph and the\nfederated knowledge extractor. Extensive experiments on the 12 graph benchmark\ndatasets validate the superior performance of AdaFGL over state-of-the-art\nbaselines. Specifically, in terms of test accuracy, our proposed AdaFGL\noutperforms baselines by significant margins of 3.24\\% and 5.57\\% on community\nsplit and structure Non-iid split, respectively.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.DB,cs.SI"}, {"arxiv_id": "2401.11751", "title": "Boosting Multi-view Stereo with Late Cost Aggregation", "abstract": "Pairwise matching cost aggregation is a crucial step for modern\nlearning-based Multi-view Stereo (MVS). Prior works adopt an early aggregation\nscheme, which adds up pairwise costs into an intermediate cost. However, we\nanalyze that this process can degrade informative pairwise matchings, thereby\nblocking the depth network from fully utilizing the original geometric matching\ncues.To address this challenge, we present a late aggregation approach that\nallows for aggregating pairwise costs throughout the network feed-forward\nprocess, achieving accurate estimations with only minor changes of the plain\nCasMVSNet.Instead of building an intermediate cost by weighted sum, late\naggregation preserves all pairwise costs along a distinct view channel. This\nenables the succeeding depth network to fully utilize the crucial geometric\ncues without loss of cost fidelity. Grounded in the new aggregation scheme, we\npropose further techniques addressing view order dependence inside the\npreserved cost, handling flexible testing views, and improving the depth\nfiltering process. Despite its technical simplicity, our method improves\nsignificantly upon the baseline cascade-based approach, achieving comparable\nresults with state-of-the-art methods with favorable computation overhead.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11752", "title": "Univalent Enriched Categories and the Enriched Rezk Completion", "abstract": "Enriched categories are categories whose sets of morphisms are enriched with\nextra structure. Such categories play a prominent role in the study of higher\ncategories, homotopy theory, and the semantics of programming languages. In\nthis paper, we study univalent enriched categories. We prove that all\nessentially surjective and fully faithful functors between univalent enriched\ncategories are equivalences, and we show that every enriched category admits a\nRezk completion. Finally, we use the Rezk completion for enriched categories to\nconstruct univalent enriched Kleisli categories.", "field": "Computer Science", "categories": "cs.LO,math.CT"}, {"arxiv_id": "2401.11753", "title": "From Knowledge Organization to Knowledge Representation and Back", "abstract": "Knowledge Organization (KO) and Knowledge Representation (KR) have been the\ntwo mainstream methodologies of knowledge modelling in the Information Science\ncommunity and the Artificial Intelligence community, respectively. The\nfacet-analytical tradition of KO has developed an exhaustive set of guiding\ncanons for ensuring quality in organising and managing knowledge but has\nremained limited in terms of technology-driven activities to expand its scope\nand services beyond the bibliographic universe of knowledge. KR, on the other\nhand, boasts of a robust ecosystem of technologies and technology-driven\nservice design which can be tailored to model any entity or scale to any\nservice in the entire universe of knowledge. This paper elucidates both the\nfacet-analytical KO and KR methodologies in detail and provides a functional\nmapping between them. Out of the mapping, the paper proposes an integrated\nKR-enriched KO methodology with all the standard components of a KO methodology\nplus the advanced technologies provided by the KR approach. The practical\nbenefits of the methodological integration has been exemplified through the\nflagship application of the Digital University at the University of Trento,\nItaly.", "field": "Computer Science", "categories": "cs.AI,cs.DL"}, {"arxiv_id": "2401.11755", "title": "FedGTA: Topology-aware Averaging for Federated Graph Learning", "abstract": "Federated Graph Learning (FGL) is a distributed machine learning paradigm\nthat enables collaborative training on large-scale subgraphs across multiple\nlocal systems. Existing FGL studies fall into two categories: (i) FGL\nOptimization, which improves multi-client training in existing machine learning\nmodels; (ii) FGL Model, which enhances performance with complex local models\nand multi-client interactions. However, most FGL optimization strategies are\ndesigned specifically for the computer vision domain and ignore graph\nstructure, presenting dissatisfied performance and slow convergence. Meanwhile,\ncomplex local model architectures in FGL Models studies lack scalability for\nhandling large-scale subgraphs and have deployment limitations. To address\nthese issues, we propose Federated Graph Topology-aware Aggregation (FedGTA), a\npersonalized optimization strategy that optimizes through topology-aware local\nsmoothing confidence and mixed neighbor features. During experiments, we deploy\nFedGTA in 12 multi-scale real-world datasets with the Louvain and Metis split.\nThis allows us to evaluate the performance and robustness of FedGTA across a\nrange of scenarios. Extensive experiments demonstrate that FedGTA achieves\nstate-of-the-art performance while exhibiting high scalability and efficiency.\nThe experiment includes ogbn-papers100M, the most representative large-scale\ngraph database so that we can verify the applicability of our method to\nlarge-scale graph learning. To the best of our knowledge, our study is the\nfirst to bridge large-scale graph learning with FGL using this optimization\nstrategy, contributing to the development of efficient and scalable FGL\nmethods.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.DB,cs.SI"}, {"arxiv_id": "2401.11759", "title": "Integrated Sensing, Communication, and Computing: An\n  Information-oriented Resource Transaction Mechanism", "abstract": "Information acquisition from target perception represents the key enabling\ntechnology of the Internet of Automatic Vehicles (IoAV), which is essential for\nthe decision-making and control operation of connected automatic vehicles\n(CAVs). Exploring target information involves multiple operations on data,\ne.g., wireless sensing (for data acquisition), communication (for data\ntransmission), and computing (for data analysis), which all rely on the\nconsumption of time-space-frequency-computing (TSFC) multi-domain resources.\nDue to the coupled resource sharing of sensing, communication, and computing\nprocedures, the resource management of information-oriented IoAV is commonly\nformulated as a non-convex NP-hard problem. In this article, further combining\nthe integrated sensing and communication (ISAC) and computing, we introduce the\nintegrated sensing, communication, and computing (ISCC), wherein the TSFC\nresources are decoupled from the specific processes and shared universally\namong sensing, communication, and computing processes. Furthermore, the\ninformation-oriented resource trading platform (IRTP) is established, which\ntransforms the problem of ISCC resource management into a resource-information\nsubstitution model. Finally, we embed the employment topology structure in IoAV\ninto neural network architecture, taking advantage of the graph neural network\n(GNN) and multi-worker reinforcement learning, and propose the dynamic resource\nmanagement strategy based on the asynchronous advantage GNN (A2GNN) algorithm,\nwhich can achieve the convergence both of information gain maximization and\nresource consumption minimization, realizing efficient information-oriented\nresource management.", "field": "Computer Science", "categories": "cs.DC"}, {"arxiv_id": "2401.1176", "title": "Towards Effective and General Graph Unlearning via Mutual Evolution", "abstract": "With the rapid advancement of AI applications, the growing needs for data\nprivacy and model robustness have highlighted the importance of machine\nunlearning, especially in thriving graph-based scenarios. However, most\nexisting graph unlearning strategies primarily rely on well-designed\narchitectures or manual process, rendering them less user-friendly and posing\nchallenges in terms of deployment efficiency. Furthermore, striking a balance\nbetween unlearning performance and framework generalization is also a pivotal\nconcern. To address the above issues, we propose \\underline{\\textbf{M}}utual\n\\underline{\\textbf{E}}volution \\underline{\\textbf{G}}raph\n\\underline{\\textbf{U}}nlearning (MEGU), a new mutual evolution paradigm that\nsimultaneously evolves the predictive and unlearning capacities of graph\nunlearning. By incorporating aforementioned two components, MEGU ensures\ncomplementary optimization in a unified training framework that aligns with the\nprediction and unlearning requirements. Extensive experiments on 9 graph\nbenchmark datasets demonstrate the superior performance of MEGU in addressing\nunlearning requirements at the feature, node, and edge levels. Specifically,\nMEGU achieves average performance improvements of 2.7\\%, 2.5\\%, and 3.2\\%\nacross these three levels of unlearning tasks when compared to state-of-the-art\nbaselines. Furthermore, MEGU exhibits satisfactory training efficiency,\nreducing time and space overhead by an average of 159.8x and 9.6x,\nrespectively, in comparison to retraining GNN from scratch.", "field": "Computer Science", "categories": "cs.LG,cs.NE,cs.SI"}, {"arxiv_id": "2401.11761", "title": "Data-oriented Coordinated Uplink Transmission for Massive IoT System", "abstract": "Recently, the paradigm of massive ultra-reliable low-latency IoT\ncommunications (URLLC-IoT) has gained growing interest. Reliable delay-critical\nuplink transmission in IoT is a challenging task since low-complex devices\ntypically do not support multiple antennas or demanding signal processing\ntasks. However, in many IoT services the data volumes are small and deployments\nmay include massive number of devices. We consider on a clustered uplink\ntransmission with two cooperation approaches: First, we focus on scenario where\nlocation-based channel knowledge map (CKM) is applied to enable cooperation.\nSecond, we consider a scenario where scarce channel side-information is applied\nin transmission. In both scenarios we also model and analyse the impact of\nerroneous information. In the performance evaluation we apply the recently\nintroduced data-oriented approach that has gathered significant attention in\nthe context of short-packet transmissions. Specifically, it introduces a\ntransient performance metric for small data transmissions, where the amount of\ndata and available bandwidth play crucial roles. Results show that cooperation\nbetween clustered IoT devices may provide notable benefits in terms of\nincreased range. It is noticed that the performance is heavily depending on the\nstrength of the static channel component in the CKM based cooperation. The\nchannel side-information based cooperation is robust against changes in the\nradio environment but sensitive to possible errors in the channel\nside-information. Even with large IoT device clusters, side-information errors\nmay set a limit for the use of services assuming high-reliability and\nlow-latency. Analytic results are verified against simulations, showing only\nminor differences at low probability levels.", "field": "Computer Science", "categories": "cs.IT,cs.NI,math.IT"}, {"arxiv_id": "2401.11764", "title": "Identity-Driven Multimedia Forgery Detection via Reference Assistance", "abstract": "Recent advancements in technologies, such as the 'deepfake' technique, have\npaved the way for the generation of various media forgeries. In response to the\npotential hazards of these media forgeries, many researchers engage in\nexploring detection methods, increasing the demand for high-quality media\nforgery datasets. Despite this, existing datasets have certain limitations.\nFirstly, most of datasets focus on the manipulation of visual modality and\nusually lack diversity, as only a few forgery approaches are considered.\nSecondly, the quality of media is often inadequate in clarity and naturalness.\nMeanwhile, the size of the dataset is also limited. Thirdly, while many\nreal-world forgeries are driven by identity, the identity information of the\nsubject in media is frequently neglected. For detection, identity information\ncould be an essential clue to boost accuracy. Moreover, official media\nconcerning certain identities on the Internet can serve as prior knowledge,\naiding both the audience and forgery detectors in determining the true\nidentity. Therefore, we propose an identity-driven multimedia forgery dataset,\nIDForge, which contains 249,138 video shots. All video shots are sourced from\n324 wild videos collected of 54 celebrities from the Internet. The fake video\nshots involve 9 types of manipulation across visual, audio and textual\nmodalities. Additionally, IDForge provides extra 214,438 real video shots as a\nreference set for the 54 celebrities. Correspondingly, we design an effective\nmultimedia detection network, Reference-assisted Multimodal Forgery Detection\nNetwork (R-MFDN). Through extensive experiments on the proposed dataset, we\ndemonstrate the effectiveness of R-MFDN on the multimedia detection task.", "field": "Computer Science", "categories": "cs.MM"}, {"arxiv_id": "2401.11767", "title": "Concealed Object Segmentation with Hierarchical Coherence Modeling", "abstract": "Concealed object segmentation (COS) is a challenging task that involves\nlocalizing and segmenting those concealed objects that are visually blended\nwith their surrounding environments. Despite achieving remarkable success,\nexisting COS segmenters still struggle to achieve complete segmentation results\nin extremely concealed scenarios. In this paper, we propose a Hierarchical\nCoherence Modeling (HCM) segmenter for COS, aiming to address this incomplete\nsegmentation limitation. In specific, HCM promotes feature coherence by\nleveraging the intra-stage coherence and cross-stage coherence modules,\nexploring feature correlations at both the single-stage and contextual levels.\nAdditionally, we introduce the reversible re-calibration decoder to detect\npreviously undetected parts in low-confidence regions, resulting in further\nenhancing segmentation performance. Extensive experiments conducted on three\nCOS tasks, including camouflaged object detection, polyp image segmentation,\nand transparent object detection, demonstrate the promising results achieved by\nthe proposed HCM segmenter.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11768", "title": "ADA-GNN: Atom-Distance-Angle Graph Neural Network for Crystal Material\n  Property Prediction", "abstract": "Property prediction is a fundamental task in crystal material research. To\nmodel atoms and structures, structures represented as graphs are widely used\nand graph learning-based methods have achieved significant progress. Bond\nangles and bond distances are two key structural information that greatly\ninfluence crystal properties. However, most of the existing works only consider\nbond distances and overlook bond angles. The main challenge lies in the time\ncost of handling bond angles, which leads to a significant increase in\ninference time. To solve this issue, we first propose a crystal structure\nmodeling based on dual scale neighbor partitioning mechanism, which uses a\nlarger scale cutoff for edge neighbors and a smaller scale cutoff for angle\nneighbors. Then, we propose a novel Atom-Distance-Angle Graph Neural Network\n(ADA-GNN) for property prediction tasks, which can process node information and\nstructural information separately. The accuracy of predictions and inference\ntime are improved with the dual scale modeling and the specially designed\narchitecture of ADA-GNN. The experimental results validate that our approach\nachieves state-of-the-art results in two large-scale material benchmark\ndatasets on property prediction tasks.", "field": "Computer Science", "categories": "cs.LG,cond-mat.mtrl-sci"}, {"arxiv_id": "2401.11772", "title": "LightDiC: A Simple yet Effective Approach for Large-scale Digraph\n  Representation Learning", "abstract": "Most existing graph neural networks (GNNs) are limited to undirected graphs,\nwhose restricted scope of the captured relational information hinders their\nexpressive capabilities and deployments in real-world scenarios. Compared with\nundirected graphs, directed graphs (digraphs) fit the demand for modeling more\ncomplex topological systems by capturing more intricate relationships between\nnodes, such as formulating transportation and financial networks. While some\ndirected GNNs have been introduced, their inspiration mainly comes from deep\nlearning architectures, which lead to redundant complexity and computation,\nmaking them inapplicable to large-scale databases. To address these issues, we\npropose LightDiC, a scalable variant of the digraph convolution based on the\nmagnetic Laplacian. Since topology-related computations are conducted solely\nduring offline pre-processing, LightDiC achieves exceptional scalability,\nenabling downstream predictions to be trained separately without incurring\nrecursive computational costs. Theoretical analysis shows that LightDiC\nutilizes directed information to achieve message passing based on the complex\nfield, which corresponds to the proximal gradient descent process of the\nDirichlet energy optimization function from the perspective of digraph signal\ndenoising, ensuring its expressiveness. Experimental results demonstrate that\nLightDiC performs comparably well or even outperforms other SOTA methods in\nvarious downstream tasks, with fewer learnable parameters and higher training\nefficiency. Notably, LightDiC is the first DiGNN to provide satisfactory\nresults in the most representative large-scale database (ogbn-papers100M).", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.SI"}, {"arxiv_id": "2401.11775", "title": "Collaborative Position Reasoning Network for Referring Image\n  Segmentation", "abstract": "Given an image and a natural language expression as input, the goal of\nreferring image segmentation is to segment the foreground masks of the entities\nreferred by the expression. Existing methods mainly focus on interactive\nlearning between vision and language to enhance the multi-modal representations\nfor global context reasoning. However, predicting directly in pixel-level space\ncan lead to collapsed positioning and poor segmentation results. Its main\nchallenge lies in how to explicitly model entity localization, especially for\nnon-salient entities. In this paper, we tackle this problem by executing a\nCollaborative Position Reasoning Network (CPRN) via the proposed novel\nRow-and-Column interactive (RoCo) and Guided Holistic interactive (Holi)\nmodules. Specifically, RoCo aggregates the visual features into the row- and\ncolumn-wise features corresponding two directional axes respectively. It offers\na fine-grained matching behavior that perceives the associations between the\nlinguistic features and two decoupled visual features to perform position\nreasoning over a hierarchical space. Holi integrates features of the two\nmodalities by a cross-modal attention mechanism, which suppresses the\nirrelevant redundancy under the guide of positioning information from RoCo.\nThus, with the incorporation of RoCo and Holi modules, CPRN captures the visual\ndetails of position reasoning so that the model can achieve more accurate\nsegmentation. To our knowledge, this is the first work that explicitly focuses\non position reasoning modeling. We also validate the proposed method on three\nevaluation datasets. It consistently outperforms existing state-of-the-art\nmethods.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11776", "title": "On the impact of robot personalization on human-robot interaction: A\n  review", "abstract": "This study reviews the impact of personalization on human-robot interaction.\nFirstly, the various strategies used to achieve personalization are briefly\ndescribed. Secondly, the effects of personalization known to date are\ndiscussed. They are presented along with the personalized parameters,\npersonalized features, used technology, and use case they relate to. It is\nobserved that various positive effects have been discussed in the literature\nwhile possible negative effects seem to require further investigation.", "field": "Computer Science", "categories": "cs.RO,I.2.9"}, {"arxiv_id": "2401.11779", "title": "Analyzing the coupling process of distributed mixed real-virtual\n  prototypes", "abstract": "The ongoing connection and automation of vehicles leads to a closer\ninteraction of the individual vehicle components, which demands for\nconsideration throughout the entire development process. In the design phase,\nthis is achieved through co-simulation of component models. However, complex\nco-simulation environments are rarely (re-)used in the verification and\nvalidation phases, in which mixed real-virtual prototypes (e.g.\nHardware-in-the-Loop) are already available. One reason for this are coupling\nerrors such as time-delays, which inevitably occur in co-simulation of virtual\nand real-time systems, and which influence system behavior in an unknown and\ngenerally detrimental way. This contribution introduces a novel, adaptive\nmethod to compensate for constant time-delays in potentially highly nonlinear,\nspatially distributed mixed real-virtual prototypes, using small feedforward\nneural networks. Their optimal initialization with respect to defined frequency\ndomain features results from a-priori frequency domain analysis of the entire\ncoupled system, including coupling faults and compensation methods. A linear\nand a nonlinear example demonstrate the method and emphasize its suitability\nfor nonlinear systems due to online training and adaptation. As the\ncompensation method requires knowledge only of the bandwidths, the proposed\nmethod is applicable to distributed mixed real-virtual prototypes in general.", "field": "Computer Science", "categories": "eess.SY,cs.SY"}, {"arxiv_id": "2401.11783", "title": "Full-Body Motion Reconstruction with Sparse Sensing from Graph\n  Perspective", "abstract": "Estimating 3D full-body pose from sparse sensor data is a pivotal technique\nemployed for the reconstruction of realistic human motions in Augmented Reality\nand Virtual Reality. However, translating sparse sensor signals into\ncomprehensive human motion remains a challenge since the sparsely distributed\nsensors in common VR systems fail to capture the motion of full human body. In\nthis paper, we use well-designed Body Pose Graph (BPG) to represent the human\nbody and translate the challenge into a prediction problem of graph missing\nnodes. Then, we propose a novel full-body motion reconstruction framework based\non BPG. To establish BPG, nodes are initially endowed with features extracted\nfrom sparse sensor signals. Features from identifiable joint nodes across\ndiverse sensors are amalgamated and processed from both temporal and spatial\nperspectives. Temporal dynamics are captured using the Temporal Pyramid\nStructure, while spatial relations in joint movements inform the spatial\nattributes. The resultant features serve as the foundational elements of the\nBPG nodes. To further refine the BPG, node features are updated through a graph\nneural network that incorporates edge reflecting varying joint relations. Our\nmethod's effectiveness is evidenced by the attained state-of-the-art\nperformance, particularly in lower body motion, outperforming other baseline\nmethods. Additionally, an ablation study validates the efficacy of each module\nin our proposed framework.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11786", "title": "EPIC: a provable accelerated Eigensolver based on Preconditioning and\n  Implicit Convexity", "abstract": "This paper is concerned with the extraction of the smallest eigenvalue and\nthe corresponding eigenvector of a symmetric positive definite matrix pencil.\nWe reveal implicit convexity of the eigenvalue problem in Euclidean space. A\nprovable accelerated eigensolver based on preconditioning and implicit\nconvexity (EPIC) is proposed. Theoretical analysis shows the acceleration of\nEPIC with the rate of convergence resembling the expected rate of convergence\nof the well-known locally optimal preconditioned conjugate gradient (LOPCG). A\ncomplete proof of the expected rate of convergence of LOPCG is elusive so far.\nNumerical results confirm our theoretical findings of EPIC.", "field": "Computer Science", "categories": "math.NA,cs.NA,15A08, 65F08, 65F15, 90C25"}, {"arxiv_id": "2401.11787", "title": "A Comparative Study of Numerical Methods for Approximating the Solutions\n  of a Macroscopic Automated-Vehicle Traffic Flow Model", "abstract": "In this paper, a particle method is used to approximate the solutions of a\n\"fluid-like\" macroscopic traffic flow model for automated vehicles. It is shown\nthat this method preserves certain differential inequalities that hold for the\nmacroscopic traffic model: mass is preserved, the mechanical energy is decaying\nand an energy functional is also decaying. To demonstrate the advantages of the\nparticle method under consideration, a comparison with other numerical methods\nfor viscous compressible fluid models is provided. Since the solutions of the\nmacroscopic traffic model can be approximated by the solutions of a reduced\nmodel consisting of a single nonlinear heat-type partial differential equation,\nthe numerical solutions produced by the particle method are also compared with\nthe numerical solutions of the reduced model. Finally, a traffic simulation\nscenario and a comparison with the Aw-Rascle-Zhang (ARZ) model are provided,\nillustrating the advantages of the use of automated vehicles.", "field": "Computer Science", "categories": "math.NA,cs.NA"}, {"arxiv_id": "2401.11788", "title": "Obtaining the pseudoinverse solution of singular range-symmetric linear\n  systems with GMRES-type methods", "abstract": "It is well known that for singular inconsistent range-symmetric linear\nsystems, the generalized minimal residual (GMRES) method determines a least\nsquares solution without breakdown. The reached least squares solution may be\nor not be the pseudoinverse solution. We show that a lift strategy can be used\nto obtain the pseudoinverse solution. In addition, we propose a new iterative\nmethod named RSMAR (minimum $\\mathbf A$-residual) for range-symmetric linear\nsystems $\\mathbf A\\mathbf x=\\mathbf b$. At step $k$ RSMAR minimizes $\\|\\mathbf\nA\\mathbf r_k\\|$ in the $k$th Krylov subspace generated with $\\{\\mathbf A,\n\\mathbf r_0\\}$ rather than $\\|\\mathbf r_k\\|$, where $\\mathbf r_k$ is the $k$th\nresidual vector and $\\|\\cdot\\|$ denotes the Euclidean vector norm. We show that\nRSMAR and GMRES terminate with the same least squares solution when applied to\nrange-symmetric linear systems. We provide two implementations for RSMAR. Our\nnumerical experiments show that RSMAR is the most suitable method among\nGMRES-type methods for singular inconsistent range-symmetric linear systems.", "field": "Computer Science", "categories": "math.NA,cs.NA,15A06, 15A09, 65F10, 65F25, 65F50"}, {"arxiv_id": "2401.1179", "title": "Deep Learning for Computer Vision based Activity Recognition and Fall\n  Detection of the Elderly: a Systematic Review", "abstract": "As the percentage of elderly people in developed countries increases\nworldwide, the healthcare of this collective is a worrying matter, especially\nif it includes the preservation of their autonomy. In this direction, many\nstudies are being published on Ambient Assisted Living (AAL) systems, which\nhelp to reduce the preoccupations raised by the independent living of the\nelderly. In this study, a systematic review of the literature is presented on\nfall detection and Human Activity Recognition (HAR) for the elderly, as the two\nmain tasks to solve to guarantee the safety of elderly people living alone. To\naddress the current tendency to perform these two tasks, the review focuses on\nthe use of Deep Learning (DL) based approaches on computer vision data. In\naddition, different collections of data like DL models, datasets or hardware\n(e.g. depth or thermal cameras) are gathered from the reviewed studies and\nprovided for reference in future studies. Strengths and weaknesses of existing\napproaches are also discussed and, based on them, our recommendations for\nfuture works are provided.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11791", "title": "SemPLeS: Semantic Prompt Learning for Weakly-Supervised Semantic\n  Segmentation", "abstract": "Weakly-Supervised Semantic Segmentation (WSSS) aims to train segmentation\nmodels using training image data with only image-level supervision. Since\nprecise pixel-level annotations are not accessible, existing methods typically\nfocus on producing pseudo masks for training segmentation models by refining\nCAM-like heatmaps. However, the produced heatmaps may only capture\ndiscriminative image regions of target object categories or the associated\nco-occurring backgrounds. To address the issues, we propose a Semantic Prompt\nLearning for WSSS (SemPLeS) framework, which learns to effectively prompt the\nCLIP space to enhance the semantic alignment between the segmented regions and\nthe target object categories. More specifically, we propose Contrastive Prompt\nLearning and Class-associated Semantic Refinement to learn the prompts that\nadequately describe and suppress the image backgrounds associated with each\ntarget object category. In this way, our proposed framework is able to perform\nbetter semantic matching between object regions and the associated text labels,\nresulting in desired pseudo masks for training the segmentation model. The\nproposed SemPLeS framework achieves SOTA performance on the standard WSSS\nbenchmarks, PASCAL VOC and MS COCO, and demonstrated interpretability with the\nsemantic visualization of our learned prompts. The codes will be released.", "field": "Computer Science", "categories": "cs.CV,cs.CL,cs.LG"}, {"arxiv_id": "2401.11792", "title": "Safe and Generalized end-to-end Autonomous Driving System with\n  Reinforcement Learning and Demonstrations", "abstract": "An intelligent driving system should be capable of dynamically formulating\nappropriate driving strategies based on the current environment and vehicle\nstatus, while ensuring the security and reliability of the system. However,\nexisting methods based on reinforcement learning and imitation learning suffer\nfrom low safety, poor generalization, and inefficient sampling. Additionally,\nthey cannot accurately predict future driving trajectories, and the accurate\nprediction of future driving trajectories is a precondition for making optimal\ndecisions. To solve these problems, in this paper, we introduce a Safe and\nGeneralized end-to-end Autonomous Driving System (SGADS) for complex and\nvarious scenarios. Our SGADS incorporates variational inference with\nnormalizing flows, enabling the intelligent vehicle to accurately predict\nfuture driving trajectories. Moreover, we propose the formulation of robust\nsafety constraints. Furthermore, we combine reinforcement learning with\ndemonstrations to augment search process of the agent. The experimental results\ndemonstrate that our SGADS can significantly improve safety performance,\nexhibit strong generalization, and enhance the training efficiency of\nintelligent vehicles in complex urban scenarios compared to existing methods.", "field": "Computer Science", "categories": "cs.RO,cs.AI,cs.LG"}, {"arxiv_id": "2401.11795", "title": "Spherical Density-Equalizing Map for Genus-0 Closed Surfaces", "abstract": "Density-equalizing maps are a class of mapping methods in which the shape\ndeformation is driven by prescribed density information. In recent years, they\nhave been widely used for data visualization on planar domains and planar\nparameterization of open surfaces. However, the theory and computation of\ndensity-equalizing maps for closed surfaces are much less explored. In this\nwork, we develop a novel method for computing spherical density-equalizing maps\nfor genus-0 closed surfaces. Specifically, we first compute a conformal\nparameterization of the given genus-0 closed surface onto the unit sphere.\nThen, we perform density equalization on the spherical domain based on the\ngiven density information to achieve a spherical density-equalizing map. The\nbijectivity of the mapping is guaranteed using quasi-conformal theory. We\nfurther propose a method for incorporating the harmonic energy and landmark\nconstraints into our formulation to achieve landmark-aligned spherical\ndensity-equalizing maps balancing different distortion measures. Using the\nproposed methods, a large variety of spherical parameterizations can be\nachieved. Applications to surface registration, remeshing, and data\nvisualization are presented to demonstrate the effectiveness of our methods.", "field": "Computer Science", "categories": "cs.GR,cs.CG,cs.NA,math.DG,math.NA"}, {"arxiv_id": "2401.11796", "title": "Local Agnostic Video Explanations: a Study on the Applicability of\n  Removal-Based Explanations to Video", "abstract": "Explainable artificial intelligence techniques are becoming increasingly\nimportant with the rise of deep learning applications in various domains. These\ntechniques aim to provide a better understanding of complex \"black box\" models\nand enhance user trust while maintaining high learning performance. While many\nstudies have focused on explaining deep learning models in computer vision for\nimage input, video explanations remain relatively unexplored due to the\ntemporal dimension's complexity. In this paper, we present a unified framework\nfor local agnostic explanations in the video domain. Our contributions include:\n(1) Extending a fine-grained explanation framework tailored for computer vision\ndata, (2) Adapting six existing explanation techniques to work on video data by\nincorporating temporal information and enabling local explanations, and (3)\nConducting an evaluation and comparison of the adapted explanation methods\nusing different models and datasets. We discuss the possibilities and choices\ninvolved in the removal-based explanation process for visual data. The\nadaptation of six explanation methods for video is explained, with comparisons\nto existing approaches. We evaluate the performance of the methods using\nautomated metrics and user-based evaluation, showing that 3D RISE, 3D LIME, and\n3D Kernel SHAP outperform other methods. By decomposing the explanation process\ninto manageable steps, we facilitate the study of each choice's impact and\nallow for further refinement of explanation methods to suit specific datasets\nand models.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11798", "title": "Knowledge Distillation on Spatial-Temporal Graph Convolutional Network\n  for Traffic Prediction", "abstract": "Efficient real-time traffic prediction is crucial for reducing transportation\ntime. To predict traffic conditions, we employ a spatio-temporal graph neural\nnetwork (ST-GNN) to model our real-time traffic data as temporal graphs.\nDespite its capabilities, it often encounters challenges in delivering\nefficient real-time predictions for real-world traffic data. Recognizing the\nsignificance of timely prediction due to the dynamic nature of real-time data,\nwe employ knowledge distillation (KD) as a solution to enhance the execution\ntime of ST-GNNs for traffic prediction. In this paper, We introduce a cost\nfunction designed to train a network with fewer parameters (the student) using\ndistilled data from a complex network (the teacher) while maintaining its\naccuracy close to that of the teacher. We use knowledge distillation,\nincorporating spatial-temporal correlations from the teacher network to enable\nthe student to learn the complex patterns perceived by the teacher. However, a\nchallenge arises in determining the student network architecture rather than\nconsidering it inadvertently. To address this challenge, we propose an\nalgorithm that utilizes the cost function to calculate pruning scores,\naddressing small network architecture search issues, and jointly fine-tunes the\nnetwork resulting from each pruning stage using KD. Ultimately, we evaluate our\nproposed ideas on two real-world datasets, PeMSD7 and PeMSD8. The results\nindicate that our method can maintain the student's accuracy close to that of\nthe teacher, even with the retention of only $3\\%$ of network parameters.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.118", "title": "Revisiting Document-Level Relation Extraction with Context-Guided Link\n  Prediction", "abstract": "Document-level relation extraction (DocRE) poses the challenge of identifying\nrelationships between entities within a document as opposed to the traditional\nRE setting where a single sentence is input. Existing approaches rely on\nlogical reasoning or contextual cues from entities. This paper reframes\ndocument-level RE as link prediction over a knowledge graph with distinct\nbenefits: 1) Our approach combines entity context with document-derived logical\nreasoning, enhancing link prediction quality. 2) Predicted links between\nentities offer interpretability, elucidating employed reasoning. We evaluate\nour approach on three benchmark datasets: DocRED, ReDocRED, and DWIE. The\nresults indicate that our proposed method outperforms the state-of-the-art\nmodels and suggests that incorporating context-based link prediction techniques\ncan enhance the performance of document-level relation extraction models.", "field": "Computer Science", "categories": "cs.IR"}, {"arxiv_id": "2401.11805", "title": "Simultaneous Blind Demixing and Super-resolution via Vectorized Hankel\n  Lift", "abstract": "In this work, we investigate the problem of simultaneous blind demixing and\nsuper-resolution. Leveraging the subspace assumption regarding unknown point\nspread functions, this problem can be reformulated as a low-rank matrix\ndemixing problem. We propose a convex recovery approach that utilizes the\nlow-rank structure of each vectorized Hankel matrix associated with the target\nmatrix. Our analysis reveals that for achieving exact recovery, the number of\nsamples needs to satisfy the condition $n\\gtrsim Ksr \\log (sn)$. Empirical\nevaluations demonstrate the recovery capabilities and the computational\nefficiency of the convex method.", "field": "Computer Science", "categories": "cs.IT,math.IT"}, {"arxiv_id": "2401.1181", "title": "Generalization and Informativeness of Conformal Prediction", "abstract": "The safe integration of machine learning modules in decision-making processes\nhinges on their ability to quantify uncertainty. A popular technique to achieve\nthis goal is conformal prediction (CP), which transforms an arbitrary base\npredictor into a set predictor with coverage guarantees. While CP certifies the\npredicted set to contain the target quantity with a user-defined tolerance, it\ndoes not provide control over the average size of the predicted sets, i.e.,\nover the informativeness of the prediction. In this work, a theoretical\nconnection is established between the generalization properties of the base\npredictor and the informativeness of the resulting CP prediction sets. To this\nend, an upper bound is derived on the expected size of the CP set predictor\nthat builds on generalization error bounds for the base predictor. The derived\nupper bound provides insights into the dependence of the average size of the CP\nset predictor on the amount of calibration data, the target reliability, and\nthe generalization performance of the base predictor. The theoretical insights\nare validated using simple numerical regression and classification tasks.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.IT,math.IT"}, {"arxiv_id": "2401.11813", "title": "Cyclic viscoelastic-viscoplastic behavior of epoxy nanocomposites under\n  hygrothermal conditions: A phase-field fracture model", "abstract": "In this study, a finite deformation phase-field formulation is developed to\ninvestigate the effect of hygrothermal conditions on the\nviscoelastic-viscoplastic fracture behavior of epoxy nanocomposites under\ncyclic loading. The formulation incorporates a definition of the Helmholtz free\nenergy, which considers the effect of nanoparticles, moisture content, and\ntemperature. The free energy is additively decomposed into a deviatoric\nequilibrium, a deviatoric non-equilibrium, and a volumetric contribution, with\ndistinct definitions for tension and compression. The proposed derivation\noffers a realistic modeling of damage and viscoplasticity mechanisms in the\nnanocomposites by coupling the phase-field damage model with a modified crack\ndriving force and a viscoelastic-viscoplastic model. Numerical simulations are\nconducted to study the cyclic force-displacement response of both dry and\nsaturated boehmite nanoparticle (BNP)/epoxy samples, considering BNP contents\nand temperature. Comparing numerical results with experimental data shows good\nagreement at various BNP contents. In addition, the predictive capability of\nthe phase-field model is evaluated through simulations of single-edge notched\nnanocomposite plates subjected to monolithic tensile and shear loading.", "field": "Computer Science", "categories": "cs.CE"}, {"arxiv_id": "2401.11814", "title": "Symbrain: A large-scale dataset of MRI images for neonatal brain\n  symmetry analysis", "abstract": "This paper presents an annotated dataset of brain MRI images designed to\nadvance the field of brain symmetry study. Magnetic resonance imaging (MRI) has\ngained interest in analyzing brain symmetry in neonatal infants, and challenges\nremain due to the vast size differences between fetal and adult brains.\nClassification methods for brain structural MRI use scales and visual cues to\nassess hemisphere symmetry, which can help diagnose neonatal patients by\ncomparing hemispheres and anatomical regions of interest in the brain. Using\nthe Developing Human Connectome Project dataset, this work presents a dataset\ncomprising cerebral images extracted as slices across selected portions of\ninterest for clinical evaluation . All the extracted images are annotated with\nthe brain's midline. All the extracted images are annotated with the brain's\nmidline. From the assumption that a decrease in symmetry is directly related to\npossible clinical pathologies, the dataset can contribute to a more precise\ndiagnosis because it can be used to train deep learning model application in\nneonatal cerebral MRI anomaly detection from postnatal infant scans thanks to\ncomputer vision. Such models learn to identify and classify anomalies by\nidentifying potential asymmetrical patterns in medical MRI images. Furthermore,\nthis dataset can contribute to the research and development of methods using\nthe relative symmetry of the two brain hemispheres for crucial diagnosis and\ntreatment planning.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.11817", "title": "Hallucination is Inevitable: An Innate Limitation of Large Language\n  Models", "abstract": "Hallucination has been widely recognized to be a significant drawback for\nlarge language models (LLMs). There have been many works that attempt to reduce\nthe extent of hallucination. These efforts have mostly been empirical so far,\nwhich cannot answer the fundamental question whether it can be completely\neliminated. In this paper, we formalize the problem and show that it is\nimpossible to eliminate hallucination in LLMs. Specifically, we define a formal\nworld where hallucination is defined as inconsistencies between a computable\nLLM and a computable ground truth function. By employing results from learning\ntheory, we show that LLMs cannot learn all of the computable functions and will\ntherefore always hallucinate. Since the formal world is a part of the real\nworld which is much more complicated, hallucinations are also inevitable for\nreal world LLMs. Furthermore, for real world LLMs constrained by provable time\ncomplexity, we describe the hallucination-prone tasks and empirically validate\nour claims. Finally, using the formal world framework, we discuss the possible\nmechanisms and efficacies of existing hallucination mitigators as well as the\npractical implications on the safe deployment of LLMs.", "field": "Computer Science", "categories": "cs.CL,cs.AI,cs.LG"}, {"arxiv_id": "2401.11818", "title": "MInD: Improving Multimodal Sentiment Analysis via Multimodal Information\n  Disentanglement", "abstract": "Learning effective joint representations has been a central task in\nmultimodal sentiment analysis. Previous methods focus on leveraging the\ncorrelations between different modalities and enhancing performance through\nsophisticated fusion techniques. However, challenges still exist due to the\ninherent heterogeneity of distinct modalities, which may lead to distributional\ngap, impeding the full exploitation of inter-modal information and resulting in\nredundancy and impurity in the information extracted from features. To address\nthis problem, we introduce the Multimodal Information Disentanglement (MInD)\napproach. MInD decomposes the multimodal inputs into a modality-invariant\ncomponent, a modality-specific component, and a remnant noise component for\neach modality through a shared encoder and multiple private encoders. The\nshared encoder aims to explore the shared information and commonality across\nmodalities, while the private encoders are deployed to capture the distinctive\ninformation and characteristic features. These representations thus furnish a\ncomprehensive perspective of the multimodal data, facilitating the fusion\nprocess instrumental for subsequent prediction tasks. Furthermore, MInD\nimproves the learned representations by explicitly modeling the task-irrelevant\nnoise in an adversarial manner. Experimental evaluations conducted on benchmark\ndatasets, including CMU-MOSI, CMU-MOSEI, and UR-Funny, demonstrate MInD's\nsuperior performance over existing state-of-the-art methods in both multimodal\nemotion recognition and multimodal humor detection tasks.", "field": "Computer Science", "categories": "cs.MM"}, {"arxiv_id": "2401.11819", "title": "SuperCLUE-Math6: Graded Multi-Step Math Reasoning Benchmark for LLMs in\n  Chinese", "abstract": "We introduce SuperCLUE-Math6(SC-Math6), a new benchmark dataset to evaluate\nthe mathematical reasoning abilities of Chinese language models. SC-Math6 is\ndesigned as an upgraded Chinese version of the GSM8K dataset with enhanced\ndifficulty, diversity, and application scope. It consists of over 2000\nmathematical word problems requiring multi-step reasoning and providing natural\nlanguage solutions. We propose an innovative scheme to quantify the reasoning\ncapability of large models based on performance over problems with different\nreasoning steps. Experiments on 12 representative Chinese models demonstrate a\nclear stratification of reasoning levels, with top models like GPT-4 showing\nsuperior performance. SC-Math6 fills the gap in Chinese mathematical reasoning\nbenchmarks and provides a comprehensive testbed to advance the intelligence of\nChinese language models.", "field": "Computer Science", "categories": "cs.CL,cs.AI"}, {"arxiv_id": "2401.1182", "title": "Performance Analysis of Fluid Antenna-aided Backscatter Communications\n  Systems", "abstract": "This paper studies the performance of backscatter communications (BC) over\nemerging fluid antenna (FA) technology. In particular, a single-antenna source\nsends information to a FA reader through the wireless forward (i.e.,\nsource-to-tag) and backscatter (tag-to-reader) channels. For the considered BC,\nwe first derive the cumulative distribution function (CDF) of the equivalent\nchannel at the FA receiver, and then we obtain closed-form expressions of the\noutage probability (OP) and delay outage rate (DOR) under a correlated Rayleigh\ndistribution. Moreover, in order to gain more insights into the system\nperformance, we present analytical expressions of the OP and DOR at the high\nSNR regime. Numerical results indicate that considering the FA at the reader\ncan significantly improve the performance of BC in terms of the OP and DOR\ncompared with a single-antenna reader.", "field": "Computer Science", "categories": "cs.IT,eess.SP,math.IT"}, {"arxiv_id": "2401.11823", "title": "Towards a satisfactory conversion of messages among agent-based\n  information systems", "abstract": "Over the last years, there has been a change of perspective concerning the\nmanagement of information systems, since they are no longer isolated and need\nto communicate with others. However, from a semantic point of view, real\ncommunication is difficult to achieve due to the heterogeneity of the systems.\nWe present a proposal which, considering information systems are represented by\nsoftware agents, provides a framework that favours a semantic communication\namong them, overcoming the heterogeneity of their agent communication\nlanguages. The main components of the framework are a suite of ontologies --\nconceptualizing communication acts -- that will be used for generating the\ncommunication conversion, and an Event Calculus interpretation of the\ncommunications, which will be used for formalizing the notion of a satisfactory\nconversion. Moreover, we present a motivating example in order to complete the\nexplanation of the whole picture.", "field": "Computer Science", "categories": "cs.MA"}, {"arxiv_id": "2401.11824", "title": "Rethinking Centered Kernel Alignment in Knowledge Distillation", "abstract": "Knowledge distillation has emerged as a highly effective method for bridging\nthe representation discrepancy between large-scale models and lightweight\nmodels. Prevalent approaches involve leveraging appropriate metrics to minimize\nthe divergence or distance between the knowledge extracted from the teacher\nmodel and the knowledge learned by the student model. Centered Kernel Alignment\n(CKA) is widely used to measure representation similarity and has been applied\nin several knowledge distillation methods. However, these methods are complex\nand fail to uncover the essence of CKA, thus not answering the question of how\nto use CKA to achieve simple and effective distillation properly. This paper\nfirst provides a theoretical perspective to illustrate the effectiveness of\nCKA, which decouples CKA to the upper bound of Maximum Mean Discrepancy~(MMD)\nand a constant term. Drawing from this, we propose a novel Relation-Centered\nKernel Alignment~(RCKA) framework, which practically establishes a connection\nbetween CKA and MMD. Furthermore, we dynamically customize the application of\nCKA based on the characteristics of each task, with less computational source\nyet comparable performance than the previous methods. The extensive experiments\non the CIFAR-100, ImageNet-1k, and MS-COCO demonstrate that our method achieves\nstate-of-the-art performance on almost all teacher-student pairs for image\nclassification and object detection, validating the effectiveness of our\napproaches.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11825", "title": "Sparse discovery of differential equations based on multi-fidelity\n  Gaussian process", "abstract": "Sparse identification of differential equations aims to compute the analytic\nexpressions from the observed data explicitly. However, there exist two primary\nchallenges. Firstly, it exhibits sensitivity to the noise in the observed data,\nparticularly for the derivatives computations. Secondly, existing literature\npredominantly concentrates on single-fidelity (SF) data, which imposes\nlimitations on its applicability due to the computational cost. In this paper,\nwe present two novel approaches to address these problems from the view of\nuncertainty quantification. We construct a surrogate model employing the\nGaussian process regression (GPR) to mitigate the effect of noise in the\nobserved data, quantify its uncertainty, and ultimately recover the equations\naccurately. Subsequently, we exploit the multi-fidelity Gaussian processes\n(MFGP) to address scenarios involving multi-fidelity (MF), sparse, and noisy\nobserved data. We demonstrate the robustness and effectiveness of our\nmethodologies through several numerical experiments.", "field": "Computer Science", "categories": "math.NA,cs.LG,cs.NA"}, {"arxiv_id": "2401.11831", "title": "A Fair Evaluation of Various Deep Learning-Based Document Image\n  Binarization Approaches", "abstract": "Binarization of document images is an important pre-processing step in the\nfield of document analysis. Traditional image binarization techniques usually\nrely on histograms or local statistics to identify a valid threshold to\ndifferentiate between different aspects of the image. Deep learning techniques\nare able to generate binarized versions of the images by learning\ncontext-dependent features that are less error-prone to degradation typically\noccurring in document images. In recent years, many deep learning-based methods\nhave been developed for document binarization. But which one to choose? There\nhave been no studies that compare these methods rigorously. Therefore, this\nwork focuses on the evaluation of different deep learning-based methods under\nthe same evaluation protocol. We evaluate them on different Document Image\nBinarization Contest (DIBCO) datasets and obtain very heterogeneous results. We\nshow that the DE-GAN model was able to perform better compared to other models\nwhen evaluated on the DIBCO2013 dataset while DP-LinkNet performed best on the\nDIBCO2017 dataset. The 2-StageGAN performed best on the DIBCO2018 dataset while\nSauvolaNet outperformed the others on the DIBCO2019 challenge. Finally, we make\nthe code, all models and evaluation publicly available\n(https://github.com/RichSu95/Document_Binarization_Collection) to ensure\nreproducibility and simplify future binarization evaluations.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11834", "title": "End-to-end Multi-Instance Robotic Reaching from Monocular Vision", "abstract": "Multi-instance scenes are especially challenging for end-to-end visuomotor\n(image-to-control) learning algorithms. \"Pipeline\" visual servo control\nalgorithms use separate detection, selection and servo stages, allowing\nalgorithms to focus on a single object instance during servo control.\nEnd-to-end systems do not have separate detection and selection stages and need\nto address the visual ambiguities introduced by the presence of arbitrary\nnumber of visually identical or similar objects during servo control. However,\nend-to-end schemes avoid embedding errors from detection and selection stages\nin the servo control behaviour, are more dynamically robust to changing scenes,\nand are algorithmically simpler. In this paper, we present a real-time\nend-to-end visuomotor learning algorithm for multi-instance reaching. The\nproposed algorithm uses a monocular RGB image and the manipulator's joint\nangles as the input to a light-weight fully-convolutional network (FCN) to\ngenerate control candidates. A key innovation of the proposed method is\nidentifying the optimal control candidate by regressing a control-Lyapunov\nfunction (cLf) value. The multi-instance capability emerges naturally from the\nstability analysis associated with the cLf formulation. We demonstrate the\nproposed algorithm effectively reaching and grasping objects from different\ncategories on a table-top amid other instances and distractors from an\nover-the-shoulder monocular RGB camera.\n  The network is able to run up to approximately 160 fps during inference on\none GTX 1080 Ti GPU.", "field": "Computer Science", "categories": "cs.RO"}, {"arxiv_id": "2401.11835", "title": "Unveiling the Human-like Similarities of Automatic Facial Expression\n  Recognition: An Empirical Exploration through Explainable AI", "abstract": "Facial expression recognition is vital for human behavior analysis, and deep\nlearning has enabled models that can outperform humans. However, it is unclear\nhow closely they mimic human processing. This study aims to explore the\nsimilarity between deep neural networks and human perception by comparing\ntwelve different networks, including both general object classifiers and\nFER-specific models. We employ an innovative global explainable AI method to\ngenerate heatmaps, revealing crucial facial regions for the twelve networks\ntrained on six facial expressions. We assess these results both quantitatively\nand qualitatively, comparing them to ground truth masks based on Friesen and\nEkman's description and among them. We use Intersection over Union (IoU) and\nnormalized correlation coefficients for comparisons. We generate 72 heatmaps to\nhighlight critical regions for each expression and architecture. Qualitatively,\nmodels with pre-trained weights show more similarity in heatmaps compared to\nthose without pre-training. Specifically, eye and nose areas influence certain\nfacial expressions, while the mouth is consistently important across all models\nand expressions. Quantitatively, we find low average IoU values (avg. 0.2702)\nacross all expressions and architectures. The best-performing architecture\naverages 0.3269, while the worst-performing one averages 0.2066. Dendrograms,\nbuilt with the normalized correlation coefficient, reveal two main clusters for\nmost expressions: models with pre-training and models without pre-training.\nFindings suggest limited alignment between human and AI facial expression\nrecognition, with network architectures influencing the similarity, as similar\narchitectures prioritize similar facial regions.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11836", "title": "Privacy-Preserving Data Fusion for Traffic State Estimation: A Vertical\n  Federated Learning Approach", "abstract": "This paper proposes a privacy-preserving data fusion method for traffic state\nestimation (TSE). Unlike existing works that assume all data sources to be\naccessible by a single trusted party, we explicitly address data privacy\nconcerns that arise in the collaboration and data sharing between multiple data\nowners, such as municipal authorities (MAs) and mobility providers (MPs). To\nthis end, we propose a novel vertical federated learning (FL) approach, FedTSE,\nthat enables multiple data owners to collaboratively train and apply a TSE\nmodel without having to exchange their private data. To enhance the\napplicability of the proposed FedTSE in common TSE scenarios with limited\navailability of ground-truth data, we further propose a privacy-preserving\nphysics-informed FL approach, i.e., FedTSE-PI, that integrates traffic models\ninto FL. Real-world data validation shows that the proposed methods can protect\nprivacy while yielding similar accuracy to the oracle method without privacy\nconsiderations.", "field": "Computer Science", "categories": "cs.LG,cs.CR,cs.SY,eess.SY"}, {"arxiv_id": "2401.11838", "title": "The Conversation is the Command: Interacting with Real-World Autonomous\n  Robot Through Natural Language", "abstract": "In recent years, autonomous agents have surged in real-world environments\nsuch as our homes, offices, and public spaces. However, natural human-robot\ninteraction remains a key challenge. In this paper, we introduce an approach\nthat synergistically exploits the capabilities of large language models (LLMs)\nand multimodal vision-language models (VLMs) to enable humans to interact\nnaturally with autonomous robots through conversational dialogue. We leveraged\nthe LLMs to decode the high-level natural language instructions from humans and\nabstract them into precise robot actionable commands or queries. Further, we\nutilised the VLMs to provide a visual and semantic understanding of the robot's\ntask environment. Our results with 99.13% command recognition accuracy and\n97.96% commands execution success show that our approach can enhance\nhuman-robot interaction in real-world applications. The video demonstrations of\nthis paper can be found at https://osf.io/wzyf6 and the code is available at\nour GitHub repository (https://github.com/LinusNEP/TCC_IRoNL.git).", "field": "Computer Science", "categories": "cs.RO,cs.HC"}, {"arxiv_id": "2401.11839", "title": "AI for social science and social science of AI: A Survey", "abstract": "Recent advancements in artificial intelligence, particularly with the\nemergence of large language models (LLMs), have sparked a rethinking of\nartificial general intelligence possibilities. The increasing human-like\ncapabilities of AI are also attracting attention in social science research,\nleading to various studies exploring the combination of these two fields. In\nthis survey, we systematically categorize previous explorations in the\ncombination of AI and social science into two directions that share common\ntechnical approaches but differ in their research objectives. The first\ndirection is focused on AI for social science, where AI is utilized as a\npowerful tool to enhance various stages of social science research. While the\nsecond direction is the social science of AI, which examines AI agents as\nsocial entities with their human-like cognitive and linguistic capabilities. By\nconducting a thorough review, particularly on the substantial progress\nfacilitated by recent advancements in large language models, this paper\nintroduces a fresh perspective to reassess the relationship between AI and\nsocial science, provides a cohesive framework that allows researchers to\nunderstand the distinctions and connections between AI for social science and\nsocial science of AI, and also summarized state-of-art experiment simulation\nplatforms to facilitate research in these two directions. We believe that as AI\ntechnology continues to advance and intelligent agents find increasing\napplications in our daily lives, the significance of the combination of AI and\nsocial science will become even more prominent.", "field": "Computer Science", "categories": "cs.CL,cs.CY"}, {"arxiv_id": "2401.1184", "title": "Learning to Approximate Adaptive Kernel Convolution on Graphs", "abstract": "Various Graph Neural Networks (GNNs) have been successful in analyzing data\nin non-Euclidean spaces, however, they have limitations such as oversmoothing,\ni.e., information becomes excessively averaged as the number of hidden layers\nincreases. The issue stems from the intrinsic formulation of conventional graph\nconvolution where the nodal features are aggregated from a direct neighborhood\nper layer across the entire nodes in the graph. As setting different number of\nhidden layers per node is infeasible, recent works leverage a diffusion kernel\nto redefine the graph structure and incorporate information from farther nodes.\nUnfortunately, such approaches suffer from heavy diagonalization of a graph\nLaplacian or learning a large transform matrix. In this regards, we propose a\ndiffusion learning framework, where the range of feature aggregation is\ncontrolled by the scale of a diffusion kernel. For efficient computation, we\nderive closed-form derivatives of approximations of the graph convolution with\nrespect to the scale, so that node-wise range can be adaptively learned. With a\ndownstream classifier, the entire framework is made trainable in an end-to-end\nmanner. Our model is tested on various standard datasets for node-wise\nclassification for the state-of-the-art performance, and it is also validated\non a real-world brain network data for graph classifications to demonstrate its\npracticality for Alzheimer classification.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.11841", "title": "Semantic Web Technology for Agent Communication Protocols", "abstract": "One relevant aspect in the development of the Semantic Web framework is the\nachievement of a real inter-agents communication capability at the semantic\nlevel. The agents should be able to communicate and understand each other using\nstandard communication protocols freely, that is, without needing a laborious a\npriori preparation, before the communication takes place. For that setting we\npresent in this paper a proposal that promotes to describe standard\ncommunication protocols using Semantic Web technology (specifically, OWL-DL and\nSWRL). Those protocols are constituted by communication acts. In our proposal\nthose communication acts are described as terms that belong to a communication\nacts ontology, that we have developed, called CommOnt. The intended semantics\nassociated to the communication acts in the ontology is expressed through\nsocial commitments that are formalized as fluents in the Event Calculus. In\nsummary, OWL-DL reasoners and rule engines help in our proposal for reasoning\nabout protocols. We define some comparison relationships (dealing with notions\nof equivalence and specialization) between protocols used by agents from\ndifferent systems.", "field": "Computer Science", "categories": "cs.MA"}, {"arxiv_id": "2401.11844", "title": "Adaptive Fusion of Multi-view Remote Sensing data for Optimal Sub-field\n  Crop Yield Prediction", "abstract": "Accurate crop yield prediction is of utmost importance for informed\ndecision-making in agriculture, aiding farmers, and industry stakeholders.\nHowever, this task is complex and depends on multiple factors, such as\nenvironmental conditions, soil properties, and management practices. Combining\nheterogeneous data views poses a fusion challenge, like identifying the\nview-specific contribution to the predictive task. We present a novel\nmulti-view learning approach to predict crop yield for different crops\n(soybean, wheat, rapeseed) and regions (Argentina, Uruguay, and Germany). Our\nmulti-view input data includes multi-spectral optical images from Sentinel-2\nsatellites and weather data as dynamic features during the crop growing season,\ncomplemented by static features like soil properties and topographic\ninformation. To effectively fuse the data, we introduce a Multi-view Gated\nFusion (MVGF) model, comprising dedicated view-encoders and a Gated Unit (GU)\nmodule. The view-encoders handle the heterogeneity of data sources with varying\ntemporal resolutions by learning a view-specific representation. These\nrepresentations are adaptively fused via a weighted sum. The fusion weights are\ncomputed for each sample by the GU using a concatenation of the\nview-representations. The MVGF model is trained at sub-field level with 10 m\nresolution pixels. Our evaluations show that the MVGF outperforms conventional\nmodels on the same task, achieving the best results by incorporating all the\ndata sources, unlike the usual fusion results in the literature. For Argentina,\nthe MVGF model achieves an R2 value of 0.68 at sub-field yield prediction,\nwhile at field level evaluation (comparing field averages), it reaches around\n0.80 across different countries. The GU module learned different weights based\non the country and crop-type, aligning with the variable significance of each\ndata source to the prediction task.", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.LG"}, {"arxiv_id": "2401.11847", "title": "SignVTCL: Multi-Modal Continuous Sign Language Recognition Enhanced by\n  Visual-Textual Contrastive Learning", "abstract": "Sign language recognition (SLR) plays a vital role in facilitating\ncommunication for the hearing-impaired community. SLR is a weakly supervised\ntask where entire videos are annotated with glosses, making it challenging to\nidentify the corresponding gloss within a video segment. Recent studies\nindicate that the main bottleneck in SLR is the insufficient training caused by\nthe limited availability of large-scale datasets. To address this challenge, we\npresent SignVTCL, a multi-modal continuous sign language recognition framework\nenhanced by visual-textual contrastive learning, which leverages the full\npotential of multi-modal data and the generalization ability of language model.\nSignVTCL integrates multi-modal data (video, keypoints, and optical flow)\nsimultaneously to train a unified visual backbone, thereby yielding more robust\nvisual representations. Furthermore, SignVTCL contains a visual-textual\nalignment approach incorporating gloss-level and sentence-level alignment to\nensure precise correspondence between visual features and glosses at the level\nof individual glosses and sentence. Experimental results conducted on three\ndatasets, Phoenix-2014, Phoenix-2014T, and CSL-Daily, demonstrate that SignVTCL\nachieves state-of-the-art results compared with previous methods.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11848", "title": "ExtruOnt: An ontology for describing a type of manufacturing machine for\n  Industry 4.0 systems", "abstract": "Semantically rich descriptions of manufacturing machines, offered in a\nmachine-interpretable code, can provide interesting benefits in Industry 4.0\nscenarios. However, the lack of that type of descriptions is evident. In this\npaper we present the development effort made to build an ontology, called\nExtruOnt, for describing a type of manufacturing machine, more precisely, a\ntype that performs an extrusion process (extruder). Although the scope of the\nontology is restricted to a concrete domain, it could be used as a model for\nthe development of other ontologies for describing manufacturing machines in\nIndustry 4.0 scenarios. The terms of the ExtruOnt ontology provide different\ntypes of information related with an extruder, which are reflected in distinct\nmodules that constitute the ontology. Thus, it contains classes and properties\nfor expressing descriptions about components of an extruder, spatial\nconnections, features, and 3D representations of those components, and finally\nthe sensors used to capture indicators about the performance of this type of\nmachine. The ontology development process has been carried out in close\ncollaboration with domain experts.", "field": "Computer Science", "categories": "cs.AI"}, {"arxiv_id": "2401.11849", "title": "Self-Labeling the Job Shop Scheduling Problem", "abstract": "In this work, we propose a Self-Supervised training strategy specifically\ndesigned for combinatorial problems. One of the main obstacles in applying\nsupervised paradigms to such problems is the requirement of expensive target\nsolutions as ground-truth, often produced with costly exact solvers. Inspired\nby Semi- and Self-Supervised learning, we show that it is possible to easily\ntrain generative models by sampling multiple solutions and using the best one\naccording to the problem objective as a pseudo-label. In this way, we\niteratively improve the model generation capability by relying only on its\nself-supervision, completely removing the need for optimality information. We\nprove the effectiveness of this Self-Labeling strategy on the Job Shop\nScheduling (JSP), a complex combinatorial problem that is receiving much\nattention from the Reinforcement Learning community. We propose a generative\nmodel based on the well-known Pointer Network and train it with our strategy.\nExperiments on two popular benchmarks demonstrate the potential of this\napproach as the resulting models outperform constructive heuristics and current\nstate-of-the-art Reinforcement Learning proposals.", "field": "Computer Science", "categories": "cs.LG,cs.AI,math.CO,I.2; G.2"}, {"arxiv_id": "2401.11851", "title": "BETA: Binarized Energy-Efficient Transformer Accelerator at the Edge", "abstract": "Existing binary Transformers are promising in edge deployment due to their\ncompact model size, low computational complexity, and considerable inference\naccuracy.However, deploying binary Transformers faces challenges on prior\nprocessors due to inefficient execution of quantized matrix multiplication\n(QMM) and the energy consumption overhead caused by multi-precision\nactivations.To tackle the challenges above, we first develop a computation flow\nabstraction method for binary Transformers to improve QMM execution efficiency\nby optimizing the computation order.Furthermore, a binarized energy-efficient\nTransformer accelerator, namely BETA, is proposed to boost the efficient\ndeployment at the edge.Notably, BETA features a configurable QMM engine,\naccommodating diverse activation precisions of binary Transformers and offering\nhigh-parallelism and high-speed for QMMs with impressive energy\nefficiency.Experimental results evaluated on ZCU102 FPGA show BETA achieves an\naverage energy efficiency of 174 GOPS/W, which is 1.76~21.92x higher than prior\nFPGA-based accelerators, showing BETA's good potential for edge Transformer\nacceleration.", "field": "Computer Science", "categories": "cs.AR,cs.AI"}, {"arxiv_id": "2401.11852", "title": "The Right Model for the Job: An Evaluation of Legal Multi-Label\n  Classification Baselines", "abstract": "Multi-Label Classification (MLC) is a common task in the legal domain, where\nmore than one label may be assigned to a legal document. A wide range of\nmethods can be applied, ranging from traditional ML approaches to the latest\nTransformer-based architectures. In this work, we perform an evaluation of\ndifferent MLC methods using two public legal datasets, POSTURE50K and\nEURLEX57K. By varying the amount of training data and the number of labels, we\nexplore the comparative advantage offered by different approaches in relation\nto the dataset properties. Our findings highlight DistilRoBERTa and LegalBERT\nas performing consistently well in legal MLC with reasonable computational\ndemands. T5 also demonstrates comparable performance while offering advantages\nas a generative model in the presence of changing label sets. Finally, we show\nthat the CrossEncoder exhibits potential for notable macro-F1 score\nimprovements, albeit with increased computational costs.", "field": "Computer Science", "categories": "cs.CL,cs.AI"}, {"arxiv_id": "2401.11854", "title": "Optimization in Sanger Sequencing", "abstract": "The main objective of this paper is to solve the optimization problem that is\nassociated with the classification of DNA samples in PCR plates for Sanger\nsequencing. To achieve this goal, we design an integer linear programming\nmodel. Given that the real instances involve the classification of thousands of\nsamples and the linear model can only be solved for small instances, the paper\nincludes a heuristic to cope with bigger problems. The heuristic algorithm is\nbased on the simulated annealing technique. This algorithm obtains satisfactory\nsolutions to the problem in a short amount of time. It has been tested with\nreal data and yields improved results compared to some commercial software\ntypically used in (clinical) laboratories. Moreover, the algorithm has already\nbeen implemented in the laboratory and is being successfully used.", "field": "Computer Science", "categories": "cs.DS,math.OC"}, {"arxiv_id": "2401.1186", "title": "A Review of Physics-Informed Machine Learning Methods with Applications\n  to Condition Monitoring and Anomaly Detection", "abstract": "This study presents a comprehensive overview of PIML techniques in the\ncontext of condition monitoring. The central concept driving PIML is the\nincorporation of known physical laws and constraints into machine learning\nalgorithms, enabling them to learn from available data while remaining\nconsistent with physical principles. Through fusing domain knowledge with\ndata-driven learning, PIML methods offer enhanced accuracy and interpretability\nin comparison to purely data-driven approaches. In this comprehensive survey,\ndetailed examinations are performed with regard to the methodology by which\nknown physical principles are integrated within machine learning frameworks, as\nwell as their suitability for specific tasks within condition monitoring.\nIncorporation of physical knowledge into the ML model may be realized in a\nvariety of methods, with each having its unique advantages and drawbacks. The\ndistinct advantages and limitations of each methodology for the integration of\nphysics within data-driven models are detailed, considering factors such as\ncomputational efficiency, model interpretability, and generalizability to\ndifferent systems in condition monitoring and fault detection. Several case\nstudies and works of literature utilizing this emerging concept are presented\nto demonstrate the efficacy of PIML in condition monitoring applications. From\nthe literature reviewed, the versatility and potential of PIML in condition\nmonitoring may be demonstrated. Novel PIML methods offer an innovative solution\nfor addressing the complexities of condition monitoring and associated\nchallenges. This comprehensive survey helps form the foundation for future work\nin the field. As the technology continues to advance, PIML is expected to play\na crucial role in enhancing maintenance strategies, system reliability, and\noverall operational efficiency in engineering systems.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.SY,eess.SY"}, {"arxiv_id": "2401.11861", "title": "A Fixed-Parameter Study on Propositional Dynamic Logic", "abstract": "Since its establishment, propositional dynamic logic (PDL) has been a subject\nof intensive academic research and frequent use in the industry. We have\nstudied the complexity of some PDL problems and in this paper, we show results\nfor some special cases of PL and PDL.", "field": "Computer Science", "categories": "cs.LO"}, {"arxiv_id": "2401.11864", "title": "Improving Small Language Models' Mathematical Reasoning via Mix Thoughts\n  Distillation", "abstract": "This work addresses the challenge of democratizing advanced Large Language\nModels (LLMs) by compressing their mathematical reasoning capabilities into\nsub-billion parameter Small Language Models (SLMs) without compromising\nperformance. We introduce Equation-of-Thought Distillation (EoTD), a novel\ntechnique that encapsulates the reasoning process into equation-based\nrepresentations to construct an EoTD dataset for fine-tuning SLMs.\nAdditionally, we propose the Mix Thoughts Distillation (MTD) framework to\nenhance the reasoning performance of SLMs. This involves creating a reasoning\ndataset with multiple thought processes and using it for fine-tuning. Our\nexperimental findings demonstrate that EoTD significantly boosts the reasoning\nabilities of SLMs, while MTD enables these models to achieve state-of-the-art\nreasoning performance.", "field": "Computer Science", "categories": "cs.CL,cs.AI"}, {"arxiv_id": "2401.11865", "title": "Toward Semantic Interoperability of Electronic Health Records", "abstract": "Although the goal of achieving semantic interoperability of electronic health\nrecords (EHRs) is pursued by many researchers, it has not been accomplished\nyet. In this paper, we present a proposal that smoothes out the way toward the\nachievement of that goal. In particular, our study focuses on medical diagnoses\nstatements. In summary, the main contributions of our ontology-based proposal\nare the following: first, it includes a canonical ontology whose EHR-related\nterms focus on semantic aspects. As a result, their descriptions are\nindependent of languages and technology aspects used in different organizations\nto represent EHRs. Moreover, those terms are related to their corresponding\ncodes in well-known medical terminologies. Second, it deals with modules that\nallow obtaining rich ontological representations of EHR information managed by\nproprietary models of health information systems. The features of one specific\nmodule are shown as reference. Third, it considers the necessary mapping axioms\nbetween ontological terms enhanced with so-called path mappings. This feature\nsmoothes out structural differences between heterogeneous EHR representations,\nallowing proper alignment of information.", "field": "Computer Science", "categories": "cs.AI"}, {"arxiv_id": "2401.11867", "title": "Modular Monolith: Is This the Trend in Software Architecture?", "abstract": "Recently modular monolith architecture has attracted the attention of\npractitioners, as Google proposed \"Service Weaver\" framework to enable\ndevelopers to write applications as modular monolithic and deploy them as a set\nof microservices. Google considered it as a framework that has the best of both\nworlds and it seems to be a trend in software architecture. This paper aims to\nunderstand the definition of the modular monolith in industry and investigate\nframeworks and cases building modular monolith architecture. We conducted a\nsystematic grey literature review, and the results show that modular monolith\ncombines the advantages of monoliths with microservices. We found three\nframeworks and four cases of building modular monolith architecture. In\ngeneral, the modular monolith is an alternative way to microservices, and it\nalso could be a previous step before systems migrate to microservices.", "field": "Computer Science", "categories": "cs.SE"}, {"arxiv_id": "2401.11868", "title": "Self-Balancing Semi-Hierarchical PCNs for CBDCs", "abstract": "We introduce a family of PCNs (Payment Channel Networks) characterized by a\nsemi-hierarchical topology and a custom set of channel rebalancing strategies.\nThis family exhibits two interesting benefits, if used as a platform for\nlarge-scale, instant, retail payment systems, such as CBDCs: Technically, the\nsolution offers state-of-the-art guarantees of fault-tolerance and integrity,\nwhile providing a latency and throughput comparable to centralized systems;\nfrom a business perspective, the solution perfectly suits the 3-tier\narchitecture of the current banking ecosystem (central banks / commercial banks\n/ retail users), assigning a pivotal and peculiar role to the members of each\ntier. Furthermore, the cryptographic privacy of payments for retail users --\ntypical of PCNs such as the public Lightning Network -- is largely (possibly\nfully) retained. We study the system by simulating a scaled-down version of a\nhypothetical European CBDC, exploring the trade-offs among liquidity locked by\nmarket operators, payment success rate, throughput, latency, and load on the\nunderpinning blockchain.", "field": "Computer Science", "categories": "cs.DC"}, {"arxiv_id": "2401.1187", "title": "An Experimental Comparison of Multiwinner Voting Rules on Approval\n  Elections", "abstract": "In this paper, we experimentally compare major approval-based\n  multiwinner voting rules. To this end, we define a measure of\n  similarity between two equal-sized committees subject to a given\n  election. Using synthetic elections coming from several\n  distributions, we analyze how similar are the committees provided by\n  prominent voting rules. Our results can be visualized as ``maps of\n  voting rules'', which provide a counterpoint to a purely axiomatic\n  classification of voting rules.\n  The strength of our proposed method is its independence from preimposed\nclassifications (such as the satisfaction of concrete axioms),\n  and that it indeed offers a much finer distinction than\n  the current state of axiomatic analysis.", "field": "Computer Science", "categories": "cs.GT"}, {"arxiv_id": "2401.11872", "title": "The complexity of elliptic normal bases", "abstract": "We study the complexity (that is, the weight of the multiplication table) of\nthe elliptic normal bases introduced by Couveignes and Lercier. We give an\nupper bound on the complexity of these elliptic normal bases, and we analyze\nthe weight of some special vectors related to the multiplication table of those\nbases. This analysis leads us to some perspectives on the search for low\ncomplexity normal bases from elliptic periods.", "field": "Computer Science", "categories": "cs.IT,math.IT"}, {"arxiv_id": "2401.11874", "title": "Detect-Order-Construct: A Tree Construction based Approach for\n  Hierarchical Document Structure Analysis", "abstract": "Document structure analysis (aka document layout analysis) is crucial for\nunderstanding the physical layout and logical structure of documents, with\napplications in information retrieval, document summarization, knowledge\nextraction, etc. In this paper, we concentrate on Hierarchical Document\nStructure Analysis (HDSA) to explore hierarchical relationships within\nstructured documents created using authoring software employing hierarchical\nschemas, such as LaTeX, Microsoft Word, and HTML. To comprehensively analyze\nhierarchical document structures, we propose a tree construction based approach\nthat addresses multiple subtasks concurrently, including page object detection\n(Detect), reading order prediction of identified objects (Order), and the\nconstruction of intended hierarchical structure (Construct). We present an\neffective end-to-end solution based on this framework to demonstrate its\nperformance. To assess our approach, we develop a comprehensive benchmark\ncalled Comp-HRDoc, which evaluates the above subtasks simultaneously. Our\nend-to-end system achieves state-of-the-art performance on two large-scale\ndocument layout analysis datasets (PubLayNet and DocLayNet), a high-quality\nhierarchical document structure reconstruction dataset (HRDoc), and our\nComp-HRDoc benchmark. The Comp-HRDoc benchmark will be released to facilitate\nfurther research in this field.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11876", "title": "First-principles Based 3D Virtual Simulation Testing for Discovering\n  SOTIF Corner Cases of Autonomous Driving", "abstract": "3D virtual simulation, which generates diversified test scenarios and tests\nfull-stack of Autonomous Driving Systems (ADSes) modules dynamically as a\nwhole, is a promising approach for Safety of The Intended Functionality (SOTIF)\nADS testing. However, as different configurations of a test scenario will\naffect the sensor perceptions and environment interaction, e.g. light pulses\nemitted by the LiDAR sensor will undergo backscattering and attenuation, which\nis usually overlooked by existing works, leading to false positives or wrong\nresults. Moreover, the input space of an ADS is extremely large, with infinite\nnumber of possible initial scenarios and mutations, along both temporal and\nspatial domains.\n  This paper proposes a first-principles based sensor modeling and environment\ninteraction scheme, and integrates it into CARLA simulator. With this scheme, a\nlong-overlooked category of adverse weather related corner cases are\ndiscovered, along with their root causes. Moreover, a meta-heuristic algorithm\nis designed based on several empirical insights, which guide both seed\nscenarios and mutations, significantly reducing the search dimensions of\nscenarios and enhancing the efficiency of corner case identification.\nExperimental results show that under identical simulation setups, our algorithm\ndiscovers about four times as many corner cases as compared to state-of-the-art\nwork.", "field": "Computer Science", "categories": "cs.SE,cs.RO"}, {"arxiv_id": "2401.11877", "title": "Evaluating the Feasibility of Standard Facial Expression Recognition in\n  Individuals with Moderate to Severe Intellectual Disabilities", "abstract": "Recent research has underscored the increasing preference of users for\nhuman-like interactions with machines. Consequently, facial expression\nrecognition has gained significance as a means of imparting social robots with\nthe capacity to discern the emotional states of users. In this investigation,\nwe assess the suitability of deep learning approaches, known for their\nremarkable performance in this domain, for recognizing facial expressions in\nindividuals with intellectual disabilities, which has not been yet studied in\nthe literature, to the best of our knowledge. To address this objective, we\ntrain a set of twelve distinct convolutional neural networks in different\napproaches, including an ensemble of datasets without individuals with\nintellectual disabilities and a dataset featuring such individuals. Our\nexamination of the outcomes achieved by the various models under distinct\ntraining conditions, coupled with a comprehensive analysis of critical facial\nregions during expression recognition facilitated by explainable artificial\nintelligence techniques, revealed significant distinctions in facial\nexpressions between individuals with and without intellectual disabilities, as\nwell as among individuals with intellectual disabilities. Remarkably, our\nfindings demonstrate the feasibility of facial expression recognition within\nthis population through tailored user-specific training methodologies, which\nenable the models to effectively address the unique expressions of each user.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.1188", "title": "PsySafe: A Comprehensive Framework for Psychological-based Attack,\n  Defense, and Evaluation of Multi-agent System Safety", "abstract": "Multi-agent systems, augmented with Large Language Models (LLMs), demonstrate\nsignificant capabilities for collective intelligence. However, the potential\nmisuse of this intelligence for malicious purposes presents significant risks.\nTo date, comprehensive research on the safety issues associated with\nmulti-agent systems remains limited. From the perspective of agent psychology,\nwe discover that the dark psychological states of agents can lead to severe\nsafety issues. To address these issues, we propose a comprehensive framework\ngrounded in agent psychology. In our framework, we focus on three aspects:\nidentifying how dark personality traits in agents might lead to risky\nbehaviors, designing defense strategies to mitigate these risks, and evaluating\nthe safety of multi-agent systems from both psychological and behavioral\nperspectives. Our experiments reveal several intriguing phenomena, such as the\ncollective dangerous behaviors among agents, agents' propensity for\nself-reflection when engaging in dangerous behavior, and the correlation\nbetween agents' psychological assessments and their dangerous behaviors. We\nanticipate that our framework and observations will provide valuable insights\nfor further research into the safety of multi-agent systems. We will make our\ndata and code publicly accessible at https:/github.com/AI4Good24/PsySafe.", "field": "Computer Science", "categories": "cs.CL,cs.AI,cs.CR,cs.MA"}, {"arxiv_id": "2401.11881", "title": "Modelling the Dynamics of Identity and Fairness in Ultimatum Game", "abstract": "Allocation games are zero-sum games that model the distribution of resources\namong multiple agents. In this paper, we explore the interplay between an\nelastic sense of subjective identity and its impact on notions of fairness in\nallocation. An elastic sense of identity in agents is known to lead to\nresponsible decision-making in non-cooperative, non-zero-sum games like\nPrisoners' Dilemma, and is a desirable feature to add into agent models.\nHowever, when it comes to allocation, an elastic sense of identity can be shown\nto exacerbate inequities in allocation, giving no rational incentive for agents\nto act fairly towards one another. This lead us to introduce a sense of\nfairness as an innate characteristic of autonomous agency. For this, we\nimplement the well-known Ultimatum Game between two agents, where their elastic\nsense of self (controlled by a parameter called $\\gamma$) and a sense of\nfairness (controlled by a parameter called $\\tau$) are both varied. We study\nthe points at which agents find it no longer rational to identify with the\nother agent, and uphold their sense of fairness, and vice versa. Such a study\nalso helps us discern the subtle difference between responsibility and fairness\nwhen it comes to autonomous agency.", "field": "Computer Science", "categories": "cs.GT,cs.MA"}, {"arxiv_id": "2401.11888", "title": "Multimodal Deep Learning of Word-of-Mouth Text and Demographics to\n  Predict Customer Rating: Handling Consumer Heterogeneity in Marketing", "abstract": "In the marketing field, understanding consumer heterogeneity, which is the\ninternal or psychological difference among consumers that cannot be captured by\nbehavioral logs, has long been a critical challenge. However, a number of\nconsumers today usually post their evaluation on the specific product on the\nonline platform, which can be the valuable source of such unobservable\ndifferences among consumers. Several previous studies have shown the validity\nof the analysis on text modality, but on the other hand, such analyses may not\nnecessarily demonstrate sufficient predictive accuracy for text alone, as they\nmay not include information readily available from cross-sectional data, such\nas consumer profile data. In addition, recent advances in machine learning\ntechniques, such as large-scale language models (LLMs) and multimodal learning\nhave made it possible to deal with the various kind of dataset simultaneously,\nincluding textual data and the traditional cross-sectional data, and the joint\nrepresentations can be effectively obtained from multiple modalities.\nTherefore, this study constructs a product evaluation model that takes into\naccount consumer heterogeneity by multimodal learning of online product reviews\nand consumer profile information. We also compare multiple models using\ndifferent modalities or hyper-parameters to demonstrate the robustness of\nmultimodal learning in marketing analysis.", "field": "Computer Science", "categories": "cs.CE,cs.LG"}, {"arxiv_id": "2401.1189", "title": "Shape uncertainty quantification of Maxwell eigenvalues and -modes with\n  application to TESLA cavities", "abstract": "We consider Maxwell eigenvalue problems on uncertain shapes with perfectly\nconducting TESLA cavities being the driving example. Due to the shape\nuncertainty, the resulting eigenvalues and eigenmodes are also uncertain and it\nis well known that the eigenvalues may exhibit crossings or bifurcations under\nperturbation. We discuss how the shape uncertainties can be modelled using the\ndomain mapping approach and how the deformation mapping can be expressed as\ncoefficients in Maxwell's equations. Using derivatives of these coefficients\nand derivatives of the eigenpairs, we follow a perturbation approach to compute\napproximations of mean and covariance of the eigenpairs. For small\nperturbations, these approximations are faster and more accurate than Monte\nCarlo or similar sampling-based strategies. Numerical experiments for a\nthree-dimensional 9-cell TESLA cavity are presented.", "field": "Computer Science", "categories": "math.NA,cs.CE,cs.NA,47A75, 65J10, 65C05, 65C20, 35Q61"}, {"arxiv_id": "2401.11892", "title": "AI, insurance, discrimination and unfair differentiation. An overview\n  and research agenda", "abstract": "Insurers increasingly use AI. We distinguish two situations in which insurers\nuse AI: (i) data-intensive underwriting, and (ii) behaviour-based insurance.\n(i) First, insurers can use AI for data analysis to assess risks:\ndata-intensive underwriting. Underwriting is, in short, calculating risks and\namending the insurance premium accordingly. (ii) Second, insurers can use AI to\nmonitor the behaviour of consumers in real-time: behaviour-based insurance. For\nexample, some car insurers give a discount if a consumer agrees to being\ntracked by the insurer and drives safely. While the two trends bring many\nadvantages, they may also have discriminatory effects. This paper focuses on\nthe following question. Which discrimination-related effects may occur if\ninsurers use data-intensive underwriting and behaviour-based insurance? We\nfocus on two types of discrimination-related effects: discrimination and other\nunfair differentiation. (i) Discrimination harms certain groups who are\nprotected by non-discrimination law, for instance people with certain\nethnicities. (ii) Unfair differentiation does not harm groups that are\nprotected by non-discrimination law, but it does seem unfair. We introduce four\nfactors to consider when assessing the fairness of insurance practices. The\npaper builds on literature from various disciplines including law, philosophy,\nand computer science.", "field": "Computer Science", "categories": "cs.CY"}, {"arxiv_id": "2401.11897", "title": "Towards Automatic Transformations of Coq Proof Scripts", "abstract": "Proof assistants like Coq are increasingly popular to help mathematicians\ncarry out proofs of the results they conjecture. However, formal proofs remain\nhighly technical and are especially difficult to reuse. In this paper, we\npresent a framework to carry out a posteriori script transformations. These\ntransformations are meant to be applied as an automated post-processing step,\nonce the proof has been completed. As an example, we present a transformation\nwhich takes an arbitrary large proof script and produces an equivalent\nsingle-line proof script, which can be executed by Coq in one single step.\nOther applications, such as fully expanding a proof script (for debugging\npurposes), removing all named hypotheses, etc. could be developed within this\nframework. We apply our tool to various Coq proof scripts, including some from\nthe GeoCoq library.", "field": "Computer Science", "categories": "cs.LO,cs.SC,cs.SE"}, {"arxiv_id": "2401.11898", "title": "Automated Completion of Statements and Proofs in Synthetic Geometry: an\n  Approach based on Constraint Solving", "abstract": "Conjecturing and theorem proving are activities at the center of mathematical\npractice and are difficult to separate. In this paper, we propose a framework\nfor completing incomplete conjectures and incomplete proofs. The framework can\nturn a conjecture with missing assumptions and with an under-specified goal\ninto a proper theorem. Also, the proposed framework can help in completing a\nproof sketch into a human-readable and machine-checkable proof. Our approach is\nfocused on synthetic geometry, and uses coherent logic and constraint solving.\nThe proposed approach is uniform for all three kinds of tasks, flexible and, to\nour knowledge, unique such approach.", "field": "Computer Science", "categories": "cs.AI,cs.LO,cs.MS"}, {"arxiv_id": "2401.119", "title": "Showing Proofs, Assessing Difficulty with GeoGebra Discovery", "abstract": "In our contribution we describe some on-going improvements concerning the\nAutomated Reasoning Tools developed in GeoGebra Discovery, providing different\nexamples of the performance of these new features. We describe the new\nShowProof command, that outputs both the sequence of the different steps\nperformed by GeoGebra Discovery to confirm a certain statement, as well as a\nnumber intending to grade the difficulty or interest of the assertion. The\nproposal of this assessment measure, involving the comparison of the expression\nof the thesis (or conclusion) as a combination of the hypotheses, will be\ndeveloped.", "field": "Computer Science", "categories": "cs.SC,cs.AI,cs.CG,cs.MS"}, {"arxiv_id": "2401.11901", "title": "ORBGRAND: Achievable Rate for General Bit Channels and Application in\n  BICM", "abstract": "Guessing random additive noise decoding (GRAND) has received widespread\nattention recently, and among its variants, ordered reliability bits GRAND\n(ORBGRAND) is particularly attractive due to its efficient utilization of soft\ninformation and its amenability to hardware implementation. It has been\nrecently shown that ORBGRAND is almost capacity-achieving in additive white\nGaussian noise channels under antipodal input. In this work, we first extend\nthe analysis of ORBGRAND achievable rate to memoryless binary-input bit\nchannels with general output conditional probability distributions. The\nanalytical result also sheds insight into understanding the gap between the\nORBGRAND achievable rate and the channel mutual information. As an application\nof the analysis, we study the ORBGRAND achievable rate of bit-interleaved coded\nmodulation (BICM). Numerical results indicate that for BICM, the gap between\nthe ORBGRAND achievable rate and the channel mutual information is typically\nsmall, and hence suggest the feasibility of ORBGRAND for channels with\nhigh-order coded modulation schemes.", "field": "Computer Science", "categories": "cs.IT,math.IT"}, {"arxiv_id": "2401.11903", "title": "Automation of Triangle Ruler-and-Compass Constructions Using Constraint\n  Solvers", "abstract": "In this paper, we present an approach to automated solving of triangle\nruler-and-compass construction problems using finite-domain constraint solvers.\nThe constraint model is described in the MiniZinc modeling language, and is\nbased on the automated planning. The main benefit of using general constraint\nsolvers for such purpose, instead of developing dedicated tools, is that we can\nrely on the efficient search that is already implemented within the solver,\nenabling us to focus on geometric aspects of the problem. We may also use the\nsolver's built-in optimization capabilities to search for the shortest possible\nconstructions. We evaluate our approach on 74 solvable problems from the\nWernick's list, and compare it to the dedicated triangle construction solver\nArgoTriCS. The results show that our approach is comparable to dedicated tools,\nwhile it requires much less effort to implement. Also, our model often finds\nshorter constructions, thanks to the optimization capabilities offered by the\nconstraint solvers.", "field": "Computer Science", "categories": "cs.AI"}, {"arxiv_id": "2401.11904", "title": "Towards an Independent Version of Tarski's System of Geometry", "abstract": "In 1926-1927, Tarski designed a set of axioms for Euclidean geometry which\nreached its final form in a manuscript by Schwabh\\\"auser, Szmielew and Tarski\nin 1983. The differences amount to simplifications obtained by Tarski and\nGupta. Gupta presented an independent version of Tarski's system of geometry,\nthus establishing that his version could not be further simplified without\nmodifying the axioms. To obtain the independence of one of his axioms, namely\nPasch's axiom, he proved the independence of one of its consequences: the\npreviously eliminated symmetry of betweenness. However, an independence model\nfor the non-degenerate part of Pasch's axiom was provided by Szczerba for\nanother version of Tarski's system of geometry in which the symmetry of\nbetweenness holds. This independence proof cannot be directly used for Gupta's\nversion as the statements of the parallel postulate differ.\n  In this paper, we present our progress towards obtaining an independent\nversion of a variant of Gupta's system. Compared to Gupta's version, we split\nPasch's axiom into this previously eliminated axiom and its non-degenerate part\nand change the statement of the parallel postulate. We verified the\nindependence properties by mechanizing counter-models using the Coq\nproof-assistant.", "field": "Computer Science", "categories": "cs.LO,F4"}, {"arxiv_id": "2401.11905", "title": "Considerations on Approaches and Metrics in Automated Theorem\n  Generation/Finding in Geometry", "abstract": "The pursue of what are properties that can be identified to permit an\nautomated reasoning program to generate and find new and interesting theorems\nis an interesting research goal (pun intended). The automatic discovery of new\ntheorems is a goal in itself, and it has been addressed in specific areas, with\ndifferent methods. The separation of the \"weeds\", uninteresting, trivial facts,\nfrom the \"wheat\", new and interesting facts, is much harder, but is also being\naddressed by different authors using different approaches. In this paper we\nwill focus on geometry. We present and discuss different approaches for the\nautomatic discovery of geometric theorems (and properties), and different\nmetrics to find the interesting theorems among all those that were generated.\nAfter this description we will introduce the first result of this article: an\nundecidability result proving that having an algorithmic procedure that decides\nfor every possible Turing Machine that produces theorems, whether it is able to\nproduce also interesting theorems, is an undecidable problem. Consequently, we\nwill argue that judging whether a theorem prover is able to produce interesting\ntheorems remains a non deterministic task, at best a task to be addressed by\nprogram based in an algorithm guided by heuristics criteria. Therefore, as a\nhuman, to satisfy this task two things are necessary: an expert survey that\nsheds light on what a theorem prover/finder of interesting geometric theorems\nis, and - to enable this analysis - other surveys that clarify metrics and\napproaches related to the interestingness of geometric theorems. In the\nconclusion of this article we will introduce the structure of two of these\nsurveys - the second result of this article - and we will discuss some future\nwork.", "field": "Computer Science", "categories": "cs.AI,cs.LO,I.2.3; F4"}, {"arxiv_id": "2401.11906", "title": "Solving with GeoGebra Discovery an Austrian Mathematics Olympiad\n  problem: Lessons Learned", "abstract": "We address, through the automated reasoning tools in GeoGebra Discovery, a\nproblem from a regional phase of the Austrian Mathematics Olympiad 2023. Trying\nto solve this problem gives rise to four different kind of feedback: the almost\ninstantaneous, automated solution of the proposed problem; the measure of its\ncomplexity, according to some recent proposals; the automated discovery of a\ngeneralization of the given assertion, showing that the same statement is true\nover more general polygons than those mentioned in the problem; and the\ndifficulties associated to the analysis of the surprising and involved high\nnumber of degenerate cases that appear when using the LocusEquation command in\nthis problem. In our communication we will describe and reflect on these\ndiverse issues, enhancing its exemplar role for showing some of the advantages,\nproblems, and current fields of development of GeoGebra Discovery.", "field": "Computer Science", "categories": "cs.SC,cs.AI,cs.CG,cs.MS"}, {"arxiv_id": "2401.11908", "title": "The Locus Story of a Rocking Camel in a Medical Center in the City of\n  Freistadt", "abstract": "We give an example of automated geometry reasoning for an imaginary classroom\nproject by using the free software package GeoGebra Discovery. The project is\nmotivated by a publicly available toy, a rocking camel, installed at a medical\ncenter in Upper Austria. We explain how the process of a false conjecture,\nexperimenting, modeling, a precise mathematical setup, and then a proof by\nautomated reasoning could help extend mathematical knowledge at secondary\nschool level and above.", "field": "Computer Science", "categories": "cs.RO,cs.CG,cs.MS,cs.SC"}, {"arxiv_id": "2401.11909", "title": "3D Space Trajectories and beyond: Abstract Art Creation with 3D Printing", "abstract": "We present simple models of trajectories in space, both in 2D and in 3D. The\nfirst examples, which model bicircular moves in the same direction, are\nclassical curves (epicycloids, etc.). Then, we explore bicircular moves in\nreverse direction and tricircular moves in 2D and 3D, to explore complex\nvisualisations of extraplanetary movements. These moves are studied in a plane\nsetting. Then, adding increasing complexity, we explore them in a non planar\nsetting (which is a closer model of the real situation). The exploration is\nfollowed by using these approaches for creating mathematical art in 2D and 3D\nprinted objects, providing new ways of mathematical representations. Students'\nactivities are organized around this exploration.", "field": "Computer Science", "categories": "cs.CG,cs.MS,cs.SC"}, {"arxiv_id": "2401.1191", "title": "Improving Angular Speed Uniformity by Piecewise Radical\n  Reparameterization", "abstract": "For a rational parameterization of a curve, it is desirable that its angular\nspeed is as uniform as possible. Hence, given a rational parameterization, one\nwants to find re-parameterization with better uniformity. One natural way is to\nuse piecewise rational reparameterization. However, it turns out that the\npiecewise rational reparameterization does not help when the angular speed of\nthe given rational parameterization is zero at some points on the curve. In\nthis paper, we show how to overcome the challenge by using piecewise radical\nreparameterization.", "field": "Computer Science", "categories": "cs.CG,I.3.3; I.3.5"}, {"arxiv_id": "2401.11911", "title": "Blinded by Generated Contexts: How Language Models Merge Generated and\n  Retrieved Contexts for Open-Domain QA?", "abstract": "While auxiliary information has become a key to enhance Large Language Models\n(LLMs), relatively little is known about how well LLMs merge these contexts,\nspecifically generated and retrieved. To study this, we formulate a task\nspecifically designed to identify whether the answers, derived from the\nintegration of generated and retrieved contexts, are attributed to either\ngenerated or retrieved contexts. To support this task, we develop a methodology\nto construct datasets with conflicting contexts, where each question is paired\nwith both generated and retrieved contexts, yet only one of them contains the\ncorrect answer. Our experiments reveal a significant bias in LLMs towards\ngenerated contexts, as evidenced across state-of-the-art open (Llama2-7b/13b)\nand closed (GPT 3.5/4) systems. We further identify two key factors\ncontributing to this bias: i) Contexts generated by LLMs typically show greater\nsimilarity to the questions, increasing their likelihood of selection; ii) The\nsegmentation process used in retrieved contexts disrupts their completeness,\nthereby hindering their full utilization in LLMs. Our analysis enhances the\nunderstanding of how LLMs merge diverse contexts, offering valuable insights\nfor advancing current augmentation methods for LLMs.", "field": "Computer Science", "categories": "cs.CL,cs.AI"}, {"arxiv_id": "2401.11913", "title": "Large receptive field strategy and important feature extraction strategy\n  in 3D object detection", "abstract": "The enhancement of 3D object detection is pivotal for precise environmental\nperception and improved task execution capabilities in autonomous driving.\nLiDAR point clouds, offering accurate depth information, serve as a crucial\ninformation for this purpose. Our study focuses on key challenges in 3D target\ndetection. To tackle the challenge of expanding the receptive field of a 3D\nconvolutional kernel, we introduce the Dynamic Feature Fusion Module (DFFM).\nThis module achieves adaptive expansion of the 3D convolutional kernel's\nreceptive field, balancing the expansion with acceptable computational loads.\nThis innovation reduces operations, expands the receptive field, and allows the\nmodel to dynamically adjust to different object requirements. Simultaneously,\nwe identify redundant information in 3D features. Employing the Feature\nSelection Module (FSM) quantitatively evaluates and eliminates non-important\nfeatures, achieving the separation of output box fitting and feature\nextraction. This innovation enables the detector to focus on critical features,\nresulting in model compression, reduced computational burden, and minimized\ncandidate frame interference. Extensive experiments confirm that both DFFM and\nFSM not only enhance current benchmarks, particularly in small target\ndetection, but also accelerate network performance. Importantly, these modules\nexhibit effective complementarity.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.11914", "title": "A Saliency Enhanced Feature Fusion based multiscale RGB-D Salient Object\n  Detection Network", "abstract": "Multiscale convolutional neural network (CNN) has demonstrated remarkable\ncapabilities in solving various vision problems. However, fusing features of\ndifferent scales alwaysresults in large model sizes, impeding the application\nof multiscale CNNs in RGB-D saliency detection. In this paper, we propose a\ncustomized feature fusion module, called Saliency Enhanced Feature Fusion\n(SEFF), for RGB-D saliency detection. SEFF utilizes saliency maps of the\nneighboring scales to enhance the necessary features for fusing, resulting in\nmore representative fused features. Our multiscale RGB-D saliency detector uses\nSEFF and processes images with three different scales. SEFF is used to fuse the\nfeatures of RGB and depth images, as well as the features of decoders at\ndifferent scales. Extensive experiments on five benchmark datasets have\ndemonstrated the superiority of our method over ten SOTA saliency detectors.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11915", "title": "Secure Multi-hop Telemetry Broadcasts for UAV Swarm Communication", "abstract": "Unmanned Aerial Vehicles (UAVs) are evolving as adaptable platforms for a\nwide range of applications such as precise inspections, emergency response, and\nremote sensing. Autonomous UAV swarms require efficient and stable\ncommunication during deployment for a successful mission execution. For\ninstance, the periodic exchange of telemetry data between all swarm members\nprovides the foundation for formation flight and collision avoidance. However,\ndue to the mobility of the vehicles and instability of wireless transmissions,\nmaintaining a secure and reliable all-to-all communication remains challenging.\nThis paper investigates encrypted and authenticated multi-hop broadcast\ncommunication based on the transmission of custom IEEE 802.11 Wi-Fi data\nframes.", "field": "Computer Science", "categories": "cs.CR,cs.RO"}, {"arxiv_id": "2401.11921", "title": "Maximizing Spectral and Energy Efficiency in Multi-user MIMO OFDM\n  Systems with RIS and Hardware Impairment", "abstract": "An emerging technology to enhance the spectral efficiency (SE) and energy\nefficiency (EE) of wireless communication systems is reconfigurable intelligent\nsurface (RIS), which is shown to be very powerful in single-carrier systems.\nHowever, in multi-user orthogonal frequency division multiplexing (OFDM)\nsystems, RIS may not be as promising as in single-carrier systems since an\nindependent optimization of RIS elements at each sub-carrier is impossible in\nmulti-carrier systems. Thus, this paper investigates the performance of various\nRIS technologies like regular (reflective and passive), simultaneously transmit\nand reflect (STAR), and multi-sector beyond diagonal (BD) RIS in multi-user\nmultiple-input multiple-output (MIMO) OFDM broadcast channels (BC). This\nrequires to formulate and solve a joint MIMO precoding and RIS optimization\nproblem. The obtained solution reveals that RIS can significantly improve the\nsystem performance even when the number of RIS elements is relatively low.\nMoreover, we develop resource allocation schemes for STAR-RIS and multi-sector\nBD-RIS in MIMO OFDM BCs, and show that these RIS technologies can outperform a\nregular RIS, especially when the regular RIS cannot assist the communications\nfor all the users.", "field": "Computer Science", "categories": "cs.IT,eess.SP,math.IT"}, {"arxiv_id": "2401.11923", "title": "VirtuWander: Enhancing Multi-modal Interaction for Virtual Tour Guidance\n  through Large Language Models", "abstract": "Tour guidance in virtual museums encourages multi-modal interactions to boost\nuser experiences, concerning engagement, immersion, and spatial awareness.\nNevertheless, achieving the goal is challenging due to the complexity of\ncomprehending diverse user needs and accommodating personalized user\npreferences. Informed by a formative study that characterizes guidance-seeking\ncontexts, we establish a multi-modal interaction design framework for virtual\ntour guidance. We then design VirtuWander, a two-stage innovative system using\ndomain-oriented large language models to transform user inquiries into diverse\nguidance-seeking contexts and facilitate multi-modal interactions. The\nfeasibility and versatility of VirtuWander are demonstrated with virtual\nguiding examples that encompass various touring scenarios and cater to\npersonalized preferences. We further evaluate VirtuWander through a user study\nwithin an immersive simulated museum. The results suggest that our system\nenhances engaging virtual tour experiences through personalized communication\nand knowledgeable assistance, indicating its potential for expanding into\nreal-world scenarios.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.11929", "title": "The Bigger the Better? Rethinking the Effective Model Scale in Long-term\n  Time Series Forecasting", "abstract": "Long-term time series forecasting (LTSF) represents a critical frontier in\ntime series analysis, distinguished by its focus on extensive input sequences,\nin contrast to the constrained lengths typical of traditional approaches. While\nlonger sequences inherently convey richer information, potentially enhancing\npredictive precision, prevailing techniques often respond by escalating model\ncomplexity. These intricate models can inflate into millions of parameters,\nincorporating parameter-intensive elements like positional encodings,\nfeed-forward networks and self-attention mechanisms. This complexity, however,\nleads to prohibitive model scale, particularly given the time series data's\nsemantic simplicity. Motivated by the pursuit of parsimony, our research\nemploys conditional correlation and auto-correlation as investigative tools,\nrevealing significant redundancies within the input data. Leveraging these\ninsights, we introduce the HDformer, a lightweight Transformer variant enhanced\nwith hierarchical decomposition. This novel architecture not only inverts the\nprevailing trend toward model expansion but also accomplishes precise\nforecasting with drastically fewer computations and parameters. Remarkably,\nHDformer outperforms existing state-of-the-art LTSF models, while requiring\nover 99\\% fewer parameters. Through this work, we advocate a paradigm shift in\nLTSF, emphasizing the importance to tailor the model to the inherent dynamics\nof time series data-a timely reminder that in the realm of LTSF, bigger is not\ninvariably better.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.11932", "title": "Accelerating Causal Algorithms for Industrial-scale Data: A Distributed\n  Computing Approach with Ray Framework", "abstract": "The increasing need for causal analysis in large-scale industrial datasets\nnecessitates the development of efficient and scalable causal algorithms for\nreal-world applications. This paper addresses the challenge of scaling causal\nalgorithms in the context of conducting causal analysis on extensive datasets\ncommonly encountered in industrial settings. Our proposed solution involves\nenhancing the scalability of causal algorithm libraries, such as EconML, by\nleveraging the parallelism capabilities offered by the distributed computing\nframework Ray. We explore the potential of parallelizing key iterative steps\nwithin causal algorithms to significantly reduce overall runtime, supported by\na case study that examines the impact on estimation times and costs. Through\nthis approach, we aim to provide a more effective solution for implementing\ncausal analysis in large-scale industrial applications.", "field": "Computer Science", "categories": "cs.DC,C.4; E.2; I.2.1"}, {"arxiv_id": "2401.11934", "title": "Systematic Performance Evaluation Framework for LEO Mega-Constellation\n  Satellite Networks", "abstract": "Low Earth orbit (LEO) mega-constellation satellite networks have shown great\npotential to extend the coverage capability of conventional terrestrial\nnetworks. How to systematically define, quantify, and assess the technical\nperformance of LEO mega-constellation satellite networks remains an open issue.\nIn this paper, we propose a comprehensive key performance indicator (KPI)\nframework for mega-constellation based LEO satellite networks. An efficient LEO\nconstellation oriented performance evaluation methodology is then carefully\ndesigned by resorting to the concept of interfering area and spherical\ngeographic cell. We have carried out rigorous system-level simulations and\nprovided numerical results to assess the KPI framework. It can be observed that\nthe achieved area traffic capacity of the reference LEO constellation is around\n4 Kbps/km2, with service availability ranging from 0.36 to 0.39. Besides, the\naverage access success probability and handover failure rate is approximate to\n96% and 10%, respectively, in the nearest satellite association scheme.", "field": "Computer Science", "categories": "cs.PF"}, {"arxiv_id": "2401.1194", "title": "Low-Tubal-Rank Tensor Recovery via Factorized Gradient Descent", "abstract": "This paper considers the problem of recovering a tensor with an underlying\nlow-tubal-rank structure from a small number of corrupted linear measurements.\nTraditional approaches tackling such a problem require the computation of\ntensor Singular Value Decomposition (t-SVD), that is a computationally\nintensive process, rendering them impractical for dealing with large-scale\ntensors. Aim to address this challenge, we propose an efficient and effective\nlow-tubal-rank tensor recovery method based on a factorization procedure akin\nto the Burer-Monteiro (BM) method. Precisely, our fundamental approach involves\ndecomposing a large tensor into two smaller factor tensors, followed by solving\nthe problem through factorized gradient descent (FGD). This strategy eliminates\nthe need for t-SVD computation, thereby reducing computational costs and\nstorage requirements. We provide rigorous theoretical analysis to ensure the\nconvergence of FGD under both noise-free and noisy situations. Additionally, it\nis worth noting that our method does not require the precise estimation of the\ntensor tubal-rank. Even in cases where the tubal-rank is slightly\noverestimated, our approach continues to demonstrate robust performance. A\nseries of experiments have been carried out to demonstrate that, as compared to\nother popular ones, our approach exhibits superior performance in multiple\nscenarios, in terms of the faster computational speed and the smaller\nconvergence error.", "field": "Computer Science", "categories": "cs.LG,math.OC,stat.ML"}, {"arxiv_id": "2401.11943", "title": "Benchmarking Large Multimodal Models against Common Corruptions", "abstract": "This technical report aims to fill a deficiency in the assessment of large\nmultimodal models (LMMs) by specifically examining the self-consistency of\ntheir outputs when subjected to common corruptions. We investigate the\ncross-modal interactions between text, image, and speech, encompassing four\nessential generation tasks: text-to-image, image-to-text, text-to-speech, and\nspeech-to-text. We create a comprehensive benchmark, named MMCBench, that\ncovers more than 100 popular LMMs (totally over 150 model checkpoints). A\nthorough evaluation under common corruptions is critical for practical\ndeployment and facilitates a better understanding of the reliability of\ncutting-edge LMMs. The benchmarking code is available at\nhttps://github.com/sail-sg/MMCBench", "field": "Computer Science", "categories": "cs.LG,cs.CL,cs.CR,cs.CV,cs.MM"}, {"arxiv_id": "2401.11944", "title": "CMMMU: A Chinese Massive Multi-discipline Multimodal Understanding\n  Benchmark", "abstract": "As the capabilities of large multimodal models (LMMs) continue to advance,\nevaluating the performance of LMMs emerges as an increasing need. Additionally,\nthere is an even larger gap in evaluating the advanced knowledge and reasoning\nabilities of LMMs in non-English contexts such as Chinese. We introduce CMMMU,\na new Chinese Massive Multi-discipline Multimodal Understanding benchmark\ndesigned to evaluate LMMs on tasks demanding college-level subject knowledge\nand deliberate reasoning in a Chinese context. CMMMU is inspired by and\nstrictly follows the annotation and analysis pattern of MMMU.\n  CMMMU includes 12k manually collected multimodal questions from college\nexams, quizzes, and textbooks, covering six core disciplines: Art & Design,\nBusiness, Science, Health & Medicine, Humanities & Social Science, and Tech &\nEngineering, like its companion, MMMU. These questions span 30 subjects and\ncomprise 39 highly heterogeneous image types, such as charts, diagrams, maps,\ntables, music sheets, and chemical structures.\n  CMMMU focuses on complex perception and reasoning with domain-specific\nknowledge in the Chinese context. We evaluate 11 open-source LLMs and one\nproprietary GPT-4V(ision). Even GPT-4V only achieves accuracies of 42%,\nindicating a large space for improvement. CMMMU will boost the community to\nbuild the next-generation LMMs towards expert artificial intelligence and\npromote the democratization of LMMs by providing diverse language contexts.", "field": "Computer Science", "categories": "cs.CL,cs.AI,cs.CV"}, {"arxiv_id": "2401.11945", "title": "The Effect of Predictive Formal Modelling at Runtime on Performance in\n  Human-Swarm Interaction", "abstract": "Formal Modelling is often used as part of the design and testing process of\nsoftware development to ensure that components operate within suitable bounds\neven in unexpected circumstances. In this paper, we use predictive formal\nmodelling (PFM) at runtime in a human-swarm mission and show that this\nintegration can be used to improve the performance of human-swarm teams. We\nrecruited 60 participants to operate a simulated aerial swarm to deliver\nparcels to target locations. In the PFM condition, operators were informed of\nthe estimated completion times given the number of drones deployed, whereas in\nthe No-PFM condition, operators did not have this information. The operators\ncould control the mission by adding or removing drones from the mission and\nthereby, increasing or decreasing the overall mission cost. The evaluation of\nhuman-swarm performance relied on four key metrics: the time taken to complete\ntasks, the number of agents involved, the total number of tasks accomplished,\nand the overall cost associated with the human-swarm task. Our results show\nthat PFM modelling at runtime improves mission performance without\nsignificantly affecting the operator's workload or the system's usability.", "field": "Computer Science", "categories": "cs.RO,cs.HC"}, {"arxiv_id": "2401.11946", "title": "A Dynamic YOLO-Based Sequence-Matching Model for Efficient Coverless\n  Image Steganography", "abstract": "Many existing coverless steganography methods establish a mapping\nrelationship between cover images and hidden data. There exists an issue that\nthe number of images stored in the database grows exponentially as the\nsteganographic capacity rises. The need for a high steganographic capacity\nmakes it challenging to build an image database. To improve the image library\nutilization and anti-attack capability of the steganography system, we present\nan efficient coverless scheme based on dynamically matched substrings. YOLO is\nemployed for selecting optimal objects, and a mapping dictionary is established\nbetween these objects and scrambling factors. With the aid of this dictionary,\neach image is effectively assigned to a specific scrambling factor, which is\nused to scramble the receiver's sequence key. To achieve sufficient\nsteganography capability based on a limited image library, all substrings of\nthe scrambled sequences hold the potential to hide data. After completing the\nsecret information matching, the ideal number of stego images will be obtained\nfrom the database. According to experimental results, this technology\noutperforms most previous works on data load, transmission security, and hiding\ncapacity. Under typical geometric attacks, it can recover 79.85\\% of secret\ninformation on average. Furthermore, only approximately 200 random images are\nneeded to meet a capacity of 19 bits per image.", "field": "Computer Science", "categories": "cs.CR"}, {"arxiv_id": "2401.11948", "title": "The Ensemble Kalman Filter for Dynamic Inverse Problems", "abstract": "In inverse problems, the goal is to estimate unknown model parameters from\nnoisy observational data. Traditionally, inverse problems are solved under the\nassumption of a fixed forward operator describing the observation model. In\nthis article, we consider the extension of this approach to situations where we\nhave a dynamic forward model, motivated by applications in scientific\ncomputation and engineering. We specifically consider this extension for a\nderivative-free optimizer, the ensemble Kalman inversion (EKI). We introduce\nand justify a new methodology called dynamic-EKI, which is a particle-based\nmethod with a changing forward operator. We analyze our new method, presenting\nresults related to the control of our particle system through its covariance\nstructure. This analysis includes moment bounds and an ensemble collapse, which\nare essential for demonstrating a convergence result. We establish convergence\nin expectation and validate our theoretical findings through experiments with\ndynamic-EKI applied to a 2D Darcy flow partial differential equation.", "field": "Computer Science", "categories": "math.NA,cs.NA,stat.ME"}, {"arxiv_id": "2401.11949", "title": "Feature Denoising Diffusion Model for Blind Image Quality Assessment", "abstract": "Blind Image Quality Assessment (BIQA) aims to evaluate image quality in line\nwith human perception, without reference benchmarks. Currently, deep learning\nBIQA methods typically depend on using features from high-level tasks for\ntransfer learning. However, the inherent differences between BIQA and these\nhigh-level tasks inevitably introduce noise into the quality-aware features. In\nthis paper, we take an initial step towards exploring the diffusion model for\nfeature denoising in BIQA, namely Perceptual Feature Diffusion for IQA\n(PFD-IQA), which aims to remove noise from quality-aware features.\nSpecifically, (i) We propose a {Perceptual Prior Discovery and Aggregation\nmodule to establish two auxiliary tasks to discover potential low-level\nfeatures in images that are used to aggregate perceptual text conditions for\nthe diffusion model. (ii) We propose a Perceptual Prior-based Feature\nRefinement strategy, which matches noisy features to predefined denoising\ntrajectories and then performs exact feature denoising based on text\nconditions. Extensive experiments on eight standard BIQA datasets demonstrate\nthe superior performance to the state-of-the-art BIQA methods, i.e., achieving\nthe PLCC values of 0.935 ( vs. 0.905 in KADID) and 0.922 ( vs. 0.894 in LIVEC).", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.11951", "title": "A Stabilised Semi-Implicit Double-Point Material Point Method for\n  Soil-Water Coupled Problems", "abstract": "A semi-implicit two-phase double-point Material Point Method (MPM)\nformulation, based on the incremental fractional-step method to model large\ndeformation geotechnical problems has been derived. The semi-implicit\nformulation has two advantages compared with the explicit approach: the time\nstep is independent of the water phase, and the pore pressure field is more\nstable. The semi-implicit MPM models based on the incremental fractional-step\nmethod available in the literature consist of modelling the soil and water\nmixture using a single set of material points only, in order to save\ncomputational time. In this study, we further derive this formulation with two\nsets of material points to represent the soil and water phases separately. The\nstress oscillations that are frequently found in the water and soil phases are\nstabilised with this approach. A new stabilisation method is developed based on\nthe modified F-bar method. The proposed method is validated with two numerical\nexamples under small and large deformations, respectively. After that, Nor-Sand\nconstitutive soil model is used to simulate landslides. Numerical examples show\nan excellent performance of the proposed coupled MPM and the stabilisation\nmethod. The formulation with two sets of material points yields significantly\ndifferent but more reliable results in the landslides analysis, compared with\nthe single-point approach. Additionally, this research shows that the\nadditional computational cost caused by the additional water material points is\nacceptable. Therefore, it is recommended to use two sets of material points for\ncertain large deformation geotechnical problems.", "field": "Computer Science", "categories": "math.NA,cs.NA"}, {"arxiv_id": "2401.11954", "title": "RUMBoost: Gradient Boosted Random Utility Models", "abstract": "This paper introduces the RUMBoost model, a novel discrete choice modelling\napproach that combines the interpretability and behavioural robustness of\nRandom Utility Models (RUMs) with the generalisation and predictive ability of\ndeep learning methods. We obtain the full functional form of non-linear utility\nspecifications by replacing each linear parameter in the utility functions of a\nRUM with an ensemble of gradient boosted regression trees. This enables\npiece-wise constant utility values to be imputed for all alternatives directly\nfrom the data for any possible combination of input variables. We introduce\nadditional constraints on the ensembles to ensure three crucial features of the\nutility specifications: (i) dependency of the utilities of each alternative on\nonly the attributes of that alternative, (ii) monotonicity of marginal\nutilities, and (iii) an intrinsically interpretable functional form, where the\nexact response of the model is known throughout the entire input space.\nFurthermore, we introduce an optimisation-based smoothing technique that\nreplaces the piece-wise constant utility values of alternative attributes with\nmonotonic piece-wise cubic splines to identify non-linear parameters with\ndefined gradient. We demonstrate the potential of the RUMBoost model compared\nto various ML and Random Utility benchmark models for revealed preference mode\nchoice data from London. The results highlight the great predictive performance\nand the direct interpretability of our proposed approach. Furthermore, the\nsmoothed attribute utility functions allow for the calculation of various\nbehavioural indicators and marginal utilities. Finally, we demonstrate the\nflexibility of our methodology by showing how the RUMBoost model can be\nextended to complex model specifications, including attribute interactions,\ncorrelation within alternative error terms and heterogeneity within the\npopulation.", "field": "Computer Science", "categories": "cs.LG,stat.ML"}, {"arxiv_id": "2401.1196", "title": "Observation-Guided Meteorological Field Downscaling at Station Scale: A\n  Benchmark and a New Method", "abstract": "Downscaling (DS) of meteorological variables involves obtaining\nhigh-resolution states from low-resolution meteorological fields and is an\nimportant task in weather forecasting. Previous methods based on deep learning\ntreat downscaling as a super-resolution task in computer vision and utilize\nhigh-resolution gridded meteorological fields as supervision to improve\nresolution at specific grid scales. However, this approach has struggled to\nalign with the continuous distribution characteristics of meteorological\nfields, leading to an inherent systematic bias between the downscaled results\nand the actual observations at meteorological stations. In this paper, we\nextend meteorological downscaling to arbitrary scattered station scales,\nestablish a brand new benchmark and dataset, and retrieve meteorological states\nat any given station location from a coarse-resolution meteorological field.\nInspired by data assimilation techniques, we integrate observational data into\nthe downscaling process, providing multi-scale observational priors. Building\non this foundation, we propose a new downscaling model based on hypernetwork\narchitecture, namely HyperDS, which efficiently integrates different\nobservational information into the model training, achieving continuous scale\nmodeling of the meteorological field. Through extensive experiments, our\nproposed method outperforms other specially designed baseline models on\nmultiple surface variables. Notably, the mean squared error (MSE) for wind\nspeed and surface pressure improved by 67% and 19.5% compared to other methods.\nWe will release the dataset and code subsequently.", "field": "Computer Science", "categories": "cs.CV,eess.IV"}, {"arxiv_id": "2401.11961", "title": "Enhancing Safety in Nonlinear Systems: Design and Stability Analysis of\n  Adaptive Cruise Control", "abstract": "The safety of autonomous driving systems, particularly self-driving vehicles,\nremains of paramount concern. These systems exhibit affine nonlinear dynamics\nand face the challenge of executing predefined control tasks while adhering to\nstate and input constraints to mitigate risks. However, achieving safety\ncontrol within the framework of control input constraints, such as collision\navoidance and maintaining system states within secure boundaries, presents\nchallenges due to limited options. In this study, we introduce a novel approach\nto address safety concerns by transforming safety conditions into control\nconstraints with a relative degree of 1. This transformation is facilitated\nthrough the design of control barrier functions, enabling the creation of a\nsafety control system for affine nonlinear networks. Subsequently, we formulate\na robust control strategy that incorporates safety protocols and conduct a\ncomprehensive analysis of its stability and reliability. To illustrate the\neffectiveness of our approach, we apply it to a specific problem involving\nadaptive cruise control. Through simulations, we validate the efficiency of our\nmodel in ensuring safety without compromising control performance. Our approach\nsignifies significant progress in the field, providing a practical solution to\nenhance safety for autonomous driving systems operating within the context of\naffine nonlinear dynamics.", "field": "Computer Science", "categories": "cs.SY,eess.SY"}, {"arxiv_id": "2401.11963", "title": "Bridging Evolutionary Algorithms and Reinforcement Learning: A\n  Comprehensive Survey", "abstract": "Evolutionary Reinforcement Learning (ERL), which integrates Evolutionary\nAlgorithms (EAs) and Reinforcement Learning (RL) for optimization, has\ndemonstrated remarkable performance advancements. By fusing the strengths of\nboth approaches, ERL has emerged as a promising research direction. This survey\noffers a comprehensive overview of the diverse research branches in ERL.\nSpecifically, we systematically summarize recent advancements in relevant\nalgorithms and identify three primary research directions: EA-assisted\noptimization of RL, RL-assisted optimization of EA, and synergistic\noptimization of EA and RL. Following that, we conduct an in-depth analysis of\neach research direction, organizing multiple research branches. We elucidate\nthe problems that each branch aims to tackle and how the integration of EA and\nRL addresses these challenges. In conclusion, we discuss potential challenges\nand prospective future research directions across various research directions.", "field": "Computer Science", "categories": "cs.NE,cs.AI,cs.LG"}, {"arxiv_id": "2401.11968", "title": "Effective Intrusion Detection in Heterogeneous Internet-of-Things\n  Networks via Ensemble Knowledge Distillation-based Federated Learning", "abstract": "With the rapid development of low-cost consumer electronics and cloud\ncomputing, Internet-of-Things (IoT) devices are widely adopted for supporting\nnext-generation distributed systems such as smart cities and industrial control\nsystems. IoT devices are often susceptible to cyber attacks due to their open\ndeployment environment and limited computing capabilities for stringent\nsecurity controls. Hence, Intrusion Detection Systems (IDS) have emerged as one\nof the effective ways of securing IoT networks by monitoring and detecting\nabnormal activities. However, existing IDS approaches rely on centralized\nservers to generate behaviour profiles and detect anomalies, causing high\nresponse time and large operational costs due to communication overhead.\nBesides, sharing of behaviour data in an open and distributed IoT network\nenvironment may violate on-device privacy requirements. Additionally, various\nIoT devices tend to capture heterogeneous data, which complicates the training\nof behaviour models. In this paper, we introduce Federated Learning (FL) to\ncollaboratively train a decentralized shared model of IDS, without exposing\ntraining data to others. Furthermore, we propose an effective method called\nFederated Learning Ensemble Knowledge Distillation (FLEKD) to mitigate the\nheterogeneity problems across various clients. FLEKD enables a more flexible\naggregation method than conventional model fusion techniques. Experiment\nresults on the public dataset CICIDS2019 demonstrate that the proposed approach\noutperforms local training and traditional FL in terms of both speed and\nperformance and significantly improves the system's ability to detect unknown\nattacks. Finally, we evaluate our proposed framework's performance in three\npotential real-world scenarios and show FLEKD has a clear advantage in\nexperimental results.", "field": "Computer Science", "categories": "cs.CR"}, {"arxiv_id": "2401.11969", "title": "Claim Detection for Automated Fact-checking: A Survey on Monolingual,\n  Multilingual and Cross-Lingual Research", "abstract": "Automated fact-checking has drawn considerable attention over the past few\ndecades due to the increase in the diffusion of misinformation on online\nplatforms. This is often carried out as a sequence of tasks comprising (i) the\ndetection of sentences circulating in online platforms which constitute claims\nneeding verification, followed by (ii) the verification process of those\nclaims. This survey focuses on the former, by discussing existing efforts\ntowards detecting claims needing fact-checking, with a particular focus on\nmultilingual data and methods. This is a challenging and fertile direction\nwhere existing methods are yet far from matching human performance due to the\nprofoundly challenging nature of the issue. Especially, the dissemination of\ninformation across multiple social platforms, articulated in multiple languages\nand modalities demands more generalized solutions for combating misinformation.\nFocusing on multilingual misinformation, we present a comprehensive survey of\nexisting multilingual claim detection research. We present state-of-the-art\nmultilingual claim detection research categorized into three key factors of the\nproblem, verifiability, priority, and similarity. Further, we present a\ndetailed overview of the existing multilingual datasets along with the\nchallenges and suggest possible future advancements.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.11972", "title": "Synergizing Machine Learning & Symbolic Methods: A Survey on Hybrid\n  Approaches to Natural Language Processing", "abstract": "The advancement of machine learning and symbolic approaches have underscored\ntheir strengths and weaknesses in Natural Language Processing (NLP). While\nmachine learning approaches are powerful in identifying patterns in data, they\noften fall short in learning commonsense and the factual knowledge required for\nthe NLP tasks. Meanwhile, the symbolic methods excel in representing\nknowledge-rich data. However, they struggle to adapt dynamic data and\ngeneralize the knowledge. Bridging these two paradigms through hybrid\napproaches enables the alleviation of weaknesses in both while preserving their\nstrengths. Recent studies extol the virtues of this union, showcasing promising\nresults in a wide range of NLP tasks. In this paper, we present an overview of\nhybrid approaches used for NLP. Specifically, we delve into the\nstate-of-the-art hybrid approaches used for a broad spectrum of NLP tasks\nrequiring natural language understanding, generation, and reasoning.\nFurthermore, we discuss the existing resources available for hybrid approaches\nfor NLP along with the challenges, offering a roadmap for future directions.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.11974", "title": "Cross-Validation Conformal Risk Control", "abstract": "Conformal risk control (CRC) is a recently proposed technique that applies\npost-hoc to a conventional point predictor to provide calibration guarantees.\nGeneralizing conformal prediction (CP), with CRC, calibration is ensured for a\nset predictor that is extracted from the point predictor to control a risk\nfunction such as the probability of miscoverage or the false negative rate. The\noriginal CRC requires the available data set to be split between training and\nvalidation data sets. This can be problematic when data availability is\nlimited, resulting in inefficient set predictors. In this paper, a novel CRC\nmethod is introduced that is based on cross-validation, rather than on\nvalidation as the original CRC. The proposed cross-validation CRC (CV-CRC)\nextends a version of the jackknife-minmax from CP to CRC, allowing for the\ncontrol of a broader range of risk functions. CV-CRC is proved to offer\ntheoretical guarantees on the average risk of the set predictor. Furthermore,\nnumerical experiments show that CV-CRC can reduce the average set size with\nrespect to CRC when the available data are limited.", "field": "Computer Science", "categories": "cs.LG,stat.ML"}, {"arxiv_id": "2401.11977", "title": "Adaptive Motion Planning for Multi-fingered Functional Grasp via Force\n  Feedback", "abstract": "Enabling multi-fingered robots to grasp and manipulate objects with\nhuman-like dexterity is especially challenging during the dynamic, continuous\nhand-object interactions. Closed-loop feedback control is essential for\ndexterous hands to dynamically finetune hand poses when performing precise\nfunctional grasps. This work proposes an adaptive motion planning method based\non deep reinforcement learning to adjust grasping poses according to real-time\nfeedback from joint torques from pre-grasp to goal grasp. We find the\nmulti-joint torques of the dexterous hand can sense object positions through\ncontacts and collisions, enabling real-time adjustment of grasps to generate\nvarying grasping trajectories for objects in different positions. In our\nexperiments, the performance gap with and without force feedback reveals the\nimportant role of force feedback in adaptive manipulation. Our approach\nutilizing force feedback preliminarily exhibits human-like flexibility,\nadaptability, and precision.", "field": "Computer Science", "categories": "cs.RO"}, {"arxiv_id": "2401.11981", "title": "Learning Analytics in Higher Education -- Exploring Students and\n  Teachers Expectations in Germany", "abstract": "Technology enhanced learning analytics has the potential to play a\nsignificant role in higher education in the future. Opinions and expectations\ntowards technology and learning analytics, thus, are vital to consider for\ninstitutional developments in higher education institutions. The Sheila\nframework offers instruments to yield exploratory knowledge about stakeholder\naspirations towards technology, such as learning analytics in higher education.\nThe sample of the study consists of students (N = 1169) and teachers (N = 497)\nat a higher education institution in Germany. Using self-report questionnaires,\nwe assessed students and teachers attitudes towards learning analytics in\nhigher education teaching, comparing ideal and expected circumstances. We\nreport results on the attitudes of students, teachers, as well as comparisons\nof the two groups and different disciplines. We discuss the results with regard\nto practical implications for the implementation and further developments of\nlearning analytics in higher education.", "field": "Computer Science", "categories": "cs.CY"}, {"arxiv_id": "2401.11983", "title": "Lightweight Protection for Privacy in Offloaded Speech Understanding", "abstract": "Speech is a common input method for mobile embedded devices, but cloud-based\nspeech recognition systems pose privacy risks. Disentanglement-based encoders,\ndesigned to safeguard user privacy by filtering sensitive information from\nspeech signals, unfortunately require substantial memory and computational\nresources, which limits their use in less powerful devices. To overcome this,\nwe introduce a novel system, XXX, optimized for such devices. XXX is built on\nthe insight that speech understanding primarily relies on understanding the\nentire utterance's long-term dependencies, while privacy concerns are often\nlinked to short-term details. Therefore, XXX focuses on selectively masking\nthese short-term elements, preserving the quality of long-term speech\nunderstanding. The core of XXX is an innovative differential mask generator,\ngrounded in interpretable learning, which fine-tunes the masking process. We\ntested XXX on the STM32H7 microcontroller, assessing its performance in various\npotential attack scenarios. The results show that XXX maintains speech\nunderstanding accuracy and privacy at levels comparable to existing encoders,\nbut with a significant improvement in efficiency, achieving up to 53.3$\\times$\nfaster processing and a 134.1$\\times$ smaller memory footprint.", "field": "Computer Science", "categories": "cs.SD,cs.CR,eess.AS"}, {"arxiv_id": "2401.11985", "title": "Scaling Face Interaction Graph Networks to Real World Scenes", "abstract": "Accurately simulating real world object dynamics is essential for various\napplications such as robotics, engineering, graphics, and design. To better\ncapture complex real dynamics such as contact and friction, learned simulators\nbased on graph networks have recently shown great promise. However, applying\nthese learned simulators to real scenes comes with two major challenges: first,\nscaling learned simulators to handle the complexity of real world scenes which\ncan involve hundreds of objects each with complicated 3D shapes, and second,\nhandling inputs from perception rather than 3D state information. Here we\nintroduce a method which substantially reduces the memory required to run\ngraph-based learned simulators. Based on this memory-efficient simulation\nmodel, we then present a perceptual interface in the form of editable NeRFs\nwhich can convert real-world scenes into a structured representation that can\nbe processed by graph network simulator. We show that our method uses\nsubstantially less memory than previous graph-based simulators while retaining\ntheir accuracy, and that the simulators learned in synthetic environments can\nbe applied to real world scenes captured from multiple camera angles. This\npaves the way for expanding the application of learned simulators to settings\nwhere only perceptual information is available at inference time.", "field": "Computer Science", "categories": "cs.LG,cs.CV,cs.RO"}, {"arxiv_id": "2401.11991", "title": "Tight Bounds on the Message Complexity of Distributed Tree Verification", "abstract": "We consider the message complexity of verifying whether a given subgraph of\nthe communication network forms a tree with specific properties both in the\nKT-$\\rho$ (nodes know their $\\rho$-hop neighborhood, including node IDs) and\nthe KT-$0$ (nodes do not have this knowledge) models. We develop a rather\ngeneral framework that helps in establishing tight lower bounds for various\ntree verification problems. We also consider two different verification\nrequirements: namely that every node detects in the case the input is\nincorrect, as well as the requirement that at least one node detects. The\nresults are stronger than previous ones in the sense that we assume that each\nnode knows the number $n$ of nodes in the graph (in some cases) or an $\\alpha$\napproximation of $n$ (in other cases). For spanning tree verification, we show\nthat the message complexity inherently depends on the quality of the given\napproximation of $n$: We show a tight lower bound of $\\Omega(n^2)$ for the case\n$\\alpha \\ge \\sqrt{2}$ and a much better upper bound (i.e., $O(n \\log n)$) when\nnodes are given a tighter approximation. On the other hand, our framework also\nyields an $\\Omega(n^2)$ lower bound on the message complexity of verifying a\nminimum spanning tree (MST), which reveals a polynomial separation between ST\nverification and MST verification. This result holds for randomized algorithms\nwith perfect knowledge of the network size, and even when just one node detects\nillegal inputs, thus improving over the work of Kor, Korman, and Peleg (2013).\nFor verifying a $d$-approximate BFS tree, we show that the same lower bound\nholds even if nodes know $n$ exactly, however, the lower bound is sensitive to\n$d$, which is the stretch parameter.", "field": "Computer Science", "categories": "cs.DC,cs.DS"}, {"arxiv_id": "2401.11993", "title": "Expert-Driven Monitoring of Operational ML Models", "abstract": "We propose Expert Monitoring, an approach that leverages domain expertise to\nenhance the detection and mitigation of concept drift in machine learning (ML)\nmodels. Our approach supports practitioners by consolidating domain expertise\nrelated to concept drift-inducing events, making this expertise accessible to\non-call personnel, and enabling automatic adaptability with expert oversight.", "field": "Computer Science", "categories": "cs.LG,cs.SE"}, {"arxiv_id": "2401.12", "title": "Integrating Statistical Significance and Discriminative Power in Pattern\n  Discovery", "abstract": "Pattern discovery plays a central role in both descriptive and predictive\ntasks across multiple domains. Actionable patterns must meet rigorous\nstatistical significance criteria and, in the presence of target variables,\nfurther uphold discriminative power. Our work addresses the underexplored area\nof guiding pattern discovery by integrating statistical significance and\ndiscriminative power criteria into state-of-the-art algorithms while preserving\npattern quality. We also address how pattern quality thresholds, imposed by\nsome algorithms, can be rectified to accommodate these additional criteria. To\ntest the proposed methodology, we select the triclustering task as the guiding\npattern discovery case and extend well-known greedy and multi-objective\noptimization triclustering algorithms, $\\delta$-Trimax and TriGen, that use\nvarious pattern quality criteria, such as Mean Squared Residual (MSR), Least\nSquared Lines (LSL), and Multi Slope Measure (MSL). Results from three case\nstudies show the role of the proposed methodology in discovering patterns with\npronounced improvements of discriminative power and statistical significance\nwithout quality deterioration, highlighting its importance in supervisedly\nguiding the search. Although the proposed methodology is motivated over\nmultivariate time series data, it can be straightforwardly extended to pattern\ndiscovery tasks involving multivariate, N-way (N>3), transactional, and\nsequential data structures.\n  Availability: The code is freely available at\nhttps://github.com/JupitersMight/MOF_Triclustering under the MIT license.", "field": "Computer Science", "categories": "cs.LG,stat.ML"}, {"arxiv_id": "2401.12001", "title": "Modeling Stereo-Confidence Out of the End-to-End Stereo-Matching Network\n  via Disparity Plane Sweep", "abstract": "We propose a novel stereo-confidence that can be measured externally to\nvarious stereo-matching networks, offering an alternative input modality choice\nof the cost volume for learning-based approaches, especially in safety-critical\nsystems. Grounded in the foundational concepts of disparity definition and the\ndisparity plane sweep, the proposed stereo-confidence method is built upon the\nidea that any shift in a stereo-image pair should be updated in a corresponding\namount shift in the disparity map. Based on this idea, the proposed\nstereo-confidence method can be summarized in three folds. 1) Using the\ndisparity plane sweep, multiple disparity maps can be obtained and treated as a\n3-D volume (predicted disparity volume), like the cost volume is constructed.\n2) One of these disparity maps serves as an anchor, allowing us to define a\ndesirable (or ideal) disparity profile at every spatial point. 3) By comparing\nthe desirable and predicted disparity profiles, we can quantify the level of\nmatching ambiguity between left and right images for confidence measurement.\nExtensive experimental results using various stereo-matching networks and\ndatasets demonstrate that the proposed stereo-confidence method not only shows\ncompetitive performance on its own but also consistent performance improvements\nwhen it is used as an input modality for learning-based stereo-confidence\nmethods.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.12002", "title": "HgbNet: predicting hemoglobin level/anemia degree from EHR data", "abstract": "Anemia is a prevalent medical condition that typically requires invasive\nblood tests for diagnosis and monitoring. Electronic health records (EHRs) have\nemerged as valuable data sources for numerous medical studies. EHR-based\nhemoglobin level/anemia degree prediction is non-invasive and rapid but still\nfaces some challenges due to the fact that EHR data is typically an irregular\nmultivariate time series containing a significant number of missing values and\nirregular time intervals. To address these issues, we introduce HgbNet, a\nmachine learning-based prediction model that emulates clinicians'\ndecision-making processes for hemoglobin level/anemia degree prediction. The\nmodel incorporates a NanDense layer with a missing indicator to handle missing\nvalues and employs attention mechanisms to account for both local irregularity\nand global irregularity. We evaluate the proposed method using two real-world\ndatasets across two use cases. In our first use case, we predict hemoglobin\nlevel/anemia degree at moment T+1 by utilizing records from moments prior to\nT+1. In our second use case, we integrate all historical records with\nadditional selected test results at moment T+1 to predict hemoglobin\nlevel/anemia degree at the same moment, T+1. HgbNet outperforms the best\nbaseline results across all datasets and use cases. These findings demonstrate\nthe feasibility of estimating hemoglobin levels and anemia degree from EHR\ndata, positioning HgbNet as an effective non-invasive anemia diagnosis solution\nthat could potentially enhance the quality of life for millions of affected\nindividuals worldwide. To our knowledge, HgbNet is the first machine learning\nmodel leveraging EHR data for hemoglobin level/anemia degree prediction.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.12005", "title": "ALMs: Authorial Language Models for Authorship Attribution", "abstract": "In this paper, we introduce an authorship attribution method called Authorial\nLanguage Models (ALMs) that involves identifying the most likely author of a\nquestioned document based on the perplexity of the questioned document\ncalculated for a set of causal language models fine-tuned on the writings of a\nset of candidate author. We benchmarked ALMs against state-of-art-systems using\nthe CCAT50 dataset and the Blogs50 datasets. We find that ALMs achieves a\nmacro-average accuracy score of 83.6% on Blogs50, outperforming all other\nmethods, and 74.9% on CCAT50, matching the performance of the best method. To\nassess the performance of ALMs on shorter texts, we also conducted text\nablation testing. We found that to reach a macro-average accuracy of 70%, ALMs\nneeds 40 tokens on Blogs50 and 400 tokens on CCAT50, while to reach 60% ALMs\nrequires 20 tokens on Blogs50 and 70 tokens on CCAT50.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.12007", "title": "Tensor-view Topological Graph Neural Network", "abstract": "Graph classification is an important learning task for graph-structured data.\nGraph neural networks (GNNs) have recently gained growing attention in graph\nlearning and have shown significant improvements in many important graph\nproblems. Despite their state-of-the-art performances, existing GNNs only use\nlocal information from a very limited neighborhood around each node, suffering\nfrom loss of multi-modal information and overheads of excessive computation. To\naddress these issues, we propose a novel Tensor-view Topological Graph Neural\nNetwork (TTG-NN), a class of simple yet effective topological deep learning\nbuilt upon persistent homology, graph convolution, and tensor operations. This\nnew method incorporates tensor learning to simultaneously capture Tensor-view\nTopological (TT), as well as Tensor-view Graph (TG) structural information on\nboth local and global levels. Computationally, to fully exploit graph topology\nand structure, we propose two flexible TT and TG representation learning\nmodules that disentangle feature tensor aggregation and transformation and\nlearn to preserve multi-modal structure with less computation. Theoretically,\nwe derive high probability bounds on both the out-of-sample and in-sample mean\nsquared approximation errors for our proposed Tensor Transformation Layer\n(TTL). Real data experiments show that the proposed TTG-NN outperforms 20\nstate-of-the-art methods on various graph benchmarks.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.1201", "title": "On a class of interdiction problems with partition matroids: complexity\n  and polynomial-time algorithms", "abstract": "In this study, we consider a class of linear matroid interdiction problems,\nwhere the feasible sets for the upper-level decision-maker (referred to as the\nleader) and the lower-level decision-maker (referred to as the follower) are\ngiven by partition matroids with a common ground set. In contrast to classical\nnetwork interdiction models where the leader is subject to a single budget\nconstraint, in our setting, both the leader and the follower are subject to\nseveral independent cardinality constraints and engage in a zero-sum game.\nWhile a single-level linear integer programming problem over a partition\nmatroid is known to be polynomially solvable, we prove that the considered\nbilevel problem is NP-hard, even when the objective function coefficients are\nall binary. On a positive note, it turns out that, if the number of cardinality\nconstraints is fixed for either the leader or the follower, then the considered\nclass of bilevel problems admits several polynomial-time solution schemes.\nSpecifically, these schemes are based on a single-level dual reformulation, a\ndynamic programming-based approach, and a 2-flip local search algorithm for the\nleader.", "field": "Computer Science", "categories": "cs.CC,math.OC"}, {"arxiv_id": "2401.12011", "title": "Architecting Data-Intensive Applications : From Data Architecture Design\n  to Its Quality Assurance", "abstract": "Context - The exponential growth of data is becoming a significant concern.\nManaging this data has become incredibly challenging, especially when dealing\nwith various sources in different formats and speeds. Moreover, Ensuring data\nquality has become increasingly crucial for effective decision-making and\noperational processes. Data Architecture is crucial in describing, collecting,\nstoring, processing, and analyzing data to meet business needs. Providing an\nabstract view of data-intensive applications is essential to ensure that the\ndata is transformed into valuable information. We must take these challenges\nseriously to ensure we can effectively manage and use the data to our\nadvantage. Objective - To establish an architecture framework that enables a\ncomprehensive description of the data architecture and effectively streamlines\ndata quality monitoring. Method - The architecture framework utilizes Model\nDriven Engineering (MDE) techniques. Its backing of data-intensive architecture\ndescriptions empowers with an automated generation for data quality checks.\nResult - The Framework offers a comprehensive solution for data-intensive\napplications to model their architecture efficiently and monitor the quality of\ntheir data. It automates the entire process and ensures precision and\nconsistency in data. With DAT, architects and analysts gain access to a\npowerful tool that simplifies their workflow and empowers them to make informed\ndecisions based on reliable data insights. Conclusion - We have evaluated the\nDAT on more than five cases within various industry domains, demonstrating its\nexceptional adaptability and effectiveness.", "field": "Computer Science", "categories": "cs.SE"}, {"arxiv_id": "2401.12012", "title": "TurboSVM-FL: Boosting Federated Learning through SVM Aggregation for\n  Lazy Clients", "abstract": "Federated learning is a distributed collaborative machine learning paradigm\nthat has gained strong momentum in recent years. In federated learning, a\ncentral server periodically coordinates models with clients and aggregates the\nmodels trained locally by clients without necessitating access to local data.\nDespite its potential, the implementation of federated learning continues to\nencounter several challenges, predominantly the slow convergence that is\nlargely due to data heterogeneity. The slow convergence becomes particularly\nproblematic in cross-device federated learning scenarios where clients may be\nstrongly limited by computing power and storage space, and hence counteracting\nmethods that induce additional computation or memory cost on the client side\nsuch as auxiliary objective terms and larger training iterations can be\nimpractical. In this paper, we propose a novel federated aggregation strategy,\nTurboSVM-FL, that poses no additional computation burden on the client side and\ncan significantly accelerate convergence for federated classification task,\nespecially when clients are \"lazy\" and train their models solely for few epochs\nfor next global aggregation. TurboSVM-FL extensively utilizes support vector\nmachine to conduct selective aggregation and max-margin spread-out\nregularization on class embeddings. We evaluate TurboSVM-FL on multiple\ndatasets including FEMNIST, CelebA, and Shakespeare using user-independent\nvalidation with non-iid data distribution. Our results show that TurboSVM-FL\ncan significantly outperform existing popular algorithms on convergence rate\nand reduce communication rounds while delivering better test metrics including\naccuracy, F1 score, and MCC.", "field": "Computer Science", "categories": "cs.LG,cs.DC"}, {"arxiv_id": "2401.12014", "title": "Robustness to distribution shifts of compressed networks for edge\n  devices", "abstract": "It is necessary to develop efficient DNNs deployed on edge devices with\nlimited computation resources. However, the compressed networks often execute\nnew tasks in the target domain, which is different from the source domain where\nthe original network is trained. It is important to investigate the robustness\nof compressed networks in two types of data distribution shifts: domain shifts\nand adversarial perturbations. In this study, we discover that compressed\nmodels are less robust to distribution shifts than their original networks.\nInterestingly, larger networks are more vulnerable to losing robustness than\nsmaller ones, even when they are compressed to a similar size as the smaller\nnetworks. Furthermore, compact networks obtained by knowledge distillation are\nmuch more robust to distribution shifts than pruned networks. Finally,\npost-training quantization is a reliable method for achieving significant\nrobustness to distribution shifts, and it outperforms both pruned and distilled\nmodels in terms of robustness.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.CV"}, {"arxiv_id": "2401.12018", "title": "PairwiseHist: Fast, Accurate and Space-Efficient Approximate Query\n  Processing with Data Compression", "abstract": "Exponential growth in data collection is creating significant challenges for\ndata storage and analytics latency.Approximate Query Processing (AQP) has long\nbeen touted as a solution for accelerating analytics on large datasets,\nhowever, there is still room for improvement across all key performance\ncriteria. In this paper, we propose a novel histogram-based data synopsis\ncalled PairwiseHist that uses recursive hypothesis testing to ensure accurate\nhistograms and can be built on top of data compressed using Generalized\nDeduplication (GD). We thus show that GD data compression can contribute to\nAQP. Compared to state-of-the-art AQP approaches, PairwiseHist achieves better\nperformance across all key metrics, including 2.6$ \\times $ higher accuracy,\n3.5$ \\times $ lower latency, 24$ \\times $ smaller synopses and 1.5--4$ \\times $\nfaster construction time.", "field": "Computer Science", "categories": "cs.DB"}, {"arxiv_id": "2401.12019", "title": "Stereo-Matching Knowledge Distilled Monocular Depth Estimation Filtered\n  by Multiple Disparity Consistency", "abstract": "In stereo-matching knowledge distillation methods of the self-supervised\nmonocular depth estimation, the stereo-matching network's knowledge is\ndistilled into a monocular depth network through pseudo-depth maps. In these\nmethods, the learning-based stereo-confidence network is generally utilized to\nidentify errors in the pseudo-depth maps to prevent transferring the errors.\nHowever, the learning-based stereo-confidence networks should be trained with\nground truth (GT), which is not feasible in a self-supervised setting. In this\npaper, we propose a method to identify and filter errors in the pseudo-depth\nmap using multiple disparity maps by checking their consistency without the\nneed for GT and a training process. Experimental results show that the proposed\nmethod outperforms the previous methods and works well on various\nconfigurations by filtering out erroneous areas where the stereo-matching is\nvulnerable, especially such as textureless regions, occlusion boundaries, and\nreflective surfaces.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.12023", "title": "A Simulation of Optimal Dryness When Moving in the Rain or Snow Using\n  MATLAB", "abstract": "The classic question of whether one should walk or run in the rain to remain\nthe least wet has inspired a myriad of solutions ranging from physically\nperforming test runs in raining conditions to mathematically modeling human\nmovement through rain. This manuscript approaches the classical problem by\nsimulating movement through rainfall using MATLAB. Our simulation was\ngeneralizable to include snowfall as well. An increase in walking speed\nresulted in a corresponding decrease in raindrop and snowflake collisions. When\nraindrops or snowflakes were given a horizontal movement vector due to wind, a\nlocal minimum in collisions was achieved when moving in parallel with the same\nhorizontal speed as the raindrop; no local minimum was detected with\nantiparallel movement. In general, our simulation revealed that the faster one\nmoves, the drier one remains.", "field": "Computer Science", "categories": "cs.DM,cs.MS,68U20"}, {"arxiv_id": "2401.12024", "title": "Multimodal Visual-Tactile Representation Learning through\n  Self-Supervised Contrastive Pre-Training", "abstract": "The rapidly evolving field of robotics necessitates methods that can\nfacilitate the fusion of multiple modalities. Specifically, when it comes to\ninteracting with tangible objects, effectively combining visual and tactile\nsensory data is key to understanding and navigating the complex dynamics of the\nphysical world, enabling a more nuanced and adaptable response to changing\nenvironments. Nevertheless, much of the earlier work in merging these two\nsensory modalities has relied on supervised methods utilizing datasets labeled\nby humans.This paper introduces MViTac, a novel methodology that leverages\ncontrastive learning to integrate vision and touch sensations in a\nself-supervised fashion. By availing both sensory inputs, MViTac leverages\nintra and inter-modality losses for learning representations, resulting in\nenhanced material property classification and more adept grasping prediction.\nThrough a series of experiments, we showcase the effectiveness of our method\nand its superiority over existing state-of-the-art self-supervised and\nsupervised techniques. In evaluating our methodology, we focus on two distinct\ntasks: material classification and grasping success prediction. Our results\nindicate that MViTac facilitates the development of improved modality encoders,\nyielding more robust representations as evidenced by linear probing\nassessments.", "field": "Computer Science", "categories": "cs.RO,cs.AI,cs.LG"}, {"arxiv_id": "2401.12025", "title": "A Survey of Advances in Optimization Methods for Wireless Communication\n  System Design", "abstract": "Mathematical optimization is now widely regarded as an indispensable modeling\nand solution tool for the design of wireless communications systems. While\noptimization has played a significant role in the revolutionary progress in\nwireless communication and networking technologies from 1G to 5G and onto the\nfuture 6G, the innovations in wireless technologies have also substantially\ntransformed the nature of the underlying mathematical optimization problems\nupon which the system designs are based and have sparked significant\ninnovations in the development of methodologies to understand, to analyze, and\nto solve those problems. In this paper, we provide a comprehensive survey of\nrecent advances in mathematical optimization theory and algorithms for wireless\ncommunication system design. We begin by illustrating common features of\nmathematical optimization problems arising in wireless communication system\ndesign. We discuss various scenarios and use cases and their associated\nmathematical structures from an optimization perspective. We then provide an\noverview of recent advances in mathematical optimization theory and algorithms,\nfrom nonconvex optimization, global optimization, and integer programming, to\ndistributed optimization and learning-based optimization. The key to successful\nsolution of mathematical optimization problems is in carefully choosing and/or\ndeveloping suitable optimization algorithms (or neural network architectures)\nthat can exploit the underlying problem structure. We conclude the paper by\nidentifying several open research challenges and outlining future research\ndirections.", "field": "Computer Science", "categories": "cs.IT,eess.SP,math.IT,math.OC"}, {"arxiv_id": "2401.12029", "title": "Near-Field Localization with $1$-bit Quantized Hybrid A/D Reception", "abstract": "In this paper, we consider a hybrid Analog and Digital (A/D) receiver\narchitecture with an extremely large Dynamic Metasurface Antenna (DMA) and an\n$1$-bit resolution Analog-to-Digital Converter (ADC) at each of its reception\nradio-frequency chains, and present a localization approach for User Equipment\n(UE) lying in its near-field regime. The proposed algorithm scans the UE area\nof interest to identify the DMA-based analog combining configuration resulting\nto the peak in a received pseudo-spectrum, yielding the UE position estimation\nin three dimensions. Our simulation results demonstrate the validity of the\nproposed scheme, especially for increasing DMA sizes, and showcase the\ninterplay among various system parameters.", "field": "Computer Science", "categories": "cs.IT,cs.ET,math.IT"}, {"arxiv_id": "2401.12032", "title": "MINT: A wrapper to make multi-modal and multi-image AI models\n  interactive", "abstract": "During the diagnostic process, doctors incorporate multimodal information\nincluding imaging and the medical history - and similarly medical AI\ndevelopment has increasingly become multimodal. In this paper we tackle a more\nsubtle challenge: doctors take a targeted medical history to obtain only the\nmost pertinent pieces of information; how do we enable AI to do the same? We\ndevelop a wrapper method named MINT (Make your model INTeractive) that\nautomatically determines what pieces of information are most valuable at each\nstep, and ask for only the most useful information. We demonstrate the efficacy\nof MINT wrapping a skin disease prediction model, where multiple images and a\nset of optional answers to $25$ standard metadata questions (i.e., structured\nmedical history) are used by a multi-modal deep network to provide a\ndifferential diagnosis. We show that MINT can identify whether metadata inputs\nare needed and if so, which question to ask next. We also demonstrate that when\ncollecting multiple images, MINT can identify if an additional image would be\nbeneficial, and if so, which type of image to capture. We showed that MINT\nreduces the number of metadata and image inputs needed by 82% and 36.2%\nrespectively, while maintaining predictive performance. Using real-world AI\ndermatology system data, we show that needing fewer inputs can retain users\nthat may otherwise fail to complete the system submission and drop off without\na diagnosis. Qualitative examples show MINT can closely mimic the step-by-step\ndecision making process of a clinical workflow and how this is different for\nstraight forward cases versus more difficult, ambiguous cases. Finally we\ndemonstrate how MINT is robust to different underlying multi-model classifiers\nand can be easily adapted to user requirements without significant model\nre-training.", "field": "Computer Science", "categories": "cs.HC,cs.AI"}, {"arxiv_id": "2401.12033", "title": "Momentum-SAM: Sharpness Aware Minimization without Computational\n  Overhead", "abstract": "The recently proposed optimization algorithm for deep neural networks\nSharpness Aware Minimization (SAM) suggests perturbing parameters before\ngradient calculation by a gradient ascent step to guide the optimization into\nparameter space regions of flat loss. While significant generalization\nimprovements and thus reduction of overfitting could be demonstrated, the\ncomputational costs are doubled due to the additionally needed gradient\ncalculation, making SAM unfeasible in case of limited computationally\ncapacities. Motivated by Nesterov Accelerated Gradient (NAG) we propose\nMomentum-SAM (MSAM), which perturbs parameters in the direction of the\naccumulated momentum vector to achieve low sharpness without significant\ncomputational overhead or memory demands over SGD or Adam. We evaluate MSAM in\ndetail and reveal insights on separable mechanisms of NAG, SAM and MSAM\nregarding training optimization and generalization. Code is available at\nhttps://github.com/MarlonBecker/MSAM.", "field": "Computer Science", "categories": "cs.LG,cs.CV"}, {"arxiv_id": "2401.12036", "title": "Joint Near-Field Target Tracking and Communications with Full Duplex\n  Holographic MIMO", "abstract": "In this paper, we present a simultaneous target tracking and multi-user\ncommunications system realized by a full duplex holographic Multiple-Input\nMultiple-Output (MIMO) node equipped with Dynamic Metasurface Antennas (DMAs)\nat both its communication ends. Focusing on the near-field regime, we extend\nFresnel's approximation to metasurfaces and devise a subspace tracking scheme\nwith DMA-based hybrid Analog and Digital (A/D) reception as well as hybrid A/D\ntransmission with a DMA for sum-rate maximization. The presented simulation\nresults corroborate the efficiency of the proposed framework for various system\nparameters.", "field": "Computer Science", "categories": "cs.IT,cs.ET,math.IT"}, {"arxiv_id": "2401.12039", "title": "Look, Listen and Recognise: Character-Aware Audio-Visual Subtitling", "abstract": "The goal of this paper is automatic character-aware subtitle generation.\nGiven a video and a minimal amount of metadata, we propose an audio-visual\nmethod that generates a full transcript of the dialogue, with precise speech\ntimestamps, and the character speaking identified. The key idea is to first use\naudio-visual cues to select a set of high-precision audio exemplars for each\ncharacter, and then use these exemplars to classify all speech segments by\nspeaker identity. Notably, the method does not require face detection or\ntracking. We evaluate the method over a variety of TV sitcoms, including\nSeinfeld, Fraiser and Scrubs. We envision this system being useful for the\nautomatic generation of subtitles to improve the accessibility of the vast\namount of videos available on modern streaming services. Project page :\n\\url{https://www.robots.ox.ac.uk/~vgg/research/look-listen-recognise/}", "field": "Computer Science", "categories": "cs.CV,cs.SD,eess.AS"}, {"arxiv_id": "2401.12043", "title": "Energy-Conserving Hermite Methods for Maxwell's Equations", "abstract": "Energy-conserving Hermite methods for solving Maxwell's equations in\ndielectric and dispersive media are described and analyzed. In three space\ndimensions methods of order $2m$ to $2m+2$ require $(m+1)^3$ degrees-of-freedom\nper node for each field variable and can be explicitly marched in time with\nsteps independent of $m$. We prove stability for time steps limited only by\ndomain-of-dependence requirements along with error estimates in a special\nseminorm associated with the interpolation process. Numerical experiments are\npresented which demonstrate that Hermite methods of very high order enable the\nefficient simulation of electromagnetic wave propagation over thousands of\nwavelengths.", "field": "Computer Science", "categories": "math.NA,cs.NA"}, {"arxiv_id": "2401.12046", "title": "Fourier Transporter: Bi-Equivariant Robotic Manipulation in 3D", "abstract": "Many complex robotic manipulation tasks can be decomposed as a sequence of\npick and place actions. Training a robotic agent to learn this sequence over\nmany different starting conditions typically requires many iterations or\ndemonstrations, especially in 3D environments. In this work, we propose Fourier\nTransporter (\\ours{}) which leverages the two-fold $\\SE(d)\\times\\SE(d)$\nsymmetry in the pick-place problem to achieve much higher sample efficiency.\n\\ours{} is an open-loop behavior cloning method trained using expert\ndemonstrations to predict pick-place actions on new environments. \\ours{} is\nconstrained to incorporate symmetries of the pick and place actions\nindependently. Our method utilizes a fiber space Fourier transformation that\nallows for memory-efficient construction. We test our proposed network on the\nRLbench benchmark and achieve state-of-the-art results across various tasks.", "field": "Computer Science", "categories": "cs.RO,cs.LG"}, {"arxiv_id": "2401.12048", "title": "HomeRobot Open Vocabulary Mobile Manipulation Challenge 2023 Participant\n  Report (Team KuzHum)", "abstract": "We report an improvements to NeurIPS 2023 HomeRobot: Open Vocabulary Mobile\nManipulation (OVMM) Challenge reinforcement learning baseline. More\nspecifically, we propose more accurate semantic segmentation module, along with\nbetter place skill policy, and high-level heuristic that outperforms the\nbaseline by 2.4% of overall success rate (sevenfold improvement) and 8.2% of\npartial success rate (1.75 times improvement) on Test Standard split of the\nchallenge dataset. With aforementioned enhancements incorporated our agent\nscored 3rd place in the challenge on both simulation and real-world stages.", "field": "Computer Science", "categories": "cs.RO,cs.CV"}, {"arxiv_id": "2401.12051", "title": "CloSe: A 3D Clothing Segmentation Dataset and Model", "abstract": "3D Clothing modeling and datasets play crucial role in the entertainment,\nanimation, and digital fashion industries. Existing work often lacks detailed\nsemantic understanding or uses synthetic datasets, lacking realism and\npersonalization. To address this, we first introduce CloSe-D: a novel\nlarge-scale dataset containing 3D clothing segmentation of 3167 scans, covering\na range of 18 distinct clothing classes. Additionally, we propose CloSe-Net,\nthe first learning-based 3D clothing segmentation model for fine-grained\nsegmentation from colored point clouds. CloSe-Net uses local point features,\nbody-clothing correlation, and a garment-class and point features-based\nattention module, improving performance over baselines and prior work. The\nproposed attention module enables our model to learn appearance and\ngeometry-dependent clothing prior from data. We further validate the efficacy\nof our approach by successfully segmenting publicly available datasets of\npeople in clothing. We also introduce CloSe-T, a 3D interactive tool for\nrefining segmentation labels. Combining the tool with CloSe-T in a continual\nlearning setup demonstrates improved generalization on real-world data.\nDataset, model, and tool can be found at\nhttps://virtualhumans.mpi-inf.mpg.de/close3dv24/.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.12055", "title": "NEUROSEC: FPGA-Based Neuromorphic Audio Security", "abstract": "Neuromorphic systems, inspired by the complexity and functionality of the\nhuman brain, have gained interest in academic and industrial attention due to\ntheir unparalleled potential across a wide range of applications. While their\ncapabilities herald innovation, it is imperative to underscore that these\ncomputational paradigms, analogous to their traditional counterparts, are not\nimpervious to security threats. Although the exploration of neuromorphic\nmethodologies for image and video processing has been rigorously pursued, the\nrealm of neuromorphic audio processing remains in its early stages. Our results\nhighlight the robustness and precision of our FPGA-based neuromorphic system.\nSpecifically, our system showcases a commendable balance between desired signal\nand background noise, efficient spike rate encoding, and unparalleled\nresilience against adversarial attacks such as FGSM and PGD. A standout feature\nof our framework is its detection rate of 94%, which, when compared to other\nmethodologies, underscores its greater capability in identifying and mitigating\nthreats within 5.39 dB, a commendable SNR ratio. Furthermore, neuromorphic\ncomputing and hardware security serve many sensor domains in mission-critical\nand privacy-preserving applications.", "field": "Computer Science", "categories": "cs.CR,cs.ET,cs.LG,cs.NE,cs.SD,eess.AS"}, {"arxiv_id": "2401.12058", "title": "The Dimension Strikes Back with Gradients: Generalization of Gradient\n  Methods in Stochastic Convex Optimization", "abstract": "We study the generalization performance of gradient methods in the\nfundamental stochastic convex optimization setting, focusing on its dimension\ndependence. First, for full-batch gradient descent (GD) we give a construction\nof a learning problem in dimension $d=O(n^2)$, where the canonical version of\nGD (tuned for optimal performance of the empirical risk) trained with $n$\ntraining examples converges, with constant probability, to an approximate\nempirical risk minimizer with $\\Omega(1)$ population excess risk. Our bound\ntranslates to a lower bound of $\\Omega (\\sqrt{d})$ on the number of training\nexamples required for standard GD to reach a non-trivial test error, answering\nan open question raised by Feldman (2016) and Amir, Koren, and Livni (2021b)\nand showing that a non-trivial dimension dependence is unavoidable.\nFurthermore, for standard one-pass stochastic gradient descent (SGD), we show\nthat an application of the same construction technique provides a similar\n$\\Omega(\\sqrt{d})$ lower bound for the sample complexity of SGD to reach a\nnon-trivial empirical error, despite achieving optimal test performance. This\nagain provides an exponential improvement in the dimension dependence compared\nto previous work (Koren, Livni, Mansour, and Sherman, 2022), resolving an open\nquestion left therein.", "field": "Computer Science", "categories": "cs.LG,stat.ML"}, {"arxiv_id": "2401.1206", "title": "SEDAC: A CVAE-Based Data Augmentation Method for Security Bug Report\n  Identification", "abstract": "Bug tracking systems store many bug reports, some of which are related to\nsecurity. Identifying those security bug reports (SBRs) may help us predict\nsome security-related bugs and solve security issues promptly so that the\nproject can avoid threats and attacks. However, in the real world, the ratio of\nsecurity bug reports is severely low; thus, directly training a prediction\nmodel with raw data may result in inaccurate results. Faced with the massive\nchallenge of data imbalance, many researchers in the past have attempted to use\ntext filtering or clustering methods to minimize the proportion of non-security\nbug reports (NSBRs) or apply oversampling methods to synthesize SBRs to make\nthe dataset as balanced as possible. Nevertheless, there are still two\nchallenges to those methods: 1) They ignore long-distance contextual\ninformation. 2) They fail to generate an utterly balanced dataset. To tackle\nthese two challenges, we propose SEDAC, a new SBR identification method that\ngenerates similar bug report vectors to solve data imbalance problems and\naccurately detect security bug reports. Unlike previous studies, it first\nconverts bug reports into individual bug report vectors with distilBERT, which\nare based on word2vec. Then, it trains a generative model through conditional\nvariational auto-encoder (CVAE) to generate similar vectors with security\nlabels, which makes the number of SBRs equal to NSBRs'. Finally, balanced data\nare used to train a security bug report classifier. To evaluate the\neffectiveness of our framework, we conduct it on 45,940 bug reports from\nChromium and four Apache projects. The experimental results show that SEDAC\noutperforms all the baselines in g-measure with improvements of around\n14.24%-50.10%.", "field": "Computer Science", "categories": "cs.CR,cs.SE"}, {"arxiv_id": "2401.12061", "title": "Scalable Automated Verification for Cyber-Physical Systems in\n  Isabelle/HOL", "abstract": "We formally introduce IsaVODEs (Isabelle verification with Ordinary\nDifferential Equations), a framework for the verification of cyber-physical\nsystems. We describe the semantic foundations of the framework's formalisation\nin the Isabelle/HOL proof assistant. A user-friendly language specification\nbased on a robust state model makes our framework flexible and adaptable to\nvarious engineering workflows. New additions to the framework increase both its\nexpressivity and proof automation. Specifically, formalisations related to\nforward diamond correctness specifications, certification of unique solutions\nto ordinary differential equations (ODEs) as flows, and invariant reasoning for\nsystems of ODEs contribute to the framework's scalability and usability.\nVarious examples and an evaluation validate the effectiveness of our framework.", "field": "Computer Science", "categories": "cs.LO,cs.MS"}, {"arxiv_id": "2401.12067", "title": "A concise proof of Commoner's theorem", "abstract": "The textbook proofs of Commoner's theorem characterizing liveness in\nfree-choice Petri nets are given in contexts of technical notions and claims\nthat make the proofs look a bit long. The aim of this note is to give a concise\nself-contained proof.", "field": "Computer Science", "categories": "cs.LO"}, {"arxiv_id": "2401.12068", "title": "Resource-constrained stereo singing voice cancellation", "abstract": "We study the problem of stereo singing voice cancellation, a subtask of music\nsource separation, whose goal is to estimate an instrumental background from a\nstereo mix. We explore how to achieve performance similar to large\nstate-of-the-art source separation networks starting from a small, efficient\nmodel for real-time speech separation. Such a model is useful when memory and\ncompute are limited and singing voice processing has to run with limited\nlook-ahead. In practice, this is realised by adapting an existing mono model to\nhandle stereo input. Improvements in quality are obtained by tuning model\nparameters and expanding the training set. Moreover, we highlight the benefits\na stereo model brings by introducing a new metric which detects attenuation\ninconsistencies between channels. Our approach is evaluated using objective\noffline metrics and a large-scale MUSHRA trial, confirming the effectiveness of\nour techniques in stringent listening tests.", "field": "Computer Science", "categories": "cs.SD,cs.LG,eess.AS"}, {"arxiv_id": "2401.12069", "title": "Beyond TreeSHAP: Efficient Computation of Any-Order Shapley Interactions\n  for Tree Ensembles", "abstract": "While shallow decision trees may be interpretable, larger ensemble models\nlike gradient-boosted trees, which often set the state of the art in machine\nlearning problems involving tabular data, still remain black box models. As a\nremedy, the Shapley value (SV) is a well-known concept in explainable\nartificial intelligence (XAI) research for quantifying additive feature\nattributions of predictions. The model-specific TreeSHAP methodology solves the\nexponential complexity for retrieving exact SVs from tree-based models.\nExpanding beyond individual feature attribution, Shapley interactions reveal\nthe impact of intricate feature interactions of any order. In this work, we\npresent TreeSHAP-IQ, an efficient method to compute any-order additive Shapley\ninteractions for predictions of tree-based models. TreeSHAP-IQ is supported by\na mathematical framework that exploits polynomial arithmetic to compute the\ninteraction scores in a single recursive traversal of the tree, akin to Linear\nTreeSHAP. We apply TreeSHAP-IQ on state-of-the-art tree ensembles and explore\ninteractions on well-established benchmark datasets.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.1207", "title": "Spotting LLMs With Binoculars: Zero-Shot Detection of Machine-Generated\n  Text", "abstract": "Detecting text generated by modern large language models is thought to be\nhard, as both LLMs and humans can exhibit a wide range of complex behaviors.\nHowever, we find that a score based on contrasting two closely related language\nmodels is highly accurate at separating human-generated and machine-generated\ntext. Based on this mechanism, we propose a novel LLM detector that only\nrequires simple calculations using a pair of pre-trained LLMs. The method,\ncalled Binoculars, achieves state-of-the-art accuracy without any training\ndata. It is capable of spotting machine text from a range of modern LLMs\nwithout any model-specific modifications. We comprehensively evaluate\nBinoculars on a number of text sources and in varied situations. Over a wide\nrange of document types, Binoculars detects over 90% of generated samples from\nChatGPT (and other LLMs) at a false positive rate of 0.01%, despite not being\ntrained on any ChatGPT data.", "field": "Computer Science", "categories": "cs.CL,cs.AI,cs.LG"}, {"arxiv_id": "2401.12071", "title": "An Irredundant and Compressed Data Layout to Optimize Bandwidth\n  Utilization of FPGA Accelerators", "abstract": "Memory bandwidth is known to be a performance bottleneck for FPGA\naccelerators, especially when they deal with large multi-dimensional data-sets.\nA large body of work focuses on reducing of off-chip transfers, but few authors\ntry to improve the efficiency of transfers. This paper addresses the later\nissue by proposing (i) a compiler-based approach to accelerator's data layout\nto maximize contiguous access to off-chip memory, and (ii) data packing and\nruntime compression techniques that take advantage of this layout to further\nimprove memory performance. We show that our approach can decrease the I/O\ncycles up to $7\\times$ compared to un-optimized memory accesses.", "field": "Computer Science", "categories": "cs.AR"}, {"arxiv_id": "2401.12072", "title": "Cross-lingual Transfer Learning for Javanese Dependency Parsing", "abstract": "While structure learning achieves remarkable performance in high-resource\nlanguages, the situation differs for under-represented languages due to the\nscarcity of annotated data. This study focuses on assessing the efficacy of\ntransfer learning in enhancing dependency parsing for Javanese, a language\nspoken by 80 million individuals but characterized by limited representation in\nnatural language processing. We utilized the Universal Dependencies dataset\nconsisting of dependency treebanks from more than 100 languages, including\nJavanese. We propose two learning strategies to train the model: transfer\nlearning (TL) and hierarchical transfer learning (HTL). While TL only uses a\nsource language to pre-train the model, the HTL method uses a source language\nand an intermediate language in the learning process. The results show that our\nbest model uses the HTL method, which improves performance with an increase of\n10% for both UAS and LAS evaluations compared to the baseline model.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.12073", "title": "The time slot allocation problem in liberalised passenger railway\n  markets: a multi-objective approach", "abstract": "The liberalisation of the European passenger railway markets through the\nEuropean Directive EU 91/440/EEC states a new scenario where different Railway\nUndertakings compete with each other in a bidding process for time slots. The\ninfrastructure resources are provided by the Infrastructure Manager, who\nanalyses and assesses the bids received, allocating the resources to each\nRailway Undertaking. Time slot allocation is a fact that drastically influences\nthe market equilibrium. In this paper, we address the time slot allocation\nproblem within the context of a liberalized passenger railway market as a\nmulti-objective model. The Infrastructure Manager is tasked with selecting a\npoint from the Pareto front as the solution to the time slot allocation\nproblem. We propose two criteria for making this selection: the first one\nallocates time slots to each company according to a set of priorities, while\nthe second one introduces a criterion of fairness in the treatment of companies\nto incentive competition. The assessment of the impact of these rules on market\nequilibrium has been conducted on a liberalized high-speed corridor within the\nSpanish railway network.", "field": "Computer Science", "categories": "cs.CE,MS-class:90-05,I.6; J.6"}, {"arxiv_id": "2401.12075", "title": "NLP-based Relation Extraction Methods in RE", "abstract": "Mobile app repositories have been largely used in scientific research as\nlarge-scale, highly adaptive crowdsourced information systems. These software\nplatforms can potentially nourish multiple software and requirements\nengineering tasks based on user reviews and other natural language documents,\nincluding feedback analysis, recommender systems and topic modelling.\nConsequently, researchers often endeavour to overcome domain-specific\nchallenges, including integration of heterogeneous data sources, large-scale\ndata collection and adaptation of a publicly available data set for a given\nresearch scenario. In this paper, we present MApp-KG, a combination of software\nresources and data artefacts in the field of mobile app repositories to support\nextended knowledge generation tasks. Our contribution aims to provide a\nframework for automatically constructing a knowledge graph modelling a\ndomain-specific catalogue of mobile apps. Complementarily, we distribute\nMApp-KG in a public triplestore and as a static data snapshot, which may be\npromptly employed for future research and reproduction of our findings.", "field": "Computer Science", "categories": "cs.SE"}, {"arxiv_id": "2401.12076", "title": "Human Impression of Humanoid Robots Mirroring Social Cues", "abstract": "Mirroring non-verbal social cues such as affect or movement can enhance\nhuman-human and human-robot interactions in the real world. The robotic\nplatforms and control methods also impact people's perception of human-robot\ninteraction. However, limited studies have compared robot imitation across\ndifferent platforms and control methods. Our research addresses this gap by\nconducting two experiments comparing people's perception of affective mirroring\nbetween the iCub and Pepper robots and movement mirroring between vision-based\niCub control and Inertial Measurement Unit (IMU)-based iCub control. We\ndiscovered that the iCub robot was perceived as more humanlike than the Pepper\nrobot when mirroring affect. A vision-based controlled iCub outperformed the\nIMU-based controlled one in the movement mirroring task. Our findings suggest\nthat different robotic platforms impact people's perception of robots'\nmirroring during HRI. The control method also contributes to the robot's\nmirroring performance. Our work sheds light on the design and application of\ndifferent humanoid robots in the real world.", "field": "Computer Science", "categories": "cs.RO,cs.HC"}, {"arxiv_id": "2401.12078", "title": "Temporal Blind Spots in Large Language Models", "abstract": "Large language models (LLMs) have recently gained significant attention due\nto their unparalleled ability to perform various natural language processing\ntasks. These models, benefiting from their advanced natural language\nunderstanding capabilities, have demonstrated impressive zero-shot performance.\nHowever, the pre-training data utilized in LLMs is often confined to a specific\ncorpus, resulting in inherent freshness and temporal scope limitations.\nConsequently, this raises concerns regarding the effectiveness of LLMs for\ntasks involving temporal intents. In this study, we aim to investigate the\nunderlying limitations of general-purpose LLMs when deployed for tasks that\nrequire a temporal understanding. We pay particular attention to handling\nfactual temporal knowledge through three popular temporal QA datasets.\nSpecifically, we observe low performance on detailed questions about the past\nand, surprisingly, for rather new information. In manual and automatic testing,\nwe find multiple temporal errors and characterize the conditions under which QA\nperformance deteriorates. Our analysis contributes to understanding LLM\nlimitations and offers valuable insights into developing future models that can\nbetter cater to the demands of temporally-oriented tasks. The code is\navailable\\footnote{https://github.com/jwallat/temporalblindspots}.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.12079", "title": "Collaborative Reinforcement Learning Based Unmanned Aerial Vehicle (UAV)\n  Trajectory Design for 3D UAV Tracking", "abstract": "In this paper, the problem of using one active unmanned aerial vehicle (UAV)\nand four passive UAVs to localize a 3D target UAV in real time is investigated.\nIn the considered model, each passive UAV receives reflection signals from the\ntarget UAV, which are initially transmitted by the active UAV. The received\nreflection signals allow each passive UAV to estimate the signal transmission\ndistance which will be transmitted to a base station (BS) for the estimation of\nthe position of the target UAV. Due to the movement of the target UAV, each\nactive/passive UAV must optimize its trajectory to continuously localize the\ntarget UAV. Meanwhile, since the accuracy of the distance estimation depends on\nthe signal-to-noise ratio of the transmission signals, the active UAV must\noptimize its transmit power. This problem is formulated as an optimization\nproblem whose goal is to jointly optimize the transmit power of the active UAV\nand trajectories of both active and passive UAVs so as to maximize the target\nUAV positioning accuracy. To solve this problem, a Z function decomposition\nbased reinforcement learning (ZD-RL) method is proposed. Compared to value\nfunction decomposition based RL (VD-RL), the proposed method can find the\nprobability distribution of the sum of future rewards to accurately estimate\nthe expected value of the sum of future rewards thus finding better transmit\npower of the active UAV and trajectories for both active and passive UAVs and\nimproving target UAV positioning accuracy. Simulation results show that the\nproposed ZD-RL method can reduce the positioning errors by up to 39.4% and\n64.6%, compared to VD-RL and independent deep RL methods, respectively.", "field": "Computer Science", "categories": "cs.MA,cs.LG"}, {"arxiv_id": "2401.12086", "title": "West-of-N: Synthetic Preference Generation for Improved Reward Modeling", "abstract": "The success of reinforcement learning from human feedback (RLHF) in language\nmodel alignment is strongly dependent on the quality of the underlying reward\nmodel. In this paper, we present a novel approach to improve reward model\nquality by generating synthetic preference data, thereby augmenting the\ntraining dataset with on-policy, high-quality preference pairs. Motivated by\nthe promising results of Best-of-N sampling strategies in language model\ntraining, we extend their application to reward model training. This results in\na self-training strategy to generate preference pairs by selecting the best and\nworst candidates in a pool of responses to a given query. Empirically, we find\nthat this approach improves the performance of any reward model, with an effect\ncomparable to the addition of a similar quantity of human preference data. This\nwork opens up new avenues of research for improving RLHF for language model\nalignment, by offering synthetic preference generation as a solution to reward\nmodeling challenges.", "field": "Computer Science", "categories": "cs.CL,cs.AI,cs.LG"}, {"arxiv_id": "2401.12087", "title": "Revisiting Demonstration Selection Strategies in In-Context Learning", "abstract": "Large language models (LLMs) have shown an impressive ability to perform a\nwide range of tasks using in-context learning (ICL), where a few examples are\nused to describe a task to the model. However, the performance of ICL varies\nsignificantly with the choice of demonstrations, and it is still unclear why\nthis happens or what factors will influence its choice. In this work, we first\nrevisit the factors contributing to this variance from both data and model\naspects, and find that the choice of demonstration is both data- and\nmodel-dependent. We further proposed a data- and model-dependent demonstration\nselection method, \\textbf{TopK + ConE}, based on the assumption that\n\\textit{the performance of a demonstration positively correlates with its\ncontribution to the model's understanding of the test samples}, resulting in a\nsimple and effective recipe for ICL. Empirically, our method yields consistent\nimprovements in both language understanding and generation tasks with different\nmodel scales. Further analyses confirm that, besides the generality and\nstability under different circumstances, our method provides a unified\nexplanation for the effectiveness of previous methods. Code will be released.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.12088", "title": "Unsupervised Learning of Graph from Recipes", "abstract": "Cooking recipes are one of the most readily available kinds of procedural\ntext. They consist of natural language instructions that can be challenging to\ninterpret. In this paper, we propose a model to identify relevant information\nfrom recipes and generate a graph to represent the sequence of actions in the\nrecipe. In contrast with other approaches, we use an unsupervised approach. We\niteratively learn the graph structure and the parameters of a $\\mathsf{GNN}$\nencoding the texts (text-to-graph) one sequence at a time while providing the\nsupervision by decoding the graph into text (graph-to-text) and comparing the\ngenerated text to the input. We evaluate the approach by comparing the\nidentified entities with annotated datasets, comparing the difference between\nthe input and output texts, and comparing our generated graphs with those\ngenerated by state of the art methods.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.12093", "title": "Monitoring the Future of Smart Contracts", "abstract": "Blockchains are decentralized systems that provide trustable execution\nguarantees. Smart contracts are programs written in specialized programming\nlanguages running on blockchains that govern how tokens and cryptocurrency are\nsent and received. Smart contracts can invoke other smart contracts during the\nexecution of transactions always initiated by external users.\n  Once deployed, smart contracts cannot be modified, so techniques like runtime\nverification are very appealing for improving their reliability. However, the\nconventional model of computation of smart contracts is transactional: once\noperations commit, their effects are permanent and cannot be undone.\n  In this paper, we proposed the concept of future monitors which allows\nmonitors to remain waiting for future transactions to occur before committing\nor aborting. This is inspired by optimistic rollups, which are modern\nblockchain implementations that increase efficiency (and reduce cost) by\ndelaying transaction effects. We exploit this delay to propose a model of\ncomputation that allows (bounded) future monitors. We show our monitors correct\nrespect of legacy transactions, how they implement future bounded monitors and\nhow they guarantee progress. We illustrate the use of future bounded monitors\nto implement correctly multi-transaction flash loans.", "field": "Computer Science", "categories": "cs.LO,cs.CR"}, {"arxiv_id": "2401.12094", "title": "CLIQUE as an AND of Polynomial-Sized Monotone Constant-Depth Circuits", "abstract": "This paper shows that calculating $k$-CLIQUE on $n$ vertex graphs, requires\nthe AND of at least $2^{n/4k}$ monotone, constant-depth, and polynomial-sized\ncircuits, for sufficiently large values of $k$. The proof relies on a new,\nmonotone, one-sided switching lemma, designed for cliques.", "field": "Computer Science", "categories": "cs.CC,68Q06,F.1.3; F.2.3"}, {"arxiv_id": "2401.12097", "title": "An Empirical Analysis of In-context Learning Abilities of LLMs for MT", "abstract": "In-context learning (ICL) has consistently demonstrated superior performance\nover zero-shot performance in large language models (LLMs). However, the\nunderstanding of the dynamics of ICL and the aspects that influence downstream\nperformance remains limited, especially for natural language generation (NLG)\ntasks. This work aims to address this gap by investigating the ICL capabilities\nof LLMs and studying the impact of different aspects of the in-context\ndemonstrations for the task of machine translation (MT). Our preliminary\ninvestigations aim to discern whether in-context learning (ICL) is\npredominantly influenced by demonstrations or instructions by applying diverse\nperturbations to in-context demonstrations while preserving the task\ninstruction. We observe varying behavior to perturbed examples across different\nmodel families, notably with BLOOM-7B derivatives being severely influenced by\nnoise, whereas Llama 2 derivatives not only exhibit robustness but also tend to\nshow enhancements over the clean baseline when subject to perturbed\ndemonstrations. This suggests that the robustness of ICL may be governed by\nseveral factors, including the type of noise, perturbation direction (source or\ntarget), the extent of pretraining of the specific model, and fine-tuning for\ndownstream tasks if applicable. Further investigation is warranted to develop a\ncomprehensive understanding of these factors in future research.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.12103", "title": "LearnedWMP: Workload Memory Prediction Using Distribution of Query\n  Templates", "abstract": "In a modern DBMS, working memory is frequently the limiting factor when\nprocessing in-memory analytic query operations such as joins, sorting, and\naggregation. Existing resource estimation approaches for a DBMS estimate the\nresource consumption of a query by computing an estimate of each individual\ndatabase operator in the query execution plan. Such an approach is slow and\nerror-prone as it relies upon simplifying assumptions, such as uniformity and\nindependence of the underlying data. Additionally, the existing approach\nfocuses on individual queries separately and does not factor in other queries\nin the workload that may be executed concurrently. In this research, we are\ninterested in query performance optimization under concurrent execution of a\nbatch of queries (a workload). Specifically, we focus on predicting the memory\ndemand for a workload rather than providing separate estimates for each query\nwithin it. We introduce the problem of workload memory prediction and formalize\nit as a distribution regression problem. We propose Learned Workload Memory\nPrediction (LearnedWMP) to improve and simplify estimating the working memory\ndemands of workloads. Through a comprehensive experimental evaluation, we show\nthat LearnedWMP reduces the memory estimation error of the\nstate-of-the-practice method by up to 47.6%. Compared to an alternative\nsingle-query model, during training and inferencing, the LearnedWMP model and\nits variants were 3x to 10x faster. Moreover, LearnedWMP-based models were at\nleast 50% smaller in most cases. Overall, the results demonstrate the\nadvantages of the LearnedWMP approach and its potential for a broader impact on\nquery performance optimization.", "field": "Computer Science", "categories": "cs.DB,cs.LG"}, {"arxiv_id": "2401.12107", "title": "Energy-aware Trajectory Optimization for UAV-mounted RIS and Full-duplex\n  Relay", "abstract": "In the evolving landscape of sixth-generation (6G) wireless networks,\nunmanned aerial vehicles (UAVs) have emerged as transformative tools for\ndynamic and adaptive connectivity. However, dynamically adjusting their\nposition to offer favorable communication channels introduces operational\nchallenges in terms of energy consumption, especially when integrating advanced\ncommunication technologies like reconfigurable intelligent surfaces (RISs) and\nfull-duplex relays (FDRs). To this end, by recognizing the pivotal role of UAV\nmobility, the paper introduces an energy-aware trajectory design for\nUAV-mounted RISs and UAV-mounted FDRs using the decode and forward (DF)\nprotocol, aiming to maximize the network minimum rate and enhance user\nfairness, while taking into consideration the available on-board energy.\nSpecifically, this work highlights their distinct energy consumption\ncharacteristics and their associated integration challenges by developing\nappropriate energy consumption models for both UAV-mounted RISs and FDRs that\ncapture the intricate relationship between key factors such as weight, and\ntheir operational characteristics. Furthermore, a joint time-division multiple\naccess (TDMA) user scheduling-UAV trajectory optimization problem is\nformulated, considering the power dynamics of both systems, while assuring that\nthe UAV energy is not depleted mid-air. Finally, simulation results underscore\nthe importance of energy considerations in determining the optimal trajectory\nand scheduling and provide insights into the performance comparison of\nUAV-mounted RISs and FDRs in UAV-assisted wireless networks.", "field": "Computer Science", "categories": "cs.IT,eess.SP,math.IT"}, {"arxiv_id": "2401.12108", "title": "On-Time Delivery in Crowdshipping Systems: An Agent-Based Approach Using\n  Streaming Data", "abstract": "In parcel delivery, the \"last mile\" from the parcel hub to the customer is\ncostly, especially for time-sensitive delivery tasks that have to be completed\nwithin hours after arrival. Recently, crowdshipping has attracted increased\nattention as a new alternative to traditional delivery modes. In crowdshipping,\nprivate citizens (\"the crowd\") perform short detours in their daily lives to\ncontribute to parcel delivery in exchange for small incentives. However,\nachieving desirable crowd behavior is challenging as the crowd is highly\ndynamic and consists of autonomous, self-interested individuals. Leveraging\ncrowdshipping for time-sensitive deliveries remains an open challenge. In this\npaper, we present an agent-based approach to on-time parcel delivery with\ncrowds. Our system performs data stream processing on the couriers' smartphone\nsensor data to predict delivery delays. Whenever a delay is predicted, the\nsystem attempts to forge an agreement for transferring the parcel from the\ncurrent deliverer to a more promising courier nearby. Our experiments show that\nthrough accurate delay predictions and purposeful task transfers many delays\ncan be prevented that would occur without our approach.", "field": "Computer Science", "categories": "cs.AI,cs.LG,cs.MA"}, {"arxiv_id": "2401.12111", "title": "Constrained Multi-Tildes: Derived Term and Position Automata", "abstract": "Multi-tildes are regular operators that were introduced to enhance the\nfactorization power of regular expressions, allowing us to add the empty word\nin several factors of a catenation product of languages. In addition to\nmulti-bars, which dually remove the empty word, they allow representing any\nacyclic automaton by a linear-sized expression, whereas the lower bound is\nexponential in the classic case.\n  In this paper, we extend multi-tildes from disjunctive combinations to any\nBoolean combination, allowing us to exponentially enhance the factorization\npower of tildes expressions. Moreover, we show how to convert these expressions\ninto finite automata and give a Haskell implementation of them using advanced\ntechniques of functional programming.", "field": "Computer Science", "categories": "cs.FL"}, {"arxiv_id": "2401.12113", "title": "Extracting Formulae in Many-Valued Logic from Deep Neural Networks", "abstract": "We propose a new perspective on deep ReLU networks, namely as circuit\ncounterparts of Lukasiewicz infinite-valued logic -- a many-valued (MV)\ngeneralization of Boolean logic. An algorithm for extracting formulae in MV\nlogic from deep ReLU networks is presented. As the algorithm applies to\nnetworks with general, in particular also real-valued, weights, it can be used\nto extract logical formulae from deep ReLU networks trained on data.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.LO"}, {"arxiv_id": "2401.12114", "title": "Improved accuracy of continuum surface flux models for metal additive\n  manufacturing melt pool simulations", "abstract": "Computational modeling of the melt pool dynamics in laser-based powder bed\nfusion metal additive manufacturing (PBF-LB/M) promises to shed light on\nfundamental defect generation mechanisms. These processes are typically\naccompanied by rapid evaporation so that the evaporation-induced recoil\npressure and cooling arise as major driving forces for fluid dynamics and\ntemperature evolution. The magnitude of these interface fluxes depends\nexponentially on the melt pool surface temperature, which, therefore, must be\npredicted with high accuracy. The present work utilizes a diffuse interface\nmodel based on a continuum surface flux (CSF) description on the interfaces to\nstudy dimensionally reduced thermal two-phase problems representing PBF-LB/M in\na finite element framework. It is demonstrated that the extreme temperature\ngradients combined with the high ratios of material properties between metal\nand ambient gas lead to significant errors in the interface temperatures and\nfluxes when classical CSF approaches, along with typical interface thicknesses\nand discretizations, are applied. A novel parameter-scaled CSF approach is\nproposed, which is constructed to yield a smoother temperature rate in the\ndiffuse interface region, significantly increasing the solution accuracy. The\ninterface thickness required to predict the temperature field with a given\nlevel of accuracy is less restrictive by at least one order of magnitude for\nthe proposed parameter-scaled CSF approach compared to classical CSF,\ndrastically reducing computational costs. Finally, we showcased the general\napplicability of the parameter-scaled CSF to a three-dimensional simulation of\nstationary laser melting of PBF-LB/M considering the fully coupled\nthermo-hydrodynamic multi-phase problem, including phase change.", "field": "Computer Science", "categories": "cs.CE"}, {"arxiv_id": "2401.12117", "title": "The Curious Case of Nonverbal Abstract Reasoning with Multi-Modal Large\n  Language Models", "abstract": "While large language models (LLMs) are still being adopted to new domains and\nutilized in novel applications, we are experiencing an influx of the new\ngeneration of foundation models, namely multi-modal large language models\n(MLLMs). These models integrate verbal and visual information, opening new\npossibilities to demonstrate more complex reasoning abilities at the\nintersection of the two modalities. However, despite the revolutionizing\nprospect of MLLMs, our understanding of their reasoning abilities is limited.\nIn this study, we assess the nonverbal abstract reasoning abilities of\nopen-source and closed-source MLLMs using variations of Raven's Progressive\nMatrices. Our experiments expose the difficulty of solving such problems while\nshowcasing the immense gap between open-source and closed-source models. We\nalso reveal critical shortcomings with individual visual and textual modules,\nsubjecting the models to low-performance ceilings. Finally, to improve MLLMs'\nperformance, we experiment with various methods, such as Chain-of-Thought\nprompting, resulting in a significant (up to 100%) boost in performance.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.1212", "title": "Centralization in Block Building and Proposer-Builder Separation", "abstract": "The goal of this paper is to rigorously interrogate conventional wisdom about\ncentralization in block-building (due to, e.g., MEV and private order flow) and\nthe outsourcing of block-building by validators to specialists (i.e.,\nproposer-builder separation):\n  1. Does heterogeneity in skills and knowledge across block producers\ninevitably lead to centralization?\n  2. Does proposer-builder separation eliminate heterogeneity and preserve\ndecentralization among proposers?\n  This paper develops mathematical models and results that offer answers to\nthese questions:\n  1. In a game-theoretic model with endogenous staking, heterogeneous block\nproducer rewards, and staking costs, we quantify the extent to which\nheterogeneous rewards lead to concentration in the equilibrium staking\ndistribution.\n  2. In a stochastic model in which heterogeneous block producers repeatedly\nreinvest rewards into staking, we quantify, as a function of the block producer\nheterogeneity, the rate at which stake concentrates on the most sophisticated\nblock producers.\n  3. In a model with heterogeneous proposers and specialized builders, we\nquantify, as a function of the competitiveness of the builder ecosystem, the\nextent to which proposer-builder separation reduces the heterogeneity in\nrewards across different proposers.\n  Our models and results take advantage of connections to contest design,\nP\\'olya urn processes, and auction theory.", "field": "Computer Science", "categories": "cs.GT,cs.CR,cs.DC,econ.TH"}, {"arxiv_id": "2401.12121", "title": "Improving genetic algorithms performance via deterministic population\n  shrinkage", "abstract": "Despite the intuition that the same population size is not needed throughout\nthe run of an Evolutionary Algorithm (EA), most EAs use a fixed population\nsize. This paper presents an empirical study on the possible benefits of a\nSimple Variable Population Sizing (SVPS) scheme on the performance of Genetic\nAlgorithms (GAs). It consists in decreasing the population for a GA run\nfollowing a predetermined schedule, configured by a speed and a severity\nparameter. The method uses as initial population size an estimation of the\nminimum size needed to supply enough building blocks, using a fixed-size\nselectorecombinative GA converging within some confidence interval toward good\nsolutions for a particular problem. Following this methodology, a scalability\nanalysis is conducted on deceptive, quasi-deceptive, and non-deceptive trap\nfunctions in order to assess whether SVPS-GA improves performances compared to\na fixed-size GA under different problem instances and difficulty levels.\nResults show several combinations of speed-severity where SVPS-GA preserves the\nsolution quality while improving performances, by reducing the number of\nevaluations needed for success.", "field": "Computer Science", "categories": "cs.NE"}, {"arxiv_id": "2401.12125", "title": "CodeTailor: Personalized Parsons Puzzles are Preferred Over AI-Generated\n  Solutions to Support Learning", "abstract": "Programming can be challenging for novices, but it is difficult to provide\nhigh-quality, comprehensive, and timely support at scale. Generative AI and its\nproducts, like ChatGPT, can create a solution for most introductory programming\nproblems. However, students may become overly reliant on these tools for quick\ncode generation and homework completion, leading to reduced engagement and\nlimited learning. In this work, we present \\sys{}, a system that utilizes large\nlanguage models (LLM) while still promoting students' cognitive engagement.\n\\sys{} provides a personalized Parsons puzzle to support struggling students.\nIn a Parsons puzzle, students place mixed-up code blocks in the correct order\nto solve a problem. A technical evaluation with 800 incorrect student code\ndemonstrated that \\sys{} can efficiently create high-quality (correct,\npersonalized, and concise) Parsons puzzles for students. In a within-subjects\nexperiment with 18 novice programmers, most students rated using \\sys{} as more\nengaging, and they preferred \\sys{} for learning rather than simply receiving\nan AI-generated solution. Additionally, students recalled more new elements\nfrom the supported practice to the posttest after using \\sys{}, compared to\nwhen they simply received a direct solution. Qualitative observations and\ninterviews provided evidence for the benefits of \\sys{} including emphasizing\nalgorithmic thinking, fostering continuity in learning, promoting metacognitive\nreflection, and boosting student confidence. We conclude by suggesting future\ndesigns for applying generative AI in a way that minimizes over-reliance and\nenhances learning.", "field": "Computer Science", "categories": "cs.CY,cs.HC"}, {"arxiv_id": "2401.12129", "title": "Out-of-Distribution Detection & Applications With Ablated Learned\n  Temperature Energy", "abstract": "As deep neural networks become adopted in high-stakes domains, it is crucial\nto be able to identify when inference inputs are Out-of-Distribution (OOD) so\nthat users can be alerted of likely drops in performance and calibration\ndespite high confidence. Among many others, existing methods use the following\ntwo scores to do so without training on any apriori OOD examples: a learned\ntemperature and an energy score. In this paper we introduce Ablated Learned\nTemperature Energy (or \"AbeT\" for short), a method which combines these prior\nmethods in novel ways with effective modifications. Due to these contributions,\nAbeT lowers the False Positive Rate at $95\\%$ True Positive Rate (FPR@95) by\n$35.39\\%$ in classification (averaged across all ID and OOD datasets measured)\ncompared to state of the art without training networks in multiple stages or\nrequiring hyperparameters or test-time backward passes. We additionally provide\nempirical insights as to how our model learns to distinguish between\nIn-Distribution (ID) and OOD samples while only being explicitly trained on ID\nsamples via exposure to misclassified ID examples at training time. Lastly, we\nshow the efficacy of our method in identifying predicted bounding boxes and\npixels corresponding to OOD objects in object detection and semantic\nsegmentation, respectively - with an AUROC increase of $5.15\\%$ in object\ndetection and both a decrease in FPR@95 of $41.48\\%$ and an increase in AUPRC\nof $34.20\\%$ on average in semantic segmentation compared to previous state of\nthe art.", "field": "Computer Science", "categories": "cs.CV,cs.LG"}, {"arxiv_id": "2401.12131", "title": "NeuroSynt: A Neuro-symbolic Portfolio Solver for Reactive Synthesis", "abstract": "We introduce NeuroSynt, a neuro-symbolic portfolio solver framework for\nreactive synthesis. At the core of the solver lies a seamless integration of\nneural and symbolic approaches to solving the reactive synthesis problem. To\nensure soundness, the neural engine is coupled with model checkers verifying\nthe predictions of the underlying neural models. The open-source implementation\nof NeuroSynt provides an integration framework for reactive synthesis in which\nnew neural and state-of-the-art symbolic approaches can be seamlessly\nintegrated. Extensive experiments demonstrate its efficacy in handling\nchallenging specifications, enhancing the state-of-the-art reactive synthesis\nsolvers, with NeuroSynt contributing novel solves in the current SYNTCOMP\nbenchmarks.", "field": "Computer Science", "categories": "cs.LO,cs.LG"}, {"arxiv_id": "2401.12132", "title": "Evaluation of QCNN-LSTM for Disability Forecasting in Multiple Sclerosis\n  Using Sequential Multisequence MRI", "abstract": "Introduction Quantum Convolutional Neural Network (QCNN)-Long Short-Term\nMemory (LSTM) models were studied to provide sequential relationships for each\ntimepoint in MRIs of patients with Multiple Sclerosis (MS). In this pilot\nstudy, we compared three QCNN-LSTM models for binary classification of MS\ndisability benchmarked against classical neural network architectures. Our\nhypothesis is that quantum models will provide competitive performance. Methods\nMatrix Product State (MPS), reverse Multistate Entanglement Renormalization\nAnsatz (MERA), and Tree-Tensor Network (TTN) circuits were paired with LSTM\nlayer to process near-annual MRI data of patients diagnosed with MS. These were\nbenchmarked against a Visual Geometry Group (VGG)-LSTM and a Video Vision\nTransformer (ViViT). Predicted logits were measured against ground truth labels\nof each patient's Extended Disability Severity Score (EDSS) using binary\ncross-entropy loss. Training/validation/holdout testing was partitioned using\n5-fold cross validation with a total split of 60:20:20. Levene's test of\nvariance was used to measure statistical difference and Student's t-test for\npaired model differences in mean. Results The MPS-LSTM, reverse MERA-LSTM, and\nTTN-LSTM had holdout testing ROC-AUC of 0.70, 0.77, and 0.81, respectively\n(p-value 0.915). VGG16-LSTM and ViViT performed similarly with ROC-AUC of 0.73\nand 0.77, respectively (p-value 0.631). Overall variance and mean were not\nstatistically significant (p-value 0.713), however, time to train was\nsignificantly faster for the QCNN-LSTMs (39.4 sec per fold vs. 224 and 218,\nrespectively, p-value <0.001). Conclusion QCNN-LSTM models perform\ncompetitively to their classical counterparts with greater efficiency in train\ntime. Clinically, these can add value in terms of efficiency to time-dependent\ndeep learning prediction of disease progression based upon medical imaging.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.ET,eess.IV,I.2.0; I.2.6"}, {"arxiv_id": "2401.12133", "title": "VRMN-bD: A Multi-modal Natural Behavior Dataset of Immersive Human Fear\n  Responses in VR Stand-up Interactive Games", "abstract": "Understanding and recognizing emotions are important and challenging issues\nin the metaverse era. Understanding, identifying, and predicting fear, which is\none of the fundamental human emotions, in virtual reality (VR) environments\nplays an essential role in immersive game development, scene development, and\nnext-generation virtual human-computer interaction applications. In this\narticle, we used VR horror games as a medium to analyze fear emotions by\ncollecting multi-modal data (posture, audio, and physiological signals) from 23\nplayers. We used an LSTM-based model to predict fear with accuracies of 65.31%\nand 90.47% under 6-level classification (no fear and five different levels of\nfear) and 2-level classification (no fear and fear), respectively. We\nconstructed a multi-modal natural behavior dataset of immersive human fear\nresponses (VRMN-bD) and compared it with existing relevant advanced datasets.\nThe results show that our dataset has fewer limitations in terms of collection\nmethod, data scale and audience scope. We are unique and advanced in targeting\nmulti-modal datasets of fear and behavior in VR stand-up interactive\nenvironments. Moreover, we discussed the implications of this work for\ncommunities and applications. The dataset and pre-trained model are available\nat https://github.com/KindOPSTAR/VRMN-bD.", "field": "Computer Science", "categories": "cs.HC,cs.CV,cs.LG"}, {"arxiv_id": "2401.12136", "title": "Spin Wave Threshold Gate", "abstract": "While Spin Waves (SW) interaction provides natural support for low power\nMajority (MAJ) gate implementations many hurdles still exists on the road\ntowards the realization of practically relevant SW circuits. In this paper we\nleave the SW interaction avenue and propose Threshold Logic (TL) inspired SW\ncomputing, which relies on successive phase rotations applied to one single SW\ninstead of on the interference of an odd number of SWs. After providing a short\nTL inside we introduce the SW TL gate concept and discuss the way to mirror TL\ngate weight and threshold values into physical phase-shifter parameters.\nSubsequently, we design and demonstrate proper operation of a SW TL based Full\nAdder (FA) by means of micro-magnetic simulations. We conclude the paper by\nproviding inside on the potential advantages of our proposal by means of a\nconceptual comparison of MAJ and TL based FA implementations.", "field": "Computer Science", "categories": "cs.ET"}, {"arxiv_id": "2401.12138", "title": "Gradient Preserving Operator Inference: Data-Driven Reduced-Order Models\n  for Equations with Gradient Structure", "abstract": "Hamiltonian Operator Inference has been introduced in [Sharma, H., Wang, Z.,\nKramer, B., Physica D: Nonlinear Phenomena, 431, p.133122, 2022] to learn\nstructure-preserving reduced-order models (ROMs) for Hamiltonian systems. This\napproach constructs a low-dimensional model using only data and knowledge of\nthe Hamiltonian function. Such ROMs can keep the intrinsic structure of the\nsystem, allowing them to capture the physics described by the governing\nequations. In this work, we extend this approach to more general systems that\nare either conservative or dissipative in energy, and which possess a gradient\nstructure. We derive the optimization problems for inferring\nstructure-preserving ROMs that preserve the gradient structure. We further\nderive an {\\em a priori} error estimate for the reduced-order approximation. To\ntest the algorithms, we consider semi-discretized partial differential\nequations with gradient structure, such as the parameterized wave and\nKorteweg-de-Vries equations in the conservative case and the one- and\ntwo-dimensional Allen-Cahn equations in the dissipative case. The numerical\nresults illustrate the accuracy, structure-preservation properties, and\npredictive capabilities of the gradient-preserving Operator Inference ROMs.", "field": "Computer Science", "categories": "math.NA,cs.NA,65P99, 65M15"}, {"arxiv_id": "2401.12143", "title": "Anisotropy Is Inherent to Self-Attention in Transformers", "abstract": "The representation degeneration problem is a phenomenon that is widely\nobserved among self-supervised learning methods based on Transformers. In NLP,\nit takes the form of anisotropy, a singular property of hidden representations\nwhich makes them unexpectedly close to each other in terms of angular distance\n(cosine-similarity). Some recent works tend to show that anisotropy is a\nconsequence of optimizing the cross-entropy loss on long-tailed distributions\nof tokens. We show in this paper that anisotropy can also be observed\nempirically in language models with specific objectives that should not suffer\ndirectly from the same consequences. We also show that the anisotropy problem\nextends to Transformers trained on other modalities. Our observations suggest\nthat anisotropy is actually inherent to Transformers-based models.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.12147", "title": "An Efficient Finite Difference-based Implicit Solver for Phase-Field\n  Equations with Spatially and Temporally Varying Parameters", "abstract": "The phase field method is an effective tool for modeling microstructure\nevolution in materials. Many efficient implicit numerical solvers have been\nproposed for phase field simulations under uniform and time-invariant model\nparameters. We use Eyre's theorem to develop an unconditionally stable implicit\nsolver for spatially non-uniform and time-varying model parameters. The\naccuracy, unconditional stability, and efficiency of the solver is validated\nagainst benchmarking examples. In its current form, the solver requires a\nuniform mesh and may only be applied to problems with periodic, Neumann, or\nmixed periodic and Neumann boundary conditions.", "field": "Computer Science", "categories": "math.NA,cs.NA,math-ph,math.MP"}, {"arxiv_id": "2401.12149", "title": "Personalized Over-the-Air Federated Learning with Personalized\n  Reconfigurable Intelligent Surfaces", "abstract": "Over-the-air federated learning (OTA-FL) provides bandwidth-efficient\nlearning by leveraging the inherent superposition property of wireless\nchannels. Personalized federated learning balances performance for users with\ndiverse datasets, addressing real-life data heterogeneity. We propose the first\npersonalized OTA-FL scheme through multi-task learning, assisted by personal\nreconfigurable intelligent surfaces (RIS) for each user. We take a cross-layer\napproach that optimizes communication and computation resources for global and\npersonalized tasks in time-varying channels with imperfect channel state\ninformation, using multi-task learning for non-i.i.d data. Our PROAR-PFed\nalgorithm adaptively designs power, local iterations, and RIS configurations.\nWe present convergence analysis for non-convex objectives and demonstrate that\nPROAR-PFed outperforms state-of-the-art on the Fashion-MNIST dataset.", "field": "Computer Science", "categories": "cs.IT,cs.LG,math.IT"}, {"arxiv_id": "2401.12151", "title": "Uncoded Storage Coded Transmission Elastic Computing with Straggler\n  Tolerance in Heterogeneous Systems", "abstract": "In 2018, Yang et al. introduced a novel and effective approach, using maximum\ndistance separable (MDS) codes, to mitigate the impact of elasticity in cloud\ncomputing systems. This approach is referred to as coded elastic computing.\nSome limitations of this approach include that it assumes all virtual machines\nhave the same computing speeds and storage capacities, and it cannot tolerate\nstragglers for matrix-matrix multiplications. In order to resolve these\nlimitations, in this paper, we introduce a new combinatorial optimization\nframework, named uncoded storage coded transmission elastic computing (USCTEC),\nfor heterogeneous speeds and storage constraints, aiming to minimize the\nexpected computation time for matrix-matrix multiplications, under the\nconsideration of straggler tolerance. Within this framework, we propose optimal\nsolutions with straggler tolerance under relaxed storage constraints. Moreover,\nwe propose a heuristic algorithm that considers the heterogeneous storage\nconstraints. Our results demonstrate that the proposed algorithm outperforms\nbaseline solutions utilizing cyclic storage placements, in terms of both\nexpected computation time and storage size.", "field": "Computer Science", "categories": "cs.IT,cs.DC,math.IT,math.OC"}, {"arxiv_id": "2401.12159", "title": "Transcending To Notions", "abstract": "Social identities play an important role in the dynamics of human societies,\nand it can be argued that some sense of identification with a larger cause or\nidea plays a critical role in making humans act responsibly. Often social\nactivists strive to get populations to identify with some cause or notion --\nlike green energy, diversity, etc. in order to bring about desired social\nchanges. We explore the problem of designing computational models for social\nidentities in the context of autonomous AI agents. For this, we propose an\nagent model that enables agents to identify with certain notions and show how\nthis affects collective outcomes. We also contrast between associations of\nidentity with rational preferences. The proposed model is simulated in an\napplication context of urban mobility, where we show how changes in social\nidentity affect mobility patterns and collective outcomes.", "field": "Computer Science", "categories": "cs.MA"}, {"arxiv_id": "2401.12161", "title": "Automated facial recognition system using deep learning for pain\n  assessment in adults with cerebral palsy", "abstract": "Background: Pain assessment in individuals with neurological conditions,\nespecially those with limited self-report ability and altered facial\nexpressions, presents challenges. Existing measures, relying on direct\nobservation by caregivers, lack sensitivity and specificity. In cerebral palsy,\npain is a common comorbidity and a reliable evaluation protocol is crucial.\nThus, having an automatic system that recognizes facial expressions could be of\nenormous help when diagnosing pain in this type of patient.\n  Objectives: 1) to build a dataset of facial pain expressions in individuals\nwith cerebral palsy, and 2) to develop an automated facial recognition system\nbased on deep learning for pain assessment addressed to this population.\n  Methods: Ten neural networks were trained on three pain image databases,\nincluding the UNBC-McMaster Shoulder Pain Expression Archive Database, the\nMultimodal Intensity Pain Dataset, and the Delaware Pain Database.\nAdditionally, a curated dataset (CPPAIN) was created, consisting of 109\npreprocessed facial pain expression images from individuals with cerebral\npalsy, categorized by two physiotherapists using the Facial Action Coding\nSystem observational scale.\n  Results: InceptionV3 exhibited promising performance on the CP-PAIN dataset,\nachieving an accuracy of 62.67% and an F1 score of 61.12%. Explainable\nartificial intelligence techniques revealed consistent essential features for\npain identification across models.\n  Conclusion: This study demonstrates the potential of deep learning models for\nrobust pain detection in populations with neurological conditions and\ncommunication disabilities. The creation of a larger dataset specific to\ncerebral palsy would further enhance model accuracy, offering a valuable tool\nfor discerning subtle and idiosyncratic pain expressions. The insights gained\ncould extend to other complex neurological conditions.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.12164", "title": "Semi-supervised segmentation of land cover images using nonlinear\n  canonical correlation analysis with multiple features and t-SNE", "abstract": "Image segmentation is a clustering task whereby each pixel is assigned a\ncluster label. Remote sensing data usually consists of multiple bands of\nspectral images in which there exist semantically meaningful land cover\nsubregions, co-registered with other source data such as LIDAR (LIght Detection\nAnd Ranging) data, where available. This suggests that, in order to account for\nspatial correlation between pixels, a feature vector associated with each pixel\nmay be a vectorized tensor representing the multiple bands and a local patch as\nappropriate. Similarly, multiple types of texture features based on a pixel's\nlocal patch would also be beneficial for encoding locally statistical\ninformation and spatial variations, without necessarily labelling pixel-wise a\nlarge amount of ground truth, then training a supervised model, which is\nsometimes impractical. In this work, by resorting to label only a small\nquantity of pixels, a new semi-supervised segmentation approach is proposed.\nInitially, over all pixels, an image data matrix is created in high dimensional\nfeature space. Then, t-SNE projects the high dimensional data onto 3D\nembedding. By using radial basis functions as input features, which use the\nlabelled data samples as centres, to pair with the output class labels, a\nmodified canonical correlation analysis algorithm, referred to as RBF-CCA, is\nintroduced which learns the associated projection matrix via the small labelled\ndata set. The associated canonical variables, obtained for the full image, are\napplied by k-means clustering algorithm. The proposed semi-supervised RBF-CCA\nalgorithm has been implemented on several remotely sensed multispectral images,\ndemonstrating excellent segmentation results.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.12168", "title": "SpatialVLM: Endowing Vision-Language Models with Spatial Reasoning\n  Capabilities", "abstract": "Understanding and reasoning about spatial relationships is a fundamental\ncapability for Visual Question Answering (VQA) and robotics. While Vision\nLanguage Models (VLM) have demonstrated remarkable performance in certain VQA\nbenchmarks, they still lack capabilities in 3D spatial reasoning, such as\nrecognizing quantitative relationships of physical objects like distances or\nsize differences. We hypothesize that VLMs' limited spatial reasoning\ncapability is due to the lack of 3D spatial knowledge in training data and aim\nto solve this problem by training VLMs with Internet-scale spatial reasoning\ndata. To this end, we present a system to facilitate this approach. We first\ndevelop an automatic 3D spatial VQA data generation framework that scales up to\n2 billion VQA examples on 10 million real-world images. We then investigate\nvarious factors in the training recipe, including data quality, training\npipeline, and VLM architecture. Our work features the first internet-scale 3D\nspatial reasoning dataset in metric space. By training a VLM on such data, we\nsignificantly enhance its ability on both qualitative and quantitative spatial\nVQA. Finally, we demonstrate that this VLM unlocks novel downstream\napplications in chain-of-thought spatial reasoning and robotics due to its\nquantitative estimation capability. Project website:\nhttps://spatial-vlm.github.io/", "field": "Computer Science", "categories": "cs.CV,cs.CL,cs.LG,cs.RO"}, {"arxiv_id": "2401.1217", "title": "Natural Strategic Ability in Stochastic Multi-Agent Systems", "abstract": "Strategies synthesized using formal methods can be complex and often require\ninfinite memory, which does not correspond to the expected behavior when trying\nto model Multi-Agent Systems (MAS). To capture such behaviors, natural\nstrategies are a recently proposed framework striking a balance between the\nability of agents to strategize with memory and the model-checking complexity,\nbut until now has been restricted to fully deterministic settings. For the\nfirst time, we consider the probabilistic temporal logics PATL and PATL* under\nnatural strategies (NatPATL and NatPATL*, resp.). As main result we show that,\nin stochastic MAS, NatPATL model-checking is NP-complete when the active\ncoalition is restricted to deterministic strategies. We also give a 2NEXPTIME\ncomplexity result for NatPATL* with the same restriction. In the unrestricted\ncase, we give an EXPSPACE complexity for NatPATL and 3EXPSPACE complexity for\nNatPATL*.", "field": "Computer Science", "categories": "cs.LO,cs.AI"}, {"arxiv_id": "2401.12172", "title": "Robust stability analysis of an energy-efficient control in a Networked\n  Control System with application to Unmanned Ground Vehicles", "abstract": "In this paper, the robust stability and disturbance rejection performance\nanalysis of an energy-efficient control is addressed in the framework of\nNetworked Control System (NCS). The control scheme under study integrates\nperiodic event-triggered control, packet-based control, time-varying Kalman\nfilter, dual-rate control and prediction techniques, whose design is aimed at\nreducing energy consumption and bandwidth usage. The robust stability against\ntime-varying model uncertainties is analyzed by means of a suficient condition\nbased on Linear Matrix Inequalities (LMI). Finally, the effectiveness of the\nproposed approach is experimentally validated in a tracking control for an\nUnmanned Ground Vehicle (UGV), which is a battery-constrained mobile device\nwith limited computation capacities.", "field": "Computer Science", "categories": "cs.SY,eess.SY,math.OC"}, {"arxiv_id": "2401.12174", "title": "IoT-Based Wireless Networkingfor Seismic Applications", "abstract": "We propose to employ a recently developed IoT-based wireless technology, so\ncalled low-power wide-area networks (LPWANs), to exploit their long range, low\npower, and inherent compatibility to cloud storage and computing. We create a\nremotely-operated minimum-maintenance wireless solution for four major seismic\napplications of interest. By proposing appropriate network architecture and\ndata coordination (aggregation and transmission) designs we show that neither\nthe low data-rate nor the low duty-cycle of LPWANs impose fundamental issues in\nhandling a considerable amount of data created by complex seismic scenarios as\nlong as the application is delay-tolerant. In order to confirm this claim, we\ncast our ideas into a practical large-scale networking design for simultaneous\nseismic monitoring and interferometry and carry out an analysis on the data\ngeneration and transmission rates. Finally, we present some results from a\nsmall-scale field test in which we have employed our IoT-based wireless nodes\nfor real-time seismic quality control (QC) over clouds.", "field": "Computer Science", "categories": "cs.DC"}, {"arxiv_id": "2401.12175", "title": "Single-View 3D Human Digitalization with Large Reconstruction Models", "abstract": "In this paper, we introduce Human-LRM, a single-stage feed-forward Large\nReconstruction Model designed to predict human Neural Radiance Fields (NeRF)\nfrom a single image. Our approach demonstrates remarkable adaptability in\ntraining using extensive datasets containing 3D scans and multi-view capture.\nFurthermore, to enhance the model's applicability for in-the-wild scenarios\nespecially with occlusions, we propose a novel strategy that distills\nmulti-view reconstruction into single-view via a conditional triplane diffusion\nmodel. This generative extension addresses the inherent variations in human\nbody shapes when observed from a single view, and makes it possible to\nreconstruct the full body human from an occluded image. Through extensive\nexperiments, we show that Human-LRM surpasses previous methods by a significant\nmargin on several benchmarks.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.12176", "title": "Broiler-Net: A Deep Convolutional Framework for Broiler Behavior\n  Analysis in Poultry Houses", "abstract": "Detecting anomalies in poultry houses is crucial for maintaining optimal\nchicken health conditions, minimizing economic losses and bolstering\nprofitability. This paper presents a novel real-time framework for analyzing\nchicken behavior in cage-free poultry houses to detect abnormal behaviors.\nSpecifically, two significant abnormalities, namely inactive broiler and\nhuddling behavior, are investigated in this study. The proposed framework\ncomprises three key steps: (1) chicken detection utilizing a state-of-the-art\ndeep learning model, (2) tracking individual chickens across consecutive frames\nwith a fast tracker module, and (3) detecting abnormal behaviors within the\nvideo stream. Experimental studies are conducted to evaluate the efficacy of\nthe proposed algorithm in accurately assessing chicken behavior. The results\nillustrate that our framework provides a precise and efficient solution for\nreal-time anomaly detection, facilitating timely interventions to maintain\nchicken health and enhance overall productivity on poultry farms. Github:\nhttps://github.com/TaherehZarratEhsan/Chicken-Behavior-Analysis", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.12178", "title": "In-Context Learning for Extreme Multi-Label Classification", "abstract": "Multi-label classification problems with thousands of classes are hard to\nsolve with in-context learning alone, as language models (LMs) might lack prior\nknowledge about the precise classes or how to assign them, and it is generally\ninfeasible to demonstrate every class in a prompt. We propose a general\nprogram, $\\texttt{Infer--Retrieve--Rank}$, that defines multi-step interactions\nbetween LMs and retrievers to efficiently tackle such problems. We implement\nthis program using the $\\texttt{DSPy}$ programming model, which specifies\nin-context systems in a declarative manner, and use $\\texttt{DSPy}$ optimizers\nto tune it towards specific datasets by bootstrapping only tens of few-shot\nexamples. Our primary extreme classification program, optimized separately for\neach task, attains state-of-the-art results across three benchmarks (HOUSE,\nTECH, TECHWOLF). We apply the same program to a benchmark with vastly different\ncharacteristics and attain competitive performance as well (BioDEX). Unlike\nprior work, our proposed solution requires no finetuning, is easily applicable\nto new tasks, alleviates prompt engineering, and requires only tens of labeled\nexamples. Our code is public at https://github.com/KarelDO/xmc.dspy.", "field": "Computer Science", "categories": "cs.CL,cs.AI"}, {"arxiv_id": "2401.12179", "title": "DITTO: Diffusion Inference-Time T-Optimization for Music Generation", "abstract": "We propose Diffusion Inference-Time T-Optimization (DITTO), a general-purpose\nframe-work for controlling pre-trained text-to-music diffusion models at\ninference-time via optimizing initial noise latents. Our method can be used to\noptimize through any differentiable feature matching loss to achieve a target\n(stylized) output and leverages gradient checkpointing for memory efficiency.\nWe demonstrate a surprisingly wide-range of applications for music generation\nincluding inpainting, outpainting, and looping as well as intensity, melody,\nand musical structure control - all without ever fine-tuning the underlying\nmodel. When we compare our approach against related training, guidance, and\noptimization-based methods, we find DITTO achieves state-of-the-art performance\non nearly all tasks, including outperforming comparable approaches on\ncontrollability, audio quality, and computational efficiency, thus opening the\ndoor for high-quality, flexible, training-free control of diffusion models.\nSound examples can be found at https://DITTO-Music.github.io/web/.", "field": "Computer Science", "categories": "cs.SD,cs.AI,cs.LG,eess.AS"}, {"arxiv_id": "2401.12181", "title": "Universal Neurons in GPT2 Language Models", "abstract": "A basic question within the emerging field of mechanistic interpretability is\nthe degree to which neural networks learn the same underlying mechanisms. In\nother words, are neural mechanisms universal across different models? In this\nwork, we study the universality of individual neurons across GPT2 models\ntrained from different initial random seeds, motivated by the hypothesis that\nuniversal neurons are likely to be interpretable. In particular, we compute\npairwise correlations of neuron activations over 100 million tokens for every\nneuron pair across five different seeds and find that 1-5\\% of neurons are\nuniversal, that is, pairs of neurons which consistently activate on the same\ninputs. We then study these universal neurons in detail, finding that they\nusually have clear interpretations and taxonomize them into a small number of\nneuron families. We conclude by studying patterns in neuron weights to\nestablish several universal functional roles of neurons in simple circuits:\ndeactivating attention heads, changing the entropy of the next token\ndistribution, and predicting the next token to (not) be within a particular\nset.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.CL"}, {"arxiv_id": "2401.12184", "title": "Is Your Kettle Smarter Than a Hacker? A Scalable Tool for Assessing\n  Replay Attack Vulnerabilities on Consumer IoT Devices", "abstract": "Consumer Internet of Things (IoT) devices often leverage the local network to\ncommunicate with the corresponding companion app or other devices. This has\nbenefits in terms of efficiency since it offloads the cloud. ENISA and NIST\nsecurity guidelines underscore the importance of enabling default local\ncommunication for safety and reliability. Indeed, an IoT device should continue\nto function in case the cloud connection is not available. While the security\nof cloud-device connections is typically strengthened through the usage of\nstandard protocols, local connectivity security is frequently overlooked.\nNeglecting the security of local communication opens doors to various threats,\nincluding replay attacks. In this paper, we investigate this class of attacks\nby designing a systematic methodology for automatically testing IoT devices\nvulnerability to replay attacks. Specifically, we propose a tool, named\nREPLIOT, able to test whether a replay attack is successful or not, without\nprior knowledge of the target devices. We perform thousands of automated\nexperiments using popular commercial devices spanning various vendors and\ncategories. Notably, our study reveals that among these devices, 51% of them do\nnot support local connectivity, thus they are not compliant with the\nreliability and safety requirements of the ENISA/NIST guidelines. We find that\n75% of the remaining devices are vulnerable to replay attacks with REPLIOT\nhaving a detection accuracy of 0.98-1. Finally, we investigate the possible\ncauses of this vulnerability, discussing possible mitigation strategies.", "field": "Computer Science", "categories": "cs.CR"}, {"arxiv_id": "2401.12187", "title": "WARM: On the Benefits of Weight Averaged Reward Models", "abstract": "Aligning large language models (LLMs) with human preferences through\nreinforcement learning (RLHF) can lead to reward hacking, where LLMs exploit\nfailures in the reward model (RM) to achieve seemingly high rewards without\nmeeting the underlying objectives. We identify two primary challenges when\ndesigning RMs to mitigate reward hacking: distribution shifts during the RL\nprocess and inconsistencies in human preferences. As a solution, we propose\nWeight Averaged Reward Models (WARM), first fine-tuning multiple RMs, then\naveraging them in the weight space. This strategy follows the observation that\nfine-tuned weights remain linearly mode connected when sharing the same\npre-training. By averaging weights, WARM improves efficiency compared to the\ntraditional ensembling of predictions, while improving reliability under\ndistribution shifts and robustness to preference inconsistencies. Our\nexperiments on summarization tasks, using best-of-N and RL methods, shows that\nWARM improves the overall quality and alignment of LLM predictions; for\nexample, a policy RL fine-tuned with WARM has a 79.4% win rate against a policy\nRL fine-tuned with a single RM.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.CL"}, {"arxiv_id": "2401.12192", "title": "Text Embedding Inversion Attacks on Multilingual Language Models", "abstract": "Representing textual information as real-numbered embeddings has become the\nnorm in NLP. Moreover, with the rise of public interest in large language\nmodels (LLMs), Embeddings as a Service (EaaS) has rapidly gained traction as a\nbusiness model. This is not without outstanding security risks, as previous\nresearch has demonstrated that sensitive data can be reconstructed from\nembeddings, even without knowledge of the underlying model that generated them.\nHowever, such work is limited by its sole focus on English, leaving all other\nlanguages vulnerable to attacks by malicious actors. %As many international and\nmultilingual companies leverage EaaS, there is an urgent need for research into\nmultilingual LLM security. To this end, this work investigates LLM security\nfrom the perspective of multilingual embedding inversion. Concretely, we define\nthe problem of black-box multilingual and cross-lingual inversion attacks, with\nspecial attention to a cross-domain scenario. Our findings reveal that\nmultilingual models are potentially more vulnerable to inversion attacks than\ntheir monolingual counterparts. This stems from the reduced data requirements\nfor achieving comparable inversion performance in settings where the underlying\nlanguage is not known a-priori. To our knowledge, this work is the first to\ndelve into multilinguality within the context of inversion attacks, and our\nfindings highlight the need for further investigation and enhanced defenses in\nthe area of NLP Security.", "field": "Computer Science", "categories": "cs.CL,cs.AI,cs.CR"}, {"arxiv_id": "2401.12193", "title": "Programmable EM Sensor Array for Golden-Model Free Run-time Trojan\n  Detection and Localization", "abstract": "Side-channel analysis has been proven effective at detecting hardware Trojans\nin integrated circuits (ICs). However, most detection techniques rely on large\nexternal probes and antennas for data collection and require a long measurement\ntime to detect Trojans. Such limitations make these techniques impractical for\nrun-time deployment and ineffective in detecting small Trojans with subtle\nside-channel signatures. To overcome these challenges, we propose a\nProgrammable Sensor Array (PSA) for run-time hardware Trojan detection,\nlocalization, and identification. PSA is a tampering-resilient integrated\non-chip magnetic field sensor array that can be re-programmed to change the\nsensors' shape, size, and location. Using PSA, EM side-channel measurement\nresults collected from sensors at different locations on an IC can be analyzed\nto localize and identify the Trojan. The PSA has better performance than\nconventional external magnetic probes and state-of-the-art on-chip single-coil\nmagnetic field sensors. We fabricated an AES-128 test chip with four AES\nHardware Trojans. They were successfully detected, located, and identified with\nthe proposed on-chip PSA within 10 milliseconds using our proposed cross-domain\nanalysis.", "field": "Computer Science", "categories": "cs.CR,eess.SP"}, {"arxiv_id": "2401.12198", "title": "LONEStar: The Lunar Flashlight Optical Navigation Experiment", "abstract": "This paper documents the results from the highly successful Lunar flashlight\nOptical Navigation Experiment with a Star tracker (LONEStar). Launched in\nDecember 2022, Lunar Flashlight (LF) was a NASA-funded technology demonstration\nmission. After a propulsion system anomaly prevented capture in lunar orbit, LF\nwas ejected from the Earth-Moon system and into heliocentric space. NASA\nsubsequently transferred ownership of LF to Georgia Tech to conduct an unfunded\nextended mission to demonstrate further advanced technology objectives,\nincluding LONEStar. From August-December 2023, the LONEStar team performed\non-orbit calibration of the optical instrument and a number of different OPNAV\nexperiments. This campaign included the processing of nearly 400 images of star\nfields, Earth and Moon, and four other planets (Mercury, Mars, Jupiter, and\nSaturn). LONEStar provided the first on-orbit demonstrations of heliocentric\nnavigation using only optical observations of planets. Of special note is the\nsuccessful in-flight demonstration of (1) instantaneous triangulation with\nsimultaneous sightings of two planets with the LOST algorithm and (2) dynamic\ntriangulation with sequential sightings of multiple planets.", "field": "Computer Science", "categories": "cs.CV,astro-ph.IM,physics.space-ph"}, {"arxiv_id": "2401.122", "title": "APT: Adaptive Pruning and Tuning Pretrained Language Models for\n  Efficient Training and Inference", "abstract": "Fine-tuning and inference with large Language Models (LM) are generally known\nto be expensive. Parameter-efficient fine-tuning over pretrained LMs reduces\ntraining memory by updating a small number of LM parameters but does not\nimprove inference efficiency. Structured pruning improves LM inference\nefficiency by removing consistent parameter blocks, yet often increases\ntraining memory and time. To improve both training and inference efficiency, we\nintroduce APT that adaptively prunes and tunes parameters for the LMs. At the\nearly stage of fine-tuning, APT dynamically adds salient tuning parameters for\nfast and accurate convergence while discarding unimportant parameters for\nefficiency. Compared to baselines, our experiments show that APT maintains up\nto 98% task performance when pruning RoBERTa and T5 models with 40% parameters\nleft while keeping 86.4% LLaMA models' performance with 70% parameters\nremained. Furthermore, APT speeds up LMs fine-tuning by up to 8x and reduces\nlarge LMs memory training footprint by up to 70%.", "field": "Computer Science", "categories": "cs.CL,cs.LG"}, {"arxiv_id": "2401.12202", "title": "OK-Robot: What Really Matters in Integrating Open-Knowledge Models for\n  Robotics", "abstract": "Remarkable progress has been made in recent years in the fields of vision,\nlanguage, and robotics. We now have vision models capable of recognizing\nobjects based on language queries, navigation systems that can effectively\ncontrol mobile systems, and grasping models that can handle a wide range of\nobjects. Despite these advancements, general-purpose applications of robotics\nstill lag behind, even though they rely on these fundamental capabilities of\nrecognition, navigation, and grasping. In this paper, we adopt a systems-first\napproach to develop a new Open Knowledge-based robotics framework called\nOK-Robot. By combining Vision-Language Models (VLMs) for object detection,\nnavigation primitives for movement, and grasping primitives for object\nmanipulation, OK-Robot offers a integrated solution for pick-and-drop\noperations without requiring any training. To evaluate its performance, we run\nOK-Robot in 10 real-world home environments. The results demonstrate that\nOK-Robot achieves a 58.5% success rate in open-ended pick-and-drop tasks,\nrepresenting a new state-of-the-art in Open Vocabulary Mobile Manipulation\n(OVMM) with nearly 1.8x the performance of prior work. On cleaner, uncluttered\nenvironments, OK-Robot's performance increases to 82%. However, the most\nimportant insight gained from OK-Robot is the critical role of nuanced details\nwhen combining Open Knowledge systems like VLMs with robotic modules. Videos of\nour experiments are available on our website: https://ok-robot.github.io", "field": "Computer Science", "categories": "cs.RO,cs.AI,cs.CV,cs.LG"}, {"arxiv_id": "2401.12205", "title": "Retrieval-Guided Reinforcement Learning for Boolean Circuit Minimization", "abstract": "Logic synthesis, a pivotal stage in chip design, entails optimizing chip\nspecifications encoded in hardware description languages like Verilog into\nhighly efficient implementations using Boolean logic gates. The process\ninvolves a sequential application of logic minimization heuristics (``synthesis\nrecipe\"), with their arrangement significantly impacting crucial metrics such\nas area and delay. Addressing the challenge posed by the broad spectrum of\ndesign complexities - from variations of past designs (e.g., adders and\nmultipliers) to entirely novel configurations (e.g., innovative processor\ninstructions) - requires a nuanced `synthesis recipe` guided by human expertise\nand intuition. This study conducts a thorough examination of learning and\nsearch techniques for logic synthesis, unearthing a surprising revelation:\npre-trained agents, when confronted with entirely novel designs, may veer off\ncourse, detrimentally affecting the search trajectory. We present ABC-RL, a\nmeticulously tuned $\\alpha$ parameter that adeptly adjusts recommendations from\npre-trained agents during the search process. Computed based on similarity\nscores through nearest neighbor retrieval from the training dataset, ABC-RL\nyields superior synthesis recipes tailored for a wide array of hardware\ndesigns. Our findings showcase substantial enhancements in the\nQuality-of-result (QoR) of synthesized circuits, boasting improvements of up to\n24.8% compared to state-of-the-art techniques. Furthermore, ABC-RL achieves an\nimpressive up to 9x reduction in runtime (iso-QoR) when compared to current\nstate-of-the-art methodologies.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.AR"}, {"arxiv_id": "2401.12207", "title": "Rate-Distortion-Perception Tradeoff Based on the\n  Conditional-Distribution Perception Measure", "abstract": "We study the rate-distortion-perception (RDP) tradeoff for a memoryless\nsource model in the asymptotic limit of large block-lengths. Our perception\nmeasure is based on a divergence between the distributions of the source and\nreconstruction sequences conditioned on the encoder output, which was first\nproposed in [1], [2]. We consider the case when there is no shared randomness\nbetween the encoder and the decoder. For the case of discrete memoryless\nsources we derive a single-letter characterization of the RDP function, thus\nsettling a problem that remains open for the marginal metric introduced in Blau\nand Michaeli [3] (with no shared randomness). Our achievability scheme is based\non lossy source coding with a posterior reference map proposed in [4]. For the\ncase of continuous valued sources under squared error distortion measure and\nsquared quadratic Wasserstein perception measure we also derive a single-letter\ncharacterization and show that a noise-adding mechanism at the decoder suffices\nto achieve the optimal representation. For the case of zero perception loss, we\nshow that our characterization interestingly coincides with the results for the\nmarginal metric derived in [5], [6] and again demonstrate that zero perception\nloss can be achieved with a $3$-dB penalty in the minimum distortion. Finally\nwe specialize our results to the case of Gaussian sources. We derive the RDP\nfunction for vector Gaussian sources and propose a waterfilling type solution.\nWe also partially characterize the RDP function for a mixture of vector\nGaussians.", "field": "Computer Science", "categories": "cs.IT,cs.LG,math.IT"}, {"arxiv_id": "2401.12208", "title": "CheXagent: Towards a Foundation Model for Chest X-Ray Interpretation", "abstract": "Chest X-rays (CXRs) are the most frequently performed imaging test in\nclinical practice. Recent advances in the development of vision-language\nfoundation models (FMs) give rise to the possibility of performing automated\nCXR interpretation, which can assist physicians with clinical decision-making\nand improve patient outcomes. However, developing FMs that can accurately\ninterpret CXRs is challenging due to the (1) limited availability of\nlarge-scale vision-language datasets in the medical image domain, (2) lack of\nvision and language encoders that can capture the complexities of medical data,\nand (3) absence of evaluation frameworks for benchmarking the abilities of FMs\non CXR interpretation. In this work, we address these challenges by first\nintroducing \\emph{CheXinstruct} - a large-scale instruction-tuning dataset\ncurated from 28 publicly-available datasets. We then present \\emph{CheXagent} -\nan instruction-tuned FM capable of analyzing and summarizing CXRs. To build\nCheXagent, we design a clinical large language model (LLM) for parsing\nradiology reports, a vision encoder for representing CXR images, and a network\nto bridge the vision and language modalities. Finally, we introduce\n\\emph{CheXbench} - a novel benchmark designed to systematically evaluate FMs\nacross 8 clinically-relevant CXR interpretation tasks. Extensive quantitative\nevaluations and qualitative reviews with five expert radiologists demonstrate\nthat CheXagent outperforms previously-developed general- and medical-domain FMs\non CheXbench tasks. Furthermore, in an effort to improve model transparency, we\nperform a fairness evaluation across factors of sex, race and age to highlight\npotential performance disparities. Our project is at\n\\url{https://stanford-aimi.github.io/chexagent.html}.", "field": "Computer Science", "categories": "cs.CV,cs.CL"}, {"arxiv_id": "2401.1221", "title": "Connecting the Dots: Leveraging Spatio-Temporal Graph Neural Networks\n  for Accurate Bangla Sign Language Recognition", "abstract": "Recent advances in Deep Learning and Computer Vision have been successfully\nleveraged to serve marginalized communities in various contexts. One such area\nis Sign Language - a primary means of communication for the deaf community.\nHowever, so far, the bulk of research efforts and investments have gone into\nAmerican Sign Language, and research activity into low-resource sign languages\n- especially Bangla Sign Language - has lagged significantly. In this research\npaper, we present a new word-level Bangla Sign Language dataset - BdSL40 -\nconsisting of 611 videos over 40 words, along with two different approaches:\none with a 3D Convolutional Neural Network model and another with a novel Graph\nNeural Network approach for the classification of BdSL40 dataset. This is the\nfirst study on word-level BdSL recognition, and the dataset was transcribed\nfrom Indian Sign Language (ISL) using the Bangla Sign Language Dictionary\n(1997). The proposed GNN model achieved an F1 score of 89%. The study\nhighlights the significant lexical and semantic similarity between BdSL, West\nBengal Sign Language, and ISL, and the lack of word-level datasets for BdSL in\nthe literature. We release the dataset and source code to stimulate further\nresearch.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.12212", "title": "Genericity Through Stratification", "abstract": "A fundamental issue in the $\\lambda$-calculus is to find appropriate notions\nfor meaningfulness. Inspired by well-known results for the call-by-name\n$\\lambda$-calculus (CbN), where meaningful terms are identified to the solvable\nones, this paper validates the challenging claim that the notion of potential\nvaluability (aka scrutability), previously introduced in the literature,\nadequately represents meaningfulness in the call-by-value $\\lambda$-calculus\n(CbV). Akin to CbN, this claim is corroborated by proving two essential\nproperties. The first one is genericity, stating that meaningless subterms have\nno bearing on evaluating normalizing terms. To prove this, we use a novel\napproach based on stratified reduction, indifferently applicable to CbN and\nCbV. The second property concerns consistency of the smallest congruence\nrelation resulting from equating all meaningless terms (without equating all\nterms). We also show that such a congruence has a unique consistent and maximal\nextension, which coincides with a natural notion of observational equivalence.\nOur results thus supply the formal concepts and tools that validate the\ninformal notion of meaningfulness underlying CbN and CbV.", "field": "Computer Science", "categories": "cs.LO,cs.PL,F.3.2; F.4.1; D.3.1"}, {"arxiv_id": "2401.12214", "title": "Quality-Aware Hydraulic Control in Drinking Water Networks via\n  Controllability Proxies", "abstract": "The operation of water distribution networks is a complex procedure aimed at\nefficiently delivering consumers with adequate water quantity while ensuring\nits safe quality. An added challenge is the dependency of the water quality\ndynamics on the system's hydraulics, which influences the performance of the\nwater quality controller. Prior research has addressed either solving the\noptimum operational hydraulic setting problem or regulating the water quality\ndynamics as separate problems. Additionally, there have been efforts to couple\nthese two problems and solve one compact problem resulting in trade-offs\nbetween the contradictory objectives. In contrast, this paper examines the\ndependency and influence from a control-theoretic standpoint. More\nspecifically, we explore the influence of accountability for water quality\ncontrollability improvement when addressing the pump scheduling problem. We\nexamine its effects on the cumulative cost of the interconnected systems as\nwell as the subsequent performance of the water quality controller. To achieve\nthis, we develop a framework that incorporates different controllability\nmetrics within the operational hydraulic optimization problem; its aim is\nattaining an adequate level of water quality control across the system. We\nassess the aforementioned aspects' performance on various scaled networks with\na wide range of numerical scenarios.", "field": "Computer Science", "categories": "eess.SY,cs.SY"}, {"arxiv_id": "2401.12215", "title": "Less Could Be Better: Parameter-efficient Fine-tuning Advances Medical\n  Vision Foundation Models", "abstract": "Parameter-efficient fine-tuning (PEFT) that was initially developed for\nexploiting pre-trained large language models has recently emerged as an\neffective approach to perform transfer learning on computer vision tasks.\nHowever, the effectiveness of PEFT on medical vision foundation models is still\nunclear and remains to be explored. As a proof of concept, we conducted a\ndetailed empirical study on applying PEFT to chest radiography foundation\nmodels. Specifically, we delved into LoRA, a representative PEFT method, and\ncompared it against full-parameter fine-tuning (FFT) on two self-supervised\nradiography foundation models across three well-established chest radiograph\ndatasets. Our results showed that LoRA outperformed FFT in 13 out of 18\ntransfer learning tasks by at most 2.9% using fewer than 1% tunable parameters.\nCombining LoRA with foundation models, we set up new state-of-the-art on a\nrange of data-efficient learning tasks, such as an AUROC score of 80.6% using\n1% labeled data on NIH ChestX-ray14. We hope this study can evoke more\nattention from the community in the use of PEFT for transfer learning on\nmedical imaging tasks. Code and models are available at\nhttps://github.com/RL4M/MED-PEFT.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.12217", "title": "Exploring Simple Open-Vocabulary Semantic Segmentation", "abstract": "Open-vocabulary semantic segmentation models aim to accurately assign a\nsemantic label to each pixel in an image from a set of arbitrary\nopen-vocabulary texts. In order to learn such pixel-level alignment, current\napproaches typically rely on a combination of (i) image-level VL model (e.g.\nCLIP), (ii) ground truth masks, and (iii) custom grouping encoders. In this\npaper, we introduce S-Seg, a novel model that can achieve surprisingly strong\nperformance without depending on any of the above elements. S-Seg leverages\npseudo-mask and language to train a MaskFormer, and can be easily trained from\npublicly available image-text datasets. Contrary to prior works, our model\ndirectly trains for pixel-level features and language alignment. Once trained,\nS-Seg generalizes well to multiple testing datasets without requiring\nfine-tuning. In addition, S-Seg has the extra benefits of scalability with data\nand consistently improvement when augmented with self-training. We believe that\nour simple yet effective approach will serve as a solid baseline for future\nresearch.", "field": "Computer Science", "categories": "cs.CV,cs.LG"}]}