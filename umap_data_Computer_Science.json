{"embeddings": [[5.663256645202637, 5.8084187507629395], [6.1449294090271, 5.911993503570557], [7.294913291931152, 8.539161682128906], [9.039176940917969, 7.917489528656006], [5.005891799926758, 8.882311820983887], [6.9251580238342285, 5.670375823974609], [6.917176723480225, 5.6760382652282715], [8.412703514099121, 7.349677562713623], [5.582730770111084, 6.196959495544434], [3.786283493041992, 6.066832542419434], [3.763636589050293, 6.151028633117676], [8.403764724731445, 6.959378719329834], [3.8891615867614746, 6.589615345001221], [8.379995346069336, 9.97169303894043], [7.952606201171875, 6.846497058868408], [7.173911094665527, 7.246004581451416], [7.079833507537842, 7.767559051513672], [5.955967903137207, 9.528009414672852], [4.056650638580322, 6.186938762664795], [6.632450103759766, 6.475094795227051], [6.794395446777344, 6.7372565269470215], [6.104186058044434, 8.859293937683105], [4.26893424987793, 6.151325225830078], [6.096618175506592, 8.525559425354004], [5.028024673461914, 9.341958045959473], [8.42349624633789, 7.8294148445129395], [6.192081928253174, 8.4349365234375], [4.56673002243042, 7.060558795928955], [7.485864162445068, 9.504256248474121], [7.288695812225342, 9.608039855957031], [6.8530592918396, 7.469844341278076], [6.29549503326416, 7.3553266525268555], [7.290890693664551, 7.4318528175354], [6.214867115020752, 6.916751861572266], [5.0366950035095215, 7.748693943023682], [7.787875175476074, 7.243102073669434], [6.298404216766357, 6.803732872009277], [4.546815395355225, 6.985743999481201], [5.87275505065918, 9.041817665100098], [6.767518520355225, 7.667943000793457], [5.766899585723877, 6.994358539581299], [6.8424906730651855, 8.988998413085938], [3.836012363433838, 6.0116400718688965], [5.019136905670166, 8.973069190979004], [5.983134746551514, 8.701632499694824], [6.1402201652526855, 7.408131122589111], [6.9671220779418945, 7.578338623046875], [6.733034133911133, 10.146347999572754], [6.72115421295166, 10.121814727783203], [4.585050582885742, 6.49360466003418], [5.951014041900635, 9.97330379486084], [6.289336204528809, 7.647886753082275], [6.708321571350098, 9.559664726257324], [3.9859015941619873, 6.8017578125], [4.95068883895874, 6.702396869659424], [6.864065170288086, 9.514138221740723], [5.007589817047119, 6.304329872131348], [3.911008358001709, 6.481892108917236], [4.644536972045898, 6.213891506195068], [5.381083011627197, 7.79194974899292], [6.603459358215332, 10.02604866027832], [5.624990463256836, 7.972799301147461], [4.4584245681762695, 5.671510219573975], [8.244277954101562, 6.572359085083008], [3.7390174865722656, 6.423604965209961], [4.281151294708252, 7.580209732055664], [7.2313337326049805, 5.971524238586426], [7.279983997344971, 6.641673564910889], [3.9809296131134033, 5.919703483581543], [3.8507983684539795, 6.253972053527832], [7.020188331604004, 8.40364933013916], [5.145181179046631, 8.482370376586914], [8.009186744689941, 6.75827693939209], [8.530585289001465, 7.388890266418457], [8.816853523254395, 7.959311008453369], [5.598198890686035, 8.006948471069336], [7.430131912231445, 10.146503448486328], [5.124302387237549, 6.7748308181762695], [7.159740924835205, 10.405364036560059], [7.5405120849609375, 6.864541053771973], [5.690948009490967, 6.260439872741699], [6.184312343597412, 6.390440464019775], [4.565508842468262, 7.727900505065918], [6.205026149749756, 9.36143684387207], [5.062450408935547, 6.587175369262695], [6.715217590332031, 8.090492248535156], [4.620118141174316, 7.700267314910889], [6.867812156677246, 7.394354343414307], [7.541627407073975, 9.737656593322754], [7.628964424133301, 7.8290114402771], [5.42578649520874, 6.539775848388672], [6.899052619934082, 8.407119750976562], [8.113056182861328, 9.645833015441895], [7.925438404083252, 9.611089706420898], [5.864367961883545, 6.474483966827393], [6.641806125640869, 8.317455291748047], [8.20577621459961, 9.54541301727295], [8.181632041931152, 7.442039489746094], [7.256445407867432, 9.144037246704102], [8.723616600036621, 9.109533309936523], [8.001374244689941, 9.660171508789062], [4.930443286895752, 7.440208435058594], [5.506430149078369, 8.562674522399902], [4.765208721160889, 5.617320537567139], [7.279713153839111, 10.108173370361328], [7.420037746429443, 10.204606056213379], [7.978753566741943, 7.669971942901611], [8.634804725646973, 8.922152519226074], [4.287731647491455, 7.558534145355225], [4.0589447021484375, 6.995239734649658], [7.073013782501221, 9.462422370910645], [5.571151256561279, 7.481201171875], [7.306375980377197, 9.45373821258545], [7.121814727783203, 6.0030388832092285], [7.2734456062316895, 9.807544708251953], [4.866796970367432, 7.912360191345215], [6.300573348999023, 6.00970458984375], [8.416936874389648, 8.777989387512207], [5.51784086227417, 9.099093437194824], [7.617976665496826, 10.110527992248535], [7.103939533233643, 9.611526489257812], [8.363327980041504, 7.86724853515625], [8.477219581604004, 7.19556188583374], [6.294260025024414, 8.095449447631836], [5.69859504699707, 7.289427757263184], [6.542043209075928, 6.842060565948486], [6.308009147644043, 6.108287811279297], [7.558680057525635, 9.81436538696289], [5.869704246520996, 6.183292865753174], [8.313749313354492, 6.699981212615967], [8.852372169494629, 8.167966842651367], [4.795487403869629, 5.605217933654785], [8.452610969543457, 9.192378997802734], [8.548552513122559, 6.855437278747559], [6.169250965118408, 9.701523780822754], [6.724294185638428, 10.120357513427734], [8.46153736114502, 9.751632690429688], [8.721494674682617, 7.601794719696045], [4.3257927894592285, 7.7109375], [4.498965740203857, 7.420949935913086], [7.090608596801758, 7.569289684295654], [8.257004737854004, 9.520790100097656], [5.505358695983887, 9.575189590454102], [7.064085960388184, 5.656517505645752], [5.160403728485107, 8.278335571289062], [7.856103897094727, 7.840211868286133], [5.3725786209106445, 6.848460674285889], [8.725038528442383, 7.526784420013428], [7.095794677734375, 5.888527870178223], [7.271857738494873, 8.909235000610352], [9.003747940063477, 7.207961559295654], [8.76421070098877, 7.595570087432861], [7.8360066413879395, 7.229221820831299], [7.352268695831299, 9.62349796295166], [6.643272876739502, 8.411834716796875], [8.884297370910645, 7.387173652648926], [6.995594501495361, 9.853951454162598], [4.9736785888671875, 6.362598419189453], [4.430104732513428, 7.778832912445068], [5.9102044105529785, 8.017621040344238], [8.85576343536377, 8.987842559814453], [4.698768615722656, 7.243259429931641], [5.367000102996826, 8.373929023742676], [3.9117250442504883, 7.198288917541504], [5.90366792678833, 7.5884108543396], [5.146412372589111, 9.528850555419922], [8.017928123474121, 8.206101417541504], [4.995699405670166, 9.34278392791748], [4.012818336486816, 6.459230899810791], [5.098651885986328, 9.428420066833496], [6.372692108154297, 6.319596290588379], [6.964207172393799, 5.936566352844238], [6.1364288330078125, 10.126518249511719], [5.912512302398682, 9.873149871826172], [5.15220308303833, 8.410752296447754], [5.055086612701416, 9.417580604553223], [5.9383544921875, 9.27199935913086], [4.89754581451416, 6.93621301651001], [7.359240531921387, 8.195948600769043], [4.630490303039551, 8.401047706604004], [4.671852111816406, 8.528053283691406], [8.060797691345215, 6.865067481994629], [3.974749803543091, 6.934914588928223], [6.768882751464844, 9.657278060913086], [6.460553169250488, 6.998720169067383], [7.30495548248291, 8.978870391845703], [8.520563125610352, 9.841508865356445], [6.006304740905762, 8.076077461242676], [8.098556518554688, 6.56044864654541], [7.38086462020874, 9.600143432617188], [6.997753143310547, 5.570436000823975], [4.607234477996826, 6.109882354736328], [8.48311710357666, 7.568016529083252], [5.813255310058594, 9.924927711486816], [4.4702839851379395, 6.003908157348633], [5.464100360870361, 5.875680446624756], [3.714700222015381, 6.428480625152588], [6.965457916259766, 7.007269382476807], [7.047658443450928, 7.884128570556641], [5.022894859313965, 5.627214431762695], [5.418179512023926, 5.908634662628174], [5.543540954589844, 9.077879905700684], [5.666286468505859, 8.039070129394531], [7.614152908325195, 10.106701850891113], [6.092438697814941, 9.400835990905762], [5.068489074707031, 7.291117191314697], [7.545759201049805, 6.473002910614014], [4.9558563232421875, 7.202636241912842], [3.9845967292785645, 6.0718994140625], [6.9441819190979, 7.827483654022217], [8.90143871307373, 9.023734092712402], [8.713800430297852, 9.203807830810547], [6.967805862426758, 9.92839527130127], [5.496678352355957, 5.789439678192139], [5.641040325164795, 6.789905548095703], [5.874301910400391, 6.686304092407227], [7.146614074707031, 10.099123001098633], [4.241623878479004, 7.320739269256592], [8.408895492553711, 6.824686050415039], [7.4451069831848145, 10.17075252532959], [6.725869655609131, 5.518614768981934], [5.238387584686279, 5.842329978942871], [4.400071620941162, 7.142591953277588], [6.573674201965332, 9.900679588317871], [6.630160808563232, 9.360848426818848], [7.6527533531188965, 10.2094144821167], [6.712522983551025, 9.791939735412598], [8.63031005859375, 9.615147590637207], [7.407383441925049, 7.5738606452941895], [6.73393440246582, 8.327207565307617], [8.083049774169922, 10.0172758102417], [8.38027572631836, 7.998839855194092], [5.491772651672363, 6.955765247344971], [7.026520252227783, 7.0487799644470215], [4.942129611968994, 9.006155967712402], [6.84155797958374, 9.934195518493652], [5.514888286590576, 8.016607284545898], [3.688786268234253, 6.397368907928467], [7.5898356437683105, 9.670185089111328], [4.810425758361816, 5.518113136291504], [7.443385601043701, 9.302128791809082], [7.79586935043335, 6.385225772857666], [5.288991451263428, 6.48078727722168], [5.036536693572998, 6.945281982421875], [6.43952751159668, 5.925435543060303], [8.815529823303223, 7.677879810333252], [4.422175407409668, 6.316697120666504], [8.210000991821289, 6.609785556793213], [7.237021446228027, 7.931437015533447], [6.169328212738037, 7.277979850769043], [5.8048415184021, 7.634628772735596], [7.389041423797607, 6.383037090301514], [8.893640518188477, 8.847895622253418], [7.334124565124512, 7.7601518630981445], [8.388869285583496, 8.736795425415039], [5.354607105255127, 8.763792991638184], [6.6040120124816895, 8.088674545288086], [6.1048126220703125, 10.044411659240723], [9.104412078857422, 7.883095741271973], [3.783210515975952, 5.914460182189941], [7.3971734046936035, 10.322783470153809], [8.780823707580566, 8.906137466430664], [5.977082252502441, 9.411081314086914], [5.268189907073975, 6.403694152832031], [6.599472522735596, 6.335020065307617], [6.785434722900391, 10.477185249328613], [5.4151530265808105, 7.861612319946289], [6.557764530181885, 8.0347261428833], [6.686742782592773, 10.221583366394043], [7.240847110748291, 7.316451549530029], [6.379225254058838, 8.083151817321777], [7.311709403991699, 10.158493995666504], [6.10598087310791, 8.25819206237793], [9.062860488891602, 7.608150959014893], [7.219074249267578, 7.875044822692871], [7.670312404632568, 10.340983390808105], [5.003853797912598, 6.326554775238037], [4.335278034210205, 7.757326602935791], [8.870176315307617, 7.1977620124816895], [5.859528064727783, 8.02239990234375], [7.06832218170166, 9.618814468383789], [7.085141658782959, 10.54554557800293], [7.417768478393555, 6.616800308227539], [7.20806360244751, 5.723014831542969], [6.576611042022705, 10.408092498779297], [6.859883785247803, 10.00068187713623], [7.495157718658447, 6.735848426818848], [9.06096363067627, 7.26619291305542], [9.121068954467773, 7.761306285858154], [6.856493949890137, 6.77951192855835], [9.073098182678223, 7.312638282775879]], "keys": ["2401.10236", "2401.10239", "2401.10241", "2401.10242", "2401.10244", "2401.10245", "2401.10246", "2401.10247", "2401.10249", "2401.1025", "2401.10251", "2401.10252", "2401.10253", "2401.10254", "2401.10256", "2401.10257", "2401.10262", "2401.10264", "2401.10265", "2401.10266", "2401.10267", "2401.10268", "2401.10269", "2401.1027", "2401.10271", "2401.10272", "2401.10273", "2401.10274", "2401.10279", "2401.10286", "2401.10287", "2401.10288", "2401.10289", "2401.1029", "2401.10294", "2401.10299", "2401.103", "2401.10302", "2401.10304", "2401.1031", "2401.10313", "2401.10314", "2401.10315", "2401.10316", "2401.10337", "2401.10338", "2401.10341", "2401.10352", "2401.10353", "2401.10354", "2401.10357", "2401.10359", "2401.1036", "2401.10361", "2401.10363", "2401.10364", "2401.10367", "2401.10368", "2401.10369", "2401.10371", "2401.10372", "2401.10375", "2401.10376", "2401.10379", "2401.10382", "2401.10383", "2401.10385", "2401.10386", "2401.10387", "2401.1039", "2401.10393", "2401.10394", "2401.10397", "2401.10402", "2401.10404", "2401.10405", "2401.10407", "2401.10409", "2401.10415", "2401.10416", "2401.10417", "2401.10418", "2401.1042", "2401.10422", "2401.10423", "2401.10428", "2401.10431", "2401.10432", "2401.1044", "2401.10442", "2401.10443", "2401.10444", "2401.10446", "2401.10447", "2401.10451", "2401.10458", "2401.1046", "2401.10461", "2401.10463", "2401.10464", "2401.10465", "2401.10467", "2401.10469", "2401.1047", "2401.10471", "2401.10472", "2401.10474", "2401.10475", "2401.10476", "2401.10478", "2401.1048", "2401.10484", "2401.10487", "2401.1049", "2401.10491", "2401.10495", "2401.10498", "2401.10501", "2401.10504", "2401.10506", "2401.1051", "2401.10511", "2401.10512", "2401.10515", "2401.10516", "2401.10518", "2401.10519", "2401.10521", "2401.10522", "2401.10525", "2401.10526", "2401.10527", "2401.10529", "2401.1053", "2401.10531", "2401.10535", "2401.10536", "2401.10537", "2401.10538", "2401.10539", "2401.10541", "2401.10544", "2401.10545", "2401.10546", "2401.10547", "2401.10549", "2401.10553", "2401.10556", "2401.10557", "2401.10559", "2401.1056", "2401.10564", "2401.10566", "2401.10567", "2401.10568", "2401.10578", "2401.1058", "2401.10582", "2401.10584", "2401.10586", "2401.10588", "2401.10589", "2401.1059", "2401.10601", "2401.10603", "2401.10607", "2401.10608", "2401.10611", "2401.10614", "2401.10617", "2401.10619", "2401.1062", "2401.10627", "2401.10629", "2401.10632", "2401.10634", "2401.10636", "2401.10638", "2401.1064", "2401.10641", "2401.10642", "2401.10643", "2401.10646", "2401.10647", "2401.10648", "2401.10652", "2401.10653", "2401.10657", "2401.10659", "2401.1066", "2401.10662", "2401.10664", "2401.10666", "2401.10669", "2401.1067", "2401.10674", "2401.10681", "2401.10685", "2401.10686", "2401.10688", "2401.10689", "2401.1069", "2401.10691", "2401.10695", "2401.10699", "2401.107", "2401.10702", "2401.10703", "2401.10708", "2401.1071", "2401.10711", "2401.10712", "2401.10716", "2401.10724", "2401.10725", "2401.10726", "2401.10727", "2401.10729", "2401.10731", "2401.10733", "2401.10735", "2401.10736", "2401.10738", "2401.10739", "2401.10741", "2401.10744", "2401.10745", "2401.10747", "2401.10748", "2401.10749", "2401.10751", "2401.10752", "2401.10753", "2401.10754", "2401.10755", "2401.10759", "2401.10765", "2401.10766", "2401.10768", "2401.10773", "2401.10774", "2401.10777", "2401.10778", "2401.10781", "2401.10785", "2401.10786", "2401.10787", "2401.1079", "2401.10791", "2401.10794", "2401.10799", "2401.10804", "2401.10805", "2401.10809", "2401.10815", "2401.10816", "2401.10819", "2401.1082", "2401.10822", "2401.10823", "2401.10825", "2401.10831", "2401.10833", "2401.10834", "2401.10837", "2401.10838", "2401.10839", "2401.1084", "2401.10841", "2401.10843", "2401.10844", "2401.10845", "2401.10846", "2401.10848", "2401.10849", "2401.1085", "2401.10852", "2401.10856", "2401.10857", "2401.10859", "2401.10862", "2401.10873", "2401.10877", "2401.10879", "2401.1088", "2401.10882", "2401.10883", "2401.10886", "2401.10889", "2401.1089", "2401.10891"], "additional_info": [{"arxiv_id": "2401.10236", "title": "MORCIC: Model Order Reduction Techniques for Electromagnetic Models of\n  Integrated Circuits", "abstract": "Model order reduction (MOR) is crucial for the design process of integrated\ncircuits. Specifically, the vast amount of passive RLCk elements in\nelectromagnetic models extracted from physical layouts exacerbates the\nextraction time, the storage requirements, and, most critically, the\npost-layout simulation time of the analyzed circuits. The MORCIC project aims\nto overcome this problem by proposing new MOR techniques that perform better\nthan commercial tools. Experimental evaluation on several analog and\nmixed-signal circuits with millions of elements indicates that the proposed\nmethods lead to x5.5 smaller ROMs while maintaining similar accuracy compared\nto golden ROMs provided by ANSYS RaptorX.", "field": "Computer Science", "categories": "math.NA,cs.AR,cs.CE,cs.NA"}, {"arxiv_id": "2401.10239", "title": "Mixed zonotopes: a set representation suitable for unbounded systems and\n  its application to set-based state estimation and active fault diagnosis of\n  descriptor systems", "abstract": "This paper proposes new methods for set-based state estimation and active\nfault diagnosis (AFD) of linear descriptor systems. In contrast to simple set\nrepresentations, such as intervals, ellipsoids, and zonotopes, linear static\nconstraints on the state variables, typical of descriptor systems, can be\ndirectly incorporated in the mathematical description of constrained zonotopes.\nThanks to this feature, set-based methods using constrained zonotopes, as\nproposed in previous works, could provide less conservative enclosures.\nHowever, an enclosure on the states was assumed to be known for all $k \\geq 0$.\nSuch assumption is violated in the case of unstable descriptor systems. In this\ncontext, this paper proposes a new representation for unbounded sets, which\nallows to develop methods for state estimation and tube-based AFD of stable and\nunstable linear descriptor systems. The new set representation inherits most of\nthe properties of constrained zonotopes, including efficient complexity\nreduction methods, while allowing to describe different classes of sets, such\nas strips, hyperplanes, and the entire $n$-dimensional Euclidean space. The\nadvantages of the proposed approaches with respect to constrained zonotope\nmethods are highlighted in numerical examples.", "field": "Computer Science", "categories": "eess.SY,cs.SY,math.DS"}, {"arxiv_id": "2401.10241", "title": "Zero Bubble Pipeline Parallelism", "abstract": "Pipeline parallelism is one of the key components for large-scale distributed\ntraining, yet its efficiency suffers from pipeline bubbles which were deemed\ninevitable. In this work, we introduce a scheduling strategy that, to our\nknowledge, is the first to successfully achieve zero pipeline bubbles under\nsynchronous training semantics. The key idea behind this improvement is to\nsplit the backward computation into two parts, one that computes gradient for\nthe input and another that computes for the parameters. Based on this idea, we\nhandcraft novel pipeline schedules that significantly outperform the baseline\nmethods. We further develop an algorithm that automatically finds an optimal\nschedule based on specific model configuration and memory limit. Additionally,\nto truly achieve zero bubble, we introduce a novel technique to bypass\nsynchronizations during the optimizer step. Experimental evaluations show that\nour method outperforms the 1F1B schedule up to 23% in throughput under a\nsimilar memory limit. This number can be further pushed to 31% when the memory\nconstraint is relaxed. We believe our results mark a major step forward in\nharnessing the true potential of pipeline parallelism. We open sourced our\nimplementation based on the popular Megatron-LM repository on\nhttps://github.com/sail-sg/zero-bubble-pipeline-parallelism.", "field": "Computer Science", "categories": "cs.DC,cs.AI,cs.LG"}, {"arxiv_id": "2401.10242", "title": "DanceMeld: Unraveling Dance Phrases with Hierarchical Latent Codes for\n  Music-to-Dance Synthesis", "abstract": "In the realm of 3D digital human applications, music-to-dance presents a\nchallenging task. Given the one-to-many relationship between music and dance,\nprevious methods have been limited in their approach, relying solely on\nmatching and generating corresponding dance movements based on music rhythm. In\nthe professional field of choreography, a dance phrase consists of several\ndance poses and dance movements. Dance poses composed of a series of basic\nmeaningful body postures, while dance movements can reflect dynamic changes\nsuch as the rhythm, melody, and style of dance. Taking inspiration from these\nconcepts, we introduce an innovative dance generation pipeline called\nDanceMeld, which comprising two stages, i.e., the dance decouple stage and the\ndance generation stage. In the decouple stage, a hierarchical VQ-VAE is used to\ndisentangle dance poses and dance movements in different feature space levels,\nwhere the bottom code represents dance poses, and the top code represents dance\nmovements. In the generation stage, we utilize a diffusion model as a prior to\nmodel the distribution and generate latent codes conditioned on music features.\nWe have experimentally demonstrated the representational capabilities of top\ncode and bottom code, enabling the explicit decoupling expression of dance\nposes and dance movements. This disentanglement not only provides control over\nmotion details, styles, and rhythm but also facilitates applications such as\ndance style transfer and dance unit editing. Our approach has undergone\nqualitative and quantitative experiments on the AIST++ dataset, demonstrating\nits superiority over other methods.", "field": "Computer Science", "categories": "cs.OH,cs.GR,cs.HC,cs.SD,eess.AS"}, {"arxiv_id": "2401.10244", "title": "Knowledge graph driven recommendation model of graph neural network", "abstract": "A new graph neural network-based recommendation model called KGLN, which\nleverages Knowledge Graph (KG) information, was developed to enhance the\naccuracy and effectiveness of personalized recommendations. This model begins\nby using a single-layer neural network to merge individual node features in the\ngraph. It then adjusts the aggregation weights of neighboring entities by\nincorporating influence factors. The model evolves from a single layer to\nmultiple layers through iteration, enabling entities to access extensive\nmulti-order associated entity information. The final step involves integrating\nfeatures of entities and users to produce a recommendation score. The model's\nperformance was evaluated by comparing its effects on various aggregation\nmethods and influence factors. In tests using the MovieLen-1M and Book-Crossing\ndatasets, KGLN showed an AUC (Area Under the ROC curve) improvement of 0.3% to\n5.9% and 1.1% to 8.2%, respectively, over established benchmark methods like\nLibFM, DeepFM, Wide&Deep, and RippleNet.", "field": "Computer Science", "categories": "cs.IR,cs.CL"}, {"arxiv_id": "2401.10245", "title": "Train Small, Model Big: Scalable Physics Simulators via Reduced Order\n  Modeling and Domain Decomposition", "abstract": "Numerous cutting-edge scientific technologies originate at the laboratory\nscale, but transitioning them to practical industry applications is a\nformidable challenge. Traditional pilot projects at intermediate scales are\ncostly and time-consuming. An alternative, the E-pilot, relies on high-fidelity\nnumerical simulations, but even these simulations can be computationally\nprohibitive at larger scales. To overcome these limitations, we propose a\nscalable, physics-constrained reduced order model (ROM) method. ROM identifies\ncritical physics modes from small-scale unit components, projecting governing\nequations onto these modes to create a reduced model that retains essential\nphysics details. We also employ Discontinuous Galerkin Domain Decomposition\n(DG-DD) to apply ROM to unit components and interfaces, enabling the\nconstruction of large-scale global systems without data at such large scales.\nThis method is demonstrated on the Poisson and Stokes flow equations, showing\nthat it can solve equations about $15 - 40$ times faster with only $\\sim$ $1\\%$\nrelative error. Furthermore, ROM takes one order of magnitude less memory than\nthe full order model, enabling larger scale predictions at a given memory\nlimitation.", "field": "Computer Science", "categories": "cs.CE,physics.flu-dyn,65F55, 65N55 (primary) 76D07 (secondary)"}, {"arxiv_id": "2401.10246", "title": "High-Performance Computing in Battery Development: From Pore Scale to\n  Continuum", "abstract": "An application for high-performance computing (HPC) is shown that is relevant\nin the field of battery development. Simulations of electrolyte wetting and\nflow are conducted using pore network models (PNM) and the lattice Boltzmann\nmethod (LBM), while electrochemical simulations are conducted using the tool\nBEST. All aforementioned software packages show an appropriate scaling\nbehavior. A workflow for optimizing battery performance by improving the\nfilling of battery components is presented. A special focus is given to the\nunwanted side effect of gas entrapment encountered during filling. It is also\nknown to adversely affect the electrochemical performance of batteries and can\nbe partially prevented by appropriate microstructure design such as electrode\nperforation.", "field": "Computer Science", "categories": "cs.CE"}, {"arxiv_id": "2401.10247", "title": "Resolution Chromatography of Diffusion Models", "abstract": "Diffusion models generate high-resolution images through iterative stochastic\nprocesses. In particular, the denoising method is one of the most popular\napproaches that predicts the noise in samples and denoises it at each time\nstep. It has been commonly observed that the resolution of generated samples\nchanges over time, starting off blurry and coarse, and becoming sharper and\nfiner. In this paper, we introduce \"resolution chromatography\" that indicates\nthe signal generation rate of each resolution, which is very helpful concept to\nmathematically explain this coarse-to-fine behavior in generation process, to\nunderstand the role of noise schedule, and to design time-dependent modulation.\nUsing resolution chromatography, we determine which resolution level becomes\ndominant at a specific time step, and experimentally verify our theory with\ntext-to-image diffusion models. We also propose some direct applications\nutilizing the concept: upscaling pre-trained models to higher resolutions and\ntime-dependent prompt composing. Our theory not only enables a better\nunderstanding of numerous pre-existing techniques for manipulating image\ngeneration, but also suggests the potential for designing better noise\nschedules.", "field": "Computer Science", "categories": "cs.CV,cs.LG"}, {"arxiv_id": "2401.10249", "title": "Building a Reusable and Extensible Automatic Compiler Infrastructure for\n  Reconfigurable Devices", "abstract": "Multi-Level Intermediate Representation (MLIR) is gaining increasing\nattention in reconfigurable hardware communities due to its capability to\nrepresent various abstract levels for software compilers. This project aims to\nbe the first to provide an end-to-end framework that leverages open-source,\ncross-platform compilation technology to generate MLIR from SYCL. Additionally,\nit aims to explore a lowering pipeline that converts MLIR to RTL using\nopen-source hardware intermediate representation (IR) and compilers.\nFurthermore, it aims to couple the generated hardware module with the host CPU\nusing vendor-specific crossbars. Our preliminary results demonstrated the\nfeasibility of lowering customized MLIR to RTL, thus paving the way for an\nend-to-end compilation.", "field": "Computer Science", "categories": "cs.AR"}, {"arxiv_id": "2401.1025", "title": "Spectrum Sharing through Marketplaces for O-RAN based Non-Terrestrial\n  and Terrestrial Networks", "abstract": "Non-terrestrial networks (NTNs), including low Earth orbit (LEO) satellites,\nare expected to play a pivotal role in achieving global coverage for\nInternet-of-Things (IoT) applications in sixth-generation (6G) systems.\nAlthough specific frequency bands have been identified for satellite use in\nNTNs, persistent challenges arise due to the limited availability of spectrum\nresources. The coexistence of multiple systems, including terrestrial networks\n(TNs), sharing these frequencies, presents a technically challenging yet\nfeasible solution. Furthermore, the effective management and regulation of such\ncoexistence should be under the purview of regional authorities. To facilitate\nefficient spectrum sharing among various systems, including NTNs and TNs,\nadopting open architectures is desirable, allowing for the seamless exchange of\nkey information for spectrum sharing. Therefore, it is essential to consider\nopen radio access networks (O-RAN) for future NTNs and TNs. In addition to\nO-RAN, the establishment of spectrum marketplaces, enabling different operators\nto trade their spectrum and dynamic resource allocation information, is\nnecessary. In this article, we highlight the role of spectrum marketplaces and\ndiscuss a few examples.", "field": "Computer Science", "categories": "cs.NI,cs.SY,eess.SY"}, {"arxiv_id": "2401.10251", "title": "Non-Terrestrial Network (NTN): a Novel Alternate Fractional Programming\n  for the Downlink Channels Power Allocation", "abstract": "Non-terrestrial network (NTN) communication has garnered considerable\nattention from government entities, industries, and academia in recent times.\nNTN networks encompass a variety of systems, including Low Earth Orbit (LEO)\nsatellites, Medium Earth Orbit (MEO) satellites, Geostationary Earth Orbit\n(GEO) satellites, High Altitude Platforms (HAPS), and Low Altitude Platforms\n(LAPS). Furthermore, the deployment of high-throughput satellites (HTS/VHTS) in\nthe GEO space has gained momentum. While LEO and MEO satellites offer\nadvantages such as low latency and reduced launching costs compared to GEO\nsatellites, this study focuses on GEO satellites due to their stationary nature\nand broader coverage. In traditional cellular networks, each user equipment\n(UE) is allocated at least one resource block (RB), which is not shared with\nother UEs. However, in NTN communications, where the coverage area is\nextensive, dedicating an RB to only one UE is an inefficient utilization of\nradio resources. To address this challenge, fractional programming (FP),\ncognitive radio, and rate splitting multiple access (RSMA) are existing\ntechnologies. This paper aims to maximize spectral efficiency, average RBG\nrate, and sum rate for GEO satellite systems. However, achieving this objective\ninvolves dealing with a non-convex, NP-hard problem, as it requires the\nlogarithmic sum of different fractions. Finding a global solution to such an\nNP-hard problem presents significant challenges. This paper introduces a novel\nalternate fractional programming algorithm specifically designed to tackle\nthese complex NP-hard problems in the context of GEO NTN cellular networks. By\nemploying this innovative approach, the study seeks to contribute to the\noptimization of NTN communication systems, enabling efficient resource\nallocation and improved network performance.", "field": "Computer Science", "categories": "cs.IT,math.IT"}, {"arxiv_id": "2401.10252", "title": "A Beam-Segmenting Polar Format Algorithm Based on Double PCS for Video\n  SAR Persistent Imaging", "abstract": "Video synthetic aperture radar (SAR) is attracting more attention in recent\nyears due to its abilities of high resolution, high frame rate and advantages\nin continuous observation. Generally, the polar format algorithm (PFA) is an\nefficient algorithm for spotlight mode video SAR. However, in the process of\nPFA, the wavefront curvature error (WCE) limits the imaging scene size and the\n2-D interpolation affects the efficiency. To solve the aforementioned problems,\na beam-segmenting PFA based on principle of chirp scaling (PCS), called\nBS-PCS-PFA, is proposed for video SAR imaging, which has the capability of\npersistent imaging for different carrier frequencies video SAR. Firstly, an\nimproved PCS applicable to video SAR PFA is proposed to replace the 2-D\ninterpolation and the coarse image in the ground output coordinate system\n(GOCS) is obtained. As for the distortion or defocus existing in the coarse\nimage, a novel sub-block imaging method based on beam-segmenting fast filtering\nis proposed to segment the image into multiple sub-beam data, whose distortion\nand defocus can be ignored when the equivalent size of sub-block is smaller\nthan the distortion negligible region. Through processing the sub-beam data and\nmosaicking the refocused subimages, the full image in GOCS without distortion\nand defocus is obtained. Moreover, a three-step MoCo method is applied to the\nalgorithm for the adaptability to the actual irregular trajectories. The\nproposed method can significantly expand the effective scene size of PFA, and\nthe better operational efficiency makes it more suitable for video SAR imaging.\nThe feasibility of the algorithm is verified by the experimental data.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10253", "title": "Hybrid-Task Meta-Learning: A Graph Neural Network Approach for Scalable\n  and Transferable Bandwidth Allocation", "abstract": "In this paper, we develop a deep learning-based bandwidth allocation policy\nthat is: 1) scalable with the number of users and 2) transferable to different\ncommunication scenarios, such as non-stationary wireless channels, different\nquality-of-service (QoS) requirements, and dynamically available resources. To\nsupport scalability, the bandwidth allocation policy is represented by a graph\nneural network (GNN), with which the number of training parameters does not\nchange with the number of users. To enable the generalization of the GNN, we\ndevelop a hybrid-task meta-learning (HML) algorithm that trains the initial\nparameters of the GNN with different communication scenarios during\nmeta-training. Next, during meta-testing, a few samples are used to fine-tune\nthe GNN with unseen communication scenarios. Simulation results demonstrate\nthat our HML approach can improve the initial performance by $8.79\\%$, and\nsampling efficiency by $73\\%$, compared with existing benchmarks. After\nfine-tuning, our near-optimal GNN-based policy can achieve close to the same\nreward with much lower inference complexity compared to the optimal policy\nobtained using iterative optimization.", "field": "Computer Science", "categories": "cs.NI,cs.LG"}, {"arxiv_id": "2401.10254", "title": "Beyond the Frame: Single and mutilple video summarization method with\n  user-defined length", "abstract": "Video smmarization is a crucial method to reduce the time of videos which\nreduces the spent time to watch/review a long video. This apporach has became\nmore important as the amount of publisehed video is increasing everyday. A\nsingle or multiple videos can be summarized into a relatively short video using\nvarious of techniques from multimodal audio-visual techniques, to natural\nlanguage processing approaches. Audiovisual techniques may be used to recognize\nsignificant visual events and pick the most important parts, while NLP\ntechniques can be used to evaluate the audio transcript and extract the main\nsentences (timestamps) and corresponding video frames from the original video.\nAnother approach is to use the best of both domain. Meaning that we can use\naudio-visual cues as well as video transcript to extract and summarize the\nvideo. In this paper, we combine a variety of NLP techniques (extractive and\ncontect-based summarizers) with video processing techniques to convert a long\nvideo into a single relatively short video. We design this toll in a way that\nuser can specify the relative length of the summarized video. We have also\nexplored ways of summarizing and concatenating multiple videos into a single\nshort video which will help having most important concepts from the same\nsubject in a single short video. Out approach shows that video summarizing is a\ndifficult but significant work, with substantial potential for further research\nand development, and it is possible thanks to the development of NLP models.", "field": "Computer Science", "categories": "cs.CV,cs.LG"}, {"arxiv_id": "2401.10256", "title": "Active headrest combined with a depth camera-based ear-positioning\n  system", "abstract": "Active headrests can reduce low-frequency noise around ears based on active\nnoise control (ANC) system. Both the control system using fixed control filters\nand the remote microphone-based adaptive control system provide good noise\nreduction performance when the head is in the original position. However, their\nperformance degrades significantly when the head is in motion. In this paper, a\nhuman ear-positioning system based on the depth camera is introduced to address\nthis problem. The system uses RTMpose model to estimate the two-dimensional\n(2D) positions of the ears in the color frame, and then derives the\ncorresponding three-dimensional (3D) coordinates in the depth frame with a\ndepth camera. Experimental results show that the ear-positioning system can\neffectively track the movement of ears, and the broadband noise reduction\nperformance of the active headrest combined with the system is significantly\nimproved when the human head is translating or rotating.", "field": "Computer Science", "categories": "cs.CV,eess.IV"}, {"arxiv_id": "2401.10257", "title": "Curriculum Design Helps Spiking Neural Networks to Classify Time Series", "abstract": "Spiking Neural Networks (SNNs) have a greater potential for modeling time\nseries data than Artificial Neural Networks (ANNs), due to their inherent\nneuron dynamics and low energy consumption. However, it is difficult to\ndemonstrate their superiority in classification accuracy, because current\nefforts mainly focus on designing better network structures. In this work,\nenlighten by brain-inspired science, we find that, not only the structure but\nalso the learning process should be human-like. To achieve this, we investigate\nthe power of Curriculum Learning (CL) on SNNs by designing a novel method named\nCSNN with two theoretically guaranteed mechanisms: The active-to-dormant\ntraining order makes the curriculum similar to that of human learning and\nsuitable for spiking neurons; The value-based regional encoding makes the\nneuron activity to mimic the brain memory when learning sequential data.\nExperiments on multiple time series sources including simulated, sensor,\nmotion, and healthcare demonstrate that CL has a more positive effect on SNNs\nthan ANNs with about twice the accuracy change, and CSNN can increase about 3%\nSNNs' accuracy by improving network sparsity, neuron firing status, anti-noise\nability, and convergence speed.", "field": "Computer Science", "categories": "cs.NE,cs.LG"}, {"arxiv_id": "2401.10262", "title": "Null Space Properties of Neural Networks with Applications to Image\n  Steganography", "abstract": "This paper explores the null space properties of neural networks. We extend\nthe null space definition from linear to nonlinear maps and discuss the\npresence of a null space in neural networks. The null space of a given neural\nnetwork can tell us the part of the input data that makes no contribution to\nthe final prediction so that we can use it to trick the neural network. This\nreveals an inherent weakness in neural networks that can be exploited. One\napplication described here leads to a method of image steganography. Through\nexperiments on image datasets such as MNIST, we show that we can use null space\ncomponents to force the neural network to choose a selected hidden image class,\neven though the overall image can be made to look like a completely different\nimage. We conclude by showing comparisons between what a human viewer would\nsee, and the part of the image that the neural network is actually using to\nmake predictions and, hence, show that what the neural network ``sees'' is\ncompletely different than what we would expect.", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.CR,cs.LG"}, {"arxiv_id": "2401.10264", "title": "Harnessing Transparent Learning Analytics for Individualized Support\n  through Auto-detection of Engagement in Face-to-Face Collaborative Learning", "abstract": "Using learning analytics to investigate and support collaborative learning\nhas been explored for many years. Recently, automated approaches with various\nartificial intelligence approaches have provided promising results for\nmodelling and predicting student engagement and performance in collaborative\nlearning tasks. However, due to the lack of transparency and interpretability\ncaused by the use of \"black box\" approaches in learning analytics design and\nimplementation, guidance for teaching and learning practice may become a\nchallenge. On the one hand, the black box created by machine learning\nalgorithms and models prevents users from obtaining educationally meaningful\nlearning and teaching suggestions. On the other hand, focusing on group and\ncohort level analysis only can make it difficult to provide specific support\nfor individual students working in collaborative groups. This paper proposes a\ntransparent approach to automatically detect student's individual engagement in\nthe process of collaboration. The results show that the proposed approach can\nreflect student's individual engagement and can be used as an indicator to\ndistinguish students with different collaborative learning challenges\n(cognitive, behavioural and emotional) and learning outcomes. The potential of\nthe proposed collaboration analytics approach for scaffolding collaborative\nlearning practice in face-to-face contexts is discussed and future research\nsuggestions are provided.", "field": "Computer Science", "categories": "cs.CY,cs.AI"}, {"arxiv_id": "2401.10265", "title": "The Best Time for an Update: Risk-Sensitive Minimization of Age-Based\n  Metrics", "abstract": "Popular methods to quantify transmitted data quality are the Age of\nInformation (AoI), the Query Age of Information (QAoI), and the Age of\nIncorrect Information (AoII). We consider these metrics in a point-to-point\nwireless communication system, where the transmitter monitors a process and\nsends status updates to a receiver. The challenge is to decide on the best time\nfor an update, balancing the transmission energy and the age-based metric at\nthe receiver. Due to the inherent risk of high age-based metric values causing\ncomplications such as unstable system states, we introduce the new concept of\nrisky states to denote states with high age-based metric. We use this new\nnotion of risky states to quantify and minimize this risk of experiencing high\nage-based metrics by directly deriving the frequency of risky states as a novel\nrisk-metric. Building on this foundation, we introduce two risk-sensitive\nstrategies for AoI, QAoI and AoII. The first strategy uses system knowledge,\ni.e., channel quality and packet arrival probability, to find an optimal\nstrategy that transmits when the age-based metric exceeds a tunable threshold.\nA lower threshold leads to higher risk-sensitivity. The second strategy uses an\nenhanced Q-learning approach and balances the age-based metric, the\ntransmission energy and the frequency of risky states without requiring\nknowledge about the system. Numerical results affirm our risk-sensitive\nstrategies' high effectiveness.", "field": "Computer Science", "categories": "cs.IT,cs.LG,cs.NI,math.IT"}, {"arxiv_id": "2401.10266", "title": "Intelligent Condition Monitoring of Industrial Plants: An Overview of\n  Methodologies and Uncertainty Management Strategies", "abstract": "Condition monitoring plays a significant role in the safety and reliability\nof modern industrial systems. Artificial intelligence (AI) approaches are\ngaining attention from academia and industry as a growing subject in industrial\napplications and as a powerful way of identifying faults. This paper provides\nan overview of intelligent condition monitoring and fault detection and\ndiagnosis methods for industrial plants with a focus on the open-source\nbenchmark Tennessee Eastman Process (TEP). In this survey, the most popular and\nstate-of-the-art deep learning (DL) and machine learning (ML) algorithms for\nindustrial plant condition monitoring, fault detection, and diagnosis are\nsummarized and the advantages and disadvantages of each algorithm are studied.\nChallenges like imbalanced data, unlabelled samples and how deep learning\nmodels can handle them are also covered. Finally, a comparison of the\naccuracies and specifications of different algorithms utilizing the Tennessee\nEastman Process (TEP) is conducted. This research will be beneficial for both\nresearchers who are new to the field and experts, as it covers the literature\non condition monitoring and state-of-the-art methods alongside the challenges\nand possible solutions to them.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.SY,eess.SP,eess.SY"}, {"arxiv_id": "2401.10267", "title": "HyperSense: Accelerating Hyper-Dimensional Computing for Intelligent\n  Sensor Data Processing", "abstract": "Introducing HyperSense, our co-designed hardware and software system\nefficiently controls Analog-to-Digital Converter (ADC) modules' data generation\nrate based on object presence predictions in sensor data. Addressing challenges\nposed by escalating sensor quantities and data rates, HyperSense reduces\nredundant digital data using energy-efficient low-precision ADC, diminishing\nmachine learning system costs. Leveraging neurally-inspired HyperDimensional\nComputing (HDC), HyperSense analyzes real-time raw low-precision sensor data,\noffering advantages in handling noise, memory-centricity, and real-time\nlearning.\n  Our proposed HyperSense model combines high-performance software for object\ndetection with real-time hardware prediction, introducing the novel concept of\nIntelligent Sensor Control. Comprehensive software and hardware evaluations\ndemonstrate our solution's superior performance, evidenced by the highest Area\nUnder the Curve (AUC) and sharpest Receiver Operating Characteristic (ROC)\ncurve among lightweight models. Hardware-wise, our FPGA-based domain-specific\naccelerator tailored for HyperSense achieves a 5.6x speedup compared to YOLOv4\non NVIDIA Jetson Orin while showing up to 92.1% energy saving compared to the\nconventional system. These results underscore HyperSense's effectiveness and\nefficiency, positioning it as a promising solution for intelligent sensing and\nreal-time data processing across diverse applications.", "field": "Computer Science", "categories": "cs.AR,cs.AI"}, {"arxiv_id": "2401.10268", "title": "The complementary contributions of academia and industry to AI research", "abstract": "Artificial intelligence (AI) has seen tremendous development in industry and\nacademia. However, striking recent advances by industry have stunned the world,\ninviting a fresh perspective on the role of academic research in this field.\nHere, we characterize the impact and type of AI produced by both environments\nover the last 25 years and establish several patterns. We find that articles\npublished by teams consisting exclusively of industry researchers tend to get\ngreater attention, with a higher chance of being highly cited and\ncitation-disruptive, and several times more likely to produce state-of-the-art\nmodels. In contrast, we find that exclusively academic teams publish the bulk\nof AI research and tend to produce higher novelty work, with single papers\nhaving several times higher likelihood of being unconventional and atypical.\nThe respective impact-novelty advantages of industry and academia are robust to\ncontrols for subfield, team size, seniority, and prestige. We find that\nacademic-industry collaborations struggle to replicate the novelty of academic\nteams and tend to look similar to industry teams. Together, our findings\nidentify the unique and nearly irreplaceable contributions that both academia\nand industry make toward the healthy progress of AI.", "field": "Computer Science", "categories": "cs.CY,cs.AI,cs.SI"}, {"arxiv_id": "2401.10269", "title": "Robust Multi-Sensor Multi-Target Tracking Using Possibility Labeled\n  Multi-Bernoulli Filter", "abstract": "With the increasing complexity of multiple target tracking scenes, a single\nsensor may not be able to effectively monitor a large number of targets.\nTherefore, it is imperative to extend the single-sensor technique to\nMulti-Sensor Multi-Target Tracking (MSMTT) for enhanced functionality. Typical\nMSMTT methods presume complete randomness of all uncertain components, and\ntherefore effective solutions such as the random finite set filter and\ncovariance intersection method have been derived to conduct the MSMTT task.\nHowever, the presence of epistemic uncertainty, arising from incomplete\ninformation, is often disregarded within the context of MSMTT. This paper\ndevelops an innovative possibility Labeled Multi-Bernoulli (LMB) Filter based\non the labeled Uncertain Finite Set (UFS) theory. The LMB filter inherits the\nhigh robustness of the possibility generalized labeled multi-Bernoulli filter\nwith simplified computational complexity. The fusion of LMB UFSs is derived and\nadapted to develop a robust MSMTT scheme. Simulation results corroborate the\nsuperior performance exhibited by the proposed approach in comparison to\ntypical probabilistic methods.", "field": "Computer Science", "categories": "cs.IT,eess.SP,math.IT,stat.ME"}, {"arxiv_id": "2401.1027", "title": "Migrating Birds Optimization-Based Feature Selection for Text\n  Classification", "abstract": "This research introduces a novel approach, MBO-NB, that leverages Migrating\nBirds Optimization (MBO) coupled with Naive Bayes as an internal classifier to\naddress feature selection challenges in text classification having large number\nof features. Focusing on computational efficiency, we preprocess raw data using\nthe Information Gain algorithm, strategically reducing the feature count from\nan average of 62221 to 2089. Our experiments demonstrate MBO-NB's superior\neffectiveness in feature reduction compared to other existing techniques,\nemphasizing an increased classification accuracy. The successful integration of\nNaive Bayes within MBO presents a well-rounded solution. In individual\ncomparisons with Particle Swarm Optimization (PSO), MBO-NB consistently\noutperforms by an average of 6.9% across four setups. This research offers\nvaluable insights into enhancing feature selection methods, providing a\nscalable and effective solution for text classification", "field": "Computer Science", "categories": "cs.NE,cs.LG"}, {"arxiv_id": "2401.10271", "title": "Querying Triadic Concepts through Partial or Complete Matching of\n  Triples", "abstract": "In this paper, we introduce a new method for querying triadic concepts\nthrough partial or complete matching of triples using an inverted index, to\nretrieve already computed triadic concepts that contain a set of terms in their\nextent, intent, and/or modus. As opposed to the approximation approach\ndescribed in Ananias, this method (i) does not need to keep the initial triadic\ncontext or its three dyadic counterparts, (ii) avoids the application of\nderivation operators on the triple components through context exploration, and\n(iii) eliminates the requirement for a factorization phase to get triadic\nconcepts as the answer to one-dimensional queries. Additionally, our solution\nintroduces a novel metric for ranking the retrieved triadic concepts based on\ntheir similarity to a given query. Lastly, an empirical study is primarily done\nto illustrate the effectiveness and scalability of our approach against the\napproximation one. Our solution not only showcases superior efficiency, but\nalso highlights a better scalability, making it suitable for big data\nscenarios.", "field": "Computer Science", "categories": "cs.DB,cs.AI"}, {"arxiv_id": "2401.10272", "title": "Multi-Source Collaborative Gradient Discrepancy Minimization for\n  Federated Domain Generalization", "abstract": "Federated Domain Generalization aims to learn a domain-invariant model from\nmultiple decentralized source domains for deployment on unseen target domain.\nDue to privacy concerns, the data from different source domains are kept\nisolated, which poses challenges in bridging the domain gap. To address this\nissue, we propose a Multi-source Collaborative Gradient Discrepancy\nMinimization (MCGDM) method for federated domain generalization. Specifically,\nwe propose intra-domain gradient matching between the original images and\naugmented images to avoid overfitting the domain-specific information within\nisolated domains. Additionally, we propose inter-domain gradient matching with\nthe collaboration of other domains, which can further reduce the domain shift\nacross decentralized domains. Combining intra-domain and inter-domain gradient\nmatching, our method enables the learned model to generalize well on unseen\ndomains. Furthermore, our method can be extended to the federated domain\nadaptation task by fine-tuning the target model on the pseudo-labeled target\ndomain. The extensive experiments on federated domain generalization and\nadaptation indicate that our method outperforms the state-of-the-art methods\nsignificantly.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.10273", "title": "Revolutionizing Pharma: Unveiling the AI and LLM Trends in the\n  Pharmaceutical Industry", "abstract": "This document offers a critical overview of the emerging trends and\nsignificant advancements in artificial intelligence (AI) within the\npharmaceutical industry. Detailing its application across key operational\nareas, including research and development, animal testing, clinical trials,\nhospital clinical stages, production, regulatory affairs, quality control and\nother supporting areas, the paper categorically examines AI's role in each\nsector. Special emphasis is placed on cutting-edge AI technologies like machine\nlearning algorithms and their contributions to various aspects of\npharmaceutical operations. Through this comprehensive analysis, the paper\nhighlights the transformative potential of AI in reshaping the pharmaceutical\nindustry's future.", "field": "Computer Science", "categories": "cs.CY,cs.AI"}, {"arxiv_id": "2401.10274", "title": "Knowledge-Assisted Dual-Stage Evolutionary Optimization of Large-Scale\n  Crude Oil Scheduling", "abstract": "With the scaling up of crude oil scheduling in modern refineries, large-scale\ncrude oil scheduling problems (LSCOSPs) emerge with thousands of binary\nvariables and non-linear constraints, which are challenging to be optimized by\ntraditional optimization methods. To solve LSCOSPs, we take the practical crude\noil scheduling from a marine-access refinery as an example and start with\nmodeling LSCOSPs from crude unloading, transportation, crude distillation unit\nprocessing, and inventory management of intermediate products. On the basis of\nthe proposed model, a dual-stage evolutionary algorithm driven by heuristic\nrules (denoted by DSEA/HR) is developed, where the dual-stage search mechanism\nconsists of global search and local refinement. In the global search stage, we\ndevise several heuristic rules based on the empirical operating knowledge to\ngenerate a well-performing initial population and accelerate convergence in the\nmixed variables space. In the local refinement stage, a repair strategy is\nproposed to move the infeasible solutions towards feasible regions by further\noptimizing the local continuous variables. During the whole evolutionary\nprocess, the proposed dual-stage framework plays a crucial role in balancing\nexploration and exploitation. Experimental results have shown that DSEA/HR\noutperforms the state-of-the-art and widely-used mathematical programming\nmethods and metaheuristic algorithms on LSCOSP instances within a reasonable\ntime.", "field": "Computer Science", "categories": "cs.NE,cs.AI"}, {"arxiv_id": "2401.10279", "title": "A systematic review of geospatial location embedding approaches in large\n  language models: A path to spatial AI systems", "abstract": "Geospatial Location Embedding (GLE) helps a Large Language Model (LLM)\nassimilate and analyze spatial data. GLE emergence in Geospatial Artificial\nIntelligence (GeoAI) is precipitated by the need for deeper geospatial\nawareness in our complex contemporary spaces and the success of LLMs in\nextracting deep meaning in Generative AI. We searched Google Scholar, Science\nDirect, and arXiv for papers on geospatial location embedding and LLM and\nreviewed articles focused on gaining deeper spatial \"knowing\" through LLMs. We\nscreened 304 titles, 30 abstracts, and 18 full-text papers that reveal four GLE\nthemes - Entity Location Embedding (ELE), Document Location Embedding (DLE),\nSequence Location Embedding (SLE), and Token Location Embedding (TLE).\nSynthesis is tabular and narrative, including a dialogic conversation between\n\"Space\" and \"LLM.\" Though GLEs aid spatial understanding by superimposing\nspatial data, they emphasize the need to advance in the intricacies of spatial\nmodalities and generalized reasoning. GLEs signal the need for a Spatial\nFoundation/Language Model (SLM) that embeds spatial knowing within the model\narchitecture. The SLM framework advances Spatial Artificial Intelligence\nSystems (SPAIS), establishing a Spatial Vector Space (SVS) that maps to\nphysical space. The resulting spatially imbued Language Model is unique. It\nsimultaneously represents actual space and an AI-capable space, paving the way\nfor AI native geo storage, analysis, and multi-modality as the basis for\nSpatial Artificial Intelligence Systems (SPAIS).", "field": "Computer Science", "categories": "cs.IR,cs.AI,cs.CL"}, {"arxiv_id": "2401.10286", "title": "Top in Chinese Data Processing: English Code Models", "abstract": "While the alignment between tasks and training corpora is a fundamental\nconsensus in the application of language models, our series of experiments and\nthe metrics we designed reveal that code-based Large Language Models (LLMs)\nsignificantly outperform models trained on data that is closely matched to the\ntasks in non-coding Chinese tasks. Moreover, in tasks high sensitivity to\nChinese hallucinations, models exhibiting fewer linguistic features of the\nChinese language achieve better performance. Our experimental results can be\neasily replicated in Chinese data processing tasks, such as preparing data for\nRetrieval-Augmented Generation (RAG), by simply replacing the base model with a\ncode-based model. Additionally, our research offers a distinct perspective for\ndiscussion on the philosophical \"Chinese Room\" thought experiment.", "field": "Computer Science", "categories": "cs.CL,cs.AI"}, {"arxiv_id": "2401.10287", "title": "Open-Source Fermionic Neural Networks with Ionic Charge Initialization", "abstract": "Finding accurate solutions to the electronic Schr\\\"odinger equation plays an\nimportant role in discovering important molecular and material energies and\ncharacteristics. Consequently, solving systems with large numbers of electrons\nhas become increasingly important. Variational Monte Carlo (VMC) methods,\nespecially those approximated through deep neural networks, are promising in\nthis regard. In this paper, we aim to integrate one such model called the\nFermiNet, a post-Hartree-Fock (HF) Deep Neural Network (DNN) model, into a\nstandard and widely used open source library, DeepChem. We also propose novel\ninitialization techniques to overcome the difficulties associated with the\nassignment of excess or lack of electrons for ions.", "field": "Computer Science", "categories": "cs.LG,physics.chem-ph"}, {"arxiv_id": "2401.10288", "title": "CLAN: A Contrastive Learning based Novelty Detection Framework for Human\n  Activity Recognition", "abstract": "In ambient assisted living, human activity recognition from time series\nsensor data mainly focuses on predefined activities, often overlooking new\nactivity patterns. We propose CLAN, a two-tower contrastive learning-based\nnovelty detection framework with diverse types of negative pairs for human\nactivity recognition. It is tailored to challenges with human activity\ncharacteristics, including the significance of temporal and frequency features,\ncomplex activity dynamics, shared features across activities, and sensor\nmodality variations. The framework aims to construct invariant representations\nof known activity robust to the challenges. To generate suitable negative\npairs, it selects data augmentation methods according to the temporal and\nfrequency characteristics of each dataset. It derives the key representations\nagainst meaningless dynamics by contrastive and classification losses-based\nrepresentation learning and score function-based novelty detection that\naccommodate dynamic numbers of the different types of augmented samples. The\nproposed two-tower model extracts the representations in terms of time and\nfrequency, mutually enhancing expressiveness for distinguishing between new and\nknown activities, even when they share common features. Experiments on four\nreal-world human activity datasets show that CLAN surpasses the best\nperformance of existing novelty detection methods, improving by 8.3%, 13.7%,\nand 53.3% in AUROC, balanced accuracy, and FPR@TPR0.95 metrics respectively.", "field": "Computer Science", "categories": "cs.LG,eess.SP"}, {"arxiv_id": "2401.10289", "title": "Design and development of opto-neural processors for simulation of\n  neural networks trained in image detection for potential implementation in\n  hybrid robotics", "abstract": "Neural networks have been employed for a wide range of processing\napplications like image processing, motor control, object detection and many\nothers. Living neural networks offer advantages of lower power consumption,\nfaster processing, and biological realism. Optogenetics offers high spatial and\ntemporal control over biological neurons and presents potential in training\nlive neural networks. This work proposes a simulated living neural network\ntrained indirectly by backpropagating STDP based algorithms using precision\nactivation by optogenetics achieving accuracy comparable to traditional neural\nnetwork training algorithms.", "field": "Computer Science", "categories": "cs.ET,cs.AI,cs.LG,cs.NE"}, {"arxiv_id": "2401.1029", "title": "Early Prediction of Geomagnetic Storms by Machine Learning Algorithms", "abstract": "Geomagnetic storms (GS) occur when solar winds disrupt Earth's magnetosphere.\nGS can cause severe damages to satellites, power grids, and communication\ninfrastructures. Estimate of direct economic impacts of a large scale GS\nexceeds $40 billion a day in the US. Early prediction is critical in preventing\nand minimizing the hazards. However, current methods either predict several\nhours ahead but fail to identify all types of GS, or make predictions within\nshort time, e.g., one hour ahead of the occurrence. This work aims to predict\nall types of geomagnetic storms reliably and as early as possible using big\ndata and machine learning algorithms. By fusing big data collected from\nmultiple ground stations in the world on different aspects of solar\nmeasurements and using Random Forests regression with feature selection and\ndownsampling on minor geomagnetic storm instances (which carry majority of the\ndata), we are able to achieve an accuracy of 82.55% on data collected in 2021\nwhen making early predictions three hours in advance. Given that important\npredictive features such as historic Kp indices are measured every 3 hours and\ntheir importance decay quickly with the amount of time in advance, an early\nprediction of 3 hours ahead of time is believed to be close to the practical\nlimit.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.10294", "title": "Tight Group-Level DP Guarantees for DP-SGD with Sampling via Mixture of\n  Gaussians Mechanisms", "abstract": "We give a procedure for computing group-level $(\\epsilon, \\delta)$-DP\nguarantees for DP-SGD, when using Poisson sampling or fixed batch size\nsampling. Up to discretization errors in the implementation, the DP guarantees\ncomputed by this procedure are tight (assuming we release every intermediate\niterate).", "field": "Computer Science", "categories": "cs.CR,cs.LG"}, {"arxiv_id": "2401.10299", "title": "An attempt to generate new bridge types from latent space of generative\n  flow", "abstract": "Through examples of coordinate and probability transformation between\ndifferent distributions, the basic principle of normalizing flow is introduced\nin a simple and concise manner. From the perspective of the distribution of\nrandom variable function, the essence of probability transformation is\nexplained, and the scaling factor Jacobian determinant of probability\ntransformation is introduced. Treating the dataset as a sample from the\npopulation, obtaining normalizing flow is essentially through sampling surveys\nto statistically infer the numerical features of the population, and then the\nloss function is established by using the maximum likelihood estimation method.\nThis article introduces how normalizing flow cleverly solves the two major\napplication challenges of high-dimensional matrix determinant calculation and\nneural network reversible transformation. Using symmetric structured image\ndataset of three-span beam bridge, arch bridge, cable-stayed bridge and\nsuspension bridge, constructing and training normalizing flow based on the Glow\nAPI in the TensorFlow Probability library. The model can smoothly transform the\ncomplex distribution of the bridge dataset into a standard normal distribution,\nand from the obtained latent space sampling, it can generate new bridge types\nthat are different from the training dataset.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.CV"}, {"arxiv_id": "2401.103", "title": "A Hierarchical Framework with Spatio-Temporal Consistency Learning for\n  Emergence Detection in Complex Adaptive Systems", "abstract": "Emergence, a global property of complex adaptive systems (CASs) constituted\nby interactive agents, is prevalent in real-world dynamic systems, e.g.,\nnetwork-level traffic congestions. Detecting its formation and evaporation\nhelps to monitor the state of a system, allowing to issue a warning signal for\nharmful emergent phenomena. Since there is no centralized controller of CAS,\ndetecting emergence based on each agent's local observation is desirable but\nchallenging. Existing works are unable to capture emergence-related spatial\npatterns, and fail to model the nonlinear relationships among agents. This\npaper proposes a hierarchical framework with spatio-temporal consistency\nlearning to solve these two problems by learning the system representation and\nagent representations, respectively. Especially, spatio-temporal encoders are\ntailored to capture agents' nonlinear relationships and the system's complex\nevolution. Representations of the agents and the system are learned by\npreserving the intrinsic spatio-temporal consistency in a self-supervised\nmanner. Our method achieves more accurate detection than traditional methods\nand deep learning methods on three datasets with well-known yet hard-to-detect\nemergent behaviors. Notably, our hierarchical framework is generic, which can\nemploy other deep learning methods for agent-level and system-level detection.", "field": "Computer Science", "categories": "cs.MA,cs.AI,cs.LG"}, {"arxiv_id": "2401.10302", "title": "Hybrid Quantum Solvers in Production: how to succeed in the NISQ era?", "abstract": "Hybrid quantum computing is considered the present and the future within the\nfield of quantum computing. Far from being a passing fad, this trend cannot be\nconsidered just a stopgap to address the limitations of NISQ-era devices. The\nfoundations linking both computing paradigms will remain robust over time.\nDespite buoyant research activity, the challenges in hybrid computing are still\ncountless, ranging from the proper characterization of current solvers to the\nestablishment of appropriate methodologies for the design and fair evaluation\nof hybrid algorithms. The contribution of this work is twofold: first, we\ndescribe and categorize some of the most frequently used hybrid solvers,\nresorting to two different taxonomies recently published in the literature.\nSecondly, we put a special focus on two solvers that are currently deployed in\nreal production and that have demonstrated to be near the real industry. These\nsolvers are the LeapHybridBQMSampler contained in D-Wave's Hybrid Solver\nService and Quantagonia's Hybrid Solver. We analyze the performance of both\nhybrid methods using as benchmarks four well-known combinatorial optimization\nproblems: the Traveling Salesman Problem, Vehicle Routing Problem, Bin Packing\nProblem, and Maximum Cut Problem. Thanks to the contributions presented in this\npaper, the reader gains insight into the performance of those hybridization\nstrategies nowadays in production and close to the industrial markets.", "field": "Computer Science", "categories": "cs.ET,quant-ph"}, {"arxiv_id": "2401.10304", "title": "On the Readiness of Scientific Data for a Fair and Transparent Use in\n  Machine Learning", "abstract": "To ensure the fairness and trustworthiness of machine learning (ML) systems,\nrecent legislative initiatives and relevant research in the ML community have\npointed out the need to document the data used to train ML models. Besides,\ndata-sharing practices in many scientific domains have evolved in recent years\nfor reproducibility purposes. In this sense, the adoption of these practices by\nacademic institutions has encouraged researchers to publish their data and\ntechnical documentation in peer-reviewed publications such as data papers. In\nthis study, we analyze how this scientific data documentation meets the needs\nof the ML community and regulatory bodies for its use in ML technologies. We\nexamine a sample of 4041 data papers of different domains, assessing their\ncompleteness and coverage of the requested dimensions, and trends in recent\nyears, putting special emphasis on the most and least documented dimensions. As\na result, we propose a set of recommendation guidelines for data creators and\nscientific data publishers to increase their data's preparedness for its\ntransparent and fairer use in ML technologies.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.DL"}, {"arxiv_id": "2401.1031", "title": "Mathematical Algorithm Design for Deep Learning under Societal and\n  Judicial Constraints: The Algorithmic Transparency Requirement", "abstract": "Deep learning still has drawbacks in terms of trustworthiness, which\ndescribes a comprehensible, fair, safe, and reliable method. To mitigate the\npotential risk of AI, clear obligations associated to trustworthiness have been\nproposed via regulatory guidelines, e.g., in the European AI Act. Therefore, a\ncentral question is to what extent trustworthy deep learning can be realized.\nEstablishing the described properties constituting trustworthiness requires\nthat the factors influencing an algorithmic computation can be retraced, i.e.,\nthe algorithmic implementation is transparent. Motivated by the observation\nthat the current evolution of deep learning models necessitates a change in\ncomputing technology, we derive a mathematical framework which enables us to\nanalyze whether a transparent implementation in a computing model is feasible.\nWe exemplarily apply our trustworthiness framework to analyze deep learning\napproaches for inverse problems in digital and analog computing models\nrepresented by Turing and Blum-Shub-Smale Machines, respectively. Based on\nprevious results, we find that Blum-Shub-Smale Machines have the potential to\nestablish trustworthy solvers for inverse problems under fairly general\nconditions, whereas Turing machines cannot guarantee trustworthiness to the\nsame degree.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.CC"}, {"arxiv_id": "2401.10313", "title": "Hacking Predictors Means Hacking Cars: Using Sensitivity Analysis to\n  Identify Trajectory Prediction Vulnerabilities for Autonomous Driving\n  Security", "abstract": "Adversarial attacks on learning-based trajectory predictors have already been\ndemonstrated. However, there are still open questions about the effects of\nperturbations on trajectory predictor inputs other than state histories, and\nhow these attacks impact downstream planning and control. In this paper, we\nconduct a sensitivity analysis on two trajectory prediction models,\nTrajectron++ and AgentFormer. We observe that between all inputs, almost all of\nthe perturbation sensitivities for Trajectron++ lie only within the most recent\nstate history time point, while perturbation sensitivities for AgentFormer are\nspread across state histories over time. We additionally demonstrate that,\ndespite dominant sensitivity on state history perturbations, an undetectable\nimage map perturbation made with the Fast Gradient Sign Method can induce large\nprediction error increases in both models. Even though image maps may\ncontribute slightly to the prediction output of both models, this result\nreveals that rather than being robust to adversarial image perturbations,\ntrajectory predictors are susceptible to image attacks. Using an\noptimization-based planner and example perturbations crafted from sensitivity\nresults, we show how this vulnerability can cause a vehicle to come to a sudden\nstop from moderate driving speeds.", "field": "Computer Science", "categories": "cs.CR,cs.LG,cs.RO,cs.SY,eess.SY"}, {"arxiv_id": "2401.10314", "title": "LangProp: A code optimization framework using Language Models applied to\n  driving", "abstract": "LangProp is a framework for iteratively optimizing code generated by large\nlanguage models (LLMs) in a supervised/reinforcement learning setting. While\nLLMs can generate sensible solutions zero-shot, the solutions are often\nsub-optimal. Especially for code generation tasks, it is likely that the\ninitial code will fail on certain edge cases. LangProp automatically evaluates\nthe code performance on a dataset of input-output pairs, as well as catches any\nexceptions, and feeds the results back to the LLM in the training loop, so that\nthe LLM can iteratively improve the code it generates. By adopting a metric-\nand data-driven training paradigm for this code optimization procedure, one\ncould easily adapt findings from traditional machine learning techniques such\nas imitation learning, DAgger, and reinforcement learning. We demonstrate the\nfirst proof of concept of automated code optimization for autonomous driving in\nCARLA, showing that LangProp can generate interpretable and transparent driving\npolicies that can be verified and improved in a metric- and data-driven way.\nOur code will be open-sourced and is available at\nhttps://github.com/shuishida/LangProp.", "field": "Computer Science", "categories": "cs.SE,cs.AI,cs.LG,cs.RO"}, {"arxiv_id": "2401.10315", "title": "Joint Processing and Transmission Energy Optimization for ISAC in\n  Cell-Free Massive MIMO with URLLC", "abstract": "In this paper, we explore the concept of integrated sensing and communication\n(ISAC) within a downlink cell-free massive MIMO (multiple-input\nmultiple-output) system featuring multi-static sensing and users requiring\nultra-reliable low-latency communications (URLLC). Our focus involves the\nformulation of two non-convex algorithms that jointly solve power and\nblocklength allocation for end-to-end (E2E) minimization. The objectives are to\njointly minimize sensing/communication processing and transmission energy\nconsumption, while simultaneously meeting the requirements for sensing and\nURLLC. To address the inherent non-convexity of these optimization problems, we\nutilize techniques such as the Feasible Point Pursuit - Successive Convex\nApproximation (FPP-SCA), Concave-Convex Programming (CCP), and fractional\nprogramming. We conduct a comparative analysis of the performance of these\nalgorithms in ISAC scenarios and against a URLLC-only scenario where sensing is\nnot integrated. Our numerical results highlight the superior performance of the\nE2E energy minimization algorithm, especially in scenarios without sensing\ncapability. Additionally, our study underscores the increasing prominence of\nenergy consumption associated with sensing processing tasks as the number of\nsensing receive access points rises. Furthermore, the results emphasize that a\nhigher sensing signal-to-interference-plus-noise ratio threshold is associated\nwith an escalation in E2E energy consumption, thereby narrowing the performance\ngap between the two proposed algorithms.", "field": "Computer Science", "categories": "cs.IT,eess.SP,math.IT"}, {"arxiv_id": "2401.10316", "title": "Improving One-class Recommendation with Multi-tasking on Various\n  Preference Intensities", "abstract": "In the one-class recommendation problem, it's required to make\nrecommendations basing on users' implicit feedback, which is inferred from\ntheir action and inaction. Existing works obtain representations of users and\nitems by encoding positive and negative interactions observed from training\ndata. However, these efforts assume that all positive signals from implicit\nfeedback reflect a fixed preference intensity, which is not realistic.\nConsequently, representations learned with these methods usually fail to\ncapture informative entity features that reflect various preference\nintensities.\n  In this paper, we propose a multi-tasking framework taking various preference\nintensities of each signal from implicit feedback into consideration.\nRepresentations of entities are required to satisfy the objective of each\nsubtask simultaneously, making them more robust and generalizable. Furthermore,\nwe incorporate attentive graph convolutional layers to explore high-order\nrelationships in the user-item bipartite graph and dynamically capture the\nlatent tendencies of users toward the items they interact with. Experimental\nresults show that our method performs better than state-of-the-art methods by a\nlarge margin on three large-scale real-world benchmark datasets.", "field": "Computer Science", "categories": "cs.IR,cs.AI,cs.LG"}, {"arxiv_id": "2401.10337", "title": "Noise Contrastive Estimation-based Matching Framework for Low-resource\n  Security Attack Pattern Recognition", "abstract": "Tactics, Techniques and Procedures (TTPs) represent sophisticated attack\npatterns in the cybersecurity domain, described encyclopedically in textual\nknowledge bases. Identifying TTPs in cybersecurity writing, often called TTP\nmapping, is an important and challenging task. Conventional learning approaches\noften target the problem in the classical multi-class or multilabel\nclassification setting. This setting hinders the learning ability of the model\ndue to a large number of classes (i.e., TTPs), the inevitable skewness of the\nlabel distribution and the complex hierarchical structure of the label space.\nWe formulate the problem in a different learning paradigm, where the assignment\nof a text to a TTP label is decided by the direct semantic similarity between\nthe two, thus reducing the complexity of competing solely over the large\nlabeling space. To that end, we propose a neural matching architecture with an\neffective sampling-based learn-to-compare mechanism, facilitating the learning\nprocess of the matching model despite constrained resources.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.CL,cs.CR"}, {"arxiv_id": "2401.10338", "title": "MELODY: Robust Semi-Supervised Hybrid Model for Entity-Level Online\n  Anomaly Detection with Multivariate Time Series", "abstract": "In large IT systems, software deployment is a crucial process in online\nservices as their code is regularly updated. However, a faulty code change may\ndegrade the target service's performance and cause cascading outages in\ndownstream services. Thus, software deployments should be comprehensively\nmonitored, and their anomalies should be detected timely. In this paper, we\nstudy the problem of anomaly detection for deployments. We begin by identifying\nthe challenges unique to this anomaly detection problem, which is at\nentity-level (e.g., deployments), relative to the more typical problem of\nanomaly detection in multivariate time series (MTS). The unique challenges\ninclude the heterogeneity of deployments, the low latency tolerance, the\nambiguous anomaly definition, and the limited supervision. To address them, we\npropose a novel framework, semi-supervised hybrid Model for Entity-Level Online\nDetection of anomalY (MELODY). MELODY first transforms the MTS of different\nentities to the same feature space by an online feature extractor, then uses a\nnewly proposed semi-supervised deep one-class model for detecting anomalous\nentities. We evaluated MELODY on real data of cloud services with 1.2M+ time\nseries. The relative F1 score improvement of MELODY over the state-of-the-art\nmethods ranges from 7.6% to 56.5%. The user evaluation suggests MELODY is\nsuitable for monitoring deployments in large online systems.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.10341", "title": "ELRT: Efficient Low-Rank Training for Compact Convolutional Neural\n  Networks", "abstract": "Low-rank compression, a popular model compression technique that produces\ncompact convolutional neural networks (CNNs) with low rankness, has been\nwell-studied in the literature. On the other hand, low-rank training, as an\nalternative way to train low-rank CNNs from scratch, has been exploited little\nyet. Unlike low-rank compression, low-rank training does not need pre-trained\nfull-rank models, and the entire training phase is always performed on the\nlow-rank structure, bringing attractive benefits for practical applications.\nHowever, the existing low-rank training solutions still face several\nchallenges, such as a considerable accuracy drop and/or still needing to update\nfull-size models during the training. In this paper, we perform a systematic\ninvestigation on low-rank CNN training. By identifying the proper low-rank\nformat and performance-improving strategy, we propose ELRT, an efficient\nlow-rank training solution for high-accuracy, high-compactness, low-rank CNN\nmodels. Our extensive evaluation results for training various CNNs on different\ndatasets demonstrate the effectiveness of ELRT.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.10352", "title": "Bridging Cultural Nuances in Dialogue Agents through Cultural Value\n  Surveys", "abstract": "The cultural landscape of interactions with dialogue agents is a compelling\nyet relatively unexplored territory. It's clear that various sociocultural\naspects -- from communication styles and beliefs to shared metaphors and\nknowledge -- profoundly impact these interactions. To delve deeper into this\ndynamic, we introduce cuDialog, a first-of-its-kind benchmark for dialogue\ngeneration with a cultural lens. We also develop baseline models capable of\nextracting cultural attributes from dialogue exchanges, with the goal of\nenhancing the predictive accuracy and quality of dialogue agents. To\neffectively co-learn cultural understanding and multi-turn dialogue\npredictions, we propose to incorporate cultural dimensions with dialogue\nencoding features. Our experimental findings highlight that incorporating\ncultural value surveys boosts alignment with references and cultural markers,\ndemonstrating its considerable influence on personalization and dialogue\nquality. To facilitate further exploration in this exciting domain, we publish\nour benchmark publicly accessible at https://github.com/yongcaoplus/cuDialog.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.10353", "title": "Inconsistent dialogue responses and how to recover from them", "abstract": "One critical issue for chat systems is to stay consistent about preferences,\nopinions, beliefs and facts of itself, which has been shown a difficult\nproblem. In this work, we study methods to assess and bolster utterance\nconsistency of chat systems. A dataset is first developed for studying the\ninconsistencies, where inconsistent dialogue responses, explanations of the\ninconsistencies, and recovery utterances are authored by annotators. This\ncovers the life span of inconsistencies, namely introduction, understanding,\nand resolution. Building on this, we introduce a set of tasks centered on\ndialogue consistency, specifically focused on its detection and resolution. Our\nexperimental findings indicate that our dataset significantly helps the\nprogress in identifying and resolving conversational inconsistencies, and\ncurrent popular large language models like ChatGPT which are good at resolving\ninconsistencies however still struggle with detection.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.10354", "title": "Towards providing reliable job completion time predictions using PCS", "abstract": "In this paper we build a case for providing job completion time predictions\nto cloud users, similar to the delivery date of a package or arrival time of a\nbooked ride. Our analysis reveals that providing predictability can come at the\nexpense of performance and fairness. Existing cloud scheduling systems optimize\nfor extreme points in the trade-off space, making them either extremely\nunpredictable or impractical.\n  To address this challenge, we present PCS, a new scheduling framework that\naims to provide predictability while balancing other traditional objectives.\nThe key idea behind PCS is to use Weighted-Fair-Queueing (WFQ) and find a\nsuitable configuration of different WFQ parameters (e.g., class weights) that\nmeets specific goals for predictability. It uses a simulation-aided search\nstrategy, to efficiently discover WFQ configurations that lie on the Pareto\nfront of the trade-off space between these objectives. We implement and\nevaluate PCS in the context of DNN job scheduling on GPUs. Our evaluation, on a\nsmall scale GPU testbed and larger-scale simulations, shows that PCS can\nprovide accurate completion time estimates while marginally compromising on\nperformance and fairness.", "field": "Computer Science", "categories": "cs.DC,cs.LG"}, {"arxiv_id": "2401.10357", "title": "Measuring User Interface Accessibility for Color Blind Users", "abstract": "Color vision deficiency (CVD, color blindness) is the failure or decreased\nability to distinguish between colors under normal lighting conditions. There\nare over 300 million people worldwide with CVD, including approx. 1 in 12 men\n(8%) and 1 in 250 women (0.5%). CVD can limit a user's ability to interact with\nwebsites and software packages that are otherwise basic commodities. User\ninterface designers have taken various approaches to tackle the issue with some\ninterfaces offering a high contrast mode, and others integrating color-blind\nawareness into their website design process. The Web Content Accessibility\nGuidelines (WCAG) outline some best practices for maintaining accessibility\nthat have been adopted and recommended by several governments; however, it is\ncurrently uncertain how this impacts perceived user functionality and if this\ncould result in a reduced aesthetic look. In our work, we present a subjective\nuser study to measure the loss of functionality and aesthetics as potentially\nseen by CVD observers for 20 popular websites and software packages. As\nrecruiting participants with CVD is non-trivial, we developed a\nsimulation-based pipeline instead for our full-reference mean opinion score\nexperiment, which as far as we know is a novelty in the field. Our results show\nthat relative aesthetics and functionality correlate positively and that an\noperating-system-wide high contrast mode can reduce both aesthetics and\nfunctionality for CVD users. Finally, we propose a AAA--A classification of the\ninterfaces we analyzed.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.10359", "title": "Keeping Deep Learning Models in Check: A History-Based Approach to\n  Mitigate Overfitting", "abstract": "In software engineering, deep learning models are increasingly deployed for\ncritical tasks such as bug detection and code review. However, overfitting\nremains a challenge that affects the quality, reliability, and trustworthiness\nof software systems that utilize deep learning models. Overfitting can be (1)\nprevented (e.g., using dropout or early stopping) or (2) detected in a trained\nmodel (e.g., using correlation-based approaches). Both overfitting detection\nand prevention approaches that are currently used have constraints (e.g.,\nrequiring modification of the model structure, and high computing resources).\nIn this paper, we propose a simple, yet powerful approach that can both detect\nand prevent overfitting based on the training history (i.e., validation\nlosses). Our approach first trains a time series classifier on training\nhistories of overfit models. This classifier is then used to detect if a\ntrained model is overfit. In addition, our trained classifier can be used to\nprevent overfitting by identifying the optimal point to stop a model's\ntraining. We evaluate our approach on its ability to identify and prevent\noverfitting in real-world samples. We compare our approach against\ncorrelation-based detection approaches and the most commonly used prevention\napproach (i.e., early stopping). Our approach achieves an F1 score of 0.91\nwhich is at least 5% higher than the current best-performing non-intrusive\noverfitting detection approach. Furthermore, our approach can stop training to\navoid overfitting at least 32% of the times earlier than early stopping and has\nthe same or a better rate of returning the best model.", "field": "Computer Science", "categories": "cs.SE,cs.AI"}, {"arxiv_id": "2401.1036", "title": "Excuse me, sir? Your language model is leaking (information)", "abstract": "We introduce a cryptographic method to hide an arbitrary secret payload in\nthe response of a Large Language Model (LLM). A secret key is required to\nextract the payload from the model's response, and without the key it is\nprovably impossible to distinguish between the responses of the original LLM\nand the LLM that hides a payload. In particular, the quality of generated text\nis not affected by the payload. Our approach extends a recent result of Christ,\nGunn and Zamir (2023) who introduced an undetectable watermarking scheme for\nLLMs.", "field": "Computer Science", "categories": "cs.CR,cs.LG"}, {"arxiv_id": "2401.10361", "title": "Hierarchical Federated Learning in Multi-hop Cluster-Based VANETs", "abstract": "The usage of federated learning (FL) in Vehicular Ad hoc Networks (VANET) has\ngarnered significant interest in research due to the advantages of reducing\ntransmission overhead and protecting user privacy by communicating local\ndataset gradients instead of raw data. However, implementing FL in VANETs faces\nchallenges, including limited communication resources, high vehicle mobility,\nand the statistical diversity of data distributions. In order to tackle these\nissues, this paper introduces a novel framework for hierarchical federated\nlearning (HFL) over multi-hop clustering-based VANET. The proposed method\nutilizes a weighted combination of the average relative speed and cosine\nsimilarity of FL model parameters as a clustering metric to consider both data\ndiversity and high vehicle mobility. This metric ensures convergence with\nminimum changes in cluster heads while tackling the complexities associated\nwith non-independent and identically distributed (non-IID) data scenarios.\nAdditionally, the framework includes a novel mechanism to manage seamless\ntransitions of cluster heads (CHs), followed by transferring the most recent FL\nmodel parameter to the designated CH. Furthermore, the proposed approach\nconsiders the option of merging CHs, aiming to reduce their count and,\nconsequently, mitigate associated overhead. Through extensive simulations, the\nproposed hierarchical federated learning over clustered VANET has been\ndemonstrated to improve accuracy and convergence time significantly while\nmaintaining an acceptable level of packet overhead compared to previously\nproposed clustering algorithms and non-clustered VANET.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.DC,cs.NI,cs.SY,eess.SY"}, {"arxiv_id": "2401.10363", "title": "Verification and Enforcement of Strong State-Based Opacity for\n  Discrete-Event Systems", "abstract": "In this paper, we investigate the verification and enforcement of strong\nstate-based opacity (SBO) in discrete-event systems modeled as\npartially-observed (nondeterministic) finite-state automata, including strong\nK-step opacity (K-SSO), strong current-state opacity (SCSO), strong\ninitial-state opacity (SISO), and strong infinite-step opacity (Inf-SSO). They\nare stronger versions of four widely-studied standard opacity notions,\nrespectively. We firstly propose a new notion of K-SSO, and then we construct a\nconcurrent-composition structure that is a variant of our previously-proposed\none to verify it. Based on this structure, a verification algorithm for the\nproposed notion of K-SSO is designed. Also, an upper bound on K in the proposed\nK-SSO is derived. Secondly, we propose a distinctive opacity-enforcement\nmechanism that has better scalability than the existing ones (such as\nsupervisory control). The basic philosophy of this new mechanism is choosing a\nsubset of controllable transitions to disable before an original system starts\nto run in order to cut off all its runs that violate a notion of strong SBO of\ninterest. Accordingly, the algorithms for enforcing the above-mentioned four\nnotions of strong SBO are designed using the proposed two\nconcurrent-composition structures. In particular, the designed algorithm for\nenforcing Inf-SSO has lower time complexity than the existing one in the\nliterature, and does not depend on any assumption. Finally, we illustrate the\napplications of the designed algorithms using examples.", "field": "Computer Science", "categories": "cs.FL"}, {"arxiv_id": "2401.10364", "title": "Using LLM such as ChatGPT for Designing and Implementing a RISC\n  Processor: Execution,Challenges and Limitations", "abstract": "This paper discusses the feasibility of using Large Language Models LLM for\ncode generation with a particular application in designing an RISC. The paper\nalso reviews the associated steps such as parsing, tokenization, encoding,\nattention mechanism, sampling the tokens and iterations during code generation.\nThe generated code for the RISC components is verified through testbenches and\nhardware implementation on a FPGA board. Four metric parameters Correct output\non the first iteration, Number of errors embedded in the code, Number of trials\nrequired to achieve the code and Failure to generate the code after three\niterations, are used to compare the efficiency of using LLM in programming. In\nall the cases, the generated code had significant errors and human intervention\nwas always required to fix the bugs. LLM can therefore be used to complement a\nprogrammer code design.", "field": "Computer Science", "categories": "cs.LG,cs.AR,cs.SE"}, {"arxiv_id": "2401.10367", "title": "gFaaS: Enabling Generic Functions in Serverless Computing", "abstract": "With the advent of AWS Lambda in 2014, Serverless Computing, particularly\nFunction-as-a-Service (FaaS), has witnessed growing popularity across various\napplication domains. FaaS enables an application to be decomposed into\nfine-grained functions that are executed on a FaaS platform. It offers several\nadvantages such as no infrastructure management, a pay-per-use billing policy,\nand on-demand fine-grained autoscaling. However, despite its advantages,\ndevelopers today encounter various challenges while adopting FaaS solutions\nthat reduce productivity. These include FaaS platform lock-in, support for\ndiverse function deployment parameters, and diverse interfaces for interacting\nwith FaaS platforms. To address these challenges, we present gFaaS, a novel\nframework that facilitates the holistic development and management of functions\nacross diverse FaaS platforms. Our framework enables the development of generic\nfunctions in multiple programming languages that can be seamlessly deployed\nacross different platforms without modifications. Results from our experiments\ndemonstrate that gFaaS functions perform similarly to native platform-specific\nfunctions across various scenarios. A video demonstrating the functioning of\ngFaaS is available from https://youtu.be/STbb6ykJFf0.", "field": "Computer Science", "categories": "cs.SE,cs.DC"}, {"arxiv_id": "2401.10368", "title": "HRL-TSCH: A Hierarchical Reinforcement Learning-based TSCH Scheduler for\n  IIoT", "abstract": "The Industrial Internet of Things (IIoT) demands adaptable Networked Embedded\nSystems (NES) for optimal performance. Combined with recent advances in\nArtificial Intelligence (AI), tailored solutions can be developed to meet\nspecific application requirements. This study introduces HRL-TSCH, an approach\nrooted in Hierarchical Reinforcement Learning (HRL), to devise Time Slotted\nChannel Hopping (TSCH) schedules provisioning IIoT demand. HRL-TSCH employs\ndual policies: one at a higher level for TSCH schedule link management, and\nanother at a lower level for timeslot and channel assignments. The proposed RL\nagents address a multi-objective problem, optimizing throughput, power\nefficiency, and network delay based on predefined application requirements.\nSimulation experiments demonstrate HRL-TSCH superiority over existing\nstate-of-art approaches, effectively achieving an optimal balance between\nthroughput, power consumption, and delay, thereby enhancing IIoT network\nperformance.", "field": "Computer Science", "categories": "cs.NI"}, {"arxiv_id": "2401.10369", "title": "Motorway: Seamless high speed BFT", "abstract": "Today's practical, high performance Byzantine Fault Tolerant (BFT) consensus\nprotocols operate in the partial synchrony model. However, existing protocols\nare often inefficient when networks are indeed partially synchronous. They\nobtain either low latency during synchrony or robust recovery from periods of\nasynchrony. At one end, traditional, view-based BFT protocols optimize for\nlatency in the sunny-network case, but when faced with periods of asynchrony\nare subject to performance degradations (hangovers) that can last beyond the\nreturn to synchrony. At the other end, modern DAG-based BFT protocols recover\ngracefully from asynchrony, but exhibit lackluster latency during synchronous\nintervals. To close the gap, this work presents Motorway, a novel\nhigh-throughput BFT protocol that offers both low latency and seamless recovery\nfrom periods of asynchrony. Motorway combines a highly parallel asynchronous\ndata dissemination layer with a low-latency, partially synchronous consensus\nmechanism to construct an efficient consensus protocol for partial synchrony.\nMotorway (i) avoids the hangovers incurred by traditional BFT protocols and\n(ii) matches the throughput of state of the art DAG-BFT protocols while\nreducing latency by 2.1x, matching the latency of traditional BFT protocols.", "field": "Computer Science", "categories": "cs.DC"}, {"arxiv_id": "2401.10371", "title": "Langevin Unlearning: A New Perspective of Noisy Gradient Descent for\n  Machine Unlearning", "abstract": "Machine unlearning has raised significant interest with the adoption of laws\nensuring the ``right to be forgotten''. Researchers have provided a\nprobabilistic notion of approximate unlearning under a similar definition of\nDifferential Privacy (DP), where privacy is defined as statistical\nindistinguishability to retraining from scratch. We propose Langevin\nunlearning, an unlearning framework based on noisy gradient descent with\nprivacy guarantees for approximate unlearning problems. Langevin unlearning\nunifies the DP learning process and the privacy-certified unlearning process\nwith many algorithmic benefits. These include approximate certified unlearning\nfor non-convex problems, complexity saving compared to retraining, sequential\nand batch unlearning for multiple unlearning requests. We verify the\npracticality of Langevin unlearning by studying its privacy-utility-complexity\ntrade-off via experiments on benchmark datasets, and also demonstrate its\nsuperiority against gradient-decent-plus-output-perturbation based approximate\nunlearning.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.10372", "title": "MutaBot: A Mutation Testing Approach for Chatbots", "abstract": "Mutation testing is a technique aimed at assessing the effectiveness of test\nsuites by seeding artificial faults into programs. Although available for many\nplatforms and languages, no mutation testing tool is currently available for\nconversational chatbots, which represent an increasingly popular solution to\ndesign systems that can interact with users through a natural language\ninterface. Note that since conversations must be explicitly engineered by the\ndevelopers of conversational chatbots, these systems are exposed to specific\ntypes of faults not supported by existing mutation testing tools.\n  In this paper, we present MutaBot, a mutation testing tool for conversational\nchatbots. MutaBot addresses mutations at multiple levels, including\nconversational flows, intents, and contexts. We designed the tool to\npotentially target multiple platforms, while we implemented initial support for\nGoogle Dialogflow chatbots. We assessed the tool with three Dialogflow chatbots\nand test cases generated with Botium, revealing weaknesses in the test suites.", "field": "Computer Science", "categories": "cs.SE,cs.AI"}, {"arxiv_id": "2401.10375", "title": "Vulnerabilities of Foundation Model Integrated Federated Learning Under\n  Adversarial Threats", "abstract": "Federated Learning (FL) addresses critical issues in machine learning related\nto data privacy and security, yet suffering from data insufficiency and\nimbalance under certain circumstances. The emergence of foundation models (FMs)\noffers potential solutions to the limitations of existing FL frameworks, e.g.,\nby generating synthetic data for model initialization. However, due to the\ninherent safety concerns of FMs, integrating FMs into FL could introduce new\nrisks, which remains largely unexplored. To address this gap, we conduct the\nfirst investigation on the vulnerability of FM integrated FL (FM-FL) under\nadversarial threats. Based on a unified framework of FM-FL, we introduce a\nnovel attack strategy that exploits safety issues of FM to compromise FL client\nmodels. Through extensive experiments with well-known models and benchmark\ndatasets in both image and text domains, we reveal the high susceptibility of\nthe FM-FL to this new threat under various FL configurations. Furthermore, we\nfind that existing FL defense strategies offer limited protection against this\nnovel attack approach. This research highlights the critical need for enhanced\nsecurity measures in FL in the era of FMs.", "field": "Computer Science", "categories": "cs.CR,cs.DC,cs.LG"}, {"arxiv_id": "2401.10376", "title": "PAC Code Rate-Profile Design Using Search-Constrained Optimization\n  Algorithms", "abstract": "In this paper, we introduce a novel rate-profile design based on\nsearch-constrained optimization techniques to assess the performance of\npolarization-adjusted convolutional (PAC) codes under Fano (sequential)\ndecoding. The results demonstrate that the resulting PAC code offers much\nreduced computational complexity compared to a construction based on a\nconventional genetic algorithm without a performance loss in error-correction\nperformance. As the fitness function of our algorithm, we propose an adaptive\nsuccessive cancellation list decoding algorithm to determine the weight\ndistribution of the rate profiles. The simulation results indicate that, for a\nPAC(256, 128) code, only 8% of the population requires that their fitness\nfunction be evaluated with a large list size. This represents an improvement of\nalmost 92% over a conventional evolutionary algorithm. For a PAC(64, 32) code,\nthis improvement is about 99%. We also plotted the performance of the high-rate\nPAC(128, 105) and PAC(64, 51) codes, and the results show that they exhibit\nsuperior performance compared to other algorithms.", "field": "Computer Science", "categories": "cs.IT,math.IT"}, {"arxiv_id": "2401.10379", "title": "Agricultural Object Detection with You Look Only Once (YOLO) Algorithm:\n  A Bibliometric and Systematic Literature Review", "abstract": "Vision is a major component in several digital technologies and tools used in\nagriculture. The object detector, You Look Only Once (YOLO), has gained\npopularity in agriculture in a relatively short span due to its\nstate-of-the-art performance. YOLO offers real-time detection with good\naccuracy and is implemented in various agricultural tasks, including\nmonitoring, surveillance, sensing, automation, and robotics. The research and\napplication of YOLO in agriculture are accelerating rapidly but are fragmented\nand multidisciplinary. Moreover, the performance characteristics (i.e.,\naccuracy, speed, computation) of the object detector influence the rate of\ntechnology implementation and adoption in agriculture. Thus, the study aims to\ncollect extensive literature to document and critically evaluate the advances\nand application of YOLO for agricultural object recognition. First, we\nconducted a bibliometric review of 257 articles to understand the scholarly\nlandscape of YOLO in agricultural domain. Secondly, we conducted a systematic\nreview of 30 articles to identify current knowledge, gaps, and modifications in\nYOLO for specific agricultural tasks. The study critically assesses and\nsummarizes the information on YOLO's end-to-end learning approach, including\ndata acquisition, processing, network modification, integration, and\ndeployment. We also discussed task-specific YOLO algorithm modification and\nintegration to meet the agricultural object or environment-specific challenges.\nIn general, YOLO-integrated digital tools and technologies show the potential\nfor real-time, automated monitoring, surveillance, and object handling to\nreduce labor, production cost, and environmental impact while maximizing\nresource efficiency. The study provides detailed documentation and\nsignificantly advances the existing knowledge on applying YOLO in agriculture,\nwhich can greatly benefit the scientific community.", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.RO"}, {"arxiv_id": "2401.10382", "title": "Node Placement and Path Planning for Improved Area Coverage in Mixed\n  Wireless Sensor Networks", "abstract": "For the large-scale monitoring of a physical phenomena using a wireless\nsensor network (WSN), a large number of static and/or mobile sensor nodes are\nrequired, resulting in higher deployment cost. In this work, we develop an\nefficient algorithm that can employ a small number of static nodes together\nwith a set of mobile nodes for improved area coverage. An efficient deployment\nof static nodes and guided mobility of the mobile nodes is critical for\nmaximizing the area coverage. To this end, we propose three mixed integer\nlinear programming (MILP) formulations. The first formulation efficiently\ndeploys a set of static nodes and the other two formulations plan the path of a\nset of mobile nodes so as to maximize the area coverage and minimize the total\nnumber of movements required to achieve the desired coverage. We present\nextensive performance evaluation of the proposed algorithms and its comparison\nwith benchmark approaches. The simulation results demonstrate the superior\nperformance of the proposed algorithms for different network sizes and number\nof static and mobile nodes.", "field": "Computer Science", "categories": "cs.NI"}, {"arxiv_id": "2401.10383", "title": "Cooperative Multi-Agent Graph Bandits: UCB Algorithm and Regret Analysis", "abstract": "In this paper, we formulate the multi-agent graph bandit problem as a\nmulti-agent extension of the graph bandit problem introduced by Zhang,\nJohansson, and Li [CISS 57, 1-6 (2023)]. In our formulation, $N$ cooperative\nagents travel on a connected graph $G$ with $K$ nodes. Upon arrival at each\nnode, agents observe a random reward drawn from a node-dependent probability\ndistribution. The reward of the system is modeled as a weighted sum of the\nrewards the agents observe, where the weights capture the decreasing marginal\nreward associated with multiple agents sampling the same node at the same time.\nWe propose an Upper Confidence Bound (UCB)-based learning algorithm,\nMulti-G-UCB, and prove that its expected regret over $T$ steps is bounded by\n$O(N\\log(T)[\\sqrt{KT} + DK])$, where $D$ is the diameter of graph $G$. Lastly,\nwe numerically test our algorithm by comparing it to alternative methods.", "field": "Computer Science", "categories": "cs.LG,cs.MA,stat.ML"}, {"arxiv_id": "2401.10385", "title": "Approximation of Solution Operators for High-dimensional PDEs", "abstract": "We propose a finite-dimensional control-based method to approximate solution\noperators for evolutional partial differential equations (PDEs), particularly\nin high-dimensions. By employing a general reduced-order model, such as a deep\nneural network, we connect the evolution of the model parameters with\ntrajectories in a corresponding function space. Using the computational\ntechnique of neural ordinary differential equation, we learn the control over\nthe parameter space such that from any initial starting point, the controlled\ntrajectories closely approximate the solutions to the PDE. Approximation\naccuracy is justified for a general class of second-order nonlinear PDEs.\nNumerical results are presented for several high-dimensional PDEs, including\nreal-world applications to solving Hamilton-Jacobi-Bellman equations. These are\ndemonstrated to show the accuracy and efficiency of the proposed method.", "field": "Computer Science", "categories": "math.NA,cs.LG,cs.NA,math.OC,65M99, 49M05"}, {"arxiv_id": "2401.10386", "title": "Noninvasive Acute Compartment Syndrome Diagnosis Using Random Forest\n  Machine Learning", "abstract": "Acute compartment syndrome (ACS) is an orthopedic emergency, caused by\nelevated pressure within a muscle compartment, that leads to permanent tissue\ndamage and eventually death. Diagnosis of ACS relies heavily on\npatient-reported symptoms, a method that is clinically unreliable and often\nsupplemented with invasive intracompartmental pressure measurements. This study\nproposes a continuous, objective, noninvasive diagnostic for ACS. The device\ndetects ACS through a random forest machine learning model that uses pressure\nreadings from force-sensitive resistors (FSRs) placed on the skin. The final\ndiagnosis is exported real-time to a web application via Bluetooth. To validate\nthe diagnostic, a data set containing FSR measurements and the corresponding\nsimulated intracompartmental pressure was created. The diagnostic achieved an\naccuracy, on par to the invasive gold standard, of 97%. The device excelled in\nkey performance metrics including precision, sensitivity, and F1 score.\nManufactured for 73 USD, our device may be an economic alternative to\nneedle-based diagnostics. These results demonstrate the potential of\nnoninvasive ACS diagnostics to meet clinical standards and enhance patient\ncare.", "field": "Computer Science", "categories": "cs.LG,eess.SP,physics.med-ph"}, {"arxiv_id": "2401.10387", "title": "Bypassing a Reactive Jammer via NOMA-Based Transmissions in Critical\n  Missions", "abstract": "Wireless networks can be vulnerable to radio jamming attacks. The quality of\nservice under a jamming attack is not guaranteed and the service requirements\nsuch as reliability, latency, and effective rate, specifically in\nmission-critical military applications, can be deeply affected by the jammer's\nactions. This paper analyzes the effect of a reactive jammer. Particularly,\nreliability, average transmission delay, and the effective sum rate (ESR) for a\nNOMA-based scheme with finite blocklength transmissions are mathematically\nderived taking the detection probability of the jammer into account.\nFurthermore, the effect of UEs' allocated power and blocklength on the network\nmetrics is explored. Contrary to the existing literature, results show that gNB\ncan mitigate the impact of reactive jamming by decreasing transmit power,\nmaking the transmissions covert at the jammer side. Finally, an optimization\nproblem is formulated to maximize the ESR under reliability, delay, and\ntransmit power constraints. It is shown that by adjusting the allocated\ntransmit power to UEs by gNB, the gNB can bypass the jammer effect to fulfill\nthe 0.99999 reliability and the latency of 5ms without the need for packet\nre-transmission.", "field": "Computer Science", "categories": "cs.CR,cs.NI"}, {"arxiv_id": "2401.1039", "title": "On the Interplay Between Network Metrics and Performance of Mobile Edge\n  Offloading", "abstract": "Multi-Access Edge Computing (MEC) emerged as a viable computing allocation\nmethod that facilitates offloading tasks to edge servers for efficient\nprocessing. The integration of MEC with 5G, referred to as 5G-MEC, provides\nreal-time processing and data-driven decision-making in close proximity to the\nuser. The 5G-MEC has gained significant recognition in task offloading as an\nessential tool for applications that require low delay. Nevertheless, few\nstudies consider the dropped task ratio metric. Disregarding this metric might\npossibly undermine system efficiency. In this paper, the dropped task ratio and\ndelay has been minimized in a realistic 5G-MEC task offloading scenario\nimplemented in NS3. We utilize Mixed Integer Linear Programming (MILP) and\nGenetic Algorithm (GA) to optimize delay and dropped task ratio. We examined\nthe effect of the number of tasks and users on the dropped task ratio and\ndelay. Compared to two traditional offloading schemes, First Come First Serve\n(FCFS) and Shortest Task First (STF), our proposed method effectively works in\n5G-MEC task offloading scenario. For MILP, the dropped task ratio and delay has\nbeen minimized by 20% and 2ms compared to GA.", "field": "Computer Science", "categories": "cs.NI,eess.SP"}, {"arxiv_id": "2401.10393", "title": "Catastrophic Interference is Mitigated in Naturalistic Power-Law\n  Learning Environments", "abstract": "Neural networks often suffer from catastrophic interference (CI): performance\non previously learned tasks drops off significantly when learning a new task.\nThis contrasts strongly with humans, who can sequentially learn new tasks\nwithout appreciably forgetting previous tasks. Prior work has explored various\ntechniques for mitigating CI such as regularization, rehearsal, generative\nreplay, and distillation methods. The current work takes a different approach,\none guided by cognitive science research showing that in naturalistic\nenvironments, the probability of encountering a task decreases as a power-law\nof the time since it was last performed. We argue that a realistic evaluation\nof techniques for the mitigation of CI should be performed in simulated\nnaturalistic learning environments. Thus, we evaluate the extent of mitigation\nof CI when training simple rehearsal-based methods in power-law environments\nsimilar to the ones humans face. Our work explores this novel rehearsal-based\napproach for a domain-incremental task: learning permutations in the MNIST\ntask. We compare our rehearsal environment with other baselines to show its\nefficacy in promoting continual learning. Additionally, we investigate whether\nthis environment shows forward facilitation, i.e., faster learning of later\ntasks. Next, we explore the robustness of our learning environment to the\nnumber of tasks, model size, and amount of data rehearsed after each task.\nNotably, our results show that the performance is comparable or superior to\nthat of models trained using popular regularization methods and also to\nrehearsals in non-power-law environments. The benefits of this training\nparadigm include simplicity and the lack of a need for extra neural circuitry.\nIn addition, because our method is orthogonal to other methods, future research\ncan combine training in power-law environments with other continual learning\nmechanisms.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.10394", "title": "Distribution Consistency based Self-Training for Graph Neural Networks\n  with Sparse Labels", "abstract": "Few-shot node classification poses a significant challenge for Graph Neural\nNetworks (GNNs) due to insufficient supervision and potential distribution\nshifts between labeled and unlabeled nodes. Self-training has emerged as a\nwidely popular framework to leverage the abundance of unlabeled data, which\nexpands the training set by assigning pseudo-labels to selected unlabeled\nnodes. Efforts have been made to develop various selection strategies based on\nconfidence, information gain, etc. However, none of these methods takes into\naccount the distribution shift between the training and testing node sets. The\npseudo-labeling step may amplify this shift and even introduce new ones,\nhindering the effectiveness of self-training. Therefore, in this work, we\nexplore the potential of explicitly bridging the distribution shift between the\nexpanded training set and test set during self-training. To this end, we\npropose a novel Distribution-Consistent Graph Self-Training (DC-GST) framework\nto identify pseudo-labeled nodes that are both informative and capable of\nredeeming the distribution discrepancy and formulate it as a differentiable\noptimization task. A distribution-shift-aware edge predictor is further adopted\nto augment the graph and increase the model's generalizability in assigning\npseudo labels. We evaluate our proposed method on four publicly available\nbenchmark datasets and extensive experiments demonstrate that our framework\nconsistently outperforms state-of-the-art baselines.", "field": "Computer Science", "categories": "cs.LG,cs.AI,F.2.2; I.2.7"}, {"arxiv_id": "2401.10397", "title": "Analyzing and Mitigating Bias for Vulnerable Classes: Towards Balanced\n  Representation in Dataset", "abstract": "The accuracy and fairness of perception systems in autonomous driving are\ncrucial, particularly for vulnerable road users. Mainstream research has looked\ninto improving the performance metrics for classification accuracy. However,\nthe hidden traits of bias inheritance in the AI models, class imbalances and\ndisparities in the datasets are often overlooked. In this context, our study\nexamines the class imbalances for vulnerable road users by focusing on class\ndistribution analysis, performance evaluation, and bias impact assessment. We\nidentify the concern of imbalances in class representation, leading to\npotential biases in detection accuracy. Utilizing popular CNN models and Vision\nTransformers (ViTs) with the nuScenes dataset, our performance evaluation\nreveals detection disparities for underrepresented classes. We propose a\nmethodology for model optimization and bias mitigation, which includes data\naugmentation, resampling, and metric-specific learning. Using the proposed\nmitigation approaches, we see improvement in IoU(%) and NDS(%) metrics from\n71.3 to 75.6 and 80.6 to 83.7 respectively, for the CNN model. Similarly, for\nViT, we observe improvement in IoU and NDS metrics from 74.9 to 79.2 and 83.8\nto 87.1 respectively. This research contributes to developing more reliable\nmodels and datasets, enhancing inclusiveness for minority classes.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10402", "title": "Reconstructing the Invisible: Video Frame Restoration through Siamese\n  Masked Conditional Variational Autoencoder", "abstract": "In the domain of computer vision, the restoration of missing information in\nvideo frames is a critical challenge, particularly in applications such as\nautonomous driving and surveillance systems. This paper introduces the Siamese\nMasked Conditional Variational Autoencoder (SiamMCVAE), leveraging a siamese\narchitecture with twin encoders based on vision transformers. This innovative\ndesign enhances the model's ability to comprehend lost content by capturing\nintrinsic similarities between paired frames. SiamMCVAE proficiently\nreconstructs missing elements in masked frames, effectively addressing issues\narising from camera malfunctions through variational inferences. Experimental\nresults robustly demonstrate the model's effectiveness in restoring missing\ninformation, thus enhancing the resilience of computer vision systems. The\nincorporation of Siamese Vision Transformer (SiamViT) encoders in SiamMCVAE\nexemplifies promising potential for addressing real-world challenges in\ncomputer vision, reinforcing the adaptability of autonomous systems in dynamic\nenvironments.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10404", "title": "Inflation with Diffusion: Efficient Temporal Adaptation for\n  Text-to-Video Super-Resolution", "abstract": "We propose an efficient diffusion-based text-to-video super-resolution (SR)\ntuning approach that leverages the readily learned capacity of pixel level\nimage diffusion model to capture spatial information for video generation. To\naccomplish this goal, we design an efficient architecture by inflating the\nweightings of the text-to-image SR model into our video generation framework.\nAdditionally, we incorporate a temporal adapter to ensure temporal coherence\nacross video frames. We investigate different tuning approaches based on our\ninflated architecture and report trade-offs between computational costs and\nsuper-resolution quality. Empirical evaluation, both quantitative and\nqualitative, on the Shutterstock video dataset, demonstrates that our approach\nis able to perform text-to-video SR generation with good visual quality and\ntemporal consistency. To evaluate temporal coherence, we also present\nvisualizations in video format in\nhttps://drive.google.com/drive/folders/1YVc-KMSJqOrEUdQWVaI-Yfu8Vsfu_1aO?usp=sharing .", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10405", "title": "Differentially Private and Adversarially Robust Machine Learning: An\n  Empirical Evaluation", "abstract": "Malicious adversaries can attack machine learning models to infer sensitive\ninformation or damage the system by launching a series of evasion attacks.\nAlthough various work addresses privacy and security concerns, they focus on\nindividual defenses, but in practice, models may undergo simultaneous attacks.\nThis study explores the combination of adversarial training and differentially\nprivate training to defend against simultaneous attacks. While\ndifferentially-private adversarial training, as presented in DP-Adv,\noutperforms the other state-of-the-art methods in performance, it lacks formal\nprivacy guarantees and empirical validation. Thus, in this work, we benchmark\nthe performance of this technique using a membership inference attack and\nempirically show that the resulting approach is as private as non-robust\nprivate models. This work also highlights the need to explore privacy\nguarantees in dynamic training paradigms.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.10407", "title": "Learning High-Quality and General-Purpose Phrase Representations", "abstract": "Phrase representations play an important role in data science and natural\nlanguage processing, benefiting various tasks like Entity Alignment, Record\nLinkage, Fuzzy Joins, and Paraphrase Classification. The current\nstate-of-the-art method involves fine-tuning pre-trained language models for\nphrasal embeddings using contrastive learning. However, we have identified\nareas for improvement. First, these pre-trained models tend to be unnecessarily\ncomplex and require to be pre-trained on a corpus with context sentences.\nSecond, leveraging the phrase type and morphology gives phrase representations\nthat are both more precise and more flexible. We propose an improved framework\nto learn phrase representations in a context-free fashion. The framework\nemploys phrase type classification as an auxiliary task and incorporates\ncharacter-level information more effectively into the phrase representation.\nFurthermore, we design three granularities of data augmentation to increase the\ndiversity of training samples. Our experiments across a wide range of tasks\nshow that our approach generates superior phrase embeddings compared to\nprevious methods while requiring a smaller model size. The code is available at\n\\faGithub~ \\url{https://github.com/tigerchen52/PEARL} \\end{abstract}", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.10409", "title": "The Session Abstract Machine (Extended Version)", "abstract": "We build on a fine-grained analysis of session-based interaction as provided\nby the linear logic typing disciplines to introduce the SAM, an abstract\nmachine for mechanically executing session-typed processes. A remarkable\nfeature of the SAM's design is its ability to naturally segregate and\ncoordinate sequential with concurrent session behaviours. In particular,\nimplicitly sequential parts of session programs may be efficiently executed by\ndeterministic sequential application of SAM transitions, amenable to\ncompilation, and without concurrent synchronisation mechanisms. We provide an\nintuitive discussion of the SAM structure and its underlying design, and state\nand prove its correctness for executing programs in a session calculus\ncorresponding to full classical linear logic CLL. We also discuss extensions\nand applications of the SAM to the execution of linear and session-based\nprogramming languages.", "field": "Computer Science", "categories": "cs.PL"}, {"arxiv_id": "2401.10415", "title": "Can Large Language Model Summarizers Adapt to Diverse Scientific\n  Communication Goals?", "abstract": "In this work, we investigate the controllability of large language models\n(LLMs) on scientific summarization tasks. We identify key stylistic and content\ncoverage factors that characterize different types of summaries such as paper\nreviews, abstracts, and lay summaries. By controlling stylistic features, we\nfind that non-fine-tuned LLMs outperform humans in the MuP review generation\ntask, both in terms of similarity to reference summaries and human preferences.\nAlso, we show that we can improve the controllability of LLMs with\nkeyword-based classifier-free guidance (CFG) while achieving lexical overlap\ncomparable to strong fine-tuned baselines on arXiv and PubMed. However, our\nresults also indicate that LLMs cannot consistently generate long summaries\nwith more than 8 sentences. Furthermore, these models exhibit limited capacity\nto produce highly abstractive lay summaries. Although LLMs demonstrate strong\ngeneric summarization competency, sophisticated content control without costly\nfine-tuning remains an open problem for domain-specific applications.", "field": "Computer Science", "categories": "cs.CL,cs.AI"}, {"arxiv_id": "2401.10416", "title": "DataViz3D: An Novel Method Leveraging Online Holographic Modeling for\n  Extensive Dataset Preprocessing and Visualization", "abstract": "DataViz3D is an innovative online software that transforms complex datasets\ninto interactive 3D spatial models using holographic technology. This tool\nenables users to generate scatter plot within a 3D space, accurately mapped to\nthe XYZ coordinates of the dataset, providing a vivid and intuitive\nunderstanding of the spatial relationships inherent in the data. DataViz3D's\nuser friendly interface makes advanced 3D modeling and holographic\nvisualization accessible to a wide range of users, fostering new opportunities\nfor collaborative research and education across various disciplines.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10417", "title": "SSR: Spatial Sequential Hybrid Architecture for Latency Throughput\n  Tradeoff in Transformer Acceleration", "abstract": "With the increase in the computation intensity of the chip, the mismatch\nbetween computation layer shapes and the available computation resource\nsignificantly limits the utilization of the chip. Driven by this observation,\nprior works discuss spatial accelerators or dataflow architecture to maximize\nthe throughput. However, using spatial accelerators could potentially increase\nthe execution latency. In this work, we first systematically investigate two\nexecution models: (1) sequentially (temporally) launch one monolithic\naccelerator, and (2) spatially launch multiple accelerators. From the\nobservations, we find that there is a latency throughput tradeoff between these\ntwo execution models, and combining these two strategies together can give us a\nmore efficient latency throughput Pareto front. To achieve this, we propose\nspatial sequential architecture (SSR) and SSR design automation framework to\nexplore both strategies together when deploying deep learning inference. We use\nthe 7nm AMD Versal ACAP VCK190 board to implement SSR accelerators for four\nend-to-end transformer-based deep learning models. SSR achieves average\nthroughput gains of 2.53x, 35.71x, and 14.20x under different batch sizes\ncompared to the 8nm Nvidia GPU A10G, 16nm AMD FPGAs ZCU102, and U250. The\naverage energy efficiency gains are 8.51x, 6.75x, and 21.22x, respectively.\nCompared with the sequential-only solution and spatial-only solution on VCK190,\nour spatial-sequential-hybrid solutions achieve higher throughput under the\nsame latency requirement and lower latency under the same throughput\nrequirement. We also use SSR analytical models to demonstrate how to use SSR to\noptimize solutions on other computing platforms, e.g., 14nm Intel Stratix 10\nNX.", "field": "Computer Science", "categories": "cs.AR,cs.PL"}, {"arxiv_id": "2401.10418", "title": "Hazard resistance-based spatiotemporal risk analysis for distribution\n  network outages during hurricanes", "abstract": "Blackouts in recent decades show an increasing prevalence of power outages\ndue to extreme weather events such as hurricanes. Precisely assessing the\nspatiotemporal outages in distribution networks, the most vulnerable part of\npower systems, is critical to enhance power system resilience. The Sequential\nMonte Carlo (SMC) simulation method is widely used for spatiotemporal risk\nanalysis of power systems during extreme weather hazards. However, it is found\nhere that the SMC method can lead to large errors by directly applying the\nfragility function or failure probability of system components in\ntime-sequential analysis, particularly overestimating damages under evolving\nhazards with high-frequency sampling. To address this issue, a novel hazard\nresistance-based spatiotemporal risk analysis (HRSRA) method is proposed. This\nmethod converts the time-varying failure probability of a component into a\nhazard resistance as a time-invariant value during the simulation of evolving\nhazards. The proposed HRSRA provides an adaptive framework for incorporating\nhigh-spatiotemporal-resolution meteorology models into power outage\nsimulations. By leveraging the geographic information system data of the power\nsystem and a physics-based hurricane wind field model, the superiority of the\nproposed method is validated using real-world time-series power outage data\nfrom Puerto Rico during Hurricane Fiona 2022.", "field": "Computer Science", "categories": "eess.SY,cs.SY"}, {"arxiv_id": "2401.1042", "title": "Generalized Nested Rollout Policy Adaptation with Limited Repetitions", "abstract": "Generalized Nested Rollout Policy Adaptation (GNRPA) is a Monte Carlo search\nalgorithm for optimizing a sequence of choices. We propose to improve on GNRPA\nby avoiding too deterministic policies that find again and again the same\nsequence of choices. We do so by limiting the number of repetitions of the best\nsequence found at a given level. Experiments show that it improves the\nalgorithm for three different combinatorial problems: Inverse RNA Folding, the\nTraveling Salesman Problem with Time Windows and the Weak Schur problem.", "field": "Computer Science", "categories": "cs.AI"}, {"arxiv_id": "2401.10422", "title": "Semantic Analysis of Macro Usage for Portability", "abstract": "C is an unsafe language. Researchers have been developing tools to port C to\nsafer languages such as Rust, Checked C, or Go. Existing tools, however, resort\nto preprocessing the source file first, then porting the resulting code,\nleaving barely recognizable code that loses macro abstractions. To preserve\nmacro usage, porting tools need analyses that understand macro behavior to port\nto equivalent constructs. But macro semantics differ from typical functions,\nprecluding simple syntactic transformations to port them. We introduce the\nfirst comprehensive framework for analyzing the portability of macro usage. We\ndecompose macro behavior into 26 fine-grained properties and implement a\nprogram analysis tool, called Maki, that identifies them in real-world code\nwith 94% accuracy. We apply Maki to 21 programs containing a total of 86,199\nmacro definitions. We found that real-world macros are much more portable than\npreviously known. More than a third (37%) are easy-to-port, and Maki provides\nhints for porting more complicated macros. We find, on average, 2x more\neasy-to-port macros and up to 7x more in the best case compared to prior work.\nGuided by Maki's output, we found and hand-ported macros in four real-world\nprograms. We submitted patches to Linux maintainers that transform eleven\nmacros, nine of which have been accepted.", "field": "Computer Science", "categories": "cs.SE,D.3.4; D.2.7"}, {"arxiv_id": "2401.10423", "title": "Verification under TSO with an infinite Data Domain", "abstract": "We examine verification of concurrent programs under the total store ordering\n(TSO) semantics used by the x86 architecture. In our model, threads manipulate\nvariables over infinite domains and they can check whether variables are\nrelated for a range of relations. We show that, in general, the control state\nreachability problem is undecidable. This result is derived through a reduction\nfrom the state reachability problem of lossy channel systems with data (which\nis known to be undecidable). In the light of this undecidability, we turn our\nattention to a more tractable variant of the reachability problem.\nSpecifically, we study context bounded runs, which provide an\nunder-approximation of the program behavior by limiting the possible\ninteractions between processes. A run consists of a number of contexts, with\neach context representing a sequence of steps where a only single designated\nthread is active. We prove that the control state reachability problem under\nbounded context switching is PSPACE complete.", "field": "Computer Science", "categories": "cs.FL,cs.PL"}, {"arxiv_id": "2401.10428", "title": "Understanding Learning through the Lens of Dynamical Invariants", "abstract": "This paper proposes a novel perspective on learning, positing it as the\npursuit of dynamical invariants -- data combinations that remain constant or\nexhibit minimal change over time as a system evolves. This concept is\nunderpinned by both informational and physical principles, rooted in the\ninherent properties of these invariants. Firstly, their stability makes them\nideal for memorization and integration into associative networks, forming the\nbasis of our knowledge structures. Secondly, the predictability of these stable\ninvariants makes them valuable sources of usable energy, quantifiable as kTln2\nper bit of accurately predicted information. This energy can be harnessed to\nexplore new transformations, rendering learning systems energetically\nautonomous and increasingly effective. Such systems are driven to continuously\nseek new data invariants as energy sources. The paper further explores several\nmeta-architectures of autonomous, self-propelled learning agents that utilize\npredictable information patterns as a source of usable energy.", "field": "Computer Science", "categories": "cs.AI,cs.IT,math.IT"}, {"arxiv_id": "2401.10431", "title": "Learning a Prior for Monte Carlo Search by Replaying Solutions to\n  Combinatorial Problems", "abstract": "Monte Carlo Search gives excellent results in multiple difficult\ncombinatorial problems. Using a prior to perform non uniform playouts during\nthe search improves a lot the results compared to uniform playouts. Handmade\nheuristics tailored to the combinatorial problem are often used as priors. We\npropose a method to automatically compute a prior. It uses statistics on solved\nproblems. It is a simple and general method that incurs no computational cost\nat playout time and that brings large performance gains. The method is applied\nto three difficult combinatorial problems: Latin Square Completion, Kakuro, and\nInverse RNA Folding.", "field": "Computer Science", "categories": "cs.AI"}, {"arxiv_id": "2401.10432", "title": "A2Q+: Improving Accumulator-Aware Weight Quantization", "abstract": "Quantization techniques commonly reduce the inference costs of neural\nnetworks by restricting the precision of weights and activations. Recent\nstudies show that also reducing the precision of the accumulator can further\nimprove hardware efficiency at the risk of numerical overflow, which introduces\narithmetic errors that can degrade model accuracy. To avoid numerical overflow\nwhile maintaining accuracy, recent work proposed accumulator-aware quantization\n(A2Q), a quantization-aware training method that constrains model weights\nduring training to safely use a target accumulator bit width during inference.\nAlthough this shows promise, we demonstrate that A2Q relies on an overly\nrestrictive constraint and a sub-optimal weight initialization strategy that\neach introduce superfluous quantization error. To address these shortcomings,\nwe introduce: (1) an improved bound that alleviates accumulator constraints\nwithout compromising overflow avoidance; and (2) a new strategy for\ninitializing quantized weights from pre-trained floating-point checkpoints. We\ncombine these contributions with weight normalization to introduce A2Q+. We\nsupport our analysis with experiments that show A2Q+ significantly improves the\ntrade-off between accumulator bit width and model accuracy and characterize new\ntrade-offs that arise as a consequence of accumulator constraints.", "field": "Computer Science", "categories": "cs.LG,cs.AR,cs.PF"}, {"arxiv_id": "2401.1044", "title": "Breaking the Curse of Multilinguality with Cross-lingual Expert Language\n  Models", "abstract": "Despite their popularity in non-English NLP, multilingual language models\noften underperform monolingual ones due to inter-language competition for model\nparameters. We propose Cross-lingual Expert Language Models (X-ELM), which\nmitigate this competition by independently training language models on subsets\nof the multilingual corpus. This process specializes X-ELMs to different\nlanguages while remaining effective as a multilingual ensemble. Our experiments\nshow that when given the same compute budget, X-ELM outperforms jointly trained\nmultilingual models across all considered languages and that these gains\ntransfer to downstream tasks. X-ELM provides additional benefits over\nperformance improvements: new experts can be iteratively added, adapting X-ELM\nto new languages without catastrophic forgetting. Furthermore, training is\nasynchronous, reducing the hardware requirements for multilingual training and\ndemocratizing multilingual modeling.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.10442", "title": "Path Choice Matters for Clear Attribution in Path Methods", "abstract": "Rigorousness and clarity are both essential for interpretations of DNNs to\nengender human trust. Path methods are commonly employed to generate rigorous\nattributions that satisfy three axioms. However, the meaning of attributions\nremains ambiguous due to distinct path choices. To address the ambiguity, we\nintroduce \\textbf{Concentration Principle}, which centrally allocates high\nattributions to indispensable features, thereby endowing aesthetic and\nsparsity. We then present \\textbf{SAMP}, a model-agnostic interpreter, which\nefficiently searches the near-optimal path from a pre-defined set of\nmanipulation paths. Moreover, we propose the infinitesimal constraint (IC) and\nmomentum strategy (MS) to improve the rigorousness and optimality.\nVisualizations show that SAMP can precisely reveal DNNs by pinpointing salient\nimage pixels. We also perform quantitative experiments and observe that our\nmethod significantly outperforms the counterparts. Code:\nhttps://github.com/zbr17/SAMP.", "field": "Computer Science", "categories": "cs.CV,cs.LG"}, {"arxiv_id": "2401.10443", "title": "Towards Automated Driving Violation Cause Analysis in Scenario-Based\n  Testing for Autonomous Driving Systems", "abstract": "The rapid advancement of Autonomous Vehicles (AVs), exemplified by companies\nlike Waymo and Cruise offering 24/7 paid taxi services, highlights the\nparamount importance of ensuring AVs' compliance with various policies, such as\nsafety regulations, traffic rules, and mission directives. Despite significant\nprogress in the development of Autonomous Driving System (ADS) testing tools,\nthere has been a notable absence of research on attributing the causes of\ndriving violations. Counterfactual causality analysis has emerged as a\npromising approach for identifying the root cause of program failures. While it\nhas demonstrated effectiveness in pinpointing error-inducing inputs, its direct\napplication to the AV context to determine which computation result, generated\nby which component, serves as the root cause poses a considerable challenge. A\nkey obstacle lies in our inability to straightforwardly eliminate the influence\nof a specific internal message to establish the causal relationship between the\noutput of each component and a system-level driving violation.\n  In this work, we propose a novel driving violation cause analysis (DVCA)\ntool. We design idealized component substitutes to enable counterfactual\nanalysis of ADS components by leveraging the unique opportunity provided by the\nsimulation. We evaluate our tool on a benchmark with real bugs and injected\nfaults. The results show that our tool can achieve perfect component-level\nattribution accuracy (100%) and almost (>98%) perfect message-level accuracy.\nOur tool can reduce the debugging scope from hundreds of complicated\ninterdependent messages to one single computation result generated by one\ncomponent.", "field": "Computer Science", "categories": "cs.SE"}, {"arxiv_id": "2401.10444", "title": "Can A Cognitive Architecture Fundamentally Enhance LLMs? Or Vice Versa?", "abstract": "The paper discusses what is needed to address the limitations of current\nLLM-centered AI systems. The paper argues that incorporating insights from\nhuman cognition and psychology, as embodied by a computational cognitive\narchitecture, can help develop systems that are more capable, more reliable,\nand more human-like. It emphasizes the importance of the dual-process\narchitecture and the hybrid neuro-symbolic approach in addressing the\nlimitations of current LLMs. In the opposite direction, the paper also\nhighlights the need for an overhaul of computational cognitive architectures to\nbetter reflect advances in AI and computing technology. Overall, the paper\nadvocates for a multidisciplinary, mutually beneficial approach towards\ndeveloping better models both for AI and for understanding the human mind.", "field": "Computer Science", "categories": "cs.AI,cs.CY"}, {"arxiv_id": "2401.10446", "title": "Large Language Models are Efficient Learners of Noise-Robust Speech\n  Recognition", "abstract": "Recent advances in large language models (LLMs) have promoted generative\nerror correction (GER) for automatic speech recognition (ASR), which leverages\nthe rich linguistic knowledge and powerful reasoning ability of LLMs to improve\nrecognition results. The latest work proposes a GER benchmark with HyPoradise\ndataset to learn the mapping from ASR N-best hypotheses to ground-truth\ntranscription by efficient LLM finetuning, which shows great effectiveness but\nlacks specificity on noise-robust ASR. In this work, we extend the benchmark to\nnoisy conditions and investigate if we can teach LLMs to perform denoising for\nGER just like what robust ASR do}, where one solution is introducing noise\ninformation as a conditioner into LLM. However, directly incorporating noise\nembeddings from audio encoder could harm the LLM tuning due to cross-modality\ngap. To this end, we propose to extract a language-space noise embedding from\nthe N-best list to represent the noise conditions of source speech, which can\npromote the denoising process in GER. Furthermore, in order to enhance its\nrepresentation ability of audio noise, we design a knowledge distillation (KD)\napproach via mutual information estimation to distill the real noise\ninformation in audio embeddings to our language embedding. Experiments on\nvarious latest LLMs demonstrate our approach achieves a new breakthrough with\nup to 53.9% correction improvement in terms of word error rate while with\nlimited training data. Analysis shows that our language-space noise embedding\ncan well represent the noise conditions of source speech, under which\noff-the-shelf LLMs show strong ability of language-space denoising.", "field": "Computer Science", "categories": "cs.CL,cs.AI,cs.LG,cs.SD,eess.AS"}, {"arxiv_id": "2401.10447", "title": "Investigating Training Strategies and Model Robustness of Low-Rank\n  Adaptation for Language Modeling in Speech Recognition", "abstract": "The use of low-rank adaptation (LoRA) with frozen pretrained language models\n(PLMs) has become increasing popular as a mainstream, resource-efficient\nmodeling approach for memory-constrained hardware. In this study, we first\nexplore how to enhance model performance by introducing various LoRA training\nstrategies, achieving relative word error rate reductions of 3.50\\% on the\npublic Librispeech dataset and of 3.67\\% on an internal dataset in the\nmessaging domain. To further characterize the stability of LoRA-based\nsecond-pass speech recognition models, we examine robustness against input\nperturbations. These perturbations are rooted in homophone replacements and a\nnovel metric called N-best Perturbation-based Rescoring Robustness (NPRR), both\ndesigned to measure the relative degradation in the performance of rescoring\nmodels. Our experimental results indicate that while advanced variants of LoRA,\nsuch as dynamic rank-allocated LoRA, lead to performance degradation in\n$1$-best perturbation, they alleviate the degradation in $N$-best perturbation.\nThis finding is in comparison to fully-tuned models and vanilla LoRA tuning\nbaselines, suggesting that a comprehensive selection is needed when using\nLoRA-based adaptation for compute-cost savings and robust language modeling.", "field": "Computer Science", "categories": "cs.CL,cs.AI,cs.LG,cs.NE,cs.SD,eess.AS"}, {"arxiv_id": "2401.10451", "title": "Learning-assisted Stochastic Capacity Expansion Planning: A Bayesian\n  Optimization Approach", "abstract": "Solving large-scale capacity expansion problems (CEPs) is central to\ncost-effective decarbonization of regional-scale energy systems. To ensure the\nintended outcomes of CEPs, modeling uncertainty due to weather-dependent\nvariable renewable energy (VRE) supply and energy demand becomes crucially\nimportant. However, the resulting stochastic optimization models are often less\ncomputationally tractable than their deterministic counterparts. Here, we\npropose a learning-assisted approximate solution method to tractably solve\ntwo-stage stochastic CEPs. Our method identifies low-cost planning decisions by\nconstructing and solving a sequence of tractable temporally aggregated\nsurrogate problems. We adopt a Bayesian optimization approach to searching the\nspace of time series aggregation hyperparameters and compute approximate\nsolutions that minimize costs on a validation set of supply-demand projections.\nImportantly, we evaluate solved planning outcomes on a held-out set of test\nprojections. We apply our approach to generation and transmission expansion\nplanning for a joint power-gas system spanning New England. We show that our\napproach yields an estimated cost savings of up to 3.8% in comparison to\nbenchmark time series aggregation approaches.", "field": "Computer Science", "categories": "eess.SY,cs.LG,cs.SY"}, {"arxiv_id": "2401.10458", "title": "Contrastive Unlearning: A Contrastive Approach to Machine Unlearning", "abstract": "Machine unlearning aims to eliminate the influence of a subset of training\nsamples (i.e., unlearning samples) from a trained model. Effectively and\nefficiently removing the unlearning samples without negatively impacting the\noverall model performance is still challenging. In this paper, we propose a\ncontrastive unlearning framework, leveraging the concept of representation\nlearning for more effective unlearning. It removes the influence of unlearning\nsamples by contrasting their embeddings against the remaining samples so that\nthey are pushed away from their original classes and pulled toward other\nclasses. By directly optimizing the representation space, it effectively\nremoves the influence of unlearning samples while maintaining the\nrepresentations learned from the remaining samples. Experiments on a variety of\ndatasets and models on both class unlearning and sample unlearning showed that\ncontrastive unlearning achieves the best unlearning effects and efficiency with\nthe lowest performance loss compared with the state-of-the-art algorithms.", "field": "Computer Science", "categories": "cs.LG,cs.CR"}, {"arxiv_id": "2401.1046", "title": "Ultra-lightweight Neural Differential DSP Vocoder For High Quality\n  Speech Synthesis", "abstract": "Neural vocoders model the raw audio waveform and synthesize high-quality\naudio, but even the highly efficient ones, like MB-MelGAN and LPCNet, fail to\nrun real-time on a low-end device like a smartglass. A pure digital signal\nprocessing (DSP) based vocoder can be implemented via lightweight fast Fourier\ntransforms (FFT), and therefore, is a magnitude faster than any neural vocoder.\nA DSP vocoder often gets a lower audio quality due to consuming over-smoothed\nacoustic model predictions of approximate representations for the vocal tract.\nIn this paper, we propose an ultra-lightweight differential DSP (DDSP) vocoder\nthat uses a jointly optimized acoustic model with a DSP vocoder, and learns\nwithout an extracted spectral feature for the vocal tract. The model achieves\naudio quality comparable to neural vocoders with a high average MOS of 4.36\nwhile being efficient as a DSP vocoder. Our C++ implementation, without any\nhardware-specific optimization, is at 15 MFLOPS, surpasses MB-MelGAN by 340\ntimes in terms of FLOPS, and achieves a vocoder-only RTF of 0.003 and overall\nRTF of 0.044 while running single-threaded on a 2GHz Intel Xeon CPU.", "field": "Computer Science", "categories": "cs.SD,cs.LG,eess.AS"}, {"arxiv_id": "2401.10461", "title": "Learning to Robustly Reconstruct Low-light Dynamic Scenes from Spike\n  Streams", "abstract": "As a neuromorphic sensor with high temporal resolution, spike camera can\ngenerate continuous binary spike streams to capture per-pixel light intensity.\nWe can use reconstruction methods to restore scene details in high-speed\nscenarios. However, due to limited information in spike streams, low-light\nscenes are difficult to effectively reconstruct. In this paper, we propose a\nbidirectional recurrent-based reconstruction framework, including a\nLight-Robust Representation (LR-Rep) and a fusion module, to better handle such\nextreme conditions. LR-Rep is designed to aggregate temporal information in\nspike streams, and a fusion module is utilized to extract temporal features.\nAdditionally, we have developed a reconstruction benchmark for high-speed\nlow-light scenes. Light sources in the scenes are carefully aligned to\nreal-world conditions. Experimental results demonstrate the superiority of our\nmethod, which also generalizes well to real spike streams. Related codes and\nproposed datasets will be released after publication.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10463", "title": "Critical Data Size of Language Models from a Grokking Perspective", "abstract": "We explore the critical data size in language models, a threshold that marks\na fundamental shift from quick memorization to slow generalization. We\nformalize the phase transition under the grokking configuration into the Data\nEfficiency Hypothesis and identify data insufficiency, sufficiency, and surplus\nregimes in language models training dynamics. We develop a grokking\nconfiguration to reproduce grokking on simplistic language models stably by\nrescaling initialization and weight decay. We show that generalization occurs\nonly when language models reach a critical size. We analyze grokking across\nsample-wise and model-wise, verifying the proposed data efficiency hypothesis.\nOur experiments reveal smoother phase transitions occurring at the critical\ndataset size for language datasets. As the model size increases, this critical\npoint also becomes larger, indicating that larger models require more data. Our\nresults deepen the understanding of language model training, offering a novel\nperspective on the role of data in the learning mechanism of language models.", "field": "Computer Science", "categories": "cs.CL,cs.AI,cs.LG"}, {"arxiv_id": "2401.10464", "title": "PhotoScout: Synthesis-Powered Multi-Modal Image Search", "abstract": "Due to the availability of increasingly large amounts of visual data, there\nis a growing need for tools that can help users find relevant images. While\nexisting tools can perform image retrieval based on similarity or metadata,\nthey fall short in scenarios that necessitate semantic reasoning about the\ncontent of the image. This paper explores a new multi-modal image search\napproach that allows users to conveniently specify and perform semantic image\nsearch tasks. With our tool, PhotoScout, the user interactively provides\nnatural language descriptions, positive and negative examples, and object tags\nto specify their search tasks. Under the hood, PhotoScout is powered by a\nprogram synthesis engine that generates visual queries in a domain-specific\nlanguage and executes the synthesized program to retrieve the desired images.\nIn a study with 25 participants, we observed that PhotoScout allows users to\nperform image retrieval tasks more accurately and with less manual effort.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.10465", "title": "Data-driven grapheme-to-phoneme representations for a lexicon-free\n  text-to-speech", "abstract": "Grapheme-to-Phoneme (G2P) is an essential first step in any modern,\nhigh-quality Text-to-Speech (TTS) system. Most of the current G2P systems rely\non carefully hand-crafted lexicons developed by experts. This poses a two-fold\nproblem. Firstly, the lexicons are generated using a fixed phoneme set,\nusually, ARPABET or IPA, which might not be the most optimal way to represent\nphonemes for all languages. Secondly, the man-hours required to produce such an\nexpert lexicon are very high. In this paper, we eliminate both of these issues\nby using recent advances in self-supervised learning to obtain data-driven\nphoneme representations instead of fixed representations. We compare our\nlexicon-free approach against strong baselines that utilize a well-crafted\nlexicon. Furthermore, we show that our data-driven lexicon-free method performs\nas good or even marginally better than the conventional rule-based or\nlexicon-based neural G2Ps in terms of Mean Opinion Score (MOS) while using no\nprior language lexicon or phoneme set, i.e. no linguistic expertise.", "field": "Computer Science", "categories": "cs.CL,cs.SD,eess.AS"}, {"arxiv_id": "2401.10467", "title": "Learning Backdoors for Mixed Integer Programs with Contrastive Learning", "abstract": "Many real-world problems can be efficiently modeled as Mixed Integer Programs\n(MIPs) and solved with the Branch-and-Bound method. Prior work has shown the\nexistence of MIP backdoors, small sets of variables such that prioritizing\nbranching on them when possible leads to faster running times. However, finding\nhigh-quality backdoors that improve running times remains an open question.\nPrevious work learns to estimate the relative solver speed of randomly sampled\nbackdoors through ranking and then decide whether to use it. In this paper, we\nutilize the Monte-Carlo tree search method to collect backdoors for training,\nrather than relying on random sampling, and adapt a contrastive learning\nframework to train a Graph Attention Network model to predict backdoors. Our\nmethod, evaluated on four common MIP problem domains, demonstrates performance\nimprovements over both Gurobi and previous models.", "field": "Computer Science", "categories": "cs.AI,cs.LG,math.OC"}, {"arxiv_id": "2401.10469", "title": "A Stable Matching Assignment for Cancer Treatment Centers using Survival\n  Analysis", "abstract": "The treatment of cancer is one of the most discussed issues in the realm of\ncontemporary public health research. One of the primary concerns of both the\ngeneral public and the government is the development of the most effective\ncancer treatment at the most affordable price. This is due to the fact that the\nnumber of persons diagnosed with cancer increases on an annual basis. Within\nthe scope of this project, we propose the development of a system for the\nrecommendation of treatment centers. This system would initially select\npatients who posed a higher risk value, and then it would recommend the most\nappropriate cancer treatment center for those patients based on their income\nand the location where they lived using a stable matching algorithm.", "field": "Computer Science", "categories": "cs.GT,cs.CY"}, {"arxiv_id": "2401.1047", "title": "Shape enumerators of self-dual NRT codes over finite fields", "abstract": "We use invariant theory of finite groups to study shape enumerators of\nself-dual linear codes in a finite NRT metric space. We provide a new approach\nthat avoids applying Molien's formula to compute all possible shape\nenumerators. Enhancing existing methods, we describe the shape enumerators of\nall self-dual NRT codes over an arbitrary finite field.", "field": "Computer Science", "categories": "cs.IT,math.IT,94B50, 13A50"}, {"arxiv_id": "2401.10471", "title": "DeepEdit: Knowledge Editing as Decoding with Constraints", "abstract": "We develop a new perspective of knowledge editing for large language models\n(LLMs) as decoding with constraints. We propose DeepEdit (Depth-first Search\nbased Progressive Decoding for Knowledge Editing), a neuro-symbolic method that\nimproves knowledge editing with better coherence of reasoning, relevance to the\nquestion, and awareness of updated knowledge. DeepEdit can be flexibly applied\nto all black-box LLMs: it does not require any access to the model parameters,\nrepresentations, or output vocabulary distributions. DeepEdit progressively\nproduces the high-quality reasoning steps towards effective knowledge editing.\nIt utilizes a depth-first search to revise the LLMs' output, which improves the\noutput's informativeness to the input question and awareness of the updated\nknowledge. Qualitatively, DeepEdit effectively controls LLMs to produce more\nsuccinct reasoning in accord with knowledge editing. Quantitatively, DeepEdit\nyields significant gains on MQuaKE, a challenging multi-hop question-answering\ndataset with knowledge editing. We release the source code at\nhttps://github.com/wangywUST/DeepEdit.", "field": "Computer Science", "categories": "cs.CL,cs.AI"}, {"arxiv_id": "2401.10472", "title": "Name Tagging Under Domain Shift via Metric Learning for Life Sciences", "abstract": "Name tagging is a key component of Information Extraction (IE), particularly\nin scientific domains such as biomedicine and chemistry, where large language\nmodels (LLMs), e.g., ChatGPT, fall short. We investigate the applicability of\ntransfer learning for enhancing a name tagging model trained in the biomedical\ndomain (the source domain) to be used in the chemical domain (the target\ndomain). A common practice for training such a model in a few-shot learning\nsetting is to pretrain the model on the labeled source data, and then, to\nfinetune it on a hand-full of labeled target examples. In our experiments we\nobserved that such a model is prone to mis-labeling the source entities, which\ncan often appear in the text, as the target entities. To alleviate this\nproblem, we propose a model to transfer the knowledge from the source domain to\nthe target domain, however, at the same time, to project the source entities\nand target entities into separate regions of the feature space. This diminishes\nthe risk of mis-labeling the source entities as the target entities. Our model\nconsists of two stages: 1) entity grouping in the source domain, which\nincorporates knowledge from annotated events to establish relations between\nentities, and 2) entity discrimination in the target domain, which relies on\npseudo labeling and contrastive learning to enhance discrimination between the\nentities in the two domains. We carry out our extensive experiments across\nthree source and three target datasets, and demonstrate that our method\noutperforms the baselines, in some scenarios by 5\\% absolute value.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.10474", "title": "LDReg: Local Dimensionality Regularized Self-Supervised Learning", "abstract": "Representations learned via self-supervised learning (SSL) can be susceptible\nto dimensional collapse, where the learned representation subspace is of\nextremely low dimensionality and thus fails to represent the full data\ndistribution and modalities. Dimensional collapse also known as the\n\"underfilling\" phenomenon is one of the major causes of degraded performance on\ndownstream tasks. Previous work has investigated the dimensional collapse\nproblem of SSL at a global level. In this paper, we demonstrate that\nrepresentations can span over high dimensional space globally, but collapse\nlocally. To address this, we propose a method called $\\textit{local\ndimensionality regularization (LDReg)}$. Our formulation is based on the\nderivation of the Fisher-Rao metric to compare and optimize local distance\ndistributions at an asymptotically small radius for each data point. By\nincreasing the local intrinsic dimensionality, we demonstrate through a range\nof experiments that LDReg improves the representation quality of SSL. The\nresults also show that LDReg can regularize dimensionality at both local and\nglobal levels.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.CV,stat.ML"}, {"arxiv_id": "2401.10475", "title": "CBVS: A Large-Scale Chinese Image-Text Benchmark for Real-World Short\n  Video Search Scenarios", "abstract": "Vision-Language Models pre-trained on large-scale image-text datasets have\nshown superior performance in downstream tasks such as image retrieval. Most of\nthe images for pre-training are presented in the form of open domain\ncommon-sense visual elements. Differently, video covers in short video search\nscenarios are presented as user-originated contents that provide important\nvisual summaries of videos. In addition, a portion of the video covers come\nwith manually designed cover texts that provide semantic complements. In order\nto fill in the gaps in short video cover data, we establish the first\nlarge-scale cover-text benchmark for Chinese short video search scenarios.\nSpecifically, we release two large-scale datasets CBVS-5M/10M to provide short\nvideo covers, and the manual fine-labeling dataset CBVS-20K to provide real\nuser queries, which serves as an image-text benchmark test in the Chinese short\nvideo search field. To integrate the semantics of cover text in the case of\nmodality missing, we propose UniCLIP where cover texts play a guiding role\nduring training, however are not relied upon by inference. Extensive evaluation\non CBVS-20K demonstrates the excellent performance of our proposal. UniCLIP has\nbeen deployed to Tencent's online video search systems with hundreds of\nmillions of visits and achieved significant gains. The complete dataset, code\nand checkpoints will be available upon release.", "field": "Computer Science", "categories": "cs.CV,cs.MM"}, {"arxiv_id": "2401.10476", "title": "Quickly Determining Who Won an Election", "abstract": "This paper considers elections in which voters choose one candidate each,\nindependently according to known probability distributions. A candidate\nreceiving a strict majority (absolute or relative, depending on the version)\nwins. After the voters have made their choices, each vote can be inspected to\ndetermine which candidate received that vote. The time (or cost) to inspect\neach of the votes is known in advance. The task is to (possibly adaptively)\ndetermine the order in which to inspect the votes, so as to minimize the\nexpected time to determine which candidate has won the election. We design\npolynomial-time constant-factor approximation algorithms for both the\nabsolute-majority and the relative-majority version. Both algorithms are based\non a two-phase approach. In the first phase, the algorithms reduce the number\nof relevant candidates to $O(1)$, and in the second phase they utilize\ntechniques from the literature on stochastic function evaluation to handle the\nremaining candidates. In the case of absolute majority, we show that the same\ncan be achieved with only two rounds of adaptivity.", "field": "Computer Science", "categories": "cs.DS"}, {"arxiv_id": "2401.10478", "title": "Budgeted Online Model Selection and Fine-Tuning via Federated Learning", "abstract": "Online model selection involves selecting a model from a set of candidate\nmodels 'on the fly' to perform prediction on a stream of data. The choice of\ncandidate models henceforth has a crucial impact on the performance. Although\nemploying a larger set of candidate models naturally leads to more flexibility\nin model selection, this may be infeasible in cases where prediction tasks are\nperformed on edge devices with limited memory. Faced with this challenge, the\npresent paper proposes an online federated model selection framework where a\ngroup of learners (clients) interacts with a server with sufficient memory such\nthat the server stores all candidate models. However, each client only chooses\nto store a subset of models that can be fit into its memory and performs its\nown prediction task using one of the stored models. Furthermore, employing the\nproposed algorithm, clients and the server collaborate to fine-tune models to\nadapt them to a non-stationary environment. Theoretical analysis proves that\nthe proposed algorithm enjoys sub-linear regret with respect to the best model\nin hindsight. Experiments on real datasets demonstrate the effectiveness of the\nproposed algorithm.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.1048", "title": "Escape Sky-high Cost: Early-stopping Self-Consistency for Multi-step\n  Reasoning", "abstract": "Self-consistency (SC) has been a widely used decoding strategy for\nchain-of-thought reasoning. Despite bringing significant performance\nimprovements across a variety of multi-step reasoning tasks, it is a high-cost\nmethod that requires multiple sampling with the preset size. In this paper, we\npropose a simple and scalable sampling process, \\textbf{E}arly-Stopping\n\\textbf{S}elf-\\textbf{C}onsistency (ESC), to greatly reduce the cost of SC\nwithout sacrificing performance. On this basis, one control scheme for ESC is\nfurther derivated to dynamically choose the performance-cost balance for\ndifferent tasks and models. To demonstrate ESC's effectiveness, we conducted\nextensive experiments on three popular categories of reasoning tasks:\narithmetic, commonsense and symbolic reasoning over language models with\nvarying scales. The empirical results show that ESC reduces the average number\nof sampling of chain-of-thought reasoning by a significant margin on six\nbenchmarks, including MATH (-33.8%), GSM8K (-80.1%), StrategyQA (-76.8%),\nCommonsenseQA (-78.5%), Coin Flip (-84.2%) and Last Letters (-67.4%), while\nattaining comparable performances.", "field": "Computer Science", "categories": "cs.CL,cs.AI"}, {"arxiv_id": "2401.10484", "title": "Enhancing Scalability in Recommender Systems through Lottery Ticket\n  Hypothesis and Knowledge Distillation-based Neural Network Pruning", "abstract": "This study introduces an innovative approach aimed at the efficient pruning\nof neural networks, with a particular focus on their deployment on edge\ndevices. Our method involves the integration of the Lottery Ticket Hypothesis\n(LTH) with the Knowledge Distillation (KD) framework, resulting in the\nformulation of three distinct pruning models. These models have been developed\nto address scalability issue in recommender systems, whereby the complexities\nof deep learning models have hindered their practical deployment. With\njudicious application of the pruning techniques, we effectively curtail the\npower consumption and model dimensions without compromising on accuracy.\nEmpirical evaluation has been performed using two real world datasets from\ndiverse domains against two baselines. Gratifyingly, our approaches yielded a\nGPU computation-power reduction of up to 66.67%. Notably, our study contributes\nto the field of recommendation system by pioneering the application of LTH and\nKD.", "field": "Computer Science", "categories": "cs.IR,cs.AI,cs.AR"}, {"arxiv_id": "2401.10487", "title": "Generative Dense Retrieval: Memory Can Be a Burden", "abstract": "Generative Retrieval (GR), autoregressively decoding relevant document\nidentifiers given a query, has been shown to perform well under the setting of\nsmall-scale corpora. By memorizing the document corpus with model parameters,\nGR implicitly achieves deep interaction between query and document. However,\nsuch a memorizing mechanism faces three drawbacks: (1) Poor memory accuracy for\nfine-grained features of documents; (2) Memory confusion gets worse as the\ncorpus size increases; (3) Huge memory update costs for new documents. To\nalleviate these problems, we propose the Generative Dense Retrieval (GDR)\nparadigm. Specifically, GDR first uses the limited memory volume to achieve\ninter-cluster matching from query to relevant document clusters.\nMemorizing-free matching mechanism from Dense Retrieval (DR) is then introduced\nto conduct fine-grained intra-cluster matching from clusters to relevant\ndocuments. The coarse-to-fine process maximizes the advantages of GR's deep\ninteraction and DR's scalability. Besides, we design a cluster identifier\nconstructing strategy to facilitate corpus memory and a cluster-adaptive\nnegative sampling strategy to enhance the intra-cluster mapping ability.\nEmpirical results show that GDR obtains an average of 3.0 R@100 improvement on\nNQ dataset under multiple settings and has better scalability.", "field": "Computer Science", "categories": "cs.IR,cs.CL"}, {"arxiv_id": "2401.1049", "title": "Generalization Error Guaranteed Auto-Encoder-Based Nonlinear Model\n  Reduction for Operator Learning", "abstract": "Many physical processes in science and engineering are naturally represented\nby operators between infinite-dimensional function spaces. The problem of\noperator learning, in this context, seeks to extract these physical processes\nfrom empirical data, which is challenging due to the infinite or high\ndimensionality of data. An integral component in addressing this challenge is\nmodel reduction, which reduces both the data dimensionality and problem size.\nIn this paper, we utilize low-dimensional nonlinear structures in model\nreduction by investigating Auto-Encoder-based Neural Network (AENet). AENet\nfirst learns the latent variables of the input data and then learns the\ntransformation from these latent variables to corresponding output data. Our\nnumerical experiments validate the ability of AENet to accurately learn the\nsolution operator of nonlinear partial differential equations. Furthermore, we\nestablish a mathematical and statistical estimation theory that analyzes the\ngeneralization error of AENet. Our theoretical framework shows that the sample\ncomplexity of training AENet is intricately tied to the intrinsic dimension of\nthe modeled process, while also demonstrating the remarkable resilience of\nAENet to noise.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.10491", "title": "Knowledge Fusion of Large Language Models", "abstract": "While training large language models (LLMs) from scratch can generate models\nwith distinct functionalities and strengths, it comes at significant costs and\nmay result in redundant capabilities. Alternatively, a cost-effective and\ncompelling approach is to merge existing pre-trained LLMs into a more potent\nmodel. However, due to the varying architectures of these LLMs, directly\nblending their weights is impractical. In this paper, we introduce the notion\nof knowledge fusion for LLMs, aimed at combining the capabilities of existing\nLLMs and transferring them into a single LLM. By leveraging the generative\ndistributions of source LLMs, we externalize their collective knowledge and\nunique strengths, thereby potentially elevating the capabilities of the target\nmodel beyond those of any individual source LLM. We validate our approach using\nthree popular LLMs with different architectures--Llama-2, MPT, and\nOpenLLaMA--across various benchmarks and tasks. Our findings confirm that the\nfusion of LLMs can improve the performance of the target model across a range\nof capabilities such as reasoning, commonsense, and code generation. Our code,\nmodel weights, and data are public at\n\\url{https://github.com/fanqiwan/FuseLLM}.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.10495", "title": "Causal Layering via Conditional Entropy", "abstract": "Causal discovery aims to recover information about an unobserved causal graph\nfrom the observable data it generates. Layerings are orderings of the variables\nwhich place causes before effects. In this paper, we provide ways to recover\nlayerings of a graph by accessing the data via a conditional entropy oracle,\nwhen distributions are discrete. Our algorithms work by repeatedly removing\nsources or sinks from the graph. Under appropriate assumptions and\nconditioning, we can separate the sources or sinks from the remainder of the\nnodes by comparing their conditional entropy to the unconditional entropy of\ntheir noise. Our algorithms are provably correct and run in worst-case\nquadratic time. The main assumptions are faithfulness and injective noise, and\neither known noise entropies or weakly monotonically increasing noise entropies\nalong directed paths. In addition, we require one of either a very mild\nextension of faithfulness, or strictly monotonically increasing noise\nentropies, or expanding noise injectivity to include an additional single\nargument in the structural functions.", "field": "Computer Science", "categories": "cs.LG,cs.AI,stat.ME"}, {"arxiv_id": "2401.10498", "title": "Efficient Probabilistic Optimal Power Flow Assessment Using an Adaptive\n  Stochastic Spectral Embedding Surrogate Model", "abstract": "This paper presents an adaptive stochastic spectral embedding (ASSE) method\nto solve the probabilistic AC optimal power flow (AC-OPF), a critical aspect of\npower system operation. The proposed method can efficiently and accurately\nestimate the probabilistic characteristics of AC-OPF solutions. An adaptive\ndomain partition strategy and expansion coefficient calculation algorithm are\nintegrated to enhance its performance. Numerical studies on a 9-bus system\ndemonstrate that the proposed ASSE method offers accurate and fast evaluations\ncompared to the Monte Carlo simulations. A comparison with a sparse polynomial\nchaos expansion method, an existing surrogate model, further demonstrates its\nefficacy in accurately assessing the responses with strongly local behaviors.", "field": "Computer Science", "categories": "eess.SY,cs.SY"}, {"arxiv_id": "2401.10501", "title": "Enhancing medical vision-language contrastive learning via\n  inter-matching relation modelling", "abstract": "Medical image representations can be learned through medical vision-language\ncontrastive learning (mVLCL) where medical imaging reports are used as weak\nsupervision through image-text alignment. These learned image representations\ncan be transferred to and benefit various downstream medical vision tasks such\nas disease classification and segmentation. Recent mVLCL methods attempt to\nalign image sub-regions and the report keywords as local-matchings. However,\nthese methods aggregate all local-matchings via simple pooling operations while\nignoring the inherent relations between them. These methods therefore fail to\nreason between local-matchings that are semantically related, e.g.,\nlocal-matchings that correspond to the disease word and the location word\n(semantic-relations), and also fail to differentiate such clinically important\nlocal-matchings from others that correspond to less meaningful words, e.g.,\nconjunction words (importance-relations). Hence, we propose a mVLCL method that\nmodels the inter-matching relations between local-matchings via a\nrelation-enhanced contrastive learning framework (RECLF). In RECLF, we\nintroduce a semantic-relation reasoning module (SRM) and an importance-relation\nreasoning module (IRM) to enable more fine-grained report supervision for image\nrepresentation learning. We evaluated our method using four public benchmark\ndatasets on four downstream tasks, including segmentation, zero-shot\nclassification, supervised classification, and cross-modal retrieval. Our\nresults demonstrated the superiority of our RECLF over the state-of-the-art\nmVLCL methods with consistent improvements across single-modal and cross-modal\ntasks. These results suggest that our RECLF, by modelling the inter-matching\nrelations, can learn improved medical image representations with better\ngeneralization capabilities.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10504", "title": "A multi-dimensional analysis of usage counts, Mendeley readership, and\n  citations for journal and conference papers", "abstract": "This study analyzed 16,799 journal papers and 98,773 conference papers\npublished by IEEE Xplore in 2016 to investigate the relationships among usage\ncounts, Mendeley readership, and citations through descriptive, regression, and\nmediation analyses. Differences in the relationship among these metrics between\njournal and conference papers are also studied. Results showed that there is no\nsignificant difference between journal and conference papers in the\ndistribution patterns and accumulation rates of the three metrics. However, the\ncorrelation coefficients of the interrelationships between the three metrics\nwere lower in conference papers compared to journal papers. Secondly, funding,\ninternational collaboration, and open access are positively associated with all\nthree metrics, except for the case of funding on the usage metrics of\nconference papers. Furthermore, early Mendeley readership is a better predictor\nof citations than early usage counts and performs better for journal papers.\nFinally, we reveal that early Mendeley readership partially mediates between\nearly usage counts and citation counts in the journal and conference papers.\nThe main difference is that conference papers rely more on the direct effect of\nearly usage counts on citations. This study contributes to expanding the\nexisting knowledge on the relationships among usage counts, Mendeley\nreadership, and citations in journal and conference papers, providing new\ninsights into the relationship between the three metrics through mediation\nanalysis.", "field": "Computer Science", "categories": "cs.DL"}, {"arxiv_id": "2401.10506", "title": "FinSQL: Model-Agnostic LLMs-based Text-to-SQL Framework for Financial\n  Analysis", "abstract": "Text-to-SQL, which provides zero-code interface for operating relational\ndatabases, has gained much attention in financial analysis; because, financial\nprofessionals may not well-skilled in SQL programming. However, until now,\nthere is no practical Text-to-SQL benchmark dataset for financial analysis, and\nexisting Text-to-SQL methods have not considered the unique characteristics of\ndatabases in financial applications, such as commonly existing wide tables. To\naddress these issues, we collect a practical Text-to-SQL benchmark dataset and\npropose a model-agnostic Large Language Model (LLMs)-based Text-to-SQL\nframework for financial analysis. The benchmark dataset, BULL, is collected\nfrom the practical financial analysis business of Hundsun Technologies Inc.,\nincluding databases for fund, stock, and macro economy. Besides, the proposed\nLLMs-based Text-to-SQL framework, FinSQL, provides a systematic treatment for\nfinancial Text-to-SQL from the perspectives of prompt construction,\nparameter-efficient fine-tuning and output calibration. Extensive experimental\nresults on BULL demonstrate that FinSQL achieves the state-of-the-art\nText-to-SQL performance at a small cost; furthermore, FinSQL can bring up to\n36.64% performance improvement in scenarios requiring few-shot cross-database\nmodel transfer.", "field": "Computer Science", "categories": "cs.CL,cs.AI,cs.DB"}, {"arxiv_id": "2401.1051", "title": "A match made in consistency heaven: when large language models meet\n  evolutionary algorithms", "abstract": "Pre-trained large language models (LLMs) have powerful capabilities for\ngenerating creative natural text. Evolutionary algorithms (EAs) can discover\ndiverse solutions to complex real-world problems. Motivated by the common\ncollective and directionality of text sequence generation and evolution, this\npaper illustrates the strong consistency of LLMs and EAs, which includes\nmultiple one-to-one key characteristics: token embedding and genotype-phenotype\nmapping, position encoding and fitness shaping, position embedding and\nselection, attention and crossover, feed-forward neural network and mutation,\nmodel training and parameter update, and multi-task learning and\nmulti-objective optimization. Based on this consistency perspective, existing\ncoupling studies are analyzed, including evolutionary fine-tuning and\nLLM-enhanced EAs. Leveraging these insights, we outline a fundamental roadmap\nfor future research in coupling LLMs and EAs, while highlighting key challenges\nalong the way. The consistency not only reveals the evolution mechanism behind\nLLMs but also facilitates the development of evolved artificial agents that\napproach or surpass biological organisms.", "field": "Computer Science", "categories": "cs.NE,cs.AI,cs.CL,cs.LG"}, {"arxiv_id": "2401.10511", "title": "GMC-IQA: Exploiting Global-correlation and Mean-opinion Consistency for\n  No-reference Image Quality Assessment", "abstract": "Due to the subjective nature of image quality assessment (IQA), assessing\nwhich image has better quality among a sequence of images is more reliable than\nassigning an absolute mean opinion score for an image. Thus, IQA models are\nevaluated by global correlation consistency (GCC) metrics like PLCC and SROCC,\nrather than mean opinion consistency (MOC) metrics like MAE and MSE. However,\nmost existing methods adopt MOC metrics to define their loss functions, due to\nthe infeasible computation of GCC metrics during training. In this work, we\nconstruct a novel loss function and network to exploit Global-correlation and\nMean-opinion Consistency, forming a GMC-IQA framework. Specifically, we propose\na novel GCC loss by defining a pairwise preference-based rank estimation to\nsolve the non-differentiable problem of SROCC and introducing a queue mechanism\nto reserve previous data to approximate the global results of the whole data.\nMoreover, we propose a mean-opinion network, which integrates diverse opinion\nfeatures to alleviate the randomness of weight learning and enhance the model\nrobustness. Experiments indicate that our method outperforms SOTA methods on\nmultiple authentic datasets with higher accuracy and generalization. We also\nadapt the proposed loss to various networks, which brings better performance\nand more stable training.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10512", "title": "Exploring Color Invariance through Image-Level Ensemble Learning", "abstract": "In the field of computer vision, the persistent presence of color bias,\nresulting from fluctuations in real-world lighting and camera conditions,\npresents a substantial challenge to the robustness of models. This issue is\nparticularly pronounced in complex wide-area surveillance scenarios, such as\nperson re-identification and industrial dust segmentation, where models often\nexperience a decline in performance due to overfitting on color information\nduring training, given the presence of environmental variations. Consequently,\nthere is a need to effectively adapt models to cope with the complexities of\ncamera conditions. To address this challenge, this study introduces a learning\nstrategy named Random Color Erasing, which draws inspiration from ensemble\nlearning. This strategy selectively erases partial or complete color\ninformation in the training data without disrupting the original image\nstructure, thereby achieving a balanced weighting of color features and other\nfeatures within the neural network. This approach mitigates the risk of\noverfitting and enhances the model's ability to handle color variation, thereby\nimproving its overall robustness. The approach we propose serves as an ensemble\nlearning strategy, characterized by robust interpretability. A comprehensive\nanalysis of this methodology is presented in this paper. Across various tasks\nsuch as person re-identification and semantic segmentation, our approach\nconsistently improves strong baseline methods. Notably, in comparison to\nexisting methods that prioritize color robustness, our strategy significantly\nenhances performance in cross-domain scenarios. The code available at\n\\url{https://github.com/layumi/Person\\_reID\\_baseline\\_pytorch/blob/master/random\\_erasing.py}\nor \\url{https://github.com/finger-monkey/Data-Augmentation}.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10515", "title": "New Pathways in Coevolutionary Computation", "abstract": "The simultaneous evolution of two or more species with coupled fitness --\ncoevolution -- has been put to good use in the field of evolutionary\ncomputation. Herein, we present two new forms of coevolutionary algorithms,\nwhich we have recently designed and applied with success. OMNIREP is a\ncooperative coevolutionary algorithm that discovers both a representation and\nan encoding for solving a particular problem of interest. SAFE is a\ncommensalistic coevolutionary algorithm that maintains two coevolving\npopulations: a population of candidate solutions and a population of candidate\nobjective functions needed to measure solution quality during evolution.", "field": "Computer Science", "categories": "cs.NE"}, {"arxiv_id": "2401.10516", "title": "Episodic Reinforcement Learning with Expanded State-reward Space", "abstract": "Empowered by deep neural networks, deep reinforcement learning (DRL) has\ndemonstrated tremendous empirical successes in various domains, including\ngames, health care, and autonomous driving. Despite these advancements, DRL is\nstill identified as data-inefficient as effective policies demand vast numbers\nof environmental samples. Recently, episodic control (EC)-based model-free DRL\nmethods enable sample efficiency by recalling past experiences from episodic\nmemory. However, existing EC-based methods suffer from the limitation of\npotential misalignment between the state and reward spaces for neglecting the\nutilization of (past) retrieval states with extensive information, which\nprobably causes inaccurate value estimation and degraded policy performance. To\ntackle this issue, we introduce an efficient EC-based DRL framework with\nexpanded state-reward space, where the expanded states used as the input and\nthe expanded rewards used in the training both contain historical and current\ninformation. To be specific, we reuse the historical states retrieved by EC as\npart of the input states and integrate the retrieved MC-returns into the\nimmediate reward in each interactive transition. As a result, our method is\nable to simultaneously achieve the full utilization of retrieval information\nand the better evaluation of state values by a Temporal Difference (TD) loss.\nEmpirical results on challenging Box2d and Mujoco tasks demonstrate the\nsuperiority of our method over a recent sibling method and common baselines.\nFurther, we also verify our method's effectiveness in alleviating Q-value\noverestimation by additional experiments of Q-value comparison.", "field": "Computer Science", "categories": "cs.LG,cs.AI"}, {"arxiv_id": "2401.10518", "title": "Spatial-temporal Forecasting for Regions without Observations", "abstract": "Spatial-temporal forecasting plays an important role in many real-world\napplications, such as traffic forecasting, air pollutant forecasting,\ncrowd-flow forecasting, and so on. State-of-the-art spatial-temporal\nforecasting models take data-driven approaches and rely heavily on data\navailability. Such models suffer from accuracy issues when data is incomplete,\nwhich is common in reality due to the heavy costs of deploying and maintaining\nsensors for data collection. A few recent studies attempted to address the\nissue of incomplete data. They typically assume some data availability in a\nregion of interest either for a short period or at a few locations. In this\npaper, we further study spatial-temporal forecasting for a region of interest\nwithout any historical observations, to address scenarios such as unbalanced\nregion development, progressive deployment of sensors or lack of open data. We\npropose a model named STSM for the task. The model takes a contrastive\nlearning-based approach to learn spatial-temporal patterns from adjacent\nregions that have recorded data. Our key insight is to learn from the locations\nthat resemble those in the region of interest, and we propose a selective\nmasking strategy to enable the learning. As a result, our model outperforms\nadapted state-of-the-art models, reducing errors consistently over both traffic\nand air pollutant forecasting tasks. The source code is available at\nhttps://github.com/suzy0223/STSM.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.10519", "title": "A Wind-Aware Path Planning Method for UAV-Asisted Bridge Inspection", "abstract": "In response to the gap in considering wind conditions in the bridge\ninspection using unmanned aerial vehicle (UAV) , this paper proposes a path\nplanning method for UAVs that takes into account the influence of wind, based\non the simulated annealing algorithm. The algorithm considers the wind factors,\nincluding the influence of different wind speeds and directions at the same\ntime on the path planning of the UAV. Firstly, An environment model is\nconstructed specifically for UAV bridge inspection, taking into account the\nvarious objective functions and constraint conditions of UAVs. A more\nsophisticated and precise mathematical model is then developed based on this\nenvironmental model to enable efficient and effective UAV path planning.\nSecondly, the bridge separation planning model is applied in a novel way, and a\nseries of parameters are simulated, including the adjustment of the initial\ntemperature value. The experimental results demonstrate that, compared with\ntraditional local search algorithms, the proposed method achieves a cost\nreduction of 30.05\\% and significantly improves effectiveness. Compared to path\nplanning methods that do not consider wind factors, the proposed approach\nyields more realistic and practical results for UAV applications, as\ndemonstrated by its improved effectiveness in simulations. These findings\nhighlight the value of our method in facilitating more accurate and efficient\nUAV path planning in wind-prone environments.", "field": "Computer Science", "categories": "eess.SY,cs.RO,cs.SY"}, {"arxiv_id": "2401.10521", "title": "Cross-lingual Editing in Multilingual Language Models", "abstract": "The training of large language models (LLMs) necessitates substantial data\nand computational resources, and updating outdated LLMs entails significant\nefforts and resources. While numerous model editing techniques (METs) have\nemerged to efficiently update model outputs without retraining, their\neffectiveness in multilingual LLMs, where knowledge is stored in diverse\nlanguages, remains an underexplored research area. This research paper\nintroduces the cross-lingual model editing (\\textbf{XME}) paradigm, wherein a\nfact is edited in one language, and the subsequent update propagation is\nobserved across other languages. To investigate the XME paradigm, we conducted\nexperiments using BLOOM, mBERT, and XLM-RoBERTa using the two writing scripts:\n\\textit{Latin} (English, French, and Spanish) and \\textit{Indic} (Hindi,\nGujarati, and Bengali). The results reveal notable performance limitations of\nstate-of-the-art METs under the XME setting, mainly when the languages involved\nbelong to two distinct script families. These findings highlight the need for\nfurther research and development of XME techniques to address these challenges.\nFor more comprehensive information, the dataset used in this research and the\nassociated code are publicly available at the following\nURL\\url{https://github.com/lingo-iitgn/XME}.", "field": "Computer Science", "categories": "cs.CL,cs.AI"}, {"arxiv_id": "2401.10522", "title": "FARe: Fault-Aware GNN Training on ReRAM-based PIM Accelerators", "abstract": "Resistive random-access memory (ReRAM)-based processing-in-memory (PIM)\narchitecture is an attractive solution for training Graph Neural Networks\n(GNNs) on edge platforms. However, the immature fabrication process and limited\nwrite endurance of ReRAMs make them prone to hardware faults, thereby limiting\ntheir widespread adoption for GNN training. Further, the existing\nfault-tolerant solutions prove inadequate for effectively training GNNs in the\npresence of faults. In this paper, we propose a fault-aware framework referred\nto as FARe that mitigates the effect of faults during GNN training. FARe\noutperforms existing approaches in terms of both accuracy and timing overhead.\nExperimental results demonstrate that FARe framework can restore GNN test\naccuracy by 47.6% on faulty ReRAM hardware with a ~1% timing overhead compared\nto the fault-free counterpart.", "field": "Computer Science", "categories": "cs.AR,cs.LG,B.8.1"}, {"arxiv_id": "2401.10525", "title": "Focaler-IoU: More Focused Intersection over Union Loss", "abstract": "Bounding box regression plays a crucial role in the field of object\ndetection, and the positioning accuracy of object detection largely depends on\nthe loss function of bounding box regression. Existing researchs improve\nregression performance by utilizing the geometric relationship between bounding\nboxes, while ignoring the impact of difficult and easy sample distribution on\nbounding box regression. In this article, we analyzed the impact of difficult\nand easy sample distribution on regression results, and then proposed\nFocaler-IoU, which can improve detector performance in different detection\ntasks by focusing on different regression samples. Finally, comparative\nexperiments were conducted using existing advanced detectors and regression\nmethods for different detection tasks, and the detection performance was\nfurther improved by using the method proposed in this paper.Code is available\nat \\url{https://github.com/malagoutou/Focaler-IoU}.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10526", "title": "On mitigating stability-plasticity dilemma in CLIP-guided image morphing\n  via geodesic distillation loss", "abstract": "Large-scale language-vision pre-training models, such as CLIP, have achieved\nremarkable text-guided image morphing results by leveraging several\nunconditional generative models. However, existing CLIP-guided image morphing\nmethods encounter difficulties when morphing photorealistic images.\nSpecifically, existing guidance fails to provide detailed explanations of the\nmorphing regions within the image, leading to misguidance. In this paper, we\nobserved that such misguidance could be effectively mitigated by simply using a\nproper regularization loss. Our approach comprises two key components: 1) a\ngeodesic cosine similarity loss that minimizes inter-modality features (i.e.,\nimage and text) on a projected subspace of CLIP space, and 2) a latent\nregularization loss that minimizes intra-modality features (i.e., image and\nimage) on the image manifold. By replacing the na\\\"ive directional CLIP loss in\na drop-in replacement manner, our method achieves superior morphing results on\nboth images and videos for various benchmarks, including CLIP-inversion.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10527", "title": "A new approach to the Berlekamp-Massey-Sakata Algorithm. Improving\n  Locator Decoding", "abstract": "We study the problem of the computation of Groebner basis for the ideal of\nlinear recurring relations of a doubly periodic array. We find a set of indexes\nsuch that, along with some conditions, guarantees that the set of polynomials\nobtained at the last iteration in the Berlekamp-Massey-Sakata algorithm is\nexactly a Groebner basis for the mentioned ideal. Then, we apply these results\nto improve locator decoding in abelian codes.", "field": "Computer Science", "categories": "cs.IT,math.IT"}, {"arxiv_id": "2401.10529", "title": "Mementos: A Comprehensive Benchmark for Multimodal Large Language Model\n  Reasoning over Image Sequences", "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated proficiency in\nhandling a variety of visual-language tasks. However, current MLLM benchmarks\nare predominantly designed to evaluate reasoning based on static information\nabout a single image, and the ability of modern MLLMs to extrapolate from image\nsequences, which is essential for understanding our ever-changing world, has\nbeen less investigated. To address this challenge, this paper introduces\nMementos, a new benchmark designed to assess MLLMs' sequential image reasoning\nabilities. Mementos features 4,761 diverse image sequences with varying\nlengths. We also employ a GPT-4 assisted method to evaluate MLLM reasoning\nperformance. Through a careful evaluation of nine recent MLLMs on Mementos,\nincluding GPT-4V and Gemini, we find that they struggle to accurately describe\ndynamic information about given image sequences, often leading to\nhallucinations/misrepresentations of objects and their corresponding behaviors.\nOur quantitative analysis and case studies identify three key factors impacting\nMLLMs' sequential image reasoning: the correlation between object and\nbehavioral hallucinations, the influence of cooccurring behaviors, and the\ncompounding impact of behavioral hallucinations. Our dataset is available at\nhttps://github.com/umd-huang-lab/Mementos.", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.CL,cs.LG"}, {"arxiv_id": "2401.1053", "title": "NWPU-MOC: A Benchmark for Fine-grained Multi-category Object Counting in\n  Aerial Images", "abstract": "Object counting is a hot topic in computer vision, which aims to estimate the\nnumber of objects in a given image. However, most methods only count objects of\na single category for an image, which cannot be applied to scenes that need to\ncount objects with multiple categories simultaneously, especially in aerial\nscenes. To this end, this paper introduces a Multi-category Object Counting\n(MOC) task to estimate the numbers of different objects (cars, buildings,\nships, etc.) in an aerial image. Considering the absence of a dataset for this\ntask, a large-scale Dataset (NWPU-MOC) is collected, consisting of 3,416 scenes\nwith a resolution of 1024 $\\times$ 1024 pixels, and well-annotated using 14\nfine-grained object categories. Besides, each scene contains RGB and Near\nInfrared (NIR) images, of which the NIR spectrum can provide richer\ncharacterization information compared with only the RGB spectrum. Based on\nNWPU-MOC, the paper presents a multi-spectrum, multi-category object counting\nframework, which employs a dual-attention module to fuse the features of RGB\nand NIR and subsequently regress multi-channel density maps corresponding to\neach object category. In addition, to modeling the dependency between different\nchannels in the density map with each object category, a spatial contrast loss\nis designed as a penalty for overlapping predictions at the same spatial\nposition. Experimental results demonstrate that the proposed method achieves\nstate-of-the-art performance compared with some mainstream counting algorithms.\nThe dataset, code and models are publicly available at\nhttps://github.com/lyongo/NWPU-MOC.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10531", "title": "Lessons Learned from Designing an Open-Source Automated Feedback System\n  for STEM Education", "abstract": "As distance learning becomes increasingly important and artificial\nintelligence tools continue to advance, automated systems for individual\nlearning have attracted significant attention. However, the scarcity of\nopen-source online tools that are capable of providing personalized feedback\nhas restricted the widespread implementation of research-based feedback\nsystems. In this work, we present RATsApp, an open-source automated feedback\nsystem (AFS) that incorporates research-based features such as formative\nfeedback. The system focuses on core STEM competencies such as mathematical\ncompetence, representational competence, and data literacy. It also allows\nlecturers to monitor students' progress. We conducted a survey based on the\ntechnology acceptance model (TAM2) among a set of students (N=64). Our findings\nconfirm the applicability of the TAM2 framework, revealing that factors such as\nthe relevance of the studies, output quality, and ease of use significantly\ninfluence the perceived usefulness. We also found a linear relation between the\nperceived usefulness and the intention to use, which in turn is a significant\npredictor of the frequency of use. Moreover, the formative feedback feature of\nRATsApp received positive feedback, indicating its potential as an educational\ntool. Furthermore, as an open-source platform, RATsApp encourages public\ncontributions to its ongoing development, fostering a collaborative approach to\nimprove educational tools.", "field": "Computer Science", "categories": "cs.CY,physics.ed-ph"}, {"arxiv_id": "2401.10535", "title": "The \"Colonial Impulse\" of Natural Language Processing: An Audit of\n  Bengali Sentiment Analysis Tools and Their Identity-based Biases", "abstract": "While colonization has sociohistorically impacted people's identities across\nvarious dimensions, those colonial values and biases continue to be perpetuated\nby sociotechnical systems. One category of sociotechnical systems--sentiment\nanalysis tools--can also perpetuate colonial values and bias, yet less\nattention has been paid to how such tools may be complicit in perpetuating\ncoloniality, although they are often used to guide various practices (e.g.,\ncontent moderation). In this paper, we explore potential bias in sentiment\nanalysis tools in the context of Bengali communities that have experienced and\ncontinue to experience the impacts of colonialism. Drawing on identity\ncategories most impacted by colonialism amongst local Bengali communities, we\nfocused our analytic attention on gender, religion, and nationality. We\nconducted an algorithmic audit of all sentiment analysis tools for Bengali,\navailable on the Python package index (PyPI) and GitHub. Despite similar\nsemantic content and structure, our analyses showed that in addition to\ninconsistencies in output from different tools, Bengali sentiment analysis\ntools exhibit bias between different identity categories and respond\ndifferently to different ways of identity expression. Connecting our findings\nwith colonially shaped sociocultural structures of Bengali communities, we\ndiscuss the implications of downstream bias of sentiment analysis tools.", "field": "Computer Science", "categories": "cs.CL,cs.CY,cs.HC,cs.LG"}, {"arxiv_id": "2401.10536", "title": "Speech Swin-Transformer: Exploring a Hierarchical Transformer with\n  Shifted Windows for Speech Emotion Recognition", "abstract": "Swin-Transformer has demonstrated remarkable success in computer vision by\nleveraging its hierarchical feature representation based on Transformer. In\nspeech signals, emotional information is distributed across different scales of\nspeech features, e.\\,g., word, phrase, and utterance. Drawing above\ninspiration, this paper presents a hierarchical speech Transformer with shifted\nwindows to aggregate multi-scale emotion features for speech emotion\nrecognition (SER), called Speech Swin-Transformer. Specifically, we first\ndivide the speech spectrogram into segment-level patches in the time domain,\ncomposed of multiple frame patches. These segment-level patches are then\nencoded using a stack of Swin blocks, in which a local window Transformer is\nutilized to explore local inter-frame emotional information across frame\npatches of each segment patch. After that, we also design a shifted window\nTransformer to compensate for patch correlations near the boundaries of segment\npatches. Finally, we employ a patch merging operation to aggregate\nsegment-level emotional features for hierarchical speech representation by\nexpanding the receptive field of Transformer from frame-level to segment-level.\nExperimental results demonstrate that our proposed Speech Swin-Transformer\noutperforms the state-of-the-art methods.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.10537", "title": "Learning Position-Aware Implicit Neural Network for Real-World Face\n  Inpainting", "abstract": "Face inpainting requires the model to have a precise global understanding of\nthe facial position structure. Benefiting from the powerful capabilities of\ndeep learning backbones, recent works in face inpainting have achieved decent\nperformance in ideal setting (square shape with $512px$). However, existing\nmethods often produce a visually unpleasant result, especially in the\nposition-sensitive details (e.g., eyes and nose), when directly applied to\narbitrary-shaped images in real-world scenarios. The visually unpleasant\nposition-sensitive details indicate the shortcomings of existing methods in\nterms of position information processing capability. In this paper, we propose\nan \\textbf{I}mplicit \\textbf{N}eural \\textbf{I}npainting \\textbf{N}etwork\n(IN$^2$) to handle arbitrary-shape face images in real-world scenarios by\nexplicit modeling for position information. Specifically, a downsample\nprocessing encoder is proposed to reduce information loss while obtaining the\nglobal semantic feature. A neighbor hybrid attention block is proposed with a\nhybrid attention mechanism to improve the facial understanding ability of the\nmodel without restricting the shape of the input. Finally, an implicit neural\npyramid decoder is introduced to explicitly model position information and\nbridge the gap between low-resolution features and high-resolution output.\nExtensive experiments demonstrate the superiority of the proposed method in\nreal-world face inpainting task.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10538", "title": "Deterministic Simple $(1+\\varepsilon)\u0394$-Edge-Coloring in\n  Near-Linear Time", "abstract": "We study the edge-coloring problem in simple $n$-vertex $m$-edge graphs with\nmaximum degree $\\Delta$. This is one of the most classical and fundamental\ngraph-algorithmic problems. Vizing's celebrated theorem provides\n$(\\Delta+1)$-edge-coloring in $O(m\\cdot n)$ deterministic time. This running\ntime was improved to $O\\left(m\\cdot\\min\\left\\{\\Delta\\cdot\\log n,\n\\sqrt{n}\\right\\}\\right)$. It is also well-known that\n$3\\left\\lceil\\frac{\\Delta}{2}\\right\\rceil$-edge-coloring can be computed in\n$O(m\\cdot\\log\\Delta)$ time deterministically. Duan et al. devised a randomized\n$(1+\\varepsilon)\\Delta$-edge-coloring algorithm with running time\n$O\\left(m\\cdot\\frac{\\log^6 n}{\\varepsilon^2}\\right)$. It was however open if\nthere exists a deterministic near-linear time algorithm for this basic problem.\nWe devise a simple deterministic $(1+\\varepsilon)\\Delta$-edge-coloring\nalgorithm with running time $O\\left(m\\cdot\\frac{\\log n}{\\varepsilon}\\right)$.\nWe also devise a randomized $(1+\\varepsilon)\\Delta$-edge-coloring algorithm\nwith running time $O(m\\cdot(\\varepsilon^{-18}+\\log(\\varepsilon\\cdot\\Delta)))$.\nFor $\\varepsilon\\geq\\frac{1}{\\log^{1/18}\\Delta}$, this running time is\n$O(m\\cdot\\log\\Delta)$.", "field": "Computer Science", "categories": "cs.DS"}, {"arxiv_id": "2401.10539", "title": "Quality-Diversity Algorithms Can Provably Be Helpful for Optimization", "abstract": "Quality-Diversity (QD) algorithms are a new type of Evolutionary Algorithms\n(EAs), aiming to find a set of high-performing, yet diverse solutions. They\nhave found many successful applications in reinforcement learning and robotics,\nhelping improve the robustness in complex environments. Furthermore, they often\nempirically find a better overall solution than traditional search algorithms\nwhich explicitly search for a single highest-performing solution. However,\ntheir theoretical analysis is far behind, leaving many fundamental questions\nunexplored. In this paper, we try to shed some light on the optimization\nability of QD algorithms via rigorous running time analysis. By comparing the\npopular QD algorithm MAP-Elites with $(\\mu+1)$-EA (a typical EA focusing on\nfinding better objective values only), we prove that on two NP-hard problem\nclasses with wide applications, i.e., monotone approximately submodular\nmaximization with a size constraint, and set cover, MAP-Elites can achieve the\n(asymptotically) optimal polynomial-time approximation ratio, while\n$(\\mu+1)$-EA requires exponential expected time on some instances. This\nprovides theoretical justification for that QD algorithms can be helpful for\noptimization, and discloses that the simultaneous search for high-performing\nsolutions with diverse behaviors can provide stepping stones to good overall\nsolutions and help avoid local optima.", "field": "Computer Science", "categories": "cs.NE"}, {"arxiv_id": "2401.10541", "title": "I-SplitEE: Image classification in Split Computing DNNs with Early Exits", "abstract": "The recent advances in Deep Neural Networks (DNNs) stem from their\nexceptional performance across various domains. However, their inherent large\nsize hinders deploying these networks on resource-constrained devices like\nedge, mobile, and IoT platforms. Strategies have emerged, from partial cloud\ncomputation offloading (split computing) to integrating early exits within DNN\nlayers. Our work presents an innovative unified approach merging early exits\nand split computing. We determine the 'splitting layer', the optimal depth in\nthe DNN for edge device computations, and whether to infer on edge device or be\noffloaded to the cloud for inference considering accuracy, computational\nefficiency, and communication costs. Also, Image classification faces diverse\nenvironmental distortions, influenced by factors like time of day, lighting,\nand weather. To adapt to these distortions, we introduce I-SplitEE, an online\nunsupervised algorithm ideal for scenarios lacking ground truths and with\nsequential data. Experimental validation using Caltech-256 and Cifar-10\ndatasets subjected to varied distortions showcases I-SplitEE's ability to\nreduce costs by a minimum of 55% with marginal performance degradation of at\nmost 5%.", "field": "Computer Science", "categories": "cs.LG,cs.CV,cs.DC"}, {"arxiv_id": "2401.10544", "title": "AAT: Adapting Audio Transformer for Various Acoustics Recognition Tasks", "abstract": "Recently, Transformers have been introduced into the field of acoustics\nrecognition. They are pre-trained on large-scale datasets using methods such as\nsupervised learning and semi-supervised learning, demonstrating robust\ngenerality--It fine-tunes easily to downstream tasks and shows more robust\nperformance. However, the predominant fine-tuning method currently used is\nstill full fine-tuning, which involves updating all parameters during training.\nThis not only incurs significant memory usage and time costs but also\ncompromises the model's generality. Other fine-tuning methods either struggle\nto address this issue or fail to achieve matching performance. Therefore, we\nconducted a comprehensive analysis of existing fine-tuning methods and proposed\nan efficient fine-tuning approach based on Adapter tuning, namely AAT. The core\nidea is to freeze the audio Transformer model and insert extra learnable\nAdapters, efficiently acquiring downstream task knowledge without compromising\nthe model's original generality. Extensive experiments have shown that our\nmethod achieves performance comparable to or even superior to full fine-tuning\nwhile optimizing only 7.118% of the parameters. It also demonstrates\nsuperiority over other fine-tuning methods.", "field": "Computer Science", "categories": "cs.SD,cs.AI,eess.AS"}, {"arxiv_id": "2401.10545", "title": "Understanding Biases in ChatGPT-based Recommender Systems: Provider\n  Fairness, Temporal Stability, and Recency", "abstract": "This study explores the nuanced capabilities and inherent biases of\nRecommender Systems using Large Language Models (RecLLMs), with a focus on\nChatGPT-based systems. It studies into the contrasting behaviors of generative\nmodels and traditional collaborative filtering models in movie recommendations.\nThe research primarily investigates prompt design strategies and their impact\non various aspects of recommendation quality, including accuracy, provider\nfairness, diversity, stability, genre dominance, and temporal freshness\n(recency).\n  Our experimental analysis reveals that the introduction of specific 'system\nroles' and 'prompt strategies' in RecLLMs significantly influences their\nperformance. For instance, role-based prompts enhance fairness and diversity in\nrecommendations, mitigating popularity bias. We find that while GPT-based\nmodels do not always match the performance of CF baselines, they exhibit a\nunique tendency to recommend newer and more diverse movie genres. Notably,\nGPT-based models tend to recommend more recent films, particularly those\nreleased post-2000, and show a preference for genres like \\sq{Drama} and\nComedy, and Romance (compared to CF Action, Adventure) presumably due to the\nRecLLMs' training on varied data sets, which allows them to capture recent\ntrends and discussions more effectively than CF models. Interestingly, our\nresults demonstrate that the 'Simple' and 'Chain of Thought (COT)' paradigms\nyield the highest accuracy. These findings imply the potential of combining\nthese strategies with scenarios that favor more recent content, thereby\noffering a more balanced and up-to-date recommendation experience. This study\ncontributes significantly to the understanding of emerging RecLLMs,\nparticularly in the context of harms and biases within these systems.", "field": "Computer Science", "categories": "cs.IR"}, {"arxiv_id": "2401.10546", "title": "High-order BDF convolution quadrature for stochastic fractional\n  evolution equations driven by integrated additive noise", "abstract": "The numerical analysis of stochastic time fractional evolution equations\npresents considerable challenges due to the limited regularity of the model\ncaused by the nonlocal operator and the presence of noise.\n  The existing time-stepping methods exhibit a significantly low order\nconvergence rate. In this work, we introduce a smoothing technique and develop\nthe novel high-order schemes for solving the linear stochastic fractional\nevolution equations driven by integrated additive noise. Our approach involves\nregularizing the additive noise through an $m$-fold integral-differential\ncalculus, and discretizing the equation using the $k$-step BDF convolution\nquadrature. This novel method, which we refer to as the ID$m$-BDF$k$ method, is\nable to achieve higher-order convergence in solving the stochastic models. Our\ntheoretical analysis reveals that the convergence rate of the ID$2$-BDF2 method\nis $O(\\tau^{\\alpha + \\gamma -1/2})$ for $1< \\alpha + \\gamma \\leq 5/2$, and\n$O(\\tau^{2})$ for $5/2< \\alpha + \\gamma <3$, where $\\alpha \\in (1, 2)$ and\n$\\gamma \\in (0, 1)$ denote the time fractional order and the order of the\nintegrated noise, respectively. Furthermore, this convergence rate could be\nimproved to $O(\\tau^{\\alpha + \\gamma -1/2})$ for any $\\alpha \\in (1, 2)$ and\n$\\gamma \\in (0, 1)$, if we employ the ID$3$-BDF3 method. The argument could be\neasily extended to the subdiffusion model with $\\alpha \\in (0, 1)$. Numerical\nexamples are provided to support and complement the theoretical findings.", "field": "Computer Science", "categories": "math.NA,cs.NA"}, {"arxiv_id": "2401.10547", "title": "PhoGAD: Graph-based Anomaly Behavior Detection with Persistent Homology\n  Optimization", "abstract": "A multitude of toxic online behaviors, ranging from network attacks to\nanonymous traffic and spam, have severely disrupted the smooth operation of\nnetworks. Due to the inherent sender-receiver nature of network behaviors,\ngraph-based frameworks are commonly used for detecting anomalous behaviors.\nHowever, in real-world scenarios, the boundary between normal and anomalous\nbehaviors tends to be ambiguous. The local heterophily of graphs interferes\nwith the detection, and existing methods based on nodes or edges introduce\nunwanted noise into representation results, thereby impacting the effectiveness\nof detection. To address these issues, we propose PhoGAD, a graph-based anomaly\ndetection framework. PhoGAD leverages persistent homology optimization to\nclarify behavioral boundaries. Building upon this, the weights of adjacent\nedges are designed to mitigate the effects of local heterophily. Subsequently,\nto tackle the noise problem, we conduct a formal analysis and propose a\ndisentangled representation-based explicit embedding method, ultimately\nachieving anomaly behavior detection. Experiments on intrusion, traffic, and\nspam datasets verify that PhoGAD has surpassed the performance of\nstate-of-the-art (SOTA) frameworks in detection efficacy. Notably, PhoGAD\ndemonstrates robust detection even with diminished anomaly proportions,\nhighlighting its applicability to real-world scenarios. The analysis of\npersistent homology demonstrates its effectiveness in capturing the topological\nstructure formed by normal edge features. Additionally, ablation experiments\nvalidate the effectiveness of the innovative mechanisms integrated within\nPhoGAD.", "field": "Computer Science", "categories": "cs.LG,cs.SI"}, {"arxiv_id": "2401.10549", "title": "Unified View Imputation and Feature Selection Learning for Incomplete\n  Multi-view Data", "abstract": "Although multi-view unsupervised feature selection (MUFS) is an effective\ntechnology for reducing dimensionality in machine learning, existing methods\ncannot directly deal with incomplete multi-view data where some samples are\nmissing in certain views. These methods should first apply predetermined values\nto impute missing data, then perform feature selection on the complete dataset.\nSeparating imputation and feature selection processes fails to capitalize on\nthe potential synergy where local structural information gleaned from feature\nselection could guide the imputation, thereby improving the feature selection\nperformance in turn. Additionally, previous methods only focus on leveraging\nsamples' local structure information, while ignoring the intrinsic locality of\nthe feature space. To tackle these problems, a novel MUFS method, called\nUNified view Imputation and Feature selectIon lEaRning (UNIFIER), is proposed.\nUNIFIER explores the local structure of multi-view data by adaptively learning\nsimilarity-induced graphs from both the sample and feature spaces. Then,\nUNIFIER dynamically recovers the missing views, guided by the sample and\nfeature similarity graphs during the feature selection procedure. Furthermore,\nthe half-quadratic minimization technique is used to automatically weight\ndifferent instances, alleviating the impact of outliers and unreliable restored\ndata. Comprehensive experimental results demonstrate that UNIFIER outperforms\nother state-of-the-art methods.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.10553", "title": "Single-set cubical categories and their formalisation with a proof\n  assistant", "abstract": "We introduce a single-set axiomatisation of cubical $\\omega$-categories,\nincluding connections and inverses. We justify these axioms by establishing a\nseries of equivalences between the category of single-set cubical\n$\\omega$-categories, and their variants with connections and inverses, and the\ncorresponding cubical $\\omega$-categories. We also report on the formalisation\nof cubical $\\omega$-categories with the Isabelle/HOL proof assistant, which has\nbeen instrumental in finding the single-set axioms.", "field": "Computer Science", "categories": "cs.LO,math.CT,18N30, 68V15, 03B35, 68Q42"}, {"arxiv_id": "2401.10556", "title": "Symbol as Points: Panoptic Symbol Spotting via Point-based\n  Representation", "abstract": "This work studies the problem of panoptic symbol spotting, which is to spot\nand parse both countable object instances (windows, doors, tables, etc.) and\nuncountable stuff (wall, railing, etc.) from computer-aided design (CAD)\ndrawings. Existing methods typically involve either rasterizing the vector\ngraphics into images and using image-based methods for symbol spotting, or\ndirectly building graphs and using graph neural networks for symbol\nrecognition. In this paper, we take a different approach, which treats graphic\nprimitives as a set of 2D points that are locally connected and use point cloud\nsegmentation methods to tackle it. Specifically, we utilize a point transformer\nto extract the primitive features and append a mask2former-like spotting head\nto predict the final output. To better use the local connection information of\nprimitives and enhance their discriminability, we further propose the attention\nwith connection module (ACM) and contrastive connection learning scheme (CCL).\nFinally, we propose a KNN interpolation mechanism for the mask attention module\nof the spotting head to better handle primitive mask downsampling, which is\nprimitive-level in contrast to pixel-level for the image. Our approach, named\nSymPoint, is simple yet effective, outperforming recent state-of-the-art method\nGAT-CADNet by an absolute increase of 9.6% PQ and 10.4% RQ on the FloorPlanCAD\ndataset. The source code and models will be available at\nhttps://github.com/nicehuster/SymPoint.", "field": "Computer Science", "categories": "cs.CV,cs.GR"}, {"arxiv_id": "2401.10557", "title": "A deep learning initialized iterative method for Navier-Stokes Darcy\n  model", "abstract": "A deep learning initialized iterative (Int-Deep) method is developed for\nnumerically solving Navier-Stokes Darcy model. For this purpose, Newton\niterative method is mentioned for solving the relative finite element\ndiscretized problem. It is proved that this method converges quadratically with\nthe convergence rate independent of the finite element mesh size under certain\nstandard conditions. Later on, a deep learning algorithm is proposed for\nsolving this nonlinear coupled problem. Following the ideas of an earlier work\nby Huang, Wang and Yang (2020), an Int-Deep algorithm is constructed for the\nprevious problem in order to further improve the computational efficiency. A\nseries of numerical examples are reported to confirm that the Int-Deep\nalgorithm converges to the true solution rapidly and is robust with respect to\nthe physical parameters in the model.", "field": "Computer Science", "categories": "math.NA,cs.NA"}, {"arxiv_id": "2401.10559", "title": "OrchMoE: Efficient Multi-Adapter Learning with Task-Skill Synergy", "abstract": "We advance the field of Parameter-Efficient Fine-Tuning (PEFT) with our novel\nmulti-adapter method, OrchMoE, which capitalizes on modular skill architecture\nfor enhanced forward transfer in neural networks. Unlike prior models that\ndepend on explicit task identification inputs, OrchMoE automatically discerns\ntask categories, streamlining the learning process. This is achieved through an\nintegrated mechanism comprising an Automatic Task Classification module and a\nTask-Skill Allocation module, which collectively deduce task-specific\nclassifications and tailor skill allocation matrices. Our extensive evaluations\non the 'Super Natural Instructions' dataset, featuring 1,600 diverse\ninstructional tasks, indicate that OrchMoE substantially outperforms comparable\nmulti-adapter baselines in terms of both performance and sample utilization\nefficiency, all while operating within the same parameter constraints. These\nfindings suggest that OrchMoE offers a significant leap forward in multi-task\nlearning efficiency.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.CL"}, {"arxiv_id": "2401.1056", "title": "360ORB-SLAM: A Visual SLAM System for Panoramic Images with Depth\n  Completion Network", "abstract": "To enhance the performance and effect of AR/VR applications and visual\nassistance and inspection systems, visual simultaneous localization and mapping\n(vSLAM) is a fundamental task in computer vision and robotics. However,\ntraditional vSLAM systems are limited by the camera's narrow field-of-view,\nresulting in challenges such as sparse feature distribution and lack of dense\ndepth information. To overcome these limitations, this paper proposes a\n360ORB-SLAM system for panoramic images that combines with a depth completion\nnetwork. The system extracts feature points from the panoramic image, utilizes\na panoramic triangulation module to generate sparse depth information, and\nemploys a depth completion network to obtain a dense panoramic depth map.\nExperimental results on our novel panoramic dataset constructed based on Carla\ndemonstrate that the proposed method achieves superior scale accuracy compared\nto existing monocular SLAM methods and effectively addresses the challenges of\nfeature association and scale ambiguity. The integration of the depth\ncompletion network enhances system stability and mitigates the impact of\ndynamic elements on SLAM performance.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10564", "title": "Dream360: Diverse and Immersive Outdoor Virtual Scene Creation via\n  Transformer-Based 360 Image Outpainting", "abstract": "360 images, with a field-of-view (FoV) of 180x360, provide immersive and\nrealistic environments for emerging virtual reality (VR) applications, such as\nvirtual tourism, where users desire to create diverse panoramic scenes from a\nnarrow FoV photo they take from a viewpoint via portable devices. It thus\nbrings us to a technical challenge: `How to allow the users to freely create\ndiverse and immersive virtual scenes from a narrow FoV image with a specified\nviewport?' To this end, we propose a transformer-based 360 image outpainting\nframework called Dream360, which can generate diverse, high-fidelity, and\nhigh-resolution panoramas from user-selected viewports, considering the\nspherical properties of 360 images. Compared with existing methods, e.g., [3],\nwhich primarily focus on inputs with rectangular masks and central locations\nwhile overlooking the spherical property of 360 images, our Dream360 offers\nhigher outpainting flexibility and fidelity based on the spherical\nrepresentation. Dream360 comprises two key learning stages: (I) codebook-based\npanorama outpainting via Spherical-VQGAN (S-VQGAN), and (II) frequency-aware\nrefinement with a novel frequency-aware consistency loss. Specifically, S-VQGAN\nlearns a sphere-specific codebook from spherical harmonic (SH) values,\nproviding a better representation of spherical data distribution for scene\nmodeling. The frequency-aware refinement matches the resolution and further\nimproves the semantic consistency and visual fidelity of the generated results.\nOur Dream360 achieves significantly lower Frechet Inception Distance (FID)\nscores and better visual fidelity than existing methods. We also conducted a\nuser study involving 15 participants to interactively evaluate the quality of\nthe generated results in VR, demonstrating the flexibility and superiority of\nour Dream360 framework.", "field": "Computer Science", "categories": "cs.CV,cs.HC"}, {"arxiv_id": "2401.10566", "title": "Robust Multi-Modal Density Estimation", "abstract": "Development of multi-modal, probabilistic prediction models has lead to a\nneed for comprehensive evaluation metrics. While several metrics can\ncharacterize the accuracy of machine-learned models (e.g., negative\nlog-likelihood, Jensen-Shannon divergence), these metrics typically operate on\nprobability densities. Applying them to purely sample-based prediction models\nthus requires that the underlying density function is estimated. However,\ncommon methods such as kernel density estimation (KDE) have been demonstrated\nto lack robustness, while more complex methods have not been evaluated in\nmulti-modal estimation problems. In this paper, we present ROME (RObust\nMulti-modal density Estimator), a non-parametric approach for density\nestimation which addresses the challenge of estimating multi-modal, non-normal,\nand highly correlated distributions. ROME utilizes clustering to segment a\nmulti-modal set of samples into multiple uni-modal ones and then combines\nsimple KDE estimates obtained for individual clusters in a single multi-modal\nestimate. We compared our approach to state-of-the-art methods for density\nestimation as well as ablations of ROME, showing that it not only outperforms\nestablished methods but is also more robust to a variety of distributions. Our\nresults demonstrate that ROME can overcome the issues of over-fitting and\nover-smoothing exhibited by other estimators, promising a more robust\nevaluation of probabilistic machine learning models.", "field": "Computer Science", "categories": "cs.LG,stat.ML"}, {"arxiv_id": "2401.10567", "title": "Self-training from Self-memory in Data-to-text Generation", "abstract": "This paper introduces a novel training model, self-training from self-memory\n(STSM) in data-to-text generation (DTG), allowing the model to self-train on\nsubsets, including self-memory as outputs inferred directly from the trained\nmodels and/or the new data. The quality of self-memory is validated by two\nmodels, data-to-text (D2T) and text-to-data (T2D), by two pre-defined\nconditions: (1) the appearance of all source values in the outputs of the D2T\nmodel and (2) the ability to convert back to source data in the outputs in the\nT2D model. We utilize a greedy algorithm to generate shorter D2T outputs if\nthey contain all source values. Subsequently, we use the T2D model to confirm\nthat these outputs can capture input relationships by demonstrating their\ncapacity to convert text back into data. With 30% of the dataset, we can train\nthe D2T model with a competitive performance compared to full training in the\nsame setup. We experiment with our model on two datasets, E2E NLG and DART.\nSTSM offers the D2T model a generalization capability from its subset memory\nwhile reducing training data volume. Ultimately, we anticipate that this paper\nwill contribute to continual learning solutions that adapt to new training\ndata, incorporating it as a form of self-memory in DTG tasks. The curated\ndataset is publicly available at: https://github.com/hoangthangta/STSM.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.10568", "title": "CivRealm: A Learning and Reasoning Odyssey in Civilization for\n  Decision-Making Agents", "abstract": "The generalization of decision-making agents encompasses two fundamental\nelements: learning from past experiences and reasoning in novel contexts.\nHowever, the predominant emphasis in most interactive environments is on\nlearning, often at the expense of complexity in reasoning. In this paper, we\nintroduce CivRealm, an environment inspired by the Civilization game.\nCivilization's profound alignment with human history and society necessitates\nsophisticated learning, while its ever-changing situations demand strong\nreasoning to generalize. Particularly, CivRealm sets up an\nimperfect-information general-sum game with a changing number of players; it\npresents a plethora of complex features, challenging the agent to deal with\nopen-ended stochastic environments that require diplomacy and negotiation\nskills. Within CivRealm, we provide interfaces for two typical agent types:\ntensor-based agents that focus on learning, and language-based agents that\nemphasize reasoning. To catalyze further research, we present initial results\nfor both paradigms. The canonical RL-based agents exhibit reasonable\nperformance in mini-games, whereas both RL- and LLM-based agents struggle to\nmake substantial progress in the full game. Overall, CivRealm stands as a\nunique learning and reasoning challenge for decision-making agents. The code is\navailable at https://github.com/bigai-ai/civrealm.", "field": "Computer Science", "categories": "cs.AI"}, {"arxiv_id": "2401.10578", "title": "3D Shape Completion on Unseen Categories:A Weakly-supervised Approach", "abstract": "3D shapes captured by scanning devices are often incomplete due to occlusion.\n3D shape completion methods have been explored to tackle this limitation.\nHowever, most of these methods are only trained and tested on a subset of\ncategories, resulting in poor generalization to unseen categories. In this\npaper, we introduce a novel weakly-supervised framework to reconstruct the\ncomplete shapes from unseen categories. We first propose an end-to-end\nprior-assisted shape learning network that leverages data from the seen\ncategories to infer a coarse shape. Specifically, we construct a prior bank\nconsisting of representative shapes from the seen categories. Then, we design a\nmulti-scale pattern correlation module for learning the complete shape of the\ninput by analyzing the correlation between local patterns within the input and\nthe priors at various scales. In addition, we propose a self-supervised shape\nrefinement model to further refine the coarse shape. Considering the shape\nvariability of 3D objects across categories, we construct a category-specific\nprior bank to facilitate shape refinement. Then, we devise a voxel-based\npartial matching loss and leverage the partial scans to drive the refinement\nprocess. Extensive experimental results show that our approach is superior to\nstate-of-the-art methods by a large margin.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.1058", "title": "PHOENIX: Open-Source Language Adaption for Direct Preference\n  Optimization", "abstract": "Large language models have gained immense importance in recent years and have\ndemonstrated outstanding results in solving various tasks. However, despite\nthese achievements, many questions remain unanswered in the context of large\nlanguage models. Besides the optimal use of the models for inference and the\nalignment of the results to the desired specifications, the transfer of models\nto other languages is still an underdeveloped area of research. The recent\npublication of models such as Llama-2 and Zephyr has provided new insights into\narchitectural improvements and the use of human feedback. However, insights\ninto adapting these techniques to other languages remain scarce. In this paper,\nwe build on latest improvements and apply the Direct Preference\nOptimization(DPO) approach to the German language. The model is available at\nhttps://huggingface.co/DRXD1000/Phoenix.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.10582", "title": "Exploiting Kubernetes' Image Pull Implementation to Deny Node\n  Availability", "abstract": "Kubernetes (K8s) has grown in popularity over the past few years to become\nthe de-facto standard for container orchestration in cloud-native environments.\nWhile research is not new to topics such as containerization and access control\nsecurity, the Application Programming Interface (API) interactions between K8s\nand its runtime interfaces have not been studied thoroughly. In particular, the\nCRI-API is responsible for abstracting the container runtime, managing the\ncreation and lifecycle of containers along with the downloads of the respective\nimages. However, this decoupling of concerns and the abstraction of the\ncontainer runtime renders K8s unaware of the status of the downloading process\nof the container images, obstructing the monitoring of the resources allocated\nto such process. In this paper, we discuss how this lack of status information\ncan be exploited as a Denial of Service attack in a K8s cluster. We show that\nsuch attacks can generate up to 95% average CPU usage, prevent downloading new\ncontainer images, and increase I/O and network usage for a potentially\nunlimited amount of time. Finally, we propose two possible mitigation\nstrategies: one, implemented as a stopgap solution, and another, requiring more\nradical architectural changes in the relationship between K8s and the CRI-API.", "field": "Computer Science", "categories": "cs.CR"}, {"arxiv_id": "2401.10584", "title": "Fast winning strategies for the attacker in eternal domination", "abstract": "Dominating sets in graphs are often used to model some monitoring of the\ngraph: guards are posted on the vertices of the dominating set, and they can\nthus react to attacks occurring on the unguarded vertices by moving there\n(yielding a new set of guards, which may not be dominating anymore). A\ndominating set is eternal if it can endlessly resist to attacks. From the\nattacker's perspective, if we are given a non-eternal dominating set, the\nquestion is to determine how fast can we provoke an attack that cannot be\nhandled by a neighboring guard. We investigate this question from a\ncomputational complexity point of view, by showing that this question is\nPSPACE-hard, even for graph classes where finding a minimum eternal dominating\nset is in P. We then complement this result by giving polynomial time\nalgorithms for cographs and trees, and showing a connection with tree-depth for\nthe latter. We also investigate the problem from a parameterized complexity\nperspective, mainly considering two parameters: the number of guards and the\nnumber of steps.", "field": "Computer Science", "categories": "cs.DM,math.CO,68R10,G.2.2"}, {"arxiv_id": "2401.10586", "title": "PuriDefense: Randomized Local Implicit Adversarial Purification for\n  Defending Black-box Query-based Attacks", "abstract": "Black-box query-based attacks constitute significant threats to Machine\nLearning as a Service (MLaaS) systems since they can generate adversarial\nexamples without accessing the target model's architecture and parameters.\nTraditional defense mechanisms, such as adversarial training, gradient masking,\nand input transformations, either impose substantial computational costs or\ncompromise the test accuracy of non-adversarial inputs. To address these\nchallenges, we propose an efficient defense mechanism, PuriDefense, that\nemploys random patch-wise purifications with an ensemble of lightweight\npurification models at a low level of inference cost. These models leverage the\nlocal implicit function and rebuild the natural image manifold. Our theoretical\nanalysis suggests that this approach slows down the convergence of query-based\nattacks by incorporating randomness into purifications. Extensive experiments\non CIFAR-10 and ImageNet validate the effectiveness of our proposed\npurifier-based defense mechanism, demonstrating significant improvements in\nrobustness against query-based attacks.", "field": "Computer Science", "categories": "cs.CR,cs.AI,cs.CV,cs.LG"}, {"arxiv_id": "2401.10588", "title": "DGL: Dynamic Global-Local Prompt Tuning for Text-Video Retrieval", "abstract": "Text-video retrieval is a critical multi-modal task to find the most relevant\nvideo for a text query. Although pretrained models like CLIP have demonstrated\nimpressive potential in this area, the rising cost of fully finetuning these\nmodels due to increasing model size continues to pose a problem. To address\nthis challenge, prompt tuning has emerged as an alternative. However, existing\nworks still face two problems when adapting pretrained image-text models to\ndownstream video-text tasks: (1) The visual encoder could only encode\nframe-level features and failed to extract global-level general video\ninformation. (2) Equipping the visual and text encoder with separated prompts\nfailed to mitigate the visual-text modality gap. To this end, we propose DGL, a\ncross-modal Dynamic prompt tuning method with Global-Local video attention. In\ncontrast to previous prompt tuning methods, we employ the shared latent space\nto generate local-level text and frame prompts that encourage inter-modal\ninteraction. Furthermore, we propose modeling video in a global-local attention\nmechanism to capture global video information from the perspective of prompt\ntuning. Extensive experiments reveal that when only 0.67% parameters are tuned,\nour cross-modal prompt tuning strategy DGL outperforms or is comparable to\nfully finetuning methods on MSR-VTT, VATEX, LSMDC, and ActivityNet datasets.\nCode will be available at https://github.com/knightyxp/DGL", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10589", "title": "Rethinking the Soft Conflict Pseudo Boolean Constraint on MaxSAT Local\n  Search Solvers", "abstract": "MaxSAT is an optimization version of the famous NP-complete Satisfiability\nproblem (SAT). Algorithms for MaxSAT mainly include complete solvers and local\nsearch incomplete solvers. In many complete solvers, once a better solution is\nfound, a Soft conflict Pseudo Boolean (SPB) constraint will be generated to\nenforce the algorithm to find better solutions. In many local search\nalgorithms, clause weighting is a key technique for effectively guiding the\nsearch directions. In this paper, we propose to transfer the SPB constraint\ninto the clause weighting system of the local search method, leading the\nalgorithm to better solutions. We further propose an adaptive clause weighting\nstrategy that breaks the tradition of using constant values to adjust clause\nweights. Based on the above methods, we propose a new local search algorithm\ncalled SPB-MaxSAT that provides new perspectives for clause weighting on MaxSAT\nlocal search solvers. Extensive experiments demonstrate the excellent\nperformance of the proposed methods.", "field": "Computer Science", "categories": "cs.AI"}, {"arxiv_id": "2401.1059", "title": "Adversarially Robust Signed Graph Contrastive Learning from Balance\n  Augmentation", "abstract": "Signed graphs consist of edges and signs, which can be separated into\nstructural information and balance-related information, respectively. Existing\nsigned graph neural networks (SGNNs) typically rely on balance-related\ninformation to generate embeddings. Nevertheless, the emergence of recent\nadversarial attacks has had a detrimental impact on the balance-related\ninformation. Similar to how structure learning can restore unsigned graphs,\nbalance learning can be applied to signed graphs by improving the balance\ndegree of the poisoned graph. However, this approach encounters the challenge\n\"Irreversibility of Balance-related Information\" - while the balance degree\nimproves, the restored edges may not be the ones originally affected by\nattacks, resulting in poor defense effectiveness. To address this challenge, we\npropose a robust SGNN framework called Balance Augmented-Signed Graph\nContrastive Learning (BA-SGCL), which combines Graph Contrastive Learning\nprinciples with balance augmentation techniques. Experimental results\ndemonstrate that BA-SGCL not only enhances robustness against existing\nadversarial attacks but also achieves superior performance on link sign\nprediction task across various datasets.", "field": "Computer Science", "categories": "cs.LG,cs.CR"}, {"arxiv_id": "2401.10601", "title": "Influential Slot and Tag Selection in Billboard Advertisement", "abstract": "The selection of influential billboard slots remains an important problem in\nbillboard advertisements. Existing studies on this problem have not considered\nthe case of context-specific influence probability. To bridge this gap, in this\npaper, we introduce the Context Dependent Influential Billboard Slot Selection\nProblem. First, we show that the problem is NP-hard. We also show that the\ninfluence function holds the bi-monotonicity, bi-submodularity, and\nnon-negativity properties. We propose an orthant-wise Stochastic Greedy\napproach to solve this problem. We show that this method leads to a constant\nfactor approximation guarantee. Subsequently, we propose an orthant-wise\nIncremental and Lazy Greedy approach. In a generic sense, this is a method for\nmaximizing a bi-submodular function under the cardinality constraint, which may\nalso be of independent interest. We analyze the performance guarantee of this\nalgorithm as well as time and space complexity. The proposed solution\napproaches have been implemented with real-world billboard and trajectory\ndatasets. We compare the performance of our method with many baseline methods,\nand the results are reported. Our proposed orthant-wise stochastic greedy\napproach leads to significant results when the parameters are set properly with\nreasonable computational overhead.", "field": "Computer Science", "categories": "cs.DS,cs.DB"}, {"arxiv_id": "2401.10603", "title": "ZnTrack -- Data as Code", "abstract": "The past decade has seen tremendous breakthroughs in computation and there is\nno indication that this will slow any time soon. Machine learning, large-scale\ncomputing resources, and increased industry focus have resulted in rising\ninvestments in computer-driven solutions for data management, simulations, and\nmodel generation. However, with this growth in computation has come an even\nlarger expansion of data and with it, complexity in data storage, sharing, and\ntracking. In this work, we introduce ZnTrack, a Python-driven data versioning\ntool. ZnTrack builds upon established version control systems to provide a\nuser-friendly and easy-to-use interface for tracking parameters in experiments,\ndesigning workflows, and storing and sharing data. From this ability to reduce\nlarge datasets to a simple Python script emerges the concept of Data as Code, a\ncore component of the work presented here and an undoubtedly important concept\nas the age of computation continues to evolve. ZnTrack offers an open-source,\nFAIR data compatible Python package to enable users to harness these concepts\nof the future.", "field": "Computer Science", "categories": "cs.SE,cs.AI,cs.LG"}, {"arxiv_id": "2401.10607", "title": "Use of topical and temporal profiles and their hybridisation for\n  content-based recommendation", "abstract": "In the context of content-based recommender systems, the aim of this paper is\nto determine how better profiles can be built and how these affect the\nrecommendation process based on the incorporation of temporality, i.e. the\ninclusion of time in the recommendation process, and topicality, i.e. the\nrepresentation of texts associated with users and items using topics and their\ncombination. The main contribution of the paper is to present two different\nways of hybridising these two dimensions and to evaluate and compare them with\nother alternatives.", "field": "Computer Science", "categories": "cs.IR"}, {"arxiv_id": "2401.10608", "title": "M2ORT: Many-To-One Regression Transformer for Spatial Transcriptomics\n  Prediction from Histopathology Images", "abstract": "The advancement of Spatial Transcriptomics (ST) has facilitated the\nspatially-aware profiling of gene expressions based on histopathology images.\nAlthough ST data offers valuable insights into the micro-environment of tumors,\nits acquisition cost remains expensive. Therefore, directly predicting the ST\nexpressions from digital pathology images is desired. Current methods usually\nadopt existing regression backbones for this task, which ignore the inherent\nmulti-scale hierarchical data structure of digital pathology images. To address\nthis limit, we propose M2ORT, a many-to-one regression Transformer that can\naccommodate the hierarchical structure of the pathology images through a\ndecoupled multi-scale feature extractor. Different from traditional models that\nare trained with one-to-one image-label pairs, M2ORT accepts multiple pathology\nimages of different magnifications at a time to jointly predict the gene\nexpressions at their corresponding common ST spot, aiming at learning a\nmany-to-one relationship through training. We have tested M2ORT on three public\nST datasets and the experimental results show that M2ORT can achieve\nstate-of-the-art performance with fewer parameters and floating-point\noperations (FLOPs). The code is available at:\nhttps://github.com/Dootmaan/M2ORT/.", "field": "Computer Science", "categories": "cs.CV,cs.MM"}, {"arxiv_id": "2401.10611", "title": "Publication venue recommendation using profiles based on clustering", "abstract": "In this paper we study the venue recommendation problem in order to help\nresearchers to identify a journal or conference to submit a given paper. A\ncommon approach to tackle this problem is to build profiles defining the scope\nof each venue. Then, these profiles are compared against the target paper. In\nour approach we will study how clustering techniques can be used to construct\ntopic-based profiles and use an Information Retrieval based approach to obtain\nthe final recommendations. Additionally, we will explore how the use of\nauthorship, representing a complementary piece of information, helps to improve\nthe recommendations.", "field": "Computer Science", "categories": "cs.IR"}, {"arxiv_id": "2401.10614", "title": "Goal-Oriented Multiple Access Connectivity for Networked Intelligent\n  Systems", "abstract": "We design a self-decision goal-oriented multiple access scheme, where sensing\nagents observe a common event and individually decide to communicate the\nevent's attributes to the monitoring agents, to satisfy a certain goal.\nDecisions are based on the usefulness of contents, which are generated under\nuniform, change- and semantics-aware content acquisition, as well as statistics\nand contents of other agents. We obtain optimal activation probabilities and\nthreshold criteria for decision-making under all schemes, maximizing a grade of\neffectiveness metric. Combined with a semantics-aware acquisition scheme, the\nself-decision scheme offers, on average, 29.52% higher effectiveness, 25.13%\nfewer drop-offs, and 67.21% fewer transmissions.", "field": "Computer Science", "categories": "cs.IT,cs.NI,math.IT"}, {"arxiv_id": "2401.10617", "title": "LDA-based Term Profiles for Expert Finding in a Political Setting", "abstract": "A common task in many political institutions (i.e. Parliament) is to find\npoliticians who are experts in a particular field. In order to tackle this\nproblem, the first step is to obtain politician profiles which include their\ninterests, and these can be automatically learned from their speeches. As a\npolitician may have various areas of expertise, one alternative is to use a set\nof subprofiles, each of which covers a different subject. In this study, we\npropose a novel approach for this task by using latent Dirichlet allocation\n(LDA) to determine the main underlying topics of each political speech, and to\ndistribute the related terms among the different topic-based subprofiles. With\nthis objective, we propose the use of fifteen distance and similarity measures\nto automatically determine the optimal number of topics discussed in a\ndocument, and to demonstrate that every measure converges into five strategies:\nEuclidean, Dice, Sorensen, Cosine and Overlap. Our experimental results showed\nthat the scores of the different accuracy metrics of the proposed strategies\ntended to be higher than those of the baselines for expert recommendation\ntasks, and that the use of an appropriate number of topics has proved relevant.", "field": "Computer Science", "categories": "cs.IR"}, {"arxiv_id": "2401.10619", "title": "A model-based framework for controlling activated sludge plants", "abstract": "This work presents a general framework for the advanced control of a common\nclass of activated sludge plants (ASPs). Based on a dynamic model of the\nprocess and plant sensors and actuators, we design and configure a highly\ncustomisable Output Model-Predictive Controller (Output MPC) for the flexible\noperation of ASPs as water resource recovery facilities. The controller\nconsists of a i) Moving-Horizon Estimator for determining the state of the\nprocess, from plant measurements, and ii) a Model-Predictive Controller for\ndetermining the optimal actions to attain high-level operational goals. The\nOutput MPC can be configured to satisfy the technological limits of the plant\nequipment, as well as operational desiderata defined by plant personnel. We\nconsider exemplary problems and show that the framework is able to control ASPs\nfor tasks of practical relevance, ranging from wastewater treatment subject to\nnormative limits, to the production of an effluent with varying nitrogen\ncontent, and energy recovery.", "field": "Computer Science", "categories": "eess.SY,cs.SY,math.OC"}, {"arxiv_id": "2401.1062", "title": "Polytopic Autoencoders with Smooth Clustering for Reduced-order\n  Modelling of Flows", "abstract": "With the advancement of neural networks, there has been a notable increase,\nboth in terms of quantity and variety, in research publications concerning the\napplication of autoencoders to reduced-order models. We propose a polytopic\nautoencoder architecture that includes a lightweight nonlinear encoder, a\nconvex combination decoder, and a smooth clustering network. Supported by\nseveral proofs, the model architecture ensures that all reconstructed states\nlie within a polytope, accompanied by a metric indicating the quality of the\nconstructed polytopes, referred to as polytope error. Additionally, it offers a\nminimal number of convex coordinates for polytopic linear-parameter varying\nsystems while achieving acceptable reconstruction errors compared to proper\northogonal decomposition (POD). To validate our proposed model, we conduct\nsimulations involving two flow scenarios with the incompressible Navier-Stokes\nequation. Numerical results demonstrate the guaranteed properties of the model,\nlow reconstruction errors compared to POD, and the improvement in error using a\nclustering network.", "field": "Computer Science", "categories": "cs.LG,cs.CV,math.DS"}, {"arxiv_id": "2401.10627", "title": "Key to Kindness: Reducing Toxicity In Online Discourse Through Proactive\n  Content Moderation in a Mobile Keyboard", "abstract": "Growing evidence shows that proactive content moderation supported by AI can\nhelp improve online discourse. However, we know little about designing these\nsystems, how design impacts efficacy and user experience, and how people\nperceive proactive moderation across public and private platforms. We developed\na mobile keyboard with built-in proactive content moderation which we tested\n(N=575) within a semi-functional simulation of a public and private\ncommunication platform. Where toxic content was detected, we used different\ninterventions that embedded three design factors: timing, friction, and the\npresentation of the AI model output. We found moderation to be effective,\nregardless of the design. However, friction was a source of annoyance while\nprompts with no friction that occurred during typing were more effective.\nFollow-up interviews highlight the differences in how these systems are\nperceived across public and private platforms, and how they can offer more than\nmoderation by acting as educational and communication support tools.", "field": "Computer Science", "categories": "cs.HC,ACM-class: H.5.2"}, {"arxiv_id": "2401.10629", "title": "A Critical Reflection on the Use of Toxicity Detection Algorithms in\n  Proactive Content Moderation Systems", "abstract": "Toxicity detection algorithms, originally designed with reactive content\nmoderation in mind, are increasingly being deployed into proactive end-user\ninterventions to moderate content. Through a socio-technical lens and focusing\non contexts in which they are applied, we explore the use of these algorithms\nin proactive moderation systems. Placing a toxicity detection algorithm in an\nimagined virtual mobile keyboard, we critically explore how such algorithms\ncould be used to proactively reduce the sending of toxic content. We present\nfindings from design workshops conducted with four distinct stakeholder groups\nand find concerns around how contextual complexities may exasperate\ninequalities around content moderation processes. Whilst only specific user\ngroups are likely to directly benefit from these interventions, we highlight\nthe potential for other groups to misuse them to circumvent detection, validate\nand gamify hate, and manipulate algorithmic models to exasperate harm.", "field": "Computer Science", "categories": "cs.HC,H.5.2"}, {"arxiv_id": "2401.10632", "title": "Interventional Fairness on Partially Known Causal Graphs: A Constrained\n  Optimization Approach", "abstract": "Fair machine learning aims to prevent discrimination against individuals or\nsub-populations based on sensitive attributes such as gender and race. In\nrecent years, causal inference methods have been increasingly used in fair\nmachine learning to measure unfairness by causal effects. However, current\nmethods assume that the true causal graph is given, which is often not true in\nreal-world applications. To address this limitation, this paper proposes a\nframework for achieving causal fairness based on the notion of interventions\nwhen the true causal graph is partially known. The proposed approach involves\nmodeling fair prediction using a Partially Directed Acyclic Graph (PDAG),\nspecifically, a class of causal DAGs that can be learned from observational\ndata combined with domain knowledge. The PDAG is used to measure causal\nfairness, and a constrained optimization problem is formulated to balance\nbetween fairness and accuracy. Results on both simulated and real-world\ndatasets demonstrate the effectiveness of this method.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.10634", "title": "Automatic Construction of Multi-faceted User Profiles using Text\n  Clustering and its Application to Expert Recommendation and Filtering\n  Problems", "abstract": "In the information age we are living in today, not only are we interested in\naccessing multimedia objects such as documents, videos, etc. but also in\nsearching for professional experts, people or celebrities, possibly for\nprofessional needs or just for fun. Information access systems need to be able\nto extract and exploit various sources of information (usually in text format)\nabout such individuals, and to represent them in a suitable way usually in the\nform of a profile. In this article, we tackle the problems of profile-based\nexpert recommendation and document filtering from a machine learning\nperspective by clustering expert textual sources to build profiles and capture\nthe different hidden topics in which the experts are interested. The experts\nwill then be represented by means of multi-faceted profiles. Our experiments\nshow that this is a valid technique to improve the performance of expert\nfinding and document filtering.", "field": "Computer Science", "categories": "cs.IR"}, {"arxiv_id": "2401.10636", "title": "Catch the Butterfly: Peeking into the Terms and Conflicts among SPDX\n  Licenses", "abstract": "The widespread adoption of third-party libraries (TPLs) in software\ndevelopment has accelerated the creation of modern software. However, this\nconvenience comes with potential legal risks. Developers may inadvertently\nviolate the licenses of TPLs, leading to legal issues. While existing studies\nhave explored software licenses and potential incompatibilities, these studies\noften focus on a limited set of licenses or rely on low-quality license data,\nwhich may affect their conclusions. To address this gap, there is a need for a\nhigh-quality license dataset that encompasses a broad range of mainstream\nlicenses to help developers navigate the complex landscape of software\nlicenses, avoid potential legal pitfalls, and guide solutions for managing\nlicense compliance and compatibility in software development. To this end, we\nconduct the first work to understand the mainstream software licenses based on\nterm granularity and obtain a high-quality dataset of 453 SPDX licenses with\nwell-labeled terms and conflicts. Specifically, we first conduct a differential\nanalysis of the mainstream platforms to understand the terms and attitudes of\neach license. Next, we propose a standardized set of license terms to capture\nand label existing mainstream licenses with high quality. Moreover, we include\ncopyleft conflicts and conclude the three major types of license conflicts\namong the 453 SPDX licenses. Based on these, we carry out two empirical studies\nto reveal the concerns and threats from the perspectives of both licensors and\nlicensees. One study provides an in-depth analysis of the similarities,\ndifferences, and conflicts among SPDX licenses, revisits the usage and\nconflicts of licenses in the NPM ecosystem, and draws conclusions that differ\nfrom previous work. Our studies reveal some insightful findings and disclose\nrelevant analytical data, which set the stage for further research.", "field": "Computer Science", "categories": "cs.SE"}, {"arxiv_id": "2401.10638", "title": "Accurately Computing Expected Visiting Times and Stationary\n  Distributions in Markov Chains", "abstract": "We study the accurate and efficient computation of the expected number of\ntimes each state is visited in discrete- and continuous-time Markov chains. To\nobtain sound accuracy guarantees efficiently, we lift interval iteration and\ntopological approaches known from the computation of reachability probabilities\nand expected rewards. We further study applications of expected visiting times,\nincluding the sound computation of the stationary distribution and expected\nrewards conditioned on reaching multiple goal states. The implementation of our\nmethods in the probabilistic model checker Storm scales to large systems with\nmillions of states. Our experiments on the quantitative verification benchmark\nset show that the computation of stationary distributions via expected visiting\ntimes consistently outperforms existing approaches - sometimes by several\norders of magnitude.", "field": "Computer Science", "categories": "cs.LO,math.PR"}, {"arxiv_id": "2401.1064", "title": "A comprehensive study on fidelity metrics for XAI", "abstract": "The use of eXplainable Artificial Intelligence (XAI) systems has introduced a\nset of challenges that need resolution. Herein, we focus on how to correctly\nselect an XAI method, an open questions within the field. The inherent\ndifficulty of this task is due to the lack of a ground truth. Several authors\nhave proposed metrics to approximate the fidelity of different XAI methods.\nThese metrics lack verification and have concerning disagreements. In this\nstudy, we proposed a novel methodology to verify fidelity metrics, using a\nwell-known transparent model, namely a decision tree. This model allowed us to\nobtain explanations with perfect fidelity. Our proposal constitutes the first\nobjective benchmark for these metrics, facilitating a comparison of existing\nproposals, and surpassing existing methods. We applied our benchmark to assess\nthe existing fidelity metrics in two different experiments, each using public\ndatasets comprising 52,000 images. The images from these datasets had a size a\n128 by 128 pixels and were synthetic data that simplified the training process.\nAll metric values, indicated a lack of fidelity, with the best one showing a 30\n\\% deviation from the expected values for perfect explanation. Our\nexperimentation led us to conclude that the current fidelity metrics are not\nreliable enough to be used in real scenarios. From this finding, we deemed it\nnecessary to development new metrics, to avoid the detected problems, and we\nrecommend the usage of our proposal as a benchmark within the scientific\ncommunity to address these limitations.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.10641", "title": "An Effective Index for Truss-based Community Search on Large Directed\n  Graphs", "abstract": "Community search is a derivative of community detection that enables online\nand personalized discovery of communities and has found extensive applications\nin massive real-world networks. Recently, there needs to be more focus on the\ncommunity search issue within directed graphs, even though substantial research\nhas been carried out on undirected graphs. The recently proposed D-truss model\nhas achieved good results in the quality of retrieved communities. However,\nexisting D-truss-based work cannot perform efficient community searches on\nlarge graphs because it consumes too many computing resources to retrieve the\nmaximal D-truss. To overcome this issue, we introduce an innovative merge\nrelation known as D-truss-connected to capture the inherent density and\ncohesiveness of edges within D-truss. This relation allows us to partition all\nthe edges in the original graph into a series of D-truss-connected classes.\nThen, we construct a concise and compact index, ConDTruss, based on\nD-truss-connected. Using ConDTruss, the efficiency of maximum D-truss retrieval\nwill be greatly improved, making it a theoretically optimal approach.\nExperimental evaluations conducted on large directed graph certificate the\neffectiveness of our proposed method.", "field": "Computer Science", "categories": "cs.SI,cs.AI"}, {"arxiv_id": "2401.10642", "title": "Fast Butterfly-Core Community Search For Large Labeled Graphs", "abstract": "Community Search (CS) aims to identify densely interconnected subgraphs\ncorresponding to query vertices within a graph. However, existing heterogeneous\ngraph-based community search methods need help identifying cross-group\ncommunities and suffer from efficiency issues, making them unsuitable for large\ngraphs. This paper presents a fast community search model based on the\nButterfly-Core Community (BCC) structure for heterogeneous graphs. The Random\nWalk with Restart (RWR) algorithm and butterfly degree comprehensively evaluate\nthe importance of vertices within communities, allowing leader vertices to be\nrapidly updated to maintain cross-group cohesion. Moreover, we devised a more\nefficient method for updating vertex distances, which minimizes vertex visits\nand enhances operational efficiency. Extensive experiments on several\nreal-world temporal graphs demonstrate the effectiveness and efficiency of this\nsolution.", "field": "Computer Science", "categories": "cs.SI,cs.AI"}, {"arxiv_id": "2401.10643", "title": "A Comprehensive Survey on Deep-Learning-based Vehicle Re-Identification:\n  Models, Data Sets and Challenges", "abstract": "Vehicle re-identification (ReID) endeavors to associate vehicle images\ncollected from a distributed network of cameras spanning diverse traffic\nenvironments. This task assumes paramount importance within the spectrum of\nvehicle-centric technologies, playing a pivotal role in deploying Intelligent\nTransportation Systems (ITS) and advancing smart city initiatives. Rapid\nadvancements in deep learning have significantly propelled the evolution of\nvehicle ReID technologies in recent years. Consequently, undertaking a\ncomprehensive survey of methodologies centered on deep learning for vehicle\nre-identification has become imperative and inescapable. This paper extensively\nexplores deep learning techniques applied to vehicle ReID. It outlines the\ncategorization of these methods, encompassing supervised and unsupervised\napproaches, delves into existing research within these categories, introduces\ndatasets and evaluation criteria, and delineates forthcoming challenges and\npotential research directions. This comprehensive assessment examines the\nlandscape of deep learning in vehicle ReID and establishes a foundation and\nstarting point for future works. It aims to serve as a complete reference by\nhighlighting challenges and emerging trends, fostering advancements and\napplications in vehicle ReID utilizing deep learning models.", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.LG,eess.IV"}, {"arxiv_id": "2401.10646", "title": "Empowering HWNs with Efficient Data Labeling: A Clustered Federated\n  Semi-Supervised Learning Approach", "abstract": "Clustered Federated Multitask Learning (CFL) has gained considerable\nattention as an effective strategy for overcoming statistical challenges,\nparticularly when dealing with non independent and identically distributed (non\nIID) data across multiple users. However, much of the existing research on CFL\noperates under the unrealistic premise that devices have access to accurate\nground truth labels. This assumption becomes especially problematic in\nhierarchical wireless networks (HWNs), where edge networks contain a large\namount of unlabeled data, resulting in slower convergence rates and increased\nprocessing times, particularly when dealing with two layers of model\naggregation. To address these issues, we introduce a novel framework, Clustered\nFederated Semi-Supervised Learning (CFSL), designed for more realistic HWN\nscenarios. Our approach leverages a best-performing specialized model\nalgorithm, wherein each device is assigned a specialized model that is highly\nadept at generating accurate pseudo-labels for unlabeled data, even when the\ndata stems from diverse environments. We validate the efficacy of CFSL through\nextensive experiments, comparing it with existing methods highlighted in recent\nliterature. Our numerical results demonstrate that CFSL significantly improves\nupon key metrics such as testing accuracy, labeling accuracy, and labeling\nlatency under varying proportions of labeled and unlabeled data while also\naccommodating the non-IID nature of the data and the unique characteristics of\nwireless edge networks.", "field": "Computer Science", "categories": "cs.NI,cs.LG"}, {"arxiv_id": "2401.10647", "title": "Sowing the Wind, Reaping the Whirlwind: The Impact of Editing Language\n  Models", "abstract": "In the rapidly advancing field of artificial intelligence, the concept of\nRed-Teaming or Jailbreaking large language models (LLMs) has emerged as a\ncrucial area of study. This approach is especially significant in terms of\nassessing and enhancing the safety and robustness of these models. This paper\ninvestigates the intricate consequences of such modifications through model\nediting, uncovering a complex relationship between enhancing model accuracy and\npreserving its ethical integrity. Our in-depth analysis reveals a striking\nparadox: while injecting accurate information is crucial for model reliability,\nit can paradoxically destabilize the model's foundational framework, resulting\nin unpredictable and potentially unsafe behaviors. Additionally, we propose a\nbenchmark dataset NicheHazardQA to investigate this unsafe behavior both within\nthe same and cross topical domain. This aspect of our research sheds light on\nhow the edits, impact the model's safety metrics and guardrails. Our findings\nshow that model editing serves as a cost-effective tool for topical red-teaming\nby methodically applying targeted edits and evaluating the resultant model\nbehavior", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.10648", "title": "Area Modeling using Stay Information for Large-Scale Users and Analysis\n  for Influence of COVID-19", "abstract": "Understanding how people use area in a city can be a valuable information in\na wide range of fields, from marketing to urban planning. Area usage is subject\nto change over time due to various events including seasonal shifts and\npandemics. Before the spread of smartphones, this data had been collected\nthrough questionnaire survey. However, this is not a sustainable approach in\nterms of time to results and cost. There are many existing studies on area\nmodeling, which characterize an area with some kind of information, using Point\nof Interest (POI) or inter-area movement data. However, since POI is data that\nis statically tied to space, and inter-area movement data ignores the behavior\nof people within an area, existing methods are not sufficient in terms of\ncapturing area usage changes. In this paper, we propose a novel area modeling\nmethod named Area2Vec, inspired by Word2Vec, which models areas based on\npeople's location data. This method is based on the discovery that it is\npossible to characterize an area based on its usage by using people's stay\ninformation in the area. And it is a novel method that can reflect the\ndynamically changing people's behavior in an area in the modeling results. We\nvalidated Area2vec by performing a functional classification of areas in a\ndistrict of Japan. The results show that Area2Vec can be usable in general area\nanalysis. We also investigated area usage changes due to COVID-19 in two\ndistricts in Japan. We could find that COVID-19 made people refrain from\nunnecessary going out, such as visiting entertainment areas.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.10652", "title": "AutoChunk: Automated Activation Chunk for Memory-Efficient Long Sequence\n  Inference", "abstract": "Large deep learning models have achieved impressive performance across a\nrange of applications. However, their large memory requirements, including\nparameter memory and activation memory, have become a significant challenge for\ntheir practical serving. While existing methods mainly address parameter\nmemory, the importance of activation memory has been overlooked. Especially for\nlong input sequences, activation memory is expected to experience a significant\nexponential growth as the length of sequences increases. In this approach, we\npropose AutoChunk, an automatic and adaptive compiler system that efficiently\nreduces activation memory for long sequence inference by chunk strategies. The\nproposed system generates chunk plans by optimizing through multiple stages. In\neach stage, the chunk search pass explores all possible chunk candidates and\nthe chunk selection pass identifies the optimal one. At runtime, AutoChunk\nemploys code generation to automatically apply chunk strategies. The\nexperiments demonstrate that AutoChunk can reduce over 80\\% of activation\nmemory while maintaining speed loss within 10%, extend max sequence length by\n3.2x to 11.7x, and outperform state-of-the-art methods by a large margin.", "field": "Computer Science", "categories": "cs.PF,cs.DC,cs.LG"}, {"arxiv_id": "2401.10653", "title": "Attentive Fusion: A Transformer-based Approach to Multimodal Hate Speech\n  Detection", "abstract": "With the recent surge and exponential growth of social media usage,\nscrutinizing social media content for the presence of any hateful content is of\nutmost importance. Researchers have been diligently working since the past\ndecade on distinguishing between content that promotes hatred and content that\ndoes not. Traditionally, the main focus has been on analyzing textual content.\nHowever, recent research attempts have also commenced into the identification\nof audio-based content. Nevertheless, studies have shown that relying solely on\naudio or text-based content may be ineffective, as recent upsurge indicates\nthat individuals often employ sarcasm in their speech and writing. To overcome\nthese challenges, we present an approach to identify whether a speech promotes\nhate or not utilizing both audio and textual representations. Our methodology\nis based on the Transformer framework that incorporates both audio and text\nsampling, accompanied by our very own layer called \"Attentive Fusion\". The\nresults of our study surpassed previous state-of-the-art techniques, achieving\nan impressive macro F1 score of 0.927 on the Test Set.", "field": "Computer Science", "categories": "cs.CL,cs.LG,cs.SD,eess.AS,eess.SP"}, {"arxiv_id": "2401.10657", "title": "FIMBA: Evaluating the Robustness of AI in Genomics via Feature\n  Importance Adversarial Attacks", "abstract": "With the steady rise of the use of AI in bio-technical applications and the\nwidespread adoption of genomics sequencing, an increasing amount of AI-based\nalgorithms and tools is entering the research and production stage affecting\ncritical decision-making streams like drug discovery and clinical outcomes.\nThis paper demonstrates the vulnerability of AI models often utilized\ndownstream tasks on recognized public genomics datasets. We undermine model\nrobustness by deploying an attack that focuses on input transformation while\nmimicking the real data and confusing the model decision-making, ultimately\nyielding a pronounced deterioration in model performance. Further, we enhance\nour approach by generating poisoned data using a variational autoencoder-based\nmodel. Our empirical findings unequivocally demonstrate a decline in model\nperformance, underscored by diminished accuracy and an upswing in false\npositives and false negatives. Furthermore, we analyze the resulting\nadversarial samples via spectral analysis yielding conclusions for\ncountermeasures against such attacks.", "field": "Computer Science", "categories": "cs.LG,cs.CR,q-bio.GN"}, {"arxiv_id": "2401.10659", "title": "BadODD: Bangladeshi Autonomous Driving Object Detection Dataset", "abstract": "We propose a comprehensive dataset for object detection in diverse driving\nenvironments across 9 districts in Bangladesh. The dataset, collected\nexclusively from smartphone cameras, provided a realistic representation of\nreal-world scenarios, including day and night conditions. Most existing\ndatasets lack suitable classes for autonomous navigation on Bangladeshi roads,\nmaking it challenging for researchers to develop models that can handle the\nintricacies of road scenarios. To address this issue, the authors proposed a\nnew set of classes based on characteristics rather than local vehicle names.\nThe dataset aims to encourage the development of models that can handle the\nunique challenges of Bangladeshi road scenarios for the effective deployment of\nautonomous vehicles. The dataset did not consist of any online images to\nsimulate real-world conditions faced by autonomous vehicles. The classification\nof vehicles is challenging because of the diverse range of vehicles on\nBangladeshi roads, including those not found elsewhere in the world. The\nproposed classification system is scalable and can accommodate future vehicles,\nmaking it a valuable resource for researchers in the autonomous vehicle sector.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.1066", "title": "A Simple Framework to Accelerate Multilingual Language Model for\n  Monolingual Text Generation", "abstract": "Recent advancements in large language models have facilitated the execution\nof complex language tasks, not only in English but also in non-English\nlanguages. However, the tokenizers of most language models, such as Llama,\ntrained on English-centric corpora, tend to excessively fragment tokens in\nnon-English languages. This issue is especially pronounced in non-roman\nalphabetic languages, which are often divided at a character or even Unicode\nlevel, leading to slower text generation. To address this, our study introduces\na novel framework designed to expedite text generation in these languages. This\nframework predicts larger linguistic units than those of conventional\nmultilingual tokenizers and is specifically tailored to the target language,\nthereby reducing the number of decoding steps required. Our empirical results\ndemonstrate that the proposed framework increases the generation speed by a\nfactor of 1.9 compared to standard decoding while maintaining the performance\nof a pre-trained multilingual model on monolingual tasks.", "field": "Computer Science", "categories": "cs.CL,cs.AI"}, {"arxiv_id": "2401.10662", "title": "Non-hydrostatic mesoscale atmospheric modeling by the anisotropic mesh\n  adaptive discontinuous Galerkin method", "abstract": "We deal with non-hydrostatic mesoscale atmospheric modeling using the fully\nimplicit space-time discontinuous Galerkin method in combination with the\nanisotropic $hp$-mesh adaptation technique. The time discontinuous\napproximation allows the treatment of different meshes at different time levels\nin a natural way which can significantly reduce the number of degrees of\nfreedom. The presented approach generates a sequence of triangular meshes\nconsisting of possible anisotropic elements and varying polynomial\napproximation degrees such that the interpolation error is below the given\ntolerance and the number of degrees of freedom at each time step is minimal. We\ndescribe the discretization of the problem together with several implementation\nissues related to the treatment of boundary conditions, algebraic solver and\nadaptive choice of the size of the time steps.The computational performance of\nthe proposed method is demonstrated on several benchmark problems.", "field": "Computer Science", "categories": "math.NA,cs.NA"}, {"arxiv_id": "2401.10664", "title": "PTPsec: Securing the Precision Time Protocol Against Time Delay Attacks\n  Using Cyclic Path Asymmetry Analysis", "abstract": "High-precision time synchronization is a vital prerequisite for many modern\napplications and technologies, including Smart Grids, Time-Sensitive Networking\n(TSN), and 5G networks. Although the Precision Time Protocol (PTP) can\naccomplish this requirement in trusted environments, it becomes unreliable in\nthe presence of specific cyber attacks. Mainly, time delay attacks pose the\nhighest threat to the protocol, enabling attackers to diverge targeted clocks\nundetected. With the increasing danger of cyber attacks, especially against\ncritical infrastructure, there is a great demand for effective countermeasures\nto secure both time synchronization and the applications that depend on it.\nHowever, current solutions are not sufficiently capable of mitigating\nsophisticated delay attacks. For example, they lack proper integration into the\nPTP protocol, scalability, or sound evaluation with the required\nmicrosecond-level accuracy. This work proposes an approach to detect and\ncounteract delay attacks against PTP based on cyclic path asymmetry\nmeasurements over redundant paths. For that, we provide a method to find\nredundant paths in arbitrary networks and show how this redundancy can be\nexploited to reveal and mitigate undesirable asymmetries on the synchronization\npath that cause the malicious clock divergence. Furthermore, we propose PTPsec,\na secure PTP protocol and its implementation based on the latest IEEE 1588-2019\nstandard. With PTPsec, we advance the conventional PTP to support reliable\ndelay attack detection and mitigation. We validate our approach on a hardware\ntestbed, which includes an attacker capable of performing static and\nincremental delay attacks at a microsecond precision. Our experimental results\nshow that all attack scenarios can be reliably detected and mitigated with\nminimal detection time.", "field": "Computer Science", "categories": "cs.CR,cs.NI"}, {"arxiv_id": "2401.10666", "title": "MixNet: Towards Effective and Efficient UHD Low-Light Image Enhancement", "abstract": "With the continuous advancement of imaging devices, the prevalence of\nUltra-High-Definition (UHD) images is rising. Although many image restoration\nmethods have achieved promising results, they are not directly applicable to\nUHD images on devices with limited computational resources due to the\ninherently high computational complexity of UHD images. In this paper, we focus\non the task of low-light image enhancement (LLIE) and propose a novel LLIE\nmethod called MixNet, which is designed explicitly for UHD images. To capture\nthe long-range dependency of features without introducing excessive\ncomputational complexity, we present the Global Feature Modulation Layer\n(GFML). GFML associates features from different views by permuting the feature\nmaps, enabling efficient modeling of long-range dependency. In addition, we\nalso design the Local Feature Modulation Layer (LFML) and Feed-forward Layer\n(FFL) to capture local features and transform features into a compact\nrepresentation. This way, our MixNet achieves effective LLIE with few model\nparameters and low computational complexity. We conducted extensive experiments\non both synthetic and real-world datasets, and the comprehensive results\ndemonstrate that our proposed method surpasses the performance of current\nstate-of-the-art methods. The code will be available at\n\\url{https://github.com/zzr-idam/MixNet}.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10669", "title": "A Room With an Overview: Towards Meaningful Transparency for the\n  Consumer Internet of Things", "abstract": "As our physical environments become ever-more connected, instrumented and\nautomated, it can be increasingly difficult for users to understand what is\nhappening within them and why. This warrants attention; with the pervasive and\nphysical nature of the IoT comes risks of data misuse, privacy, surveillance,\nand even physical harm. Such concerns come amid increasing calls for more\ntransparency surrounding technologies (in general), as a means for supporting\nscrutiny and accountability.\n  This paper explores the practical dimensions to transparency mechanisms\nwithin the consumer IoT. That is, we consider how smart homes might be made\nmore meaningfully transparent, so as to support users in gaining greater\nunderstanding, oversight, and control. Through a series of three user-centric\nstudies, we (i) survey prospective smart home users to gain a general\nunderstanding of what meaningful transparency within smart homes might entail;\n(ii) identify categories of user-derived requirements and design elements\n(design features for supporting smart home transparency) that have been created\nthrough two co-design workshops; and (iii) validate these through an evaluation\nwith an altogether new set of participants. In all, these categories of\nrequirements and interface design elements provide a foundation for\nunderstanding how meaningful transparency might be achieved within smart homes,\nand introduces several wider considerations for doing so.", "field": "Computer Science", "categories": "cs.HC,cs.CY"}, {"arxiv_id": "2401.1067", "title": "Time synchronization for deterministic communication", "abstract": "Deterministic communication is required for applications of several industry\nverticals including manufacturing, automotive, financial, and health care, etc.\nThese applications rely on reliable and time-synchronized delivery of\ninformation among the communicating devices. Therefore, large delay variations\nin packet delivery or inaccuracies in time synchronization cannot be tolerated.\nIn particular, the industrial revolution on digitization, connectivity of\ndigital and physical systems, and flexible production design require\ndeterministic and time-synchronized communication. A network supporting\ndeterministic communication guarantees data delivery in a specified time with\nhigh reliability. The IEEE 802.1 TSN task group is developing standards to\nprovide deterministic communication through IEEE 802 networks. The IEEE 802.1AS\nstandard defines time synchronization mechanism for accurate distribution of\ntime among the communicating devices. The time synchronization accuracy depends\non the accurate calculation of the residence time which is the time between the\ningress and the egress ports of the bridge and includes the processing,\nqueuing, transmission, and link latency of the timing information. This paper\ndiscusses time synchronization mechanisms supported in current wired and\nwireless integrated systems.", "field": "Computer Science", "categories": "cs.NI"}, {"arxiv_id": "2401.10674", "title": "Deep Learning-based Embedded Intrusion Detection System for Automotive\n  CAN", "abstract": "Rising complexity of in-vehicle electronics is enabling new capabilities like\nautonomous driving and active safety. However, rising automation also increases\nrisk of security threats which is compounded by lack of in-built security\nmeasures in legacy networks like CAN, allowing attackers to observe, tamper and\nmodify information shared over such broadcast networks. Various intrusion\ndetection approaches have been proposed to detect and tackle such threats, with\nmachine learning models proving highly effective. However, deploying machine\nlearning models will require high processing power through high-end processors\nor GPUs to perform them close to line rate. In this paper, we propose a hybrid\nFPGA-based ECU approach that can transparently integrate IDS functionality\nthrough a dedicated off-the-shelf hardware accelerator that implements a\ndeep-CNN intrusion detection model. Our results show that the proposed approach\nprovides an average accuracy of over 99% across multiple attack datasets with\n0.64% false detection rates while consuming 94% less energy and achieving 51.8%\nreduction in per-message processing latency when compared to IDS\nimplementations on GPUs.", "field": "Computer Science", "categories": "cs.CR,cs.LG"}, {"arxiv_id": "2401.10681", "title": "Maximizing Real-Time Video QoE via Bandwidth Sharing under Markovian\n  setting", "abstract": "We consider the problem of optimizing Quality of Experience (QoE) of clients\nstreaming real-time video, served by networks managed by different operators\nthat can share bandwidth with each other. The abundance of real-time video\ntraffic is evident in the popularity of applications like video conferencing\nand video streaming of live events, which have increased significantly since\nthe recent pandemic. We model the problem as a joint optimization of resource\nallocation for the clients and bandwidth sharing across the operators, with\nspecial attention to how the resource allocation impacts clients' perceived\nvideo quality. We propose an online policy as a solution, which involves\ndynamically sharing a portion of one operator's bandwidth with another\noperator. We provide strong theoretical optimality guarantees for the policy.\nWe also use extensive simulations to demonstrate the policy's substantial\nperformance improvements (of up to ninety percent), and identify insights into\nkey system parameters (e.g., imbalance in arrival rates or channel conditions\nof the operators) that dictate the improvements.", "field": "Computer Science", "categories": "cs.NI"}, {"arxiv_id": "2401.10685", "title": "Towards End-to-End GPS Localization with Neural Pseudorange Correction", "abstract": "Pseudorange errors are the root cause of localization inaccuracy in GPS.\nPrevious data-driven methods regress and eliminate pseudorange errors using\nhandcrafted intermediate labels. Unlike them, we propose an end-to-end GPS\nlocalization framework, E2E-PrNet, to train a neural network for pseudorange\ncorrection (PrNet) directly using the final task loss calculated with the\nground truth of GPS receiver states. The gradients of the loss with respect to\nlearnable parameters are backpropagated through a differentiable nonlinear\nleast squares optimizer to PrNet. The feasibility is verified with GPS data\ncollected by Android phones, showing that E2E-PrNet outperforms the\nstate-of-the-art end-to-end GPS localization methods.", "field": "Computer Science", "categories": "cs.LG,cs.AI,eess.SP"}, {"arxiv_id": "2401.10686", "title": "Manipulating Sparse Double Descent", "abstract": "This paper investigates the double descent phenomenon in two-layer neural\nnetworks, focusing on the role of L1 regularization and representation\ndimensions. It explores an alternative double descent phenomenon, named sparse\ndouble descent. The study emphasizes the complex relationship between model\ncomplexity, sparsity, and generalization, and suggests further research into\nmore diverse models and datasets. The findings contribute to a deeper\nunderstanding of neural network training and optimization.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.10688", "title": "Unraveling codes: fast, robust, beyond-bound error correction for DRAM", "abstract": "Generalized Reed-Solomon (RS) codes are a common choice for efficient,\nreliable error correction in memory and communications systems. These codes add\n$2t$ extra parity symbols to a block of memory, and can efficiently and\nreliably correct up to $t$ symbol errors in that block. Decoding is possible\nbeyond this bound, but it is imperfectly reliable and often computationally\nexpensive. Beyond-bound decoding is an important problem to solve for\nerror-correcting Dynamic Random Access Memory (DRAM). These memories are often\ndesigned so that each access touches two extra memory devices, so that a\nfailure in any one device can be corrected. But system architectures\nincreasingly require DRAM to store metadata in addition to user data. When the\nmetadata replaces parity data, a single-device failure is then beyond-bound. An\nerror-correction system can either protect each access with a single RS code,\nor divide it into several segments protected with a shorter code, usually in an\nInterleaved Reed-Solomon (IRS) configuration. The full-block RS approach is\nmore reliable, both at correcting errors and at preventing silent data\ncorruption (SDC). The IRS option is faster, and is especially efficient at\nbeyond-bound correction of single- or double-device failures. Here we describe\na new family of \"unraveling\" Reed-Solomon codes that bridges the gap between\nthese options. Our codes are full-block generalized RS codes, but they can also\nbe decoded using an IRS decoder. As a result, they combine the speed and\nbeyond-bound correction capabilities of interleaved codes with the robustness\nof full-block codes, including the ability of the latter to reliably correct\nfailures across multiple devices. We show that unraveling codes are an\nespecially good fit for high-reliability DRAM error correction.", "field": "Computer Science", "categories": "cs.IT,cs.AR,math.IT"}, {"arxiv_id": "2401.10689", "title": "A Lightweight Multi-Attack CAN Intrusion Detection System on Hybrid\n  FPGAs", "abstract": "Rising connectivity in vehicles is enabling new capabilities like connected\nautonomous driving and advanced driver assistance systems (ADAS) for improving\nthe safety and reliability of next-generation vehicles. This increased access\nto in-vehicle functions compromises critical capabilities that use legacy\ninvehicle networks like Controller Area Network (CAN), which has no inherent\nsecurity or authentication mechanism. Intrusion detection and mitigation\napproaches, particularly using machine learning models, have shown promising\nresults in detecting multiple attack vectors in CAN through their ability to\ngeneralise to new vectors. However, most deployments require dedicated\ncomputing units like GPUs to perform line-rate detection, consuming much higher\npower. In this paper, we present a lightweight multi-attack quantised machine\nlearning model that is deployed using Xilinx's Deep Learning Processing Unit IP\non a Zynq Ultrascale+ (XCZU3EG) FPGA, which is trained and validated using the\npublic CAN Intrusion Detection dataset. The quantised model detects denial of\nservice and fuzzing attacks with an accuracy of above 99 % and a false positive\nrate of 0.07%, which are comparable to the state-of-the-art techniques in the\nliterature. The Intrusion Detection System (IDS) execution consumes just 2.0 W\nwith software tasks running on the ECU and achieves a 25 % reduction in\nper-message processing latency over the state-of-the-art implementations. This\ndeployment allows the ECU function to coexist with the IDS with minimal changes\nto the tasks, making it ideal for real-time IDS in in-vehicle systems.", "field": "Computer Science", "categories": "cs.CR,cs.LG,cs.SY,eess.SY"}, {"arxiv_id": "2401.1069", "title": "Beyond RMSE and MAE: Introducing EAUC to unmask hidden bias and\n  unfairness in dyadic regression models", "abstract": "Dyadic regression models, which predict real-valued outcomes for pairs of\nentities, are fundamental in many domains (e.g. predicting the rating of a user\nto a product in Recommender Systems) and promising and under exploration in\nmany others (e.g. approximating the adequate dosage of a drug for a patient in\npersonalized pharmacology). In this work, we demonstrate that non-uniformity in\nthe observed value distributions of individual entities leads to severely\nbiased predictions in state-of-the-art models, skewing predictions towards the\naverage of observed past values for the entity and providing worse-than-random\npredictive power in eccentric yet equally important cases. We show that the\nusage of global error metrics like Root Mean Squared Error (RMSE) and Mean\nAbsolute Error (MAE) is insufficient to capture this phenomenon, which we name\neccentricity bias, and we introduce Eccentricity-Area Under the Curve (EAUC) as\na new complementary metric that can quantify it in all studied models and\ndatasets. We also prove the adequateness of EAUC by using naive de-biasing\ncorrections to demonstrate that a lower model bias correlates with a lower EAUC\nand vice-versa. This work contributes a bias-aware evaluation of dyadic\nregression models to avoid potential unfairness and risks in critical\nreal-world applications of such systems.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.IR"}, {"arxiv_id": "2401.10691", "title": "Explainable and Transferable Adversarial Attack for ML-Based Network\n  Intrusion Detectors", "abstract": "espite being widely used in network intrusion detection systems (NIDSs),\nmachine learning (ML) has proven to be highly vulnerable to adversarial\nattacks. White-box and black-box adversarial attacks of NIDS have been explored\nin several studies. However, white-box attacks unrealistically assume that the\nattackers have full knowledge of the target NIDSs. Meanwhile, existing\nblack-box attacks can not achieve high attack success rate due to the weak\nadversarial transferability between models (e.g., neural networks and tree\nmodels). Additionally, neither of them explains why adversarial examples exist\nand why they can transfer across models. To address these challenges, this\npaper introduces ETA, an Explainable Transfer-based Black-Box Adversarial\nAttack framework. ETA aims to achieve two primary objectives: 1) create\ntransferable adversarial examples applicable to various ML models and 2)\nprovide insights into the existence of adversarial examples and their\ntransferability within NIDSs. Specifically, we first provide a general\ntransfer-based adversarial attack method applicable across the entire ML space.\nFollowing that, we exploit a unique insight based on cooperative game theory\nand perturbation interpretations to explain adversarial examples and\nadversarial transferability. On this basis, we propose an Important-Sensitive\nFeature Selection (ISFS) method to guide the search for adversarial examples,\nachieving stronger transferability and ensuring traffic-space constraints.", "field": "Computer Science", "categories": "cs.CR"}, {"arxiv_id": "2401.10695", "title": "LangBridge: Multilingual Reasoning Without Multilingual Supervision", "abstract": "We introduce LangBridge, a zero-shot approach to adapt language models for\nmultilingual reasoning tasks without multilingual supervision. LangBridge\noperates by bridging two models, each specialized in different aspects: (1) one\nspecialized in understanding multiple languages (e.g., mT5 encoder) and (2) one\nspecialized in reasoning (e.g., Orca 2). LangBridge connects the two models by\nintroducing minimal trainable parameters between them. Despite utilizing only\nEnglish data for training, LangBridge considerably enhances the performance of\nlanguage models on low-resource languages across mathematical reasoning,\ncoding, and logical reasoning. Our analysis suggests that the efficacy of\nLangBridge stems from the language-agnostic characteristics of multilingual\nrepresentations. We publicly release our code and models.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.10699", "title": "Navigating Expertise in Configurable Software Systems through the Maze\n  of Variability", "abstract": "The understanding of source code in large-scale software systems poses a\nchallenge for developers. The role of expertise in source code becomes critical\nfor identifying developers accountable for substantial changes. However, in the\ncontext of configurable software systems (CSS) using pre-processing and\nconditional compilation, conventional expertise metrics may encounter\nlimitations due to the non-alignment of variability implementation with the\nnatural module structure. This early research study investigates the\ndistribution of development efforts in CSS, specifically focusing on variable\nand mandatory code. It also examines the engagement of designated experts with\nvariable code in their assigned files. The findings provide insights into task\nallocation dynamics and raise questions about the applicability of existing\nmetrics, laying the groundwork for alternative approaches to assess developer\nexpertise in handling variable code. This research aims to contribute to a\ncomprehensive understanding of challenges within CSS, marking initial steps\ntoward advancing the evaluation of expertise in this context.", "field": "Computer Science", "categories": "cs.SE"}, {"arxiv_id": "2401.107", "title": "Safe Offline Reinforcement Learning with Feasibility-Guided Diffusion\n  Model", "abstract": "Safe offline RL is a promising way to bypass risky online interactions\ntowards safe policy learning. Most existing methods only enforce soft\nconstraints, i.e., constraining safety violations in expectation below\nthresholds predetermined. This can lead to potentially unsafe outcomes, thus\nunacceptable in safety-critical scenarios. An alternative is to enforce the\nhard constraint of zero violation. However, this can be challenging in offline\nsetting, as it needs to strike the right balance among three highly intricate\nand correlated aspects: safety constraint satisfaction, reward maximization,\nand behavior regularization imposed by offline datasets. Interestingly, we\ndiscover that via reachability analysis of safe-control theory, the hard safety\nconstraint can be equivalently translated to identifying the largest feasible\nregion given the offline dataset. This seamlessly converts the original trilogy\nproblem to a feasibility-dependent objective, i.e., maximizing reward value\nwithin the feasible region while minimizing safety risks in the infeasible\nregion. Inspired by these, we propose FISOR (FeasIbility-guided Safe Offline\nRL), which allows safety constraint adherence, reward maximization, and offline\npolicy learning to be realized via three decoupled processes, while offering\nstrong safety performance and stability. In FISOR, the optimal policy for the\ntranslated optimization problem can be derived in a special form of weighted\nbehavior cloning. Thus, we propose a novel energy-guided diffusion model that\ndoes not require training a complicated time-dependent classifier to extract\nthe policy, greatly simplifying the training. We compare FISOR against\nbaselines on DSRL benchmark for safe offline RL. Evaluation results show that\nFISOR is the only method that can guarantee safety satisfaction in all tasks,\nwhile achieving top returns in most tasks.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.RO"}, {"arxiv_id": "2401.10702", "title": "G.O.G: A Versatile Gripper-On-Gripper Design for Bimanual Cloth\n  Manipulation with a Single Robotic Arm", "abstract": "The manipulation of garments poses research challenges due to their\ndeformable nature and the extensive variability in shapes and sizes. Despite\nnumerous attempts by researchers to address these via approaches involving\nrobot perception and control, there has been a relatively limited interest in\nresolving it through the co-development of robot hardware. Consequently, the\nmajority of studies employ off-the-shelf grippers in conjunction with dual\nrobot arms to enable bimanual manipulation and high dexterity. However, this\ndual-arm system increases the overall cost of the robotic system as well as its\ncontrol complexity in order to tackle robot collisions and other robot\ncoordination issues. As an alternative approach, we propose to enable bimanual\ncloth manipulation using a single robot arm via novel end effector design --\nsharing dexterity skills between manipulator and gripper rather than relying\nentirely on robot arm coordination. To this end, we introduce a new gripper,\ncalled G.O.G., based on a gripper-on-gripper structure where the first gripper\nindependently regulates the span, up to 500mm, between its fingers which are in\nturn also grippers. These finger grippers consist of a variable friction module\nthat enables two grasping modes: firm and sliding grasps. Household item and\ncloth object benchmarks are employed to evaluate the performance of the\nproposed design, encompassing both experiments on the gripper design itself and\non cloth manipulation. Experimental results demonstrate the potential of the\nintroduced ideas to undertake a range of bimanual cloth manipulation tasks with\na single robot arm. Supplementary material is available at\nhttps://sites.google.com/view/gripperongripper.", "field": "Computer Science", "categories": "cs.RO"}, {"arxiv_id": "2401.10703", "title": "DRAT Proofs of Unsatisfiability for SAT Modulo Monotonic Theories", "abstract": "Generating proofs of unsatisfiability is a valuable capability of most SAT\nsolvers, and is an active area of research for SMT solvers. This paper\nintroduces the first method to efficiently generate proofs of unsatisfiability\nspecifically for an important subset of SMT: SAT Modulo Monotonic Theories\n(SMMT), which includes many useful finite-domain theories (e.g., bit vectors\nand many graph-theoretic properties) and is used in production at Amazon Web\nServices. Our method uses propositional definitions of the theory predicates,\nfrom which it generates compact Horn approximations of the definitions, which\nlead to efficient DRAT proofs, leveraging the large investment the SAT\ncommunity has made in DRAT. In experiments on practical SMMT problems, our\nproof generation overhead is minimal (7.41% geometric mean slowdown, 28.8%\nworst-case), and we can generate and check proofs for many problems that were\npreviously intractable.", "field": "Computer Science", "categories": "cs.LO"}, {"arxiv_id": "2401.10708", "title": "Demonstration of Cooperative Transport Interface using open-source 5G\n  OpenRAN and virtualised PON network", "abstract": "We demonstrate a real-time, converged 5G-PON through the Cooperative\nTransport Interface, synchronising 5G and PON-DBA upstream schedulers. This\ninnovative approach, implemented using 5G and PON open network implementations,\nsignificantly enhances network resource allocation, reducing latency.", "field": "Computer Science", "categories": "cs.NI"}, {"arxiv_id": "2401.1071", "title": "Classification with neural networks with quadratic decision functions", "abstract": "Neural network with quadratic decision functions have been introduced as\nalternatives to standard neural networks with affine linear one. They are\nadvantageous when the objects to be identified are of compact basic geometries\nlike circles, ellipsis etc. In this paper we investigate the use of such ansatz\nfunctions for classification. In particular we test and compare the algorithm\non the MNIST dataset for classification of handwritten digits and for\nclassification of subspecies. We also show, that the implementation can be\nbased on the neural network structure in the software Tensorflow and Keras,\nrespectively.", "field": "Computer Science", "categories": "cs.LG,cs.NA,math.NA,49N45, 41A30, 65XX, 68TXX"}, {"arxiv_id": "2401.10711", "title": "Weakly Supervised Gaussian Contrastive Grounding with Large Multimodal\n  Models for Video Question Answering", "abstract": "Video Question Answering (VideoQA) aims to answer natural language questions\nbased on the information observed in videos. Despite the recent success of\nLarge Multimodal Models (LMMs) in image-language understanding and reasoning,\nthey deal with VideoQA insufficiently by simply taking uniformly sampled frames\nas visual inputs, which ignores question-relevant visual clues. Moreover, there\nare no human annotations for question-critical timestamps in existing VideoQA\ndatasets. In light of this, we propose a novel weakly supervised framework to\nenforce the LMMs to reason out the answers with question-critical moments as\nvisual inputs. Specifically, we fuse the question and answer pairs as event\ndescriptions to find multiple keyframes as target moments, which will be\npseudo-labels. With these pseudo-labels as additionally weak supervision, we\ndevise a lightweight Gaussian-based Contrastive Grounding (GCG) module. GCG\nlearns multiple Gaussian functions to characterize the temporal structure of\nthe video, and sample question-critical frames as positive moments to be the\nvisual inputs of LMMs. Extensive experiments on several VideoQA benchmarks\nverify the effectiveness of our framework, and we achieve substantial\nimprovements compared to previous state-of-the-art methods.", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.CL"}, {"arxiv_id": "2401.10712", "title": "Q&A Prompts: Discovering Rich Visual Clues through Mining\n  Question-Answer Prompts for VQA requiring Diverse World Knowledge", "abstract": "With the breakthrough of multi-modal large language models, answering complex\nvisual questions that demand advanced reasoning abilities and world knowledge\nhas become a much more important testbed for developing AI models than ever.\nHowever, equipping AI models with robust cross-modality reasoning ability\nremains challenging since the cognition scheme of humans has not been\nunderstood systematically. In this paper, we believe that if we can collect\nvisual clues in the given image as much as possible, we will recognize the\nimage more accurately, understand the question better, recall relevant\nknowledge more easily, and finally reason out the answer. We discover these\nrich visual clues by mining question-answer pairs in images and sending them\ninto multi-modal large language models as prompts. We call the proposed method\nQ&A Prompts. Specifically, we first use the image-answer pairs and the\ncorresponding questions in the training set as inputs and outputs to train a\nvisual question generation model. Then, we use an image tagging model to\nidentify various instances and send packaged image-tag pairs into the visual\nquestion generation model to generate relevant questions with the extracted\nimage tags as answers. Finally, we encode these generated question-answer pairs\nas prompts with a visual-aware prompting module and send them into pre-trained\nmulti-modal large language models to reason out the final answers. Experimental\nresults show that, compared with state-of-the-art methods, our Q&A Prompts\nachieves substantial improvements on the challenging visual question answering\ndatasets requiring reasoning over diverse world knowledge, such as OK-VQA and\nA-OKVQA.", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.CL"}, {"arxiv_id": "2401.10716", "title": "Structured Code Representations Enable Data-Efficient Adaptation of Code\n  Language Models", "abstract": "Current language models tailored for code tasks often adopt the\npre-training-then-fine-tuning paradigm from natural language processing,\nmodeling source code as plain text. This approach, however, overlooks the\nunambiguous structures inherent in programming languages. In this work, we\nexplore data-efficient adaptation of pre-trained code models by further\npre-training and fine-tuning them with program structures. Specifically, we\nrepresent programs as parse trees -- also known as concrete syntax trees (CSTs)\n-- and adapt pre-trained models on serialized CSTs. Although the models that we\nadapt have been pre-trained only on the surface form of programs, we find that\na small amount of continual pre-training and fine-tuning on CSTs without\nchanging the model architecture yields improvements over the baseline approach\nacross various code tasks. The improvements are found to be particularly\nsignificant when there are limited training examples, demonstrating the\neffectiveness of integrating program structures with plain-text representation\neven when working with backbone models that have not been pre-trained with\nstructures.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.10724", "title": "Real-Time Zero-Day Intrusion Detection System for Automotive Controller\n  Area Network on FPGAs", "abstract": "Increasing automation in vehicles enabled by increased connectivity to the\noutside world has exposed vulnerabilities in previously siloed automotive\nnetworks like controller area networks (CAN). Attributes of CAN such as\nbroadcast-based communication among electronic control units (ECUs) that\nlowered deployment costs are now being exploited to carry out active injection\nattacks like denial of service (DoS), fuzzing, and spoofing attacks. Research\nliterature has proposed multiple supervised machine learning models deployed as\nIntrusion detection systems (IDSs) to detect such malicious activity; however,\nthese are largely limited to identifying previously known attack vectors. With\nthe ever-increasing complexity of active injection attacks, detecting zero-day\n(novel) attacks in these networks in real-time (to prevent propagation) becomes\na problem of particular interest. This paper presents an\nunsupervised-learning-based convolutional autoencoder architecture for\ndetecting zero-day attacks, which is trained only on benign (attack-free) CAN\nmessages. We quantise the model using Vitis-AI tools from AMD/Xilinx targeting\na resource-constrained Zynq Ultrascale platform as our IDS-ECU system for\nintegration. The proposed model successfully achieves equal or higher\nclassification accuracy (> 99.5%) on unseen DoS, fuzzing, and spoofing attacks\nfrom a publicly available attack dataset when compared to the state-of-the-art\nunsupervised learning-based IDSs. Additionally, by cleverly overlapping IDS\noperation on a window of CAN messages with the reception, the model is able to\nmeet line-rate detection (0.43 ms per window) of high-speed CAN, which when\ncoupled with the low energy consumption per inference, makes this architecture\nideally suited for detecting zero-day attacks on critical CAN networks.", "field": "Computer Science", "categories": "cs.CR,cs.LG,cs.SY,eess.SY"}, {"arxiv_id": "2401.10725", "title": "Proceedings 14th International Conference on Automated Deduction in\n  Geometry", "abstract": "ADG is a forum to exchange ideas and views, to present research results and\nprogress, and to demonstrate software tools at the intersection between\ngeometry and automated deduction. The conference is held every two years. The\nprevious editions of ADG were held in Hagenberg in 2021 (online, postponed from\n2020 due to COVID-19), Nanning in 2018, Strasbourg in 2016, Coimbra in 2014,\nEdinburgh in 2012, Munich in 2010, Shanghai in 2008, Pontevedra in 2006,\nGainesville in 2004, Hagenberg in 2002, Zurich in 2000, Beijing in 1998, and\nToulouse in 1996.\n  The 14th edition, ADG 2023, was held in Belgrade, Serbia, in September 20-22,\n2023. This edition of ADG had an additional special focus topic, Deduction in\nEducation.\n  Invited Speakers: Julien Narboux, University of Strasbourg, France\n\"Formalisation, arithmetization and automatisation of geometry\"; Filip Mari\\'c,\nUniversity of Belgrade, Serbia, \"Automatization, formalization and\nvisualization of hyperbolic geometry\"; Zlatan Magajna, University of Ljubljana,\nSlovenia, \"Workshop OK Geometry\"", "field": "Computer Science", "categories": "cs.LO,cs.AI,cs.CG,cs.MS"}, {"arxiv_id": "2401.10726", "title": "Empowering Aggregators with Practical Data-Driven Tools: Harnessing\n  Aggregated and Disaggregated Flexibility for Demand Response", "abstract": "This study explores the crucial interplay between aggregators and building\noccupants in activating flexibility through Demand Response (DR) programs, with\na keen focus on achieving robust decarbonization and fortifying the resilience\nof the energy system amidst the uncertainties presented by Renewable Energy\nSources (RES). Firstly, it introduces a methodology of optimizing aggregated\nflexibility provision strategies in environments with limited data, utilizing\nDiscrete Fourier Transformation (DFT) and clustering techniques to identify\nbuilding occupant's activity patterns. Secondly, the study assesses the\ndisaggregated flexibility provision of Heating Ventilation and Air Conditioning\n(HVAC) systems during DR events, employing machine learning and optimization\ntechniques for precise, device-level analysis. The first approach offers a\nnon-intrusive pathway for aggregators to provide flexibility services in\nenvironments of a single smart meter for the whole building's consumption,\nwhile the second approach carefully considers building occupants' thermal\ncomfort profiles, while maximizing flexibility in case of existence of\ndedicated smart meters to the HVAC systems. Through the application of\ndata-driven techniques and encompassing case studies from both industrial and\nresidential buildings, this paper not only unveils pivotal opportunities for\naggregators in the balancing and emerging flexibility markets but also\nsuccessfully develops end-to-end practical tools for aggregators. Furthermore,\nthe efficacy of this tool is validated through detailed case studies,\nsubstantiating its operational capability and contributing to the evolution of\na resilient and efficient energy system.", "field": "Computer Science", "categories": "eess.SY,cs.LG,cs.SY"}, {"arxiv_id": "2401.10727", "title": "Tool-LMM: A Large Multi-Modal Model for Tool Agent Learning", "abstract": "Recently, the astonishing performance of large language models (LLMs) in\nnatural language comprehension and generation tasks triggered lots of\nexploration of using them as central controllers to build agent systems.\nMultiple studies focus on bridging the LLMs to external tools to extend the\napplication scenarios. However, the current LLMs' perceiving tool-use ability\nis limited to a single text query, which may result in ambiguity in\nunderstanding the users' real intentions. LLMs are expected to eliminate that\nby perceiving the visual- or auditory-grounded instructions' information.\nTherefore, in this paper, we propose Tool-LMM, a system incorporating\nopen-source LLMs and multi-modal encoders so that the learnt LLMs can be\nconscious of multi-modal input instruction and then select the function-matched\ntool correctly. To facilitate the evaluation of the model's capability, we\ncollect a dataset featured by consisting of multi-modal input tools from\nHuggingFace. Another important feature of our dataset is that our dataset also\ncontains multiple potential choices for the same instruction due to the\nexistence of identical functions and synonymous functions, which provides more\npotential solutions for the same query. The experiments reveal that our LMM is\ncapable of recommending appropriate tools for multi-modal instructions. Codes\nand data are available at https://github.com/Tool-LMM/Tool-LMM.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10729", "title": "Network Design on Undirected Series-Parallel Graphs", "abstract": "We study the single pair capacitated network design problem and the budget\nconstrained max flow problem on undirected series-parallel graphs. These\nproblems were well studied on directed series-parallel graphs, but little is\nknown in the context of undirected graphs. The major difference between the\ncases is that the source and sink of the problem instance do not necessarily\ncoincide with the terminals of the underlying series-parallel graph in the\nundirected case, thus creating certain complications. We provide\npseudopolynomial time algorithms to solve both of the problems and provide an\nFPTAS for the budget constrained max flow problem. We also provide some\nextensions, arguing important cases when the problems are polynomial-time\nsolvable, and describing a series-parallel gadget that captures an edge upgrade\nversion of the problems.", "field": "Computer Science", "categories": "cs.DS"}, {"arxiv_id": "2401.10731", "title": "Removal and Selection: Improving RGB-Infrared Object Detection via\n  Coarse-to-Fine Fusion", "abstract": "Object detection in visible (RGB) and infrared (IR) images has been widely\napplied in recent years. Leveraging the complementary characteristics of RGB\nand IR images, the object detector provides reliable and robust object\nlocalization from day to night. Existing fusion strategies directly inject RGB\nand IR images into convolution neural networks, leading to inferior detection\nperformance. Since the RGB and IR features have modality-specific noise, these\nstrategies will worsen the fused features along with the propagation. Inspired\nby the mechanism of human brain processing multimodal information, this work\nintroduces a new coarse-to-fine perspective to purify and fuse two modality\nfeatures. Specifically, following this perspective, we design a Redundant\nSpectrum Removal module to coarsely remove interfering information within each\nmodality and a Dynamic Feature Selection module to finely select the desired\nfeatures for feature fusion. To verify the effectiveness of the coarse-to-fine\nfusion strategy, we construct a new object detector called Removal and\nSelection Detector (RSDet). Extensive experiments on three RGB-IR object\ndetection datasets verify the superior performance of our method.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10733", "title": "Dynamic Q&A of Clinical Documents with Large Language Models", "abstract": "Electronic health records (EHRs) house crucial patient data in clinical\nnotes. As these notes grow in volume and complexity, manual extraction becomes\nchallenging. This work introduces a natural language interface using large\nlanguage models (LLMs) for dynamic question-answering on clinical notes. Our\nchatbot, powered by Langchain and transformer-based LLMs, allows users to query\nin natural language, receiving relevant answers from clinical notes.\nExperiments, utilizing various embedding models and advanced LLMs, show Wizard\nVicuna's superior accuracy, albeit with high compute demands. Model\noptimization, including weight quantization, improves latency by approximately\n48 times. Promising results indicate potential, yet challenges such as model\nhallucinations and limited diverse medical case evaluations remain. Addressing\nthese gaps is crucial for unlocking the value in clinical notes and advancing\nAI-driven clinical decision-making.", "field": "Computer Science", "categories": "cs.IR,cs.AI"}, {"arxiv_id": "2401.10735", "title": "A Low-Frequency-Stable Higher-Order Spline-Based Integral Equation\n  Method", "abstract": "This contribution investigates the connection between Isogeometric Analysis\nand Integral Equation methods for full-wave electromagnetic problems. The\nproposed spline-based integral equation method allows for an exact\nrepresentation of the model geometry described in terms of Non-Uniform Rational\nB-Splines without meshing. This is particularly useful when high accuracy is\nrequired or when meshing is cumbersome for instance during optimization of\nelectric components. The Augmented Electric Field Integral Equation is adopted,\nso the low-frequency breakdown is avoided. The extension to higher-order basis\nfunctions is analyzed and the convergence rate discussed. The analogy with the\nPartial Element Equivalent Circuit method for the lowest-order case is\nestablished, allowing for a circuit interpretation while maintaining the exact\nrepresentation of geometry even for coarse discretizations. Numerical\nexperiments on academic and realistic test cases demonstrate the high accuracy\nof the proposed approach.", "field": "Computer Science", "categories": "cs.CE,cs.NA,math.NA"}, {"arxiv_id": "2401.10736", "title": "A Survey and Comparative Analysis of Security Properties of CAN\n  Authentication Protocols", "abstract": "The large number of Electronic Control Units (ECUs) mounted on modern cars\nand their expansive communication capabilities create a substantial attack\nsurface for potential exploitation. Despite the evolution of automotive\ntechnology, the continued use of the originally insecure Controller Area\nNetwork (CAN) bus leaves in-vehicle communications inherently non-secure. In\nresponse to the absence of standardized authentication protocols within the\nautomotive domain, researchers propose diverse solutions, each with unique\nstrengths and vulnerabilities. However, the continuous influx of new protocols\nand potential oversights in meeting security requirements and essential\noperational features further complicate the implementability of these\nprotocols. This paper comprehensively reviews and compares the 15 most\nprominent authentication protocols for the CAN bus. Our analysis emphasizes\ntheir strengths and weaknesses, evaluating their alignment with critical\nsecurity requirements for automotive authentication. Additionally, we evaluate\nprotocols based on essential operational criteria that contribute to ease of\nimplementation in predefined infrastructures, enhancing overall reliability and\nreducing the probability of successful attacks. Our study reveals a prevalent\nfocus on defending against external attackers in existing protocols, exposing\nvulnerabilities to internal threats. Notably, authentication protocols\nemploying hash chains, Mixed Message Authentication Codes, and asymmetric\nencryption techniques emerge as the most effective approaches. Through our\ncomparative study, we classify the considered protocols based on their security\nattributes and suitability for implementation, providing valuable insights for\nfuture developments in the field.", "field": "Computer Science", "categories": "cs.CR"}, {"arxiv_id": "2401.10738", "title": "Warehouse Problem with Multiple Vendors and Generalized Complementarity\n  Constraints", "abstract": "We study the warehouse problem, arising in the area of inventory management\nand production planning. Here, a merchant wants to decide an optimal trading\npolicy that computes quantities of a single commodity to purchase, store and\nsell during each time period of a finite discrete time horizon. Motivated by\nrecent applications in energy markets, we extend the models by Wolsey and Yaman\n(2018) and Bansal and G\\\"unl\\\"uk (2023) and consider markets with multiple\nvendors and a more general form of the complementarity constraints. We show\nthat these extensions can capture various practical conditions such as surge\npricing and discounted sales, ramp-up and ramp-down constraints and batch\npricing. We analyze the extreme points of the underlying non-linear integer\nprogram and provide an algorithm that exactly solves the problem. Our algorithm\nruns in polynomial time under reasonable practical conditions. We also show\nthat the absence of such conditions renders the problem NP-Hard.", "field": "Computer Science", "categories": "cs.DS"}, {"arxiv_id": "2401.10739", "title": "In-IDE Human-AI Experience in the Era of Large Language Models; A\n  Literature Review", "abstract": "Integrated Development Environments (IDEs) have become central to modern\nsoftware development, especially with the integration of Artificial\nIntelligence (AI) to enhance programming efficiency and decision-making. The\nstudy of in-IDE Human-AI Experience is critical in understanding how these AI\ntools are transforming the software development process, impacting programmer\nproductivity, and influencing code quality. We conducted a literature review to\nstudy the current state of in-IDE Human-AI Experience research, bridging a gap\nin understanding the nuanced interactions between programmers and AI assistants\nwithin IDEs. By analyzing 36 selected papers, our study illustrates three\nprimary research branches: Design, Impact, and Quality of Interaction. The\ntrends, challenges, and opportunities identified in this paper emphasize the\nevolving landscape of software development and inform future directions for\nresearch and development in this dynamic field. Specifically, we invite the\ncommunity to investigate three aspects of these interactions: designing\ntask-specific user interface, building trust, and improving readability.", "field": "Computer Science", "categories": "cs.SE,cs.HC"}, {"arxiv_id": "2401.10741", "title": "Character Recognition in Byzantine Seals with Deep Neural Networks", "abstract": "Seals are small coin-shaped artifacts, mostly made of lead, held with strings\nto seal letters. This work presents the first attempt towards automatic reading\nof text on Byzantine seal images.Byzantine seals are generally decorated with\niconography on the obverse side and Greek text on the reverse side. Text may\ninclude the sender's name, position in the Byzantine aristocracy, and elements\nof prayers. Both text and iconography are precious literary sources that wait\nto be exploited electronically, so the development of computerized systems for\ninterpreting seals images is of paramount importance. This work's contribution\nis hence a deep, two-stages, character reading pipeline for transcribing\nByzantine seal images. A first deep convolutional neural network (CNN) detects\ncharacters in the seal (character localization). A second convolutional network\nreads the localized characters (character classification). Finally, a\ndiplomatic transcription of the seal is provided by post-processing the two\nnetwork outputs. We provide an experimental evaluation of each CNN in isolation\nand both CNNs in combination. All performances are evaluated by\ncross-validation. Character localization achieves a mean average precision\n(mAP@0.5) greater than 0.9. Classification of characters cropped from ground\ntruth bounding boxes achieves Top-1 accuracy greater than 0.92. End-to-end\nevaluation shows the efficiency of the proposed approach when compared to the\nSoTA for similar tasks.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10744", "title": "FinLLMs: A Framework for Financial Reasoning Dataset Generation with\n  Large Language Models", "abstract": "Large Language models (LLMs) usually rely on extensive training datasets. In\nthe financial domain, creating numerical reasoning datasets that include a mix\nof tables and long text often involves substantial manual annotation expenses.\nTo address the limited data resources and reduce the annotation cost, we\nintroduce FinLLMs, a method for generating financial question-answering data\nbased on common financial formulas using Large Language Models. First, we\ncompile a list of common financial formulas and construct a graph based on the\nvariables these formulas employ. We then augment the formula set by combining\nthose that share identical variables as new elements. Specifically, we explore\nformulas obtained by manual annotation and merge those formulas with shared\nvariables by traversing the constructed graph. Finally, utilizing GPT-3.5, we\ngenerate financial question-answering data that encompasses both tabular\ninformation and long textual content, building on the collected formula set.\nOur experiments demonstrate that synthetic data generated by FinLLMs\neffectively enhances the performance of several large-scale numerical reasoning\nmodels in the financial domain, outperforming two established benchmark\nfinancial question-answering datasets.", "field": "Computer Science", "categories": "cs.AI"}, {"arxiv_id": "2401.10745", "title": "Ethical Artificial Intelligence Principles and Guidelines for the\n  Governance and Utilization of Highly Advanced Large Language Models", "abstract": "Given the success of ChatGPT, LaMDA and other large language models (LLMs),\nthere has been an increase in development and usage of LLMs within the\ntechnology sector and other sectors. While the level in which LLMs has not\nreached a level where it has surpassed human intelligence, there will be a time\nwhen it will. Such LLMs can be referred to as advanced LLMs. Currently, there\nare limited usage of ethical artificial intelligence (AI) principles and\nguidelines addressing advanced LLMs due to the fact that we have not reached\nthat point yet. However, this is a problem as once we do reach that point, we\nwill not be adequately prepared to deal with the aftermath of it in an ethical\nand optimal way, which will lead to undesired and unexpected consequences. This\npaper addresses this issue by discussing what ethical AI principles and\nguidelines can be used to address highly advanced LLMs.", "field": "Computer Science", "categories": "cs.CY,cs.AI,cs.CE,cs.LG,68Txx,I.2; K.4.1; K.5.2; K.6.5; K.4.2"}, {"arxiv_id": "2401.10747", "title": "Multimodal Sentiment Analysis with Missing Modality: A\n  Knowledge-Transfer Approach", "abstract": "Multimodal sentiment analysis aims to identify the emotions expressed by\nindividuals through visual, language, and acoustic cues. However, most of the\nexisting research efforts assume that all modalities are available during both\ntraining and testing, making their algorithms susceptible to the missing\nmodality scenario. In this paper, we propose a novel knowledge-transfer network\nto translate between different modalities to reconstruct the missing audio\nmodalities. Moreover, we develop a cross-modality attention mechanism to retain\nthe maximal information of the reconstructed and observed modalities for\nsentiment prediction. Extensive experiments on three publicly available\ndatasets demonstrate significant improvements over baselines and achieve\ncomparable results to the previous methods with complete multi-modality\nsupervision.", "field": "Computer Science", "categories": "cs.SD,cs.AI,cs.CL,cs.LG,eess.AS"}, {"arxiv_id": "2401.10748", "title": "Fast gradient-free activation maximization for neurons in spiking neural\n  networks", "abstract": "Neural networks (NNs), both living and artificial, work due to being complex\nsystems of neurons, each having its own specialization. Revealing these\nspecializations is important for understanding NNs inner working mechanisms.\nThe only way to do this for a living system, the neural response of which to a\nstimulus is not a known (let alone differentiable) function is to build a\nfeedback loop of exposing it to stimuli, the properties of which can be\niteratively varied aiming in the direction of maximal response. To test such a\nloop on a living network, one should first learn how to run it quickly and\nefficiently, reaching most effective stimuli (ones that maximize certain\nneurons activation) in least possible number of iterations. We present a\nframework with an effective design of such a loop, successfully testing it on\nan artificial spiking neural network (SNN, a model that mimics the behaviour of\nNNs in living brains). Our optimization method used for activation maximization\n(AM) was based on low-rank tensor decomposition (Tensor Train, TT) of the\nactivation function's discretization over its domain the latent parameter space\nof stimuli (CIFAR10-size color images, generated by either VQ-VAE or SN-GAN\nfrom their latent description vectors, fed to the SNN). To our knowledge, the\npresent work is the first attempt to perform effective AM for SNNs. The source\ncode of our framework, MANGO (for Maximization of neural Activation via\nNon-Gradient Optimization) is available on GitHub.", "field": "Computer Science", "categories": "cs.NE,cs.LG"}, {"arxiv_id": "2401.10749", "title": "ReliCD: A Reliable Cognitive Diagnosis Framework with Confidence\n  Awareness", "abstract": "During the past few decades, cognitive diagnostics modeling has attracted\nincreasing attention in computational education communities, which is capable\nof quantifying the learning status and knowledge mastery levels of students.\nIndeed, the recent advances in neural networks have greatly enhanced the\nperformance of traditional cognitive diagnosis models through learning the deep\nrepresentations of students and exercises. Nevertheless, existing approaches\noften suffer from the issue of overconfidence in predicting students' mastery\nlevels, which is primarily caused by the unavoidable noise and sparsity in\nrealistic student-exercise interaction data, severely hindering the educational\napplication of diagnostic feedback. To address this, in this paper, we propose\na novel Reliable Cognitive Diagnosis(ReliCD) framework, which can quantify the\nconfidence of the diagnosis feedback and is flexible for different cognitive\ndiagnostic functions. Specifically, we first propose a Bayesian method to\nexplicitly estimate the state uncertainty of different knowledge concepts for\nstudents, which enables the confidence quantification of diagnostic feedback.\nIn particular, to account for potential differences, we suggest modeling\nindividual prior distributions for the latent variables of different ability\nconcepts using a pre-trained model. Additionally, we introduce a logical\nhypothesis for ranking confidence levels. Along this line, we design a novel\ncalibration loss to optimize the confidence parameters by modeling the process\nof student performance prediction. Finally, extensive experiments on four\nreal-world datasets clearly demonstrate the effectiveness of our ReliCD\nframework.", "field": "Computer Science", "categories": "cs.CY,cs.LG"}, {"arxiv_id": "2401.10751", "title": "EFO: the Emotion Frame Ontology", "abstract": "Emotions are a subject of intense debate in various disciplines. Despite the\nproliferation of theories and definitions, there is still no consensus on what\nemotions are, and how to model the different concepts involved when we talk\nabout - or categorize - them. In this paper, we propose an OWL frame-based\nontology of emotions: the Emotion Frames Ontology (EFO). EFO treats emotions as\nsemantic frames, with a set of semantic roles that capture the different\naspects of emotional experience. EFO follows pattern-based ontology design, and\nis aligned to the DOLCE foundational ontology. EFO is used to model multiple\nemotion theories, which can be cross-linked as modules in an Emotion Ontology\nNetwork. In this paper, we exemplify it by modeling Ekman's Basic Emotions (BE)\nTheory as an EFO-BE module, and demonstrate how to perform automated inferences\non the representation of emotion situations. EFO-BE has been evaluated by\nlexicalizing the BE emotion frames from within the Framester knowledge graph,\nand implementing a graph-based emotion detector from text. In addition, an EFO\nintegration of multimodal datasets, including emotional speech and emotional\nface expressions, has been performed to enable further inquiry into crossmodal\nemotion semantics.", "field": "Computer Science", "categories": "cs.AI,cs.CY,cs.SC"}, {"arxiv_id": "2401.10752", "title": "HiCD: Change Detection in Quality-Varied Images via Hierarchical\n  Correlation Distillation", "abstract": "Advanced change detection techniques primarily target image pairs of equal\nand high quality. However, variations in imaging conditions and platforms\nfrequently lead to image pairs with distinct qualities: one image being\nhigh-quality, while the other being low-quality. These disparities in image\nquality present significant challenges for understanding image pairs\nsemantically and extracting change features, ultimately resulting in a notable\ndecline in performance. To tackle this challenge, we introduce an innovative\ntraining strategy grounded in knowledge distillation. The core idea revolves\naround leveraging task knowledge acquired from high-quality image pairs to\nguide the model's learning process when dealing with image pairs that exhibit\ndifferences in quality. Additionally, we develop a hierarchical correlation\ndistillation approach (involving self-correlation, cross-correlation, and\nglobal correlation). This approach compels the student model to replicate the\ncorrelations inherent in the teacher model, rather than focusing solely on\nindividual features. This ensures effective knowledge transfer while\nmaintaining the student model's training flexibility.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10753", "title": "BoolGebra: Attributed Graph-learning for Boolean Algebraic Manipulation", "abstract": "Boolean algebraic manipulation is at the core of logic synthesis in\nElectronic Design Automation (EDA) design flow. Existing methods struggle to\nfully exploit optimization opportunities, and often suffer from an explosive\nsearch space and limited scalability efficiency. This work presents BoolGebra,\na novel attributed graph-learning approach for Boolean algebraic manipulation\nthat aims to improve fundamental logic synthesis. BoolGebra incorporates Graph\nNeural Networks (GNNs) and takes initial feature embeddings from both\nstructural and functional information as inputs. A fully connected neural\nnetwork is employed as the predictor for direct optimization result\npredictions, significantly reducing the search space and efficiently locating\nthe optimization space. The experiments involve training the BoolGebra model\nw.r.t design-specific and cross-design inferences using the trained model,\nwhere BoolGebra demonstrates generalizability for cross-design inference and\nits potential to scale from small, simple training datasets to large, complex\ninference datasets. Finally, BoolGebra is integrated with existing synthesis\ntool ABC to perform end-to-end logic minimization evaluation w.r.t SOTA\nbaselines.", "field": "Computer Science", "categories": "cs.AR,cs.AI,cs.LG"}, {"arxiv_id": "2401.10754", "title": "Data Augmentation for Traffic Classification", "abstract": "Data Augmentation (DA) -- enriching training data by adding synthetic samples\n-- is a technique widely adopted in Computer Vision (CV) and Natural Language\nProcessing (NLP) tasks to improve models performance. Yet, DA has struggled to\ngain traction in networking contexts, particularly in Traffic Classification\n(TC) tasks. In this work, we fulfill this gap by benchmarking 18 augmentation\nfunctions applied to 3 TC datasets using packet time series as input\nrepresentation and considering a variety of training conditions. Our results\nshow that (i) DA can reap benefits previously unexplored with (ii)\naugmentations acting on time series sequence order and masking being a better\nsuit for TC and (iii) simple latent space analysis can provide hints about why\naugmentations have positive or negative effects.", "field": "Computer Science", "categories": "cs.LG,cs.NI"}, {"arxiv_id": "2401.10755", "title": "Code Reviewer Recommendation Based on a Hypergraph with Multiplex\n  Relationships", "abstract": "Code review is an essential component of software development, playing a\nvital role in ensuring a comprehensive check of code changes. However, the\ncontinuous influx of pull requests and the limited pool of available reviewer\ncandidates pose a significant challenge to the review process, making the task\nof assigning suitable reviewers to each review request increasingly difficult.\nTo tackle this issue, we present MIRRec, a novel code reviewer recommendation\nmethod that leverages a hypergraph with multiplex relationships. MIRRec encodes\nhigh-order correlations that go beyond traditional pairwise connections using\ndegree-free hyperedges among pull requests and developers. This way, it can\ncapture high-order implicit connectivity and identify potential reviewers. To\nvalidate the effectiveness of MIRRec, we conducted experiments using a dataset\ncomprising 48,374 pull requests from ten popular open-source software projects\nhosted on GitHub. The experiment results demonstrate that MIRRec, especially\nwithout PR-Review Commenters relationship, outperforms existing stateof-the-art\ncode reviewer recommendation methods in terms of ACC and MRR, highlighting its\nsignificance in improving the code review process.", "field": "Computer Science", "categories": "cs.SE"}, {"arxiv_id": "2401.10759", "title": "Interactions with Prompt Problems: A New Way to Teach Programming with\n  Large Language Models", "abstract": "Large Language Models (LLMs) have upended decades of pedagogy in computing\neducation. Students previously learned to code through \\textit{writing} many\nsmall problems with less emphasis on code reading and comprehension. Recent\nresearch has shown that free code generation tools powered by LLMs can solve\nintroductory programming problems presented in natural language with ease. In\nthis paper, we propose a new way to teach programming with Prompt Problems.\nStudents receive a problem visually, indicating how input should be transformed\nto output, and must translate that to a prompt for an LLM to decipher. The\nproblem is considered correct when the code that is generated by the student\nprompt can pass all test cases. In this paper we present the design of this\ntool, discuss student interactions with it as they learn, and provide insights\ninto this new class of programming problems as well as the design tools that\nintegrate LLMs.", "field": "Computer Science", "categories": "cs.HC,cs.AI"}, {"arxiv_id": "2401.10765", "title": "Starlit: Privacy-Preserving Federated Learning to Enhance Financial\n  Fraud Detection", "abstract": "Federated Learning (FL) is a data-minimization approach enabling\ncollaborative model training across diverse clients with local data, avoiding\ndirect data exchange. However, state-of-the-art FL solutions to identify\nfraudulent financial transactions exhibit a subset of the following\nlimitations. They (1) lack a formal security definition and proof, (2) assume\nprior freezing of suspicious customers' accounts by financial institutions\n(limiting the solutions' adoption), (3) scale poorly, involving either $O(n^2)$\ncomputationally expensive modular exponentiation (where $n$ is the total number\nof financial institutions) or highly inefficient fully homomorphic encryption,\n(4) assume the parties have already completed the identity alignment phase,\nhence excluding it from the implementation, performance evaluation, and\nsecurity analysis, and (5) struggle to resist clients' dropouts. This work\nintroduces Starlit, a novel scalable privacy-preserving FL mechanism that\novercomes these limitations. It has various applications, such as enhancing\nfinancial fraud detection, mitigating terrorism, and enhancing digital health.\nWe implemented Starlit and conducted a thorough performance analysis using\nsynthetic data from a key player in global financial transactions. The\nevaluation indicates Starlit's scalability, efficiency, and accuracy.", "field": "Computer Science", "categories": "cs.LG,cs.CR"}, {"arxiv_id": "2401.10766", "title": "Semantic-Aware Resource Allocation in Constrained Networks with Limited\n  User Participation", "abstract": "Semantic communication has gained attention as a key enabler for intelligent\nand context-aware communication. However, one of the key challenges of semantic\ncommunications is the need to tailor the resource allocation to meet the\nspecific requirements of semantic transmission. In this paper, we focus on\nnetworks with limited resources where devices are constrained to transmit with\nlimited bandwidth and power over large distance. Specifically, we devise an\nefficient strategy to select the most pertinent semantic features and\nparticipating users, taking into account the channel quality, the transmission\ntime, and the recovery accuracy. To this end, we formulate an optimization\nproblem with the goal of selecting the most relevant and accurate semantic\nfeatures over devices while satisfying constraints on transmission time and\nquality of the channel. This involves optimizing communication resources,\nidentifying participating users, and choosing specific semantic information for\ntransmission. The underlying problem is inherently complex due to its\nnon-convex nature and combinatorial constraints. To overcome this challenge, we\nefficiently approximate the optimal solution by solving a series of integer\nlinear programming problems. Our numerical findings illustrate the\neffectiveness and efficiency of our approach in managing semantic\ncommunications in networks with limited resources.", "field": "Computer Science", "categories": "cs.IT,math.IT"}, {"arxiv_id": "2401.10768", "title": "Mitigating Hallucinations of Large Language Models via Knowledge\n  Consistent Alignment", "abstract": "While Large Language Models (LLMs) have proven to be exceptional on a variety\nof tasks after alignment, they may still produce responses that contradict the\ncontext or world knowledge confidently, a phenomenon known as\n``hallucination''. In this paper, we demonstrate that reducing the\ninconsistency between the external knowledge encapsulated in the training data\nand the intrinsic knowledge inherited in the pretraining corpus could mitigate\nhallucination in alignment. Specifically, we introduce a novel knowledge\nconsistent alignment (KCA) approach, which involves automatically formulating\nexaminations based on external knowledge for accessing the comprehension of\nLLMs. For data encompassing knowledge inconsistency, KCA implements several\nsimple yet efficient strategies for processing. We illustrate the superior\nperformance of the proposed KCA approach in mitigating hallucinations across\nsix benchmarks using LLMs of different backbones and scales. Furthermore, we\nconfirm the correlation between knowledge inconsistency and hallucination,\nsignifying the effectiveness of reducing knowledge inconsistency in alleviating\nhallucinations. Our code, model weights, and data are public at\n\\url{https://github.com/fanqiwan/KCA}.", "field": "Computer Science", "categories": "cs.CL"}, {"arxiv_id": "2401.10773", "title": "Multilevel lattice codes from Hurwitz integers", "abstract": "This study extends the Construction $\\pi_A$ lattices proposed in\n\\cite{huang2017construction}, to Hurwitz integers. To this, we use a modified\nversion of the Chinese remainder theorem applied to maximal orders. Exploiting\nthe isomorphism guaranteed by this theorem, we construct multilevel lattice\ncodes that effectively attain the Poltyrev-limit. The performance of the\nproposed lattice codes is evaluated via computer simulations, showing notably\nreduced computational complexity provided by the multistage decoding.", "field": "Computer Science", "categories": "cs.IT,math.IT"}, {"arxiv_id": "2401.10774", "title": "Medusa: Simple LLM Inference Acceleration Framework with Multiple\n  Decoding Heads", "abstract": "The inference process in Large Language Models (LLMs) is often limited due to\nthe absence of parallelism in the auto-regressive decoding process, resulting\nin most operations being restricted by the memory bandwidth of accelerators.\nWhile methods such as speculative decoding have been suggested to address this\nissue, their implementation is impeded by the challenges associated with\nacquiring and maintaining a separate draft model. In this paper, we present\nMedusa, an efficient method that augments LLM inference by adding extra\ndecoding heads to predict multiple subsequent tokens in parallel. Using a\ntree-based attention mechanism, Medusa constructs multiple candidate\ncontinuations and verifies them simultaneously in each decoding step. By\nleveraging parallel processing, Medusa introduces only minimal overhead in\nterms of single-step latency while substantially reducing the number of\ndecoding steps required.\n  We present two levels of fine-tuning procedures for Medusa to meet the needs\nof different use cases: Medusa-1: Medusa is directly fine-tuned on top of a\nfrozen backbone LLM, enabling lossless inference acceleration. Medusa-2: Medusa\nis fine-tuned together with the backbone LLM, enabling better prediction\naccuracy of Medusa heads and higher speedup but needing a special training\nrecipe that preserves the backbone model's capabilities.\n  Moreover, we propose several extensions that improve or expand the utility of\nMedusa, including a self-distillation to handle situations where no training\ndata is available and a typical acceptance scheme to boost the acceptance rate\nwhile maintaining generation quality. We evaluate Medusa on models of various\nsizes and training procedures. Our experiments demonstrate that Medusa-1 can\nachieve over 2.2x speedup without compromising generation quality, while\nMedusa-2 further improves the speedup to 2.3-3.6x.", "field": "Computer Science", "categories": "cs.LG,cs.CL"}, {"arxiv_id": "2401.10777", "title": "Determination of efficiency indicators of the stand for intelligent\n  control of manual operations in industrial production", "abstract": "Systems of intelligent control of manual operations in industrial production\nare being implemented in many industries nowadays. Such systems use\nhigh-resolution cameras and computer vision algorithms to automatically track\nthe operator's manipulations and prevent technological errors in the assembly\nprocess. At the same time compliance with safety regulations in the workspace\nis monitored. As a result, the defect rate of manufactured products and the\nnumber of accidents during the manual assembly of any device are decreased.\nBefore implementing an intelligent control system into a real production it is\nnecessary to calculate its efficiency. In order to do it experiments on the\nstand for manual operations control systems were carried out. This paper\nproposes the methodology for calculating the efficiency indicators. This\nmathematical approach is based on the IoU calculation of real- and\npredicted-time intervals between assembly stages. The results show high\nprecision in tracking the validity of manual assembly and do not depend on the\nduration of the assembly process.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10778", "title": "HaliVer: Deductive Verification and Scheduling Languages Join Forces", "abstract": "The HaliVer tool integrates deductive verification into the popular\nscheduling language Halide, used for image processing pipelines and array\ncomputations. HaliVer uses Vercors, a separation logic-based verifier, to\nverify the correctness of (1) the Halide algorithms and (2) the optimised\nparallel code produced by \\halide when an optimisation schedule is applied to\nthe algorithm. This allows proving complex, optimised code correct while\nreducing the effort to provide the required verification annotations. For both\napproaches, the same specification is used. We evaluated the tool on several\noptimised programs generated from characteristic Halide algorithms, using all\nbut one of the essential scheduling directives available in Halide. Without\nannotation effort, Haliver proves memory safety in almost all programs. With\nannotations Haliver, additionally, proves functional correctness properties. We\nshow that the approach is viable and reduces the manual annotation effort by an\norder of magnitude.", "field": "Computer Science", "categories": "cs.LO,cs.PL"}, {"arxiv_id": "2401.10781", "title": "Metric Dynamic Equilibrium Logic", "abstract": "In temporal extensions of Answer Set Programming (ASP) based on linear-time,\nthe behavior of dynamic systems is captured by sequences of states. While this\nrepresentation reflects their relative order, it abstracts away the specific\ntimes associated with each state. In many applications, however, timing\nconstraints are important like, for instance, when planning and scheduling go\nhand in hand. We address this by developing a metric extension of linear-time\nDynamic Equilibrium Logic, in which dynamic operators are constrained by\nintervals over integers. The resulting Metric Dynamic Equilibrium Logic\nprovides the foundation of an ASP-based approach for specifying qualitative and\nquantitative dynamic constraints. As such, it constitutes the most general\namong a whole spectrum of temporal extensions of Equilibrium Logic. In detail,\nwe show that it encompasses Temporal, Dynamic, Metric, and regular Equilibrium\nLogic, as well as its classic counterparts once the law of the excluded middle\nis added.", "field": "Computer Science", "categories": "cs.AI,cs.LO"}, {"arxiv_id": "2401.10785", "title": "Composite learning backstepping control with guaranteed exponential\n  stability and robustness", "abstract": "Adaptive backstepping control provides a feasible solution to achieve\nasymptotic tracking for mismatched uncertain nonlinear systems. However,\ninput-to-state stability depends on high-gain feedback generated by nonlinear\ndamping terms, and closed-loop exponential stability with parameter convergence\ninvolves a stringent condition named persistent excitation (PE). This paper\nproposes a composite learning backstepping control (CLBC) strategy based on\nmodular backstepping and high-order tuners to compensate for the transient\nprocess of parameter estimation and achieve closed-loop exponential stability\nwithout the nonlinear damping terms and the PE condition. A novel composite\nlearning mechanism that maximizes the staged exciting strength is designed for\nparameter estimation, such that parameter convergence can be achieved under a\ncondition of interval excitation (IE) or even partial IE that is strictly\nweaker than PE. An extra prediction error is employed in the adaptive law to\nensure the transient performance without nonlinear damping terms. The\nexponential stability of the closed-loop system is proved rigorously under the\npartial IE or IE condition. Simulations have demonstrated the effectiveness and\nsuperiority of the proposed method in both parameter estimation and control\ncompared to state-of-the-art methods.", "field": "Computer Science", "categories": "eess.SY,cs.SY"}, {"arxiv_id": "2401.10786", "title": "Sat2Scene: 3D Urban Scene Generation from Satellite Images with\n  Diffusion", "abstract": "Directly generating scenes from satellite imagery offers exciting\npossibilities for integration into applications like games and map services.\nHowever, challenges arise from significant view changes and scene scale.\nPrevious efforts mainly focused on image or video generation, lacking\nexploration into the adaptability of scene generation for arbitrary views.\nExisting 3D generation works either operate at the object level or are\ndifficult to utilize the geometry obtained from satellite imagery. To overcome\nthese limitations, we propose a novel architecture for direct 3D scene\ngeneration by introducing diffusion models into 3D sparse representations and\ncombining them with neural rendering techniques. Specifically, our approach\ngenerates texture colors at the point level for a given geometry using a 3D\ndiffusion model first, which is then transformed into a scene representation in\na feed-forward manner. The representation can be utilized to render arbitrary\nviews which would excel in both single-frame quality and inter-frame\nconsistency. Experiments in two city-scale datasets show that our model\ndemonstrates proficiency in generating photo-realistic street-view image\nsequences and cross-view urban scenes from satellite imagery.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10787", "title": "Hybrid Online Certificate Status Protocol with Certificate Revocation\n  List for Smart Grid Public Key Infrastructure", "abstract": "Hsu et al. (2022) proposed a cryptographic scheme within the public key\ninfrastructure to bolster the security of smart grid meters. Their proposal\ninvolved developing the Certificate Management over CMS mechanism to establish\nSimple Certificate Enrollment Protocol and Enrollment over Secure Transport\nprotocol. Additionally, they implemented Online Certificate Status Protocol\n(OCSP) services to independently query the status of certificates. However,\ntheir implementation featured a single OCSP server handling all query requests.\nConsidering the typical scenario in smart grid PKI environments with over tens\nof thousands of end-meters, we introduced a Hybrid Online Certificate Status\nProtocol mechanism. This approach decreases demand of query resources from the\nclient to OCSP servers collaborating with Certificate Revocation Lists. Our\nsimulations, mimicking meter behavior, demonstrated increased efficiency,\ncreating a more robust architecture tailored to the smart grid meter landscape.", "field": "Computer Science", "categories": "cs.CR"}, {"arxiv_id": "2401.1079", "title": "Measuring the Impact of Scene Level Objects on Object Detection: Towards\n  Quantitative Explanations of Detection Decisions", "abstract": "Although accuracy and other common metrics can provide a useful window into\nthe performance of an object detection model, they lack a deeper view of the\nmodel's decision process. Regardless of the quality of the training data and\nprocess, the features that an object detection model learns cannot be\nguaranteed. A model may learn a relationship between certain background\ncontext, i.e., scene level objects, and the presence of the labeled classes.\nFurthermore, standard performance verification and metrics would not identify\nthis phenomenon. This paper presents a new black box explainability method for\nadditional verification of object detection models by finding the impact of\nscene level objects on the identification of the objects within the image. By\ncomparing the accuracies of a model on test data with and without certain scene\nlevel objects, the contributions of these objects to the model's performance\nbecomes clearer. The experiment presented here will assess the impact of\nbuildings and people in image context on the detection of emergency road\nvehicles by a fine-tuned YOLOv8 model. A large increase in accuracy in the\npresence of a scene level object will indicate the model's reliance on that\nobject to make its detections. The results of this research lead to providing a\nquantitative explanation of the object detection model's decision process,\nenabling a deeper understanding of the model's performance.", "field": "Computer Science", "categories": "cs.CV,cs.LG"}, {"arxiv_id": "2401.10791", "title": "Early alignment in two-layer networks training is a two-edged sword", "abstract": "Training neural networks with first order optimisation methods is at the core\nof the empirical success of deep learning. The scale of initialisation is a\ncrucial factor, as small initialisations are generally associated to a feature\nlearning regime, for which gradient descent is implicitly biased towards simple\nsolutions. This work provides a general and quantitative description of the\nearly alignment phase, originally introduced by Maennel et al. (2018) . For\nsmall initialisation and one hidden ReLU layer networks, the early stage of the\ntraining dynamics leads to an alignment of the neurons towards key directions.\nThis alignment induces a sparse representation of the network, which is\ndirectly related to the implicit bias of gradient flow at convergence. This\nsparsity inducing alignment however comes at the expense of difficulties in\nminimising the training objective: we also provide a simple data example for\nwhich overparameterised networks fail to converge towards global minima and\nonly converge to a spurious stationary point instead.", "field": "Computer Science", "categories": "cs.LG,stat.ML"}, {"arxiv_id": "2401.10794", "title": "Deep Reinforcement Learning Empowered Activity-Aware Dynamic Health\n  Monitoring Systems", "abstract": "In smart healthcare, health monitoring utilizes diverse tools and\ntechnologies to analyze patients' real-time biosignal data, enabling immediate\nactions and interventions. Existing monitoring approaches were designed on the\npremise that medical devices track several health metrics concurrently,\ntailored to their designated functional scope. This means that they report all\nrelevant health values within that scope, which can result in excess resource\nuse and the gathering of extraneous data due to monitoring irrelevant health\nmetrics. In this context, we propose Dynamic Activity-Aware Health Monitoring\nstrategy (DActAHM) for striking a balance between optimal monitoring\nperformance and cost efficiency, a novel framework based on Deep Reinforcement\nLearning (DRL) and SlowFast Model to ensure precise monitoring based on users'\nactivities. Specifically, with the SlowFast Model, DActAHM efficiently\nidentifies individual activities and captures these results for enhanced\nprocessing. Subsequently, DActAHM refines health metric monitoring in response\nto the identified activity by incorporating a DRL framework. Extensive\nexperiments comparing DActAHM against three state-of-the-art approaches\ndemonstrate it achieves 27.3% higher gain than the best-performing baseline\nthat fixes monitoring actions over timeline.", "field": "Computer Science", "categories": "cs.LG,cs.CY"}, {"arxiv_id": "2401.10799", "title": "Novel Representation Learning Technique using Graphs for Performance\n  Analytics", "abstract": "The performance analytics domain in High Performance Computing (HPC) uses\ntabular data to solve regression problems, such as predicting the execution\ntime. Existing Machine Learning (ML) techniques leverage the correlations among\nfeatures given tabular datasets, not leveraging the relationships between\nsamples directly. Moreover, since high-quality embeddings from raw features\nimprove the fidelity of the downstream predictive models, existing methods rely\non extensive feature engineering and pre-processing steps, costing time and\nmanual effort. To fill these two gaps, we propose a novel idea of transforming\ntabular performance data into graphs to leverage the advancement of Graph\nNeural Network-based (GNN) techniques in capturing complex relationships\nbetween features and samples. In contrast to other ML application domains, such\nas social networks, the graph is not given; instead, we need to build it. To\naddress this gap, we propose graph-building methods where nodes represent\nsamples, and the edges are automatically inferred iteratively based on the\nsimilarity between the features in the samples. We evaluate the effectiveness\nof the generated embeddings from GNNs based on how well they make even a simple\nfeed-forward neural network perform for regression tasks compared to other\nstate-of-the-art representation learning techniques. Our evaluation\ndemonstrates that even with up to 25% random missing values for each dataset,\nour method outperforms commonly used graph and Deep Neural Network (DNN)-based\napproaches and achieves up to 61.67% & 78.56% improvement in MSE loss over the\nDNN baseline respectively for HPC dataset and Machine Learning Datasets.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.10804", "title": "Endovascular Detection of Catheter-Thrombus Contact by Vacuum Excitation", "abstract": "Objective: The objective of this work is to introduce and demonstrate the\neffectiveness of a novel sensing modality for contact detection between an\noff-the-shelf aspiration catheter and a thrombus. Methods: A custom robotic\nactuator with a pressure sensor was used to generate an oscillatory vacuum\nexcitation and sense the pressure inside the extracorporeal portion of the\ncatheter. Vacuum pressure profiles and robotic motion data were used to train a\nsupport vector machine (SVM) classification model to detect contact between the\naspiration catheter tip and a mock thrombus. Validation consisted of benchtop\naccuracy verification, as well as user study comparison to the current standard\nof angiographic presentation. Results: Benchtop accuracy of the sensing\nmodality was shown to be 99.67%. The user study demonstrated statistically\nsignificant improvement in identifying catheter-thrombus contact compared to\nthe current standard. The odds ratio of successful detection of clot contact\nwas 2.86 (p=0.03) when using the proposed sensory method compared to without\nit. Conclusion: The results of this work indicate that the proposed sensing\nmodality can offer intraoperative feedback to interventionalists that can\nimprove their ability to detect contact between the distal tip of a catheter\nand a thrombus. Significance: By offering a relatively low-cost technology that\naffords off-the-shelf aspiration catheters as clot-detecting sensors,\ninterventionalists can improve the first-pass effect of the mechanical\nthrombectomy procedure while reducing procedural times and mental burden.", "field": "Computer Science", "categories": "cs.RO"}, {"arxiv_id": "2401.10805", "title": "Learning to Visually Connect Actions and their Effects", "abstract": "In this work, we introduce the novel concept of visually Connecting Actions\nand Their Effects (CATE) in video understanding. CATE can have applications in\nareas like task planning and learning from demonstration. We propose different\nCATE-based task formulations, such as action selection and action\nspecification, where video understanding models connect actions and effects at\nsemantic and fine-grained levels. We observe that different formulations\nproduce representations capturing intuitive action properties. We also design\nvarious baseline models for action selection and action specification. Despite\nthe intuitive nature of the task, we observe that models struggle, and humans\noutperform them by a large margin. The study aims to establish a foundation for\nfuture efforts, showcasing the flexibility and versatility of connecting\nactions and effects in video understanding, with the hope of inspiring advanced\nformulations and models.", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.LG,cs.RO"}, {"arxiv_id": "2401.10809", "title": "Neglected Hessian component explains mysteries in Sharpness\n  regularization", "abstract": "Recent work has shown that methods like SAM which either explicitly or\nimplicitly penalize second order information can improve generalization in deep\nlearning. Seemingly similar methods like weight noise and gradient penalties\noften fail to provide such benefits. We show that these differences can be\nexplained by the structure of the Hessian of the loss. First, we show that a\ncommon decomposition of the Hessian can be quantitatively interpreted as\nseparating the feature exploitation from feature exploration. The feature\nexploration, which can be described by the Nonlinear Modeling Error matrix\n(NME), is commonly neglected in the literature since it vanishes at\ninterpolation. Our work shows that the NME is in fact important as it can\nexplain why gradient penalties are sensitive to the choice of activation\nfunction. Using this insight we design interventions to improve performance. We\nalso provide evidence that challenges the long held equivalence of weight noise\nand gradient penalties. This equivalence relies on the assumption that the NME\ncan be ignored, which we find does not hold for modern networks since they\ninvolve significant feature learning. We find that regularizing feature\nexploitation but not feature exploration yields performance similar to gradient\npenalties.", "field": "Computer Science", "categories": "cs.LG"}, {"arxiv_id": "2401.10815", "title": "RAD-DINO: Exploring Scalable Medical Image Encoders Beyond Text\n  Supervision", "abstract": "Language-supervised pre-training has proven to be a valuable method for\nextracting semantically meaningful features from images, serving as a\nfoundational element in multimodal systems within the computer vision and\nmedical imaging domains. However, resulting features are limited by the\ninformation contained within the text. This is particularly problematic in\nmedical imaging, where radiologists' written findings focus on specific\nobservations; a challenge compounded by the scarcity of paired imaging-text\ndata due to concerns over leakage of personal health information. In this work,\nwe fundamentally challenge the prevailing reliance on language supervision for\nlearning general purpose biomedical imaging encoders. We introduce RAD-DINO, a\nbiomedical image encoder pre-trained solely on unimodal biomedical imaging data\nthat obtains similar or greater performance than state-of-the-art biomedical\nlanguage supervised models on a diverse range of benchmarks. Specifically, the\nquality of learned representations is evaluated on standard imaging tasks\n(classification and semantic segmentation), and a vision-language alignment\ntask (text report generation from images). To further demonstrate the drawback\nof language supervision, we show that features from RAD-DINO correlate with\nother medical records (e.g., sex or age) better than language-supervised\nmodels, which are generally not mentioned in radiology reports. Finally, we\nconduct a series of ablations determining the factors in RAD-DINO's\nperformance; notably, we observe that RAD-DINO's downstream performance scales\nwell with the quantity and diversity of training data, demonstrating that\nimage-only supervision is a scalable approach for training a foundational\nbiomedical image encoder.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10816", "title": "Co-Pilot for Health: Personalized Algorithmic AI Nudging to Improve\n  Health Outcomes", "abstract": "The ability to shape health behaviors of large populations automatically,\nacross wearable types and disease conditions at scale has tremendous potential\nto improve global health outcomes. We designed and implemented an AI driven\nplatform for digital algorithmic nudging, enabled by a Graph-Neural Network\n(GNN) based Recommendation System, and granular health behavior data from\nwearable fitness devices. Here we describe the efficacy results of this\nplatform with its capabilities of personalized and contextual nudging to\n$n=84,764$ individuals over a 12-week period in Singapore. We statistically\nvalidated that participants in the target group who received such AI optimized\ndaily nudges increased daily physical activity like step count by 6.17% ($p =\n3.09\\times10^{-4}$) and weekly minutes of Moderate to Vigorous Physical\nActivity (MVPA) by 7.61% ($p = 1.16\\times10^{-2}$), compared to matched\nparticipants in control group who did not receive any nudges. Further, such\nnudges were very well received, with a 13.1% of nudges sent being opened (open\nrate), and 11.7% of the opened nudges rated useful compared to 1.9% rated as\nnot useful thereby demonstrating significant improvement in population level\nengagement metrics.", "field": "Computer Science", "categories": "cs.HC,cs.AI,cs.LG"}, {"arxiv_id": "2401.10819", "title": "Optimisation in Neurosymbolic Learning Systems", "abstract": "Neurosymbolic AI aims to integrate deep learning with symbolic AI. This\nintegration has many promises, such as decreasing the amount of data required\nto train a neural network, improving the explainability and interpretability of\nanswers given by models and verifying the correctness of trained systems. We\nstudy neurosymbolic learning, where we have both data and background knowledge\nexpressed using symbolic languages. How do we connect the symbolic and neural\ncomponents to communicate this knowledge? One option is fuzzy reasoning, which\nstudies degrees of truth. For example, being tall is not a binary concept.\nInstead, probabilistic reasoning studies the probability that something is true\nor will happen. Our first research question studies how different forms of\nfuzzy reasoning combine with learning. We find surprising results like a\nconnection to the Raven paradox stating we confirm \"ravens are black\" when we\nobserve a green apple. In this study, we did not use the background knowledge\nwhen we deployed our models after training. In our second research question, we\nstudied how to use background knowledge in deployed models. We developed a new\nneural network layer based on fuzzy reasoning. Probabilistic reasoning is a\nnatural fit for neural networks, which we usually train to be probabilistic.\nHowever, they are expensive to compute and do not scale well to large tasks. In\nour third research question, we study how to connect probabilistic reasoning\nwith neural networks by sampling to estimate averages, while in the final\nresearch question, we study scaling probabilistic neurosymbolic learning to\nmuch larger problems than before. Our insight is to train a neural network with\nsynthetic data to predict the result of probabilistic reasoning.", "field": "Computer Science", "categories": "cs.AI,cs.LG"}, {"arxiv_id": "2401.1082", "title": "Help Me Reflect: Leveraging Self-Reflection Interface Nudges to Enhance\n  Deliberativeness on Online Deliberation Platforms", "abstract": "The deliberative potential of online platforms has been widely examined.\nHowever, little is known about how various interface-based reflection nudges\nimpact the quality of deliberation. This paper presents two user studies with\n12 and 120 participants, respectively, to investigate the impacts of different\nreflective nudges on the quality of deliberation. In the first study, we\nexamined five distinct reflective nudges: persona, temporal prompts, analogies\nand metaphors, cultural prompts and storytelling. Persona, temporal prompts,\nand storytelling emerged as the preferred nudges for implementation on online\ndeliberation platforms. In the second study, we assess the impacts of these\npreferred reflectors more thoroughly. Results revealed a significant positive\nimpact of these reflectors on deliberative quality. Specifically, persona\npromotes a deliberative environment for balanced and opinionated viewpoints\nwhile temporal prompts promote more individualised viewpoints. Our findings\nsuggest that the choice of reflectors can significantly influence the dynamics\nand shape the nature of online discussions.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.10822", "title": "ActAnywhere: Subject-Aware Video Background Generation", "abstract": "Generating video background that tailors to foreground subject motion is an\nimportant problem for the movie industry and visual effects community. This\ntask involves synthesizing background that aligns with the motion and\nappearance of the foreground subject, while also complies with the artist's\ncreative intention. We introduce ActAnywhere, a generative model that automates\nthis process which traditionally requires tedious manual efforts. Our model\nleverages the power of large-scale video diffusion models, and is specifically\ntailored for this task. ActAnywhere takes a sequence of foreground subject\nsegmentation as input and an image that describes the desired scene as\ncondition, to produce a coherent video with realistic foreground-background\ninteractions while adhering to the condition frame. We train our model on a\nlarge-scale dataset of human-scene interaction videos. Extensive evaluations\ndemonstrate the superior performance of our model, significantly outperforming\nbaselines. Moreover, we show that ActAnywhere generalizes to diverse\nout-of-distribution samples, including non-human subjects. Please visit our\nproject webpage at https://actanywhere.github.io.", "field": "Computer Science", "categories": "cs.CV"}, {"arxiv_id": "2401.10823", "title": "Reconfigurable Intelligent Surface (RIS)-Assisted Entanglement\n  Distribution in FSO Quantum Networks", "abstract": "Quantum networks (QNs) relying on free-space optical (FSO) quantum channels\ncan support quantum applications in environments wherein establishing an\noptical fiber infrastructure is challenging and costly. However, FSO-based QNs\nrequire a clear line-of-sight (LoS) between users, which is challenging due to\nblockages and natural obstacles. In this paper, a reconfigurable intelligent\nsurface (RIS)-assisted FSO-based QN is proposed as a cost-efficient framework\nproviding a virtual LoS between users for entanglement distribution. A novel\nmodeling of the quantum noise and losses experienced by quantum states over FSO\nchannels defined by atmospheric losses, turbulence, and pointing errors is\nderived. Then, the joint optimization of entanglement distribution and RIS\nplacement problem is formulated, under heterogeneous entanglement rate and\nfidelity constraints. This problem is solved using a simulated annealing\nmetaheuristic algorithm. Simulation results show that the proposed framework\neffectively meets the minimum fidelity requirements of all users' quantum\napplications. This is in stark contrast to baseline algorithms that lead to a\ndrop of at least 83% in users' end-to-end fidelities. The proposed framework\nalso achieves a 64% enhancement in the fairness level between users compared to\nbaseline rate maximizing frameworks. Finally, the weather conditions, e.g.,\nrain, are observed to have a more significant effect than pointing errors and\nturbulence.", "field": "Computer Science", "categories": "cs.NI,quant-ph"}, {"arxiv_id": "2401.10825", "title": "A survey on recent advances in named entity recognition", "abstract": "Named Entity Recognition seeks to extract substrings within a text that name\nreal-world objects and to determine their type (for example, whether they refer\nto persons or organizations). In this survey, we first present an overview of\nrecent popular approaches, but we also look at graph- and transformer- based\nmethods including Large Language Models (LLMs) that have not had much coverage\nin other surveys. Second, we focus on methods designed for datasets with scarce\nannotations. Third, we evaluate the performance of the main NER implementations\non a variety of datasets with differing characteristics (as regards their\ndomain, their size, and their number of classes). We thus provide a deep\ncomparison of algorithms that are never considered together. Our experiments\nshed some light on how the characteristics of datasets affect the behavior of\nthe methods that we compare.", "field": "Computer Science", "categories": "cs.CL,cs.LG,68T50, 68Q32"}, {"arxiv_id": "2401.10831", "title": "Understanding Video Transformers via Universal Concept Discovery", "abstract": "This paper studies the problem of concept-based interpretability of\ntransformer representations for videos. Concretely, we seek to explain the\ndecision-making process of video transformers based on high-level,\nspatiotemporal concepts that are automatically discovered. Prior research on\nconcept-based interpretability has concentrated solely on image-level tasks.\nComparatively, video models deal with the added temporal dimension, increasing\ncomplexity and posing challenges in identifying dynamic concepts over time. In\nthis work, we systematically address these challenges by introducing the first\nVideo Transformer Concept Discovery (VTCD) algorithm. To this end, we propose\nan efficient approach for unsupervised identification of units of video\ntransformer representations - concepts, and ranking their importance to the\noutput of a model. The resulting concepts are highly interpretable, revealing\nspatio-temporal reasoning mechanisms and object-centric representations in\nunstructured video models. Performing this analysis jointly over a diverse set\nof supervised and self-supervised representations, we discover that some of\nthese mechanism are universal in video transformers. Finally, we demonstrate\nthat VTCDcan be used to improve model performance for fine-grained tasks.", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.LG,cs.RO"}, {"arxiv_id": "2401.10833", "title": "Quality Requirements for Code: On the Untapped Potential in\n  Maintainability Specifications", "abstract": "Quality requirements are critical for successful software engineering, with\nmaintainability being a key internal quality. Despite significant attention in\nsoftware metrics research, maintainability has attracted surprisingly little\nfocus in the Requirements Engineering (RE) community. This position paper\nproposes a synergistic approach, combining code-oriented research with RE\nexpertise, to create meaningful industrial impact. We introduce six\nillustrative use cases and propose three future research directions.\nPreliminary findings indicate that the established QUPER model, designed for\nsetting quality targets, does not adequately address the unique aspects of\nmaintainability.", "field": "Computer Science", "categories": "cs.SE"}, {"arxiv_id": "2401.10834", "title": "Cppless: Productive and Performant Serverless Programming in C++", "abstract": "The rise of serverless introduced a new class of scalable, elastic and highly\navailable parallel workers in the cloud. Many systems and applications benefit\nfrom offloading computations and parallel tasks to dynamically allocated\nresources. However, the developers of C++ applications found it difficult to\nintegrate functions due to complex deployment, lack of compatibility between\nclient and cloud environments, and loosely typed input and output data. To\nenable single-source and efficient serverless acceleration in C++, we introduce\nCppless, an end-to-end framework for implementing serverless functions which\nhandles the creation, deployment, and invocation of functions. Cppless is built\non top of LLVM and requires only two compiler extensions to automatically\nextract C++ function objects and deploy them to the cloud. We demonstrate that\noffloading parallel computations from a C++ application to serverless workers\ncan provide up to 30x speedup, requiring only minor code modifications and\ncosting less than one cent per computation.", "field": "Computer Science", "categories": "cs.DC"}, {"arxiv_id": "2401.10837", "title": "Aerial Field Robotics", "abstract": "Aerial field robotics research represents the domain of study that aims to\nequip unmanned aerial vehicles - and as it pertains to this chapter,\nspecifically Micro Aerial Vehicles (MAVs)- with the ability to operate in\nreal-life environments that present challenges to safe navigation. We present\nthe key elements of autonomy for MAVs that are resilient to collisions and\nsensing degradation, while operating under constrained computational resources.\nWe overview aspects of the state of the art, outline bottlenecks to resilient\nnavigation autonomy, and overview the field-readiness of MAVs. We conclude with\nnotable contributions and discuss considerations for future research that are\nessential for resilience in aerial robotics.", "field": "Computer Science", "categories": "cs.RO"}, {"arxiv_id": "2401.10838", "title": "Rambler: Supporting Writing With Speech via LLM-Assisted Gist\n  Manipulation", "abstract": "Dictation enables efficient text input on mobile devices. However, writing\nwith speech can produce disfluent, wordy, and incoherent text and thus requires\nheavy post-processing. This paper presents Rambler, an LLM-powered graphical\nuser interface that supports gist-level manipulation of dictated text with two\nmain sets of functions: gist extraction and macro revision. Gist extraction\ngenerates keywords and summaries as anchors to support the review and\ninteraction with spoken text. LLM-assisted macro revisions allow users to\nrespeak, split, merge and transform dictated text without specifying precise\nediting locations. Together they pave the way for interactive dictation and\nrevision that help close gaps between spontaneous spoken words and\nwell-structured writing. In a comparative study with 12 participants performing\nverbal composition tasks, Rambler outperformed the baseline of a speech-to-text\neditor + ChatGPT, as it better facilitates iterative revisions with enhanced\nuser control over the content while supporting surprisingly diverse user\nstrategies.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.10839", "title": "Holonic Learning: A Flexible Agent-based Distributed Machine Learning\n  Framework", "abstract": "Ever-increasing ubiquity of data and computational resources in the last\ndecade have propelled a notable transition in the machine learning paradigm\ntowards more distributed approaches. Such a transition seeks to not only tackle\nthe scalability and resource distribution challenges but also to address\npressing privacy and security concerns. To contribute to the ongoing discourse,\nthis paper introduces Holonic Learning (HoL), a collaborative and\nprivacy-focused learning framework designed for training deep learning models.\nBy leveraging holonic concepts, the HoL framework establishes a structured\nself-similar hierarchy in the learning process, enabling more nuanced control\nover collaborations through the individual model aggregation approach of each\nholon, along with their intra-holon commitment and communication patterns. HoL,\nin its general form, provides extensive design and flexibility potentials. For\nempirical analysis and to demonstrate its effectiveness, this paper implements\nHoloAvg, a special variant of HoL that employs weighted averaging for model\naggregation across all holons. The convergence of the proposed method is\nvalidated through experiments on both IID and Non-IID settings of the standard\nMNISt dataset. Furthermore, the performance behaviors of HoL are investigated\nunder various holarchical designs and data distribution scenarios. The\npresented results affirm HoL's prowess in delivering competitive performance\nparticularly, in the context of the Non-IID data distribution.", "field": "Computer Science", "categories": "cs.DC,cs.AI,cs.LG,cs.MA"}, {"arxiv_id": "2401.1084", "title": "Symbolic Cognitive Diagnosis via Hybrid Optimization for Intelligent\n  Education Systems", "abstract": "Cognitive diagnosis assessment is a fundamental and crucial task for student\nlearning. It models the student-exercise interaction, and discovers the\nstudents' proficiency levels on each knowledge attribute. In real-world\nintelligent education systems, generalization and interpretability of cognitive\ndiagnosis methods are of equal importance. However, most existing methods can\nhardly make the best of both worlds due to the complicated student-exercise\ninteraction. To this end, this paper proposes a symbolic cognitive\ndiagnosis~(SCD) framework to simultaneously enhance generalization and\ninterpretability. The SCD framework incorporates the symbolic tree to\nexplicably represent the complicated student-exercise interaction function, and\nutilizes gradient-based optimization methods to effectively learn the student\nand exercise parameters. Meanwhile, the accompanying challenge is that we need\nto tunnel the discrete symbolic representation and continuous parameter\noptimization. To address this challenge, we propose to hybridly optimize the\nrepresentation and parameters in an alternating manner. To fulfill SCD, it\nalternately learns the symbolic tree by derivative-free genetic programming and\nlearns the student and exercise parameters via gradient-based Adam. The\nextensive experimental results on various real-world datasets show the\nsuperiority of SCD on both generalization and interpretability. The ablation\nstudy verifies the efficacy of each ingredient in SCD, and the case study\nexplicitly showcases how the interpretable ability of SCD works.", "field": "Computer Science", "categories": "cs.CY,cs.AI,cs.LG"}, {"arxiv_id": "2401.10841", "title": "Using LLMs to discover emerging coded antisemitic hate-speech emergence\n  in extremist social media", "abstract": "Online hate speech proliferation has created a difficult problem for social\nmedia platforms. A particular challenge relates to the use of coded language by\ngroups interested in both creating a sense of belonging for its users and\nevading detection. Coded language evolves quickly and its use varies over time.\nThis paper proposes a methodology for detecting emerging coded hate-laden\nterminology. The methodology is tested in the context of online antisemitic\ndiscourse. The approach considers posts scraped from social media platforms,\noften used by extremist users. The posts are scraped using seed expressions\nrelated to previously known discourse of hatred towards Jews. The method begins\nby identifying the expressions most representative of each post and calculating\ntheir frequency in the whole corpus. It filters out grammatically incoherent\nexpressions as well as previously encountered ones so as to focus on emergent\nwell-formed terminology. This is followed by an assessment of semantic\nsimilarity to known antisemitic terminology using a fine-tuned large language\nmodel, and subsequent filtering out of the expressions that are too distant\nfrom known expressions of hatred. Emergent antisemitic expressions containing\nterms clearly relating to Jewish topics are then removed to return only coded\nexpressions of hatred.", "field": "Computer Science", "categories": "cs.CL,cs.AI,cs.IR,cs.LG"}, {"arxiv_id": "2401.10843", "title": "Training a General Spiking Neural Network with Improved Efficiency and\n  Minimum Latency", "abstract": "Spiking Neural Networks (SNNs) that operate in an event-driven manner and\nemploy binary spike representation have recently emerged as promising\ncandidates for energy-efficient computing. However, a cost bottleneck arises in\nobtaining high-performance SNNs: training a SNN model requires a large number\nof time steps in addition to the usual learning iterations, hence this limits\ntheir energy efficiency. This paper proposes a general training framework that\nenhances feature learning and activation efficiency within a limited time step,\nproviding a new solution for more energy-efficient SNNs. Our framework allows\nSNN neurons to learn robust spike feature from different receptive fields and\nupdate neuron states by utilizing both current stimuli and recurrence\ninformation transmitted from other neurons. This setting continuously\ncomplements information within a single time step. Additionally, we propose a\nprojection function to merge these two stimuli to smoothly optimize neuron\nweights (spike firing threshold and activation). We evaluate the proposal for\nboth convolution and recurrent models. Our experimental results indicate\nstate-of-the-art visual classification tasks, including CIFAR10, CIFAR100, and\nTinyImageNet.Our framework achieves 72.41% and 72.31% top-1 accuracy with only\n1 time step on CIFAR100 for CNNs and RNNs, respectively. Our method reduces 10x\nand 3x joule energy than a standard ANN and SNN, respectively, on CIFAR10,\nwithout additional time steps.", "field": "Computer Science", "categories": "cs.NE,cs.LG"}, {"arxiv_id": "2401.10844", "title": "Neural Population Decoding and Imbalanced Multi-Omic Datasets For Cancer\n  Subtype Diagnosis", "abstract": "Recent strides in the field of neural computation has seen the adoption of\nWinner Take All (WTA) circuits to facilitate the unification of hierarchical\nBayesian inference and spiking neural networks as a neurobiologically plausible\nmodel of information processing. Current research commonly validates the\nperformance of these networks via classification tasks, particularly of the\nMNIST dataset. However, researchers have not yet reached consensus about how\nbest to translate the stochastic responses from these networks into discrete\ndecisions, a process known as population decoding. Despite being an often\nunderexamined part of SNNs, in this work we show that population decoding has a\nsignificanct impact on the classification performance of WTA networks. For this\npurpose, we apply a WTA network to the problem of cancer subtype diagnosis from\nmulti omic data, using datasets from The Cancer Genome Atlas (TCGA). In doing\nso we utilise a novel implementation of gene similarity networks, a feature\nencoding technique based on Kohoens self organising map algorithm. We further\nshow that the impact of selecting certain population decoding methods is\namplified when facing imbalanced datasets.", "field": "Computer Science", "categories": "cs.NE,cs.LG,q-bio.GN,q-bio.QM,stat.AP"}, {"arxiv_id": "2401.10845", "title": "Emotion Classification In Software Engineering Texts: A Comparative\n  Analysis of Pre-trained Transformers Language Models", "abstract": "Emotion recognition in software engineering texts is critical for\nunderstanding developer expressions and improving collaboration. This paper\npresents a comparative analysis of state-of-the-art Pre-trained Language Models\n(PTMs) for fine-grained emotion classification on two benchmark datasets from\nGitHub and Stack Overflow. We evaluate six transformer models - BERT, RoBERTa,\nALBERT, DeBERTa, CodeBERT and GraphCodeBERT against the current best-performing\ntool SEntiMoji. Our analysis reveals consistent improvements ranging from\n1.17\\% to 16.79\\% in terms of macro-averaged and micro-averaged F1 scores, with\ngeneral domain models outperforming specialized ones. To further enhance PTMs,\nwe incorporate polarity features in attention layer during training,\ndemonstrating additional average gains of 1.0\\% to 10.23\\% over baseline PTMs\napproaches. Our work provides strong evidence for the advancements afforded by\nPTMs in recognizing nuanced emotions like Anger, Love, Fear, Joy, Sadness, and\nSurprise in software engineering contexts. Through comprehensive benchmarking\nand error analysis, we also outline scope for improvements to address\ncontextual gaps.", "field": "Computer Science", "categories": "cs.SE"}, {"arxiv_id": "2401.10846", "title": "Distributed Genetic Algorithm for Feature Selection", "abstract": "We empirically show that process-based Parallelism speeds up the Genetic\nAlgorithm (GA) for Feature Selection (FS) 2x to 25x, while additionally\nincreasing the Machine Learning (ML) model performance on metrics such as\nF1-score, Accuracy, and Receiver Operating Characteristic Area Under the Curve\n(ROC-AUC).", "field": "Computer Science", "categories": "cs.DC"}, {"arxiv_id": "2401.10848", "title": "Source-Free and Image-Only Unsupervised Domain Adaptation for Category\n  Level Object Pose Estimation", "abstract": "We consider the problem of source-free unsupervised category-level pose\nestimation from only RGB images to a target domain without any access to source\ndomain data or 3D annotations during adaptation. Collecting and annotating\nreal-world 3D data and corresponding images is laborious, expensive, yet\nunavoidable process, since even 3D pose domain adaptation methods require 3D\ndata in the target domain. We introduce 3DUDA, a method capable of adapting to\na nuisance-ridden target domain without 3D or depth data. Our key insight stems\nfrom the observation that specific object subparts remain stable across\nout-of-domain (OOD) scenarios, enabling strategic utilization of these\ninvariant subcomponents for effective model updates. We represent object\ncategories as simple cuboid meshes, and harness a generative model of neural\nfeature activations modeled at each mesh vertex learnt using differential\nrendering. We focus on individual locally robust mesh vertex features and\niteratively update them based on their proximity to corresponding features in\nthe target domain even when the global pose is not correct. Our model is then\ntrained in an EM fashion, alternating between updating the vertex features and\nthe feature extractor. We show that our method simulates fine-tuning on a\nglobal pseudo-labeled dataset under mild assumptions, which converges to the\ntarget domain asymptotically. Through extensive empirical validation, including\na complex extreme UDA setup which combines real nuisances, synthetic noise, and\nocclusion, we demonstrate the potency of our simple approach in addressing the\ndomain shift challenge and significantly improving pose estimation accuracy.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.10849", "title": "Exploring the role of structure in a time constrained decision task", "abstract": "The structure of the basal ganglia is remarkably similar across a number of\nspecies (often described in terms of direct, indirect and hyperdirect pathways)\nand is deeply involved in decision making and action selection. In this\narticle, we are interested in exploring the role of structure when solving a\ndecision task while avoiding to make any strong assumption regarding the actual\nstructure. To do so, we exploit the echo state network paradigm that allows to\nsolve complex task based on a random architecture. Considering a temporal\ndecision task, the question is whether a specific structure allows for better\nperformance and if so, whether this structure shares some similarity with the\nbasal ganglia. Our results highlight the advantage of having a slow (direct)\nand a fast (hyperdirect) pathway that allows to deal with late information\nduring a decision making task.", "field": "Computer Science", "categories": "cs.NE,q-bio.NC"}, {"arxiv_id": "2401.1085", "title": "Advancements in eHealth Data Analytics through Natural Language\n  Processing and Deep Learning", "abstract": "The healthcare environment is commonly referred to as \"information-rich\" but\nalso \"knowledge poor\". Healthcare systems collect huge amounts of data from\nvarious sources: lab reports, medical letters, logs of medical tools or\nprograms, medical prescriptions, etc. These massive sets of data can provide\ngreat knowledge and information that can improve the medical services, and\noverall the healthcare domain, such as disease prediction by analyzing the\npatient's symptoms or disease prevention, by facilitating the discovery of\nbehavioral factors for diseases. Unfortunately, only a relatively small volume\nof the textual eHealth data is processed and interpreted, an important factor\nbeing the difficulty in efficiently performing Big Data operations. In the\nmedical field, detecting domain-specific multi-word terms is a crucial task as\nthey can define an entire concept with a few words. A term can be defined as a\nlinguistic structure or a concept, and it is composed of one or more words with\na specific meaning to a domain. All the terms of a domain create its\nterminology. This chapter offers a critical study of the current, most\nperformant solutions for analyzing unstructured (image and textual) eHealth\ndata. This study also provides a comparison of the current Natural Language\nProcessing and Deep Learning techniques in the eHealth context. Finally, we\nexamine and discuss some of the current issues, and we define a set of research\ndirections in this area.", "field": "Computer Science", "categories": "cs.CL,cs.AI"}, {"arxiv_id": "2401.10852", "title": "Software Resource Disaggregation for HPC with Serverless Computing", "abstract": "Aggregated HPC resources have rigid allocation systems and programming models\nwhich struggle to adapt to diverse and changing workloads. Consequently, HPC\nsystems fail to efficiently use the large pools of unused memory and increase\nthe utilization of idle computing resources. Prior work attempted to increase\nthe throughput and efficiency of supercomputing systems through workload\nco-location and resource disaggregation. However, these methods fall short of\nproviding a solution that can be applied to existing systems without major\nhardware modifications and performance losses. In this paper, we improve the\nutilization of supercomputers by employing the new cloud paradigm of serverless\ncomputing. We show how serverless functions provide fine-grained access to the\nresources of batch-managed cluster nodes. We present an HPC-oriented\nFunction-as-a-Service (FaaS) that satisfies the requirements of\nhigh-performance applications. We demonstrate a \\emph{software resource\ndisaggregation} approach where placing functions on unallocated and\nunderutilized nodes allows idle cores and accelerators to be utilized while\nretaining near-native performance.", "field": "Computer Science", "categories": "cs.DC"}, {"arxiv_id": "2401.10856", "title": "Cactus Representation of Minimum Cuts: Derandomize and Speed up", "abstract": "Given an undirected weighted graph with $n$ vertices and $m$ edges, we give\nthe first deterministic $m^{1+o(1)}$-time algorithm for constructing the cactus\nrepresentation of \\emph{all} global minimum cuts. This improves the current\n$n^{2+o(1)}$-time state-of-the-art deterministic algorithm, which can be\nobtained by combining ideas implicitly from three papers [Karger JACM'2000, Li\nSTOC'2021, and Gabow TALG'2016] The known explicitly stated deterministic\nalgorithm has a runtime of $\\tilde{O}(mn)$ [Fleischer 1999, Nagamochi and Nakao\n2000]. Using our technique, we can even speed up the fastest randomized\nalgorithm of [Karger and Panigrahi, SODA'2009] whose running time is at least\n$\\Omega(m\\log^4 n)$ to $O(m\\log^3 n)$.", "field": "Computer Science", "categories": "cs.DS"}, {"arxiv_id": "2401.10857", "title": "Motion Consistency Loss for Monocular Visual Odometry with\n  Attention-Based Deep Learning", "abstract": "Deep learning algorithms have driven expressive progress in many complex\ntasks. The loss function is a core component of deep learning techniques,\nguiding the learning process of neural networks. This paper contributes by\nintroducing a consistency loss for visual odometry with deep learning-based\napproaches. The motion consistency loss explores repeated motions that appear\nin consecutive overlapped video clips. Experimental results show that our\napproach increased the performance of a model on the KITTI odometry benchmark.", "field": "Computer Science", "categories": "cs.CV,cs.RO,68T45 68T07"}, {"arxiv_id": "2401.10859", "title": "Ensembler: Combating model inversion attacks using model ensemble during\n  collaborative inference", "abstract": "Deep learning models have exhibited remarkable performance across various\ndomains. Nevertheless, the burgeoning model sizes compel edge devices to\noffload a significant portion of the inference process to the cloud. While this\npractice offers numerous advantages, it also raises critical concerns regarding\nuser data privacy. In scenarios where the cloud server's trustworthiness is in\nquestion, the need for a practical and adaptable method to safeguard data\nprivacy becomes imperative. In this paper, we introduce Ensembler, an\nextensible framework designed to substantially increase the difficulty of\nconducting model inversion attacks for adversarial parties. Ensembler leverages\nmodel ensembling on the adversarial server, running in parallel with existing\napproaches that introduce perturbations to sensitive data during colloborative\ninference. Our experiments demonstrate that when combined with even basic\nGaussian noise, Ensembler can effectively shield images from reconstruction\nattacks, achieving recognition levels that fall below human performance in some\nstrict settings, significantly outperforming baseline methods lacking the\nEnsembler framework.", "field": "Computer Science", "categories": "cs.CR,cs.LG"}, {"arxiv_id": "2401.10862", "title": "Pruning for Protection: Increasing Jailbreak Resistance in Aligned LLMs\n  Without Fine-Tuning", "abstract": "Large Language Models (LLMs) are vulnerable to `Jailbreaking' prompts, a type\nof attack that can coax these models into generating harmful and illegal\ncontent. In this paper, we show that pruning up to 20% of LLM parameters\nmarkedly increases their resistance to such attacks without additional training\nand without sacrificing their performance in standard benchmarks. Intriguingly,\nwe discovered that the enhanced safety observed post-pruning correlates to the\ninitial safety training level of the model, hinting that the effect of pruning\ncould be more general and may hold for other LLM behaviors beyond safety.\nAdditionally, we introduce a curated dataset of 225 harmful tasks across five\ncategories, inserted into ten different Jailbreaking prompts, showing that\npruning aids LLMs in concentrating attention on task-relevant tokens in\njailbreaking prompts. Lastly, our experiments reveal that the prominent chat\nmodels, such as LLaMA-2 Chat, Vicuna, and Mistral Instruct exhibit high\nsusceptibility to jailbreaking attacks, with some categories achieving nearly\n70-100% success rate. These insights underline the potential of pruning as a\ngeneralizable approach for improving LLM safety, reliability, and potentially\nother desired behaviors.", "field": "Computer Science", "categories": "cs.LG,cs.AI,cs.CL,cs.CR"}, {"arxiv_id": "2401.10873", "title": "An AI-Resilient Text Rendering Technique for Reading and Skimming\n  Documents", "abstract": "Readers find text difficult to consume for many reasons. Summarization can\naddress some of these difficulties, but introduce others, such as omitting,\nmisrepresenting, or hallucinating information, which can be hard for a reader\nto notice. One approach to addressing this problem is to instead modify how the\noriginal text is rendered to make important information more salient. We\nintroduce Grammar-Preserving Text Saliency Modulation (GP-TSM), a text\nrendering method with a novel means of identifying what to de-emphasize.\nSpecifically, GP-TSM uses a recursive sentence compression method to identify\nsuccessive levels of detail beyond the core meaning of a passage, which are\nde-emphasized by rendering words in successively lighter but still legible gray\ntext. In a lab study (n=18), participants preferred GP-TSM over pre-existing\nword-level text rendering methods and were able to answer GRE reading\ncomprehension questions more efficiently.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.10877", "title": "The Cadaver in the Machine: The Social Practices of Measurement and\n  Validation in Motion Capture Technology", "abstract": "Motion capture systems, used across various domains, make body\nrepresentations concrete through technical processes. We argue that the\nmeasurement of bodies and the validation of measurements for motion capture\nsystems can be understood as social practices. By analyzing the findings of a\nsystematic literature review (N=278) through the lens of social practice\ntheory, we show how these practices, and their varying attention to errors,\nbecome ingrained in motion capture design and innovation over time. Moreover,\nwe show how contemporary motion capture systems perpetuate assumptions about\nhuman bodies and their movements. We suggest that social practices of\nmeasurement and validation are ubiquitous in the development of data- and\nsensor-driven systems more broadly, and provide this work as a basis for\ninvestigating hidden design assumptions and their potential negative\nconsequences in human-computer interaction.", "field": "Computer Science", "categories": "cs.CY,cs.CV,cs.HC"}, {"arxiv_id": "2401.10879", "title": "Accuracy Analysis of Physics-Informed Neural Networks for Approximating\n  the Critical SQG Equation", "abstract": "We systematically analyze the accuracy of Physics-Informed Neural Networks\n(PINNs) in approximating solutions to the critical Surface Quasi-Geostrophic\n(SQG) equation on two-dimensional periodic boxes. The critical SQG equation\ninvolves advection and diffusion described by nonlocal periodic operators,\nposing challenges for neural network-based methods that do not commonly exhibit\nperiodic boundary conditions. In this paper, we present a novel approximation\nof these operators using their nonperiodic analogs based on singular integral\nrepresentation formulas and use it to perform error estimates. This idea can be\ngeneralized to a larger class of nonlocal partial differential equations whose\nsolutions satisfy prescribed boundary conditions, thereby initiating a new\nPINNs theory for equations with nonlocalities.", "field": "Computer Science", "categories": "math.NA,cs.NA,math.AP"}, {"arxiv_id": "2401.1088", "title": "DynaVis: Dynamically Synthesized UI Widgets for Visualization Editing", "abstract": "Users often rely on GUIs to edit and interact with visualizations - a\ndaunting task due to the large space of editing options. As a result, users are\neither overwhelmed by a complex UI or constrained by a custom UI with a\ntailored, fixed subset of options with limited editing flexibility. Natural\nLanguage Interfaces (NLIs) are emerging as a feasible alternative for users to\nspecify edits. However, NLIs forgo the advantages of traditional GUI: the\nability to explore and repeat edits and see instant visual feedback.\n  We introduce DynaVis, which blends natural language and dynamically\nsynthesized UI widgets. As the user describes an editing task in natural\nlanguage, DynaVis performs the edit and synthesizes a persistent widget that\nthe user can interact with to make further modifications. Study participants\n(n=24) preferred DynaVis over the NLI-only interface citing ease of further\nedits and editing confidence due to immediate visual feedback.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.10882", "title": "Reinforcement learning for question answering in programming domain\n  using public community scoring as a human feedback", "abstract": "In this study, we investigate the enhancement of the GPT Neo 125M performance\nin Community Question Answering (CQA) with a focus on programming, through the\nintegration of Reinforcement Learning from Human Feedback (RLHF) and the\nutilization of scores from Stack Overflow. Two distinct reward model training\nstrategies are employed for fine-tuning with Proximal Policy Optimization\n(PPO). Notably, the improvements in performance achieved through this method\nare comparable to those of GPT Neo 2.7B parameter variant. Additionally, an\nauxiliary scoring mechanism is introduced, which demonstrates the limitations\nof conventional linguistic metrics in evaluating responses in the programming\ndomain. Through accurate analysis, this paper looks at the divergence between\ntraditional linguistic metrics and our human-preferences-based reward model,\nunderscoring the imperative for domain-specific evaluation methods. By\nelucidating the complexities involved in applying RLHF to programming CQA and\naccentuating the significance of context-aware evaluation, this study\ncontributes to the ongoing efforts in refining Large Language Models through\nfocused human feedback.", "field": "Computer Science", "categories": "cs.CL,cs.AI,cs.HC"}, {"arxiv_id": "2401.10883", "title": "RetinaVR: Democratizing Vitreoretinal Surgery Training with a Portable\n  and Affordable Virtual Reality Simulator in the Metaverse", "abstract": "We developed and validated RetinaVR, an affordable and immersive virtual\nreality simulator for vitreoretinal surgery training, using the Meta Quest 2 VR\nheadset. We focused on four core fundamental skills: core vitrectomy,\nperipheral shaving, membrane peeling, and endolaser application. The validation\nstudy involved 10 novice ophthalmology residents and 10 expert vitreoretinal\nsurgeons. We demonstrated construct validity, as shown by the varying user\nperformance in a way that correlates with experimental runs, age, sex, and\nexpertise. RetinaVR shows promise as a portable and affordable simulator, with\npotential to democratize surgical simulation access, especially in developing\ncountries.", "field": "Computer Science", "categories": "cs.HC"}, {"arxiv_id": "2401.10886", "title": "SCENES: Subpixel Correspondence Estimation With Epipolar Supervision", "abstract": "Extracting point correspondences from two or more views of a scene is a\nfundamental computer vision problem with particular importance for relative\ncamera pose estimation and structure-from-motion. Existing local feature\nmatching approaches, trained with correspondence supervision on large-scale\ndatasets, obtain highly-accurate matches on the test sets. However, they do not\ngeneralise well to new datasets with different characteristics to those they\nwere trained on, unlike classic feature extractors. Instead, they require\nfinetuning, which assumes that ground-truth correspondences or ground-truth\ncamera poses and 3D structure are available. We relax this assumption by\nremoving the requirement of 3D structure, e.g., depth maps or point clouds, and\nonly require camera pose information, which can be obtained from odometry. We\ndo so by replacing correspondence losses with epipolar losses, which encourage\nputative matches to lie on the associated epipolar line. While weaker than\ncorrespondence supervision, we observe that this cue is sufficient for\nfinetuning existing models on new data. We then further relax the assumption of\nknown camera poses by using pose estimates in a novel bootstrapping approach.\nWe evaluate on highly challenging datasets, including an indoor drone dataset\nand an outdoor smartphone camera dataset, and obtain state-of-the-art results\nwithout strong supervision.", "field": "Computer Science", "categories": "cs.CV,cs.AI,cs.LG,cs.RO"}, {"arxiv_id": "2401.10889", "title": "Synthesizing Moving People with 3D Control", "abstract": "In this paper, we present a diffusion model-based framework for animating\npeople from a single image for a given target 3D motion sequence. Our approach\nhas two core components: a) learning priors about invisible parts of the human\nbody and clothing, and b) rendering novel body poses with proper clothing and\ntexture. For the first part, we learn an in-filling diffusion model to\nhallucinate unseen parts of a person given a single image. We train this model\non texture map space, which makes it more sample-efficient since it is\ninvariant to pose and viewpoint. Second, we develop a diffusion-based rendering\npipeline, which is controlled by 3D human poses. This produces realistic\nrenderings of novel poses of the person, including clothing, hair, and\nplausible in-filling of unseen regions. This disentangled approach allows our\nmethod to generate a sequence of images that are faithful to the target motion\nin the 3D pose and, to the input image in terms of visual similarity. In\naddition to that, the 3D control allows various synthetic camera trajectories\nto render a person. Our experiments show that our method is resilient in\ngenerating prolonged motions and varied challenging and complex poses compared\nto prior methods. Please check our website for more details:\nhttps://boyiliee.github.io/3DHM.github.io/.", "field": "Computer Science", "categories": "cs.CV,cs.AI"}, {"arxiv_id": "2401.1089", "title": "Event detection from novel data sources: Leveraging satellite imagery\n  alongside GPS traces", "abstract": "Rapid identification and response to breaking events, particularly those that\npose a threat to human life such as natural disasters or conflicts, is of\nparamount importance. The prevalence of mobile devices and the ubiquity of\nnetwork connectivity has generated a massive amount of temporally- and\nspatially-stamped data. Numerous studies have used mobile data to derive\nindividual human mobility patterns for various applications. Similarly, the\nincreasing number of orbital satellites has made it easier to gather\nhigh-resolution images capturing a snapshot of a geographical area in sub-daily\ntemporal frequency. We propose a novel data fusion methodology integrating\nsatellite imagery with privacy-enhanced mobile data to augment the event\ninference task, whether in real-time or historical. In the absence of boots on\nthe ground, mobile data is able to give an approximation of human mobility,\nproximity to one another, and the built environment. On the other hand,\nsatellite imagery can provide visual information on physical changes to the\nbuilt and natural environment. The expected use cases for our methodology\ninclude small-scale disaster detection (i.e., tornadoes, wildfires, and floods)\nin rural regions, search and rescue operation augmentation for lost hikers in\nremote wilderness areas, and identification of active conflict areas and\npopulation displacement in war-torn states. Our implementation is open-source\non GitHub: https://github.com/ekinugurel/SatMobFusion.", "field": "Computer Science", "categories": "cs.CV,cs.SI"}, {"arxiv_id": "2401.10891", "title": "Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data", "abstract": "This work presents Depth Anything, a highly practical solution for robust\nmonocular depth estimation. Without pursuing novel technical modules, we aim to\nbuild a simple yet powerful foundation model dealing with any images under any\ncircumstances. To this end, we scale up the dataset by designing a data engine\nto collect and automatically annotate large-scale unlabeled data (~62M), which\nsignificantly enlarges the data coverage and thus is able to reduce the\ngeneralization error. We investigate two simple yet effective strategies that\nmake data scaling-up promising. First, a more challenging optimization target\nis created by leveraging data augmentation tools. It compels the model to\nactively seek extra visual knowledge and acquire robust representations.\nSecond, an auxiliary supervision is developed to enforce the model to inherit\nrich semantic priors from pre-trained encoders. We evaluate its zero-shot\ncapabilities extensively, including six public datasets and randomly captured\nphotos. It demonstrates impressive generalization ability. Further, through\nfine-tuning it with metric depth information from NYUv2 and KITTI, new SOTAs\nare set. Our better depth model also results in a better depth-conditioned\nControlNet. Our models are released at\nhttps://github.com/LiheYoung/Depth-Anything.", "field": "Computer Science", "categories": "cs.CV"}]}