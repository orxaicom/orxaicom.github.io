{"embeddings": [[14.86583423614502, 2.366785764694214], [14.052008628845215, 2.242765188217163], [13.355895042419434, 3.1897175312042236], [13.047988891601562, 1.9916603565216064], [14.38145923614502, 3.781099796295166], [13.422348976135254, 2.5898895263671875], [13.812568664550781, 3.6632933616638184], [12.647069931030273, 3.241154670715332], [14.577495574951172, 3.2744052410125732], [14.78541374206543, 1.7489147186279297], [13.064949989318848, 4.080866813659668], [13.75173282623291, 1.5577605962753296], [12.5067720413208, 2.705883741378784], [13.890710830688477, 4.346288681030273]], "keys": ["2401.13007", "2401.1301", "2401.13045", "2401.13065", "2401.1309", "2401.13094", "2401.13208", "2401.13335", "2401.13379", "2401.13532", "2401.13572", "2401.13615", "2401.13624", "2401.13665"], "additional_info": [{"arxiv_id": "2401.13007", "title": "Ordinal pattern dependence and multivariate measures of dependence", "abstract": "Ordinal pattern dependence has been introduced in order to capture\nco-monotonic behavior between two time series. This concept has several\nfeatures one would intuitively demand from a dependence measure. It was\nbelieved that ordinal pattern dependence satisfies the axioms which Grothe et\nal. [8] proclaimed for a multivariate measure of dependence. In the present\narticle we show that this is not true and that there is a mistake in the\narticle Betken et al. [5]. Furthermore we show that ordinal pattern dependence\nsatisfies a slightly modified set of axioms.", "field": "Statistics", "categories": "math.ST,math.PR,stat.TH,62M10 (Primary), 62H12 (Secondary)"}, {"arxiv_id": "2401.1301", "title": "Bartholomew's trend test -- approximated by a multiple contrast test", "abstract": "Bartholomew's trend test belongs to the broad class of isotonic regression\nmodels, specifically with a single qualitative factor, e.g. dose levels. Using\nthe approximation of the ANOVA F-test by the maximum contrast test against\ngrand mean and pool-adjacent-violator estimates under order restriction, an\neasier to use approximation is proposed.", "field": "Statistics", "categories": "stat.ME"}, {"arxiv_id": "2401.13045", "title": "Assessment of Sports Concussion in Female Athletes: A Role for\n  Neuroinformatics?", "abstract": "Over the past decade, the intricacies of sports-related concussions among\nfemale athletes have become readily apparent. Traditional clinical methods for\ndiagnosing concussions suffer limitations when applied to female athletes,\noften failing to capture subtle changes in brain structure and function.\nAdvanced neuroinformatics techniques and machine learning models have become\ninvaluable assets in this endeavor. While these technologies have been\nextensively employed in understanding concussion in male athletes, there\nremains a significant gap in our comprehension of their effectiveness for\nfemale athletes. With its remarkable data analysis capacity, machine learning\noffers a promising avenue to bridge this deficit. By harnessing the power of\nmachine learning, researchers can link observed phenotypic neuroimaging data to\nsex-specific biological mechanisms, unraveling the mysteries of concussions in\nfemale athletes. Furthermore, embedding methods within machine learning enable\nexamining brain architecture and its alterations beyond the conventional\nanatomical reference frame. In turn, allows researchers to gain deeper insights\ninto the dynamics of concussions, treatment responses, and recovery processes.\nTo guarantee that female athletes receive the optimal care they deserve,\nresearchers must employ advanced neuroimaging techniques and sophisticated\nmachine-learning models. These tools enable an in-depth investigation of the\nunderlying mechanisms responsible for concussion symptoms stemming from\nneuronal dysfunction in female athletes. This paper endeavors to address the\ncrucial issue of sex differences in multimodal neuroimaging experimental design\nand machine learning approaches within female athlete populations, ultimately\nensuring that they receive the tailored care they require when facing the\nchallenges of concussions.", "field": "Statistics", "categories": "stat.ML,cs.LG,stat.AP,stat.ME"}, {"arxiv_id": "2401.13065", "title": "Extropy and Varextropy estimators with applications", "abstract": "In many statistical studies, the measure of uncertainties like entropy,\nextropy, varentropy and varextropy of a distribution function is of prime\ninterest. This paper proposes estimators of extropy and varextropy. Proposed\nestimators are consistent. Based on extropy estimator, a test of symmetry is\ngiven. The proposed test has the advantage that we do not need to estimate the\ncentre of symmetry. The critical value and power of the proposed test\nstatistics have been obtained. The test procedure has been implemented on six\nreal-life data sets to verify its performance in identifying the symmetric\nnature.", "field": "Statistics", "categories": "math.ST,stat.TH"}, {"arxiv_id": "2401.1309", "title": "Variational Estimation for Multidimensional Generalized Partial Credit\n  Model", "abstract": "Multidimensional item response theory (MIRT) models have generated increasing\ninterest in the psychometrics literature. Efficient approaches for estimating\nMIRT models with dichotomous responses have been developed, but constructing an\nequally efficient and robust algorithm for polytomous models has received\nlimited attention. To address this gap, this paper presents a novel Gaussian\nvariational estimation algorithm for the multidimensional generalized partial\ncredit model (MGPCM). The proposed algorithm demonstrates both fast and\naccurate performance, as illustrated through a series of simulation studies and\ntwo real data analyses.", "field": "Statistics", "categories": "stat.ME"}, {"arxiv_id": "2401.13094", "title": "On cross-validated estimation of skew normal model", "abstract": "Skew normal model suffers from inferential drawbacks, namely singular Fisher\ninformation in the vicinity of symmetry and diverging of maximum likelihood\nestimation. To address the above drawbacks, Azzalini and Arellano-Valle (2013)\nintroduced maximum penalised likelihood estimation (MPLE) by subtracting a\npenalty function from the log-likelihood function with a pre-specified penalty\ncoefficient. Here, we propose a cross-validated MPLE to improve its performance\nwhen the underlying model is close to symmetry. We develop a theory for MPLE,\nwhere an asymptotic rate for the cross-validated penalty coefficient is\nderived. We further show that the proposed cross-validated MPLE is\nasymptotically efficient under certain conditions. In simulation studies and a\nreal data application, we demonstrate that the proposed estimator can\noutperform the conventional MPLE when the model is close to symmetry.", "field": "Statistics", "categories": "stat.ME"}, {"arxiv_id": "2401.13208", "title": "Assessing Influential Observations in Pain Prediction using fMRI Data", "abstract": "Influential diagnosis is an integral part of data analysis, of which most\nexisting methodological frameworks presume a deterministic submodel and are\ndesigned for low-dimensional data (i.e., the number of predictors p smaller\nthan the sample size n). However, the stochastic selection of a submodel from\nhigh-dimensional data where p exceeds n has become ubiquitous. Thus, methods\nfor identifying observations that could exert undue influence on the choice of\na submodel can play an important role in this setting. To date, discussion of\nthis topic has been limited, falling short in two domains: (i) constrained\nability to detect multiple influential points, and (ii) applicability only in\nrestrictive settings. After describing the problem, we characterize and\nformalize the concept of influential observations on variable selection. Then,\nwe propose a generalized diagnostic measure, extended from an available metric\naccommodating different model selectors and multiple influential observations,\nthe asymptotic distribution of which is subsequently establish large p, thus\nproviding guidelines to ascertain influential observations. A high-dimensional\nclustering procedure is further incorporated into our proposed scheme to detect\nmultiple influential points. Simulation is conducted to assess the performances\nof various diagnostic approaches. The proposed procedure further demonstrates\nits value in improving predictive power when analyzing thermal-stimulated pain\nbased on fMRI data.", "field": "Statistics", "categories": "stat.ME"}, {"arxiv_id": "2401.13335", "title": "Full Bayesian Significance Testing for Neural Networks", "abstract": "Significance testing aims to determine whether a proposition about the\npopulation distribution is the truth or not given observations. However,\ntraditional significance testing often needs to derive the distribution of the\ntesting statistic, failing to deal with complex nonlinear relationships. In\nthis paper, we propose to conduct Full Bayesian Significance Testing for neural\nnetworks, called \\textit{n}FBST, to overcome the limitation in relationship\ncharacterization of traditional approaches. A Bayesian neural network is\nutilized to fit the nonlinear and multi-dimensional relationships with small\nerrors and avoid hard theoretical derivation by computing the evidence value.\nBesides, \\textit{n}FBST can test not only global significance but also local\nand instance-wise significance, which previous testing methods don't focus on.\nMoreover, \\textit{n}FBST is a general framework that can be extended based on\nthe measures selected, such as Grad-\\textit{n}FBST, LRP-\\textit{n}FBST,\nDeepLIFT-\\textit{n}FBST, LIME-\\textit{n}FBST. A range of experiments on both\nsimulated and real data are conducted to show the advantages of our method.", "field": "Statistics", "categories": "stat.ML,cs.AI,cs.LG"}, {"arxiv_id": "2401.13379", "title": "An Ising Similarity Regression Model for Modeling Multivariate Binary\n  Data", "abstract": "Understanding the dependence structure between response variables is an\nimportant component in the analysis of correlated multivariate data. This\narticle focuses on modeling dependence structures in multivariate binary data,\nmotivated by a study aiming to understand how patterns in different U.S.\nsenators' votes are determined by similarities (or lack thereof) in their\nattributes, e.g., political parties and social network profiles. To address\nsuch a research question, we propose a new Ising similarity regression model\nwhich regresses pairwise interaction coefficients in the Ising model against a\nset of similarity measures available/constructed from covariates. Model\nselection approaches are further developed through regularizing the\npseudo-likelihood function with an adaptive lasso penalty to enable the\nselection of relevant similarity measures. We establish estimation and\nselection consistency of the proposed estimator under a general setting where\nthe number of similarity measures and responses tend to infinity. Simulation\nstudy demonstrates the strong finite sample performance of the proposed\nestimator in terms of parameter estimation and similarity selection. Applying\nthe Ising similarity regression model to a dataset of roll call voting records\nof 100 U.S. senators, we are able to quantify how similarities in senators'\nparties, businessman occupations and social network profiles drive their voting\nassociations.", "field": "Statistics", "categories": "stat.ME,math.ST,stat.AP,stat.TH"}, {"arxiv_id": "2401.13532", "title": "Depth Patterns", "abstract": "We establish a definition of ordinal patterns for multivariate time series\ndata based on the concept of Tukey's halfspace depth. Given the definition of\nthese \\emph{depth patterns}, we are interested in the probabilities of\nobserving specific patterns in a time series. For this, we consider the\nrelative frequency of depth patterns as natural estimators for their occurrence\nprobabilities. Depending on the choice of reference distribution and the\nrelation between reference and data distribution, we distinguish different\nsettings that are considered separately. Within these settings we study\nstatistical properties of ordinal pattern probabilities, establishing\nconsistency and asymptotic normality under the assumption of weakly dependent\ntime series data. Since our concept only depends on ordinal depth information,\nthe resulting values are robust under small perturbations and measurement\nerrors.", "field": "Statistics", "categories": "math.ST,math.PR,stat.TH,62M10, 62H10, 62H12, 60F05"}, {"arxiv_id": "2401.13572", "title": "Rare event probability estimation for groundwater inverse problems with\n  a two-stage Sequential Monte Carlo approach", "abstract": "Bayesian inversions followed by estimations of rare event probabilities are\noften needed to analyse groundwater hazards. Instead of focusing on the\nposterior distribution of model parameters, the main interest lies then in the\ndistribution of a specific quantity of interest contingent upon these\nparameters. To address the associated methodological challenges, we introduce a\ntwo-stage Sequential Monte Carlo approach. In the first stage, it generates\nparticles that approximate the posterior distribution; in the second stage, it\nemploys subset sampling techniques to assess the probability of the rare event\nof interest. By considering two hydrogeological problems of increasing\ncomplexity, we showcase the efficiency and accuracy of the resulting\nPostRisk-SMC method for rare event probability estimation related to\ngroundwater hazards. We compare the performance of the PostRisk-SMC method with\na traditional Monte Carlo approach that relies on Markov chain Monte Carlo\nsamples. We showcase that our estimates align with those of the traditional\nmethod, but the coefficients of variation are notably lower for the same\ncomputational budget when targeting more rare events. Furthermore, we highlight\nthat the PostRisk-SMC method allows estimating rare event probabilities\napproaching one in a billion using less than one hundred thousand forward\nsimulations. Even if the presented examples are related to groundwater hazards,\nthe methodology is well-suited for addressing a wide range of topics in the\ngeosciences and beyond.", "field": "Statistics", "categories": "stat.AP"}, {"arxiv_id": "2401.13615", "title": "The assessment of replicability using the sum of p-values", "abstract": "Statistical significance of both the original and the replication study is a\ncommonly used criterion to assess replication attempts, also known as the\ntwo-trials rule in drug development. However, replication studies are sometimes\nconducted although the original study is non-significant, in which case Type-I\nerror rate control across both studies is no longer guaranteed. We propose an\nalternative method to assess replicability using the sum of p-values from the\ntwo studies. The approach provides a combined p-value and can be calibrated to\ncontrol the overall Type-I error rate at the same level as the two-trials rule\nbut allows for replication success even if the original study is\nnon-significant. The unweighted version requires a less restrictive level of\nsignificance at replication if the original study is already convincing which\nfacilitates sample size reductions of up to 10%. Downweighting the original\nstudy accounts for possible bias and requires a more stringent significance\nlevel and larger samples sizes at replication. Data from four large-scale\nreplication projects are used to illustrate and compare the proposed method\nwith the two-trials rule, meta-analysis and Fisher's combination method.", "field": "Statistics", "categories": "stat.AP"}, {"arxiv_id": "2401.13624", "title": "Can overfitted deep neural networks in adversarial training generalize?\n  -- An approximation viewpoint", "abstract": "Adversarial training is a widely used method to improve the robustness of\ndeep neural networks (DNNs) over adversarial perturbations. However, it is\nempirically observed that adversarial training on over-parameterized networks\noften suffers from the \\textit{robust overfitting}: it can achieve almost zero\nadversarial training error while the robust generalization performance is not\npromising. In this paper, we provide a theoretical understanding of the\nquestion of whether overfitted DNNs in adversarial training can generalize from\nan approximation viewpoint. Specifically, our main results are summarized into\nthree folds: i) For classification, we prove by construction the existence of\ninfinitely many adversarial training classifiers on over-parameterized DNNs\nthat obtain arbitrarily small adversarial training error (overfitting), whereas\nachieving good robust generalization error under certain conditions concerning\nthe data quality, well separated, and perturbation level. ii) Linear\nover-parameterization (meaning that the number of parameters is only slightly\nlarger than the sample size) is enough to ensure such existence if the target\nfunction is smooth enough. iii) For regression, our results demonstrate that\nthere also exist infinitely many overfitted DNNs with linear\nover-parameterization in adversarial training that can achieve almost optimal\nrates of convergence for the standard generalization error. Overall, our\nanalysis points out that robust overfitting can be avoided but the required\nmodel capacity will depend on the smoothness of the target function, while a\nrobust generalization gap is inevitable. We hope our analysis will give a\nbetter understanding of the mathematical foundations of robustness in DNNs from\nan approximation view.", "field": "Statistics", "categories": "stat.ML,cs.LG"}, {"arxiv_id": "2401.13665", "title": "Entrywise Inference for Causal Panel Data: A Simple and Instance-Optimal\n  Approach", "abstract": "In causal inference with panel data under staggered adoption, the goal is to\nestimate and derive confidence intervals for potential outcomes and treatment\neffects. We propose a computationally efficient procedure, involving only\nsimple matrix algebra and singular value decomposition. We derive\nnon-asymptotic bounds on the entrywise error, establishing its proximity to a\nsuitably scaled Gaussian variable. Despite its simplicity, our procedure turns\nout to be instance-optimal, in that our theoretical scaling matches a local\ninstance-wise lower bound derived via a Bayesian Cram\\'{e}r-Rao argument. Using\nour insights, we develop a data-driven procedure for constructing entrywise\nconfidence intervals with pre-specified coverage guarantees. Our analysis is\nbased on a general inferential toolbox for the SVD algorithm applied to the\nmatrix denoising model, which might be of independent interest.", "field": "Statistics", "categories": "math.ST,econ.EM,stat.ME,stat.ML,stat.TH"}]}